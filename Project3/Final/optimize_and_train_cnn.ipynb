{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DHRUV JOSHI, AHMED KAMAL**\n",
    "\n",
    "Fall 2019\n",
    "\n",
    "CS343: Neural Networks\n",
    "\n",
    "Project 3: Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-colorblind', 'seaborn-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=7)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Global note: Make sure any debug printouts do not appear if `verbose=False`!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4) Implement weight optimizers for gradient descent\n",
    "\n",
    "To change the weights during training, we need an optimization algorithm to have our loss decrease over epochs as we learn the structure of the input patterns. Until now, we used **Stochastic gradient descent (SGD)**, which is the simplest algorithm. We will implement 3 popular algorithms:\n",
    "\n",
    "- `SGD` (stochastic gradient descent)\n",
    "- `SGD_Momentum` (stochastic gradient descent with momentum)\n",
    "- `Adam` (Adaptive Moment Estimation)\n",
    "\n",
    "Implement each of these according to the update equations (in `optimizer.py::update_weights` in each subclass). Let's use $w_t$ in the math below to represent the weights in a layer at time step $t$, $dw$ to represent the gradient of the weights in a layer, and $\\eta$ represent the learning rate. We use vectorized notation below (update applies to all weights element-wise). Then:\n",
    "\n",
    "**SGD**: \n",
    "\n",
    "$w_{t} = w_{t-1} - \\eta \\times dw$\n",
    "\n",
    "**SGD (momentum)**:\n",
    "\n",
    "$v_{t} = m \\times v_{t-1} - \\eta \\times dw$\n",
    "\n",
    "$w_{t} = w_{t-1} + v_t$\n",
    "\n",
    "where $v_t$ is called the `velocity` at time $t$. At the first time step (0), velocity should be set to all zeros and have the same shape as $w$. $m$ is a constant that determines how much of the gradient obtained on the previous time step should factor into the weight update for the current time step.\n",
    "\n",
    "\n",
    "**Adam**:\n",
    "\n",
    "$m_{t} = \\beta_1 \\times m_{t-1} + (1 - \\beta_1)\\times dw$\n",
    "\n",
    "$v_{t} = \\beta_2 \\times v_{t-1} + (1 - \\beta_2)\\times dw^2$\n",
    "\n",
    "$n = m_{t} / \\left (1-(\\beta_1^t) \\right )$\n",
    "\n",
    "$u = v_{t} / \\left (1-(\\beta_2^t) \\right )$\n",
    "\n",
    "$w_{t} = w_{t-1} - \\left ( \\eta \\times n \\right ) / \\left ( \\sqrt(u) + \\epsilon \\right ) $\n",
    "\n",
    "\n",
    "Like SGD (momentum), Adam records momentum terms $m$ and $v$. At time step 0, you should initialize them to zeros in an array equal in size to the weights. $n$ and $u$ are variables computed on each time step. The remaining quantities are constants. Note that $t$ keeps track of the integer time step, and needs to be incremented on each update. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Test SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD: Wts after 1 iter [-3.1764052 -2.0400157 -1.0978738 -0.2240893  0.8132442  2.0977278]\n",
      "SGD: Wts after 2 iter [-3.3528105 -2.0800314 -1.1957476 -0.4481786  0.6264884  2.1954556]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "wts = np.arange(-3, 3, dtype=np.float64)\n",
    "d_wts = np.random.randn(len(wts))\n",
    "\n",
    "optimizer = SGD()\n",
    "optimizer.prepare(wts, d_wts)\n",
    "\n",
    "new_wts_1 = optimizer.update_weights()\n",
    "new_wts_2 = optimizer.update_weights()\n",
    "\n",
    "print(f'SGD: Wts after 1 iter {new_wts_1}')\n",
    "print(f'SGD: Wts after 2 iter {new_wts_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output should be:\n",
    "\n",
    "    SGD: Wts after 1 iter [-3.1764052 -2.0400157 -1.0978738 -0.2240893  0.8132442  2.0977278]\n",
    "    SGD: Wts after 2 iter [-3.3528105 -2.0800314 -1.1957476 -0.4481786  0.6264884  2.1954556]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Test SGD_Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD M: Wts after 1 iter\n",
      "[[ 1.6879486  0.3879897  0.9343517  2.2075258]\n",
      " [ 1.7181501 -0.9567621  0.9187816 -0.0659476]\n",
      " [ 0.1520801  0.3452366  0.0576     1.52849  ]]\n",
      "SGD M: Wts after 2 iter\n",
      "[[ 1.5661825  0.3685217  0.8633335  2.1541379]\n",
      " [ 1.4790974 -0.9239367  0.8686908  0.0707077]\n",
      " [ 0.5605585  0.2406577 -0.0807098  1.6472364]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "wts = np.random.randn(3, 4)\n",
    "d_wts = np.random.randn(3, 4)\n",
    "\n",
    "optimizer = SGD_Momentum(lr=0.1, m=0.6)\n",
    "optimizer.prepare(wts, d_wts)\n",
    "\n",
    "new_wts_1 = optimizer.update_weights()\n",
    "new_wts_2 = optimizer.update_weights()\n",
    "\n",
    "print(f'SGD M: Wts after 1 iter\\n{new_wts_1}')\n",
    "print(f'SGD M: Wts after 2 iter\\n{new_wts_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output should be:\n",
    "\n",
    "    SGD M: Wts after 1 iter\n",
    "    [[ 1.6879486  0.3879897  0.9343517  2.2075258]\n",
    "     [ 1.7181501 -0.9567621  0.9187816 -0.0659476]\n",
    "     [ 0.1520801  0.3452366  0.0576     1.52849  ]]\n",
    "    SGD M: Wts after 2 iter\n",
    "    [[ 1.5661825  0.3685217  0.8633335  2.1541379]\n",
    "     [ 1.4790974 -0.9239367  0.8686908  0.0707077]\n",
    "     [ 0.5605585  0.2406577 -0.0807098  1.6472364]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Test Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam: Wts after 1 iter\n",
      "[[ 1.6640523  0.3001572  0.878738   2.1408932]\n",
      " [ 1.767558  -0.8772779  0.8500884 -0.0513572]\n",
      " [-0.0032189  0.3105985  0.0440436  1.5542735]]\n",
      "Adam: Wts after 2 iter\n",
      "[[ 1.5640523  0.2001572  0.778738   2.0408932]\n",
      " [ 1.667558  -0.7772779  0.7500884  0.0486428]\n",
      " [ 0.0967811  0.2105985 -0.0559564  1.6542735]]\n",
      "Adam: Wts after 3 iter\n",
      "[[ 1.4640523  0.1001572  0.678738   1.9408932]\n",
      " [ 1.567558  -0.6772779  0.6500884  0.1486428]\n",
      " [ 0.1967811  0.1105985 -0.1559564  1.7542735]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "wts = np.random.randn(3, 4)\n",
    "d_wts = np.random.randn(3, 4)\n",
    "\n",
    "optimizer = Adam(lr=0.1)\n",
    "optimizer.prepare(wts, d_wts)\n",
    "\n",
    "new_wts_1 = optimizer.update_weights()\n",
    "new_wts_2 = optimizer.update_weights()\n",
    "new_wts_3 = optimizer.update_weights()\n",
    "\n",
    "print(f'Adam: Wts after 1 iter\\n{new_wts_1}')\n",
    "print(f'Adam: Wts after 2 iter\\n{new_wts_2}')\n",
    "print(f'Adam: Wts after 3 iter\\n{new_wts_3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output should be:\n",
    "\n",
    "    Adam: Wts after 1 iter\n",
    "    [[ 1.6640523  0.3001572  0.878738   2.1408932]\n",
    "     [ 1.767558  -0.8772779  0.8500884 -0.0513572]\n",
    "     [-0.0032189  0.3105985  0.0440436  1.5542735]]\n",
    "    Adam: Wts after 2 iter\n",
    "    [[ 1.5640523  0.2001572  0.778738   2.0408932]\n",
    "     [ 1.667558  -0.7772779  0.7500884  0.0486428]\n",
    "     [ 0.0967811  0.2105985 -0.0559564  1.6542735]]\n",
    "    Adam: Wts after 3 iter\n",
    "    [[ 1.4640523  0.1001572  0.678738   1.9408932]\n",
    "     [ 1.567558  -0.6772779  0.6500884  0.1486428]\n",
    "     [ 0.1967811  0.1105985 -0.1559564  1.7542735]]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5) Write network training methods\n",
    "\n",
    "Implement methods in `network.py` to actually train the network, using all the building blocks that you have created. The methods to implement are:\n",
    "\n",
    "- `predict`\n",
    "- `fit`. Add an optional parameter `print_every=1` that controls the frequency (in iterations) with which to wait before printing out the loss and iteration number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6) Overfitting a convolutional neural network\n",
    "\n",
    "Usually we try to prevent overfitting, but we can use it as a valuable debugging tool to test out a complex backprop-style neural network. Assuming everything is working, it is almost always the case that we should be able to overfit a tiny dataset with a huge model with tons of parameters (i.e. your CNN). You will use this strategy to verify that your network is working.\n",
    "\n",
    "Let's use a small amount of real data from STL-10. If everything is working properly, the network should overfit and you should see a significant drop in the loss from its starting value of ~2.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a) Move your `preprocess_data.py` from the MLP project\n",
    "\n",
    "Make the one following change:\n",
    "\n",
    "- Re-arrange dimensions of `imgs` so that when it is returned, `shape=(Num imgs, RGB color chans, height, width)` (No longer flatten non-batch dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_stl10_dataset\n",
    "import preprocess_data\n",
    "from network import ConvNet4\n",
    "import optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b) Load in STL-10 at 16x16 resolution\n",
    "\n",
    "If you don't want to wait for STL-10 to download from the internet and resize, copy over your data and numpy folders from your MLP project.\n",
    "\n",
    "**Notes:**\n",
    "- You will need to download the new version of `load_stl10_dataset`.\n",
    "- The different train/test split here won't work if you hard coded the proportions in your `create_splits` implementation! *This isn't catastrophic, it just means that it will take longer to compute accuracy on the validation set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images are: (5000, 96, 96, 3)\n",
      "Labels are: (5000,)\n",
      "Resizing 5000 images to 16x16...Done!\n",
      "Saving Numpy arrays the images and labels to ./numpy...Done!\n",
      "imgs shape before transpose (5000, 16, 16, 3)\n",
      "imgs shape after transpose (5000, 3, 16, 16)\n",
      "Train data shape:  (4548, 3, 16, 16)\n",
      "Train labels shape:  (4548,)\n",
      "Test data shape:  (400, 3, 16, 16)\n",
      "Test labels shape:  (400,)\n",
      "Validation data shape:  (2, 3, 16, 16)\n",
      "Validation labels shape:  (2,)\n",
      "dev data shape:  (50, 3, 16, 16)\n",
      "dev labels shape:  (50,)\n"
     ]
    }
   ],
   "source": [
    "# Download the STL-10 dataset from the internet, convert it to Numpy ndarray, resize to 16x16\n",
    "# cache it locally on your computer for faster loading next time.\n",
    "load_stl10_dataset.purge_cached_dataset()\n",
    "stl_imgs, stl_labels = load_stl10_dataset.load(scale_fact=6)\n",
    "# preprocess\n",
    "stl_imgs, stl_labels = preprocess_data.preprocess_stl(stl_imgs, stl_labels)\n",
    "# create splits\n",
    "x_train, y_train, x_test, y_test, x_val, y_val, x_dev, y_dev = preprocess_data.create_splits(\n",
    "    stl_imgs, stl_labels, n_train_samps=4548, n_test_samps=400, n_valid_samps=2, n_dev_samps=50)\n",
    "\n",
    "print ('Train data shape: ', x_train.shape)\n",
    "print ('Train labels shape: ', y_train.shape)\n",
    "print ('Test data shape: ', x_test.shape)\n",
    "print ('Test labels shape: ', y_test.shape)\n",
    "print ('Validation data shape: ', x_val.shape)\n",
    "print ('Validation labels shape: ', y_val.shape)\n",
    "print ('dev data shape: ', x_dev.shape)\n",
    "print ('dev labels shape: ', y_dev.shape)\n",
    "\n",
    "classes = np.loadtxt(os.path.join('data', 'stl10_binary', 'class_names.txt'), dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6c) Train and overfit the network on a small STL-10 sample with each optimizer\n",
    "\n",
    "**Goal:** If your network works, you should see a drop in loss over epochs to 0.\n",
    "\n",
    "In 3 seperate cells below\n",
    "\n",
    "- Create 3 different `ConvNet4` networks.\n",
    "- Compile each with a different optimizer (each net uses a different optimizer).\n",
    "- Train each on the **dev** set and validate on the tiny validation set (we dont care about out-of-training-set performance here).\n",
    "\n",
    "You will be making plots demonstrating the overfitting for each optimizer below. **You should train the nets with the same number of epochs such that at least 2/3 of them clearly show loss convergence to a small value; one optimizer may not converge yet, and that's ok**. Cut off the simulations based on the 2/3 that do converge.\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "- Weight scales and learning rates of `1e-2` should work well.\n",
    "- Start by testing the Adam optimizer.\n",
    "- Remember that the input shape is (3, 16, 16). You need to specify this to the network constructor.\n",
    "- The hyperparameters are up to you, though I wouldn't recommend a batch size that is too small (close to 1), otherwise it may be tricky to see whether the loss is actually decreasing on average.\n",
    "- Decreasing `acc_freq` will make the `fit` function evaluate the training and validation accuracy more often. This is a computationally intensive process, so small values come with an increase in training time. On the other hand, checking the accuracy too infrequently means you won't know whether the network is trending toward overfitting the training data, which is what you're checking for.\n",
    "- Each training session takes ~30 mins on my laptop.\n",
    "\n",
    "**Caveat emptor:** Training convolutional networks is notoriously computationally intensive. If you experiment with hyperparameters, each training session may take several hours. Use the loss/accuracy print outs to quickly gauge whether your hyperparameter choices are getting your network to decrease in loss. Monitor print outs and interrupt the Jupyter kernel if things are not trending in the right direction. Consider using the Davis 102 iMacs if this is running too slow on your laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train...\n",
      "875 iterations. 5 iter/epoch.\n",
      "iteration: 0 | loss: 2.305625\n",
      "iteration: 1 | loss: 2.384778\n",
      "iteration: 2 | loss: 2.350124\n",
      "iteration: 3 | loss: 2.228444\n",
      "iteration: 4 | loss: 1.930200\n",
      "iteration: 5 | loss: 2.400039\n",
      "iteration: 6 | loss: 2.425473\n",
      "iteration: 7 | loss: 2.557827\n",
      "iteration: 8 | loss: 1.914247\n",
      "iteration: 9 | loss: 1.976410\n",
      "iteration: 10 | loss: 1.962039\n",
      "iteration: 11 | loss: 1.983968\n",
      "iteration: 12 | loss: 1.940868\n",
      "iteration: 13 | loss: 2.776922\n",
      "iteration: 14 | loss: 1.361508\n",
      "iteration: 15 | loss: 1.430377\n",
      "iteration: 16 | loss: 1.737449\n",
      "iteration: 17 | loss: 1.189857\n",
      "iteration: 18 | loss: 1.828708\n",
      "iteration: 19 | loss: 1.947134\n",
      "iteration: 20 | loss: 1.269693\n",
      "iteration: 21 | loss: 1.482443\n",
      "iteration: 22 | loss: 1.157401\n",
      "iteration: 23 | loss: 1.467909\n",
      "iteration: 24 | loss: 1.478534\n",
      "  Train acc: 0.48, Val acc: 0.0\n",
      "iteration: 25 | loss: 1.875702\n",
      "iteration: 26 | loss: 1.400402\n",
      "iteration: 27 | loss: 1.119682\n",
      "iteration: 28 | loss: 1.669084\n",
      "iteration: 29 | loss: 1.383288\n",
      "iteration: 30 | loss: 1.310615\n",
      "iteration: 31 | loss: 1.612073\n",
      "iteration: 32 | loss: 0.920241\n",
      "iteration: 33 | loss: 1.692236\n",
      "iteration: 34 | loss: 1.785469\n",
      "iteration: 35 | loss: 2.049490\n",
      "iteration: 36 | loss: 1.845950\n",
      "iteration: 37 | loss: 2.436572\n",
      "iteration: 38 | loss: 1.903262\n",
      "iteration: 39 | loss: 2.945025\n",
      "iteration: 40 | loss: 3.900921\n",
      "iteration: 41 | loss: 4.954878\n",
      "iteration: 42 | loss: 2.819069\n",
      "iteration: 43 | loss: 3.570610\n",
      "iteration: 44 | loss: 1.695342\n",
      "iteration: 45 | loss: 3.921719\n",
      "iteration: 46 | loss: 2.785297\n",
      "iteration: 47 | loss: 1.469325\n",
      "iteration: 48 | loss: 2.328282\n",
      "iteration: 49 | loss: 2.059249\n",
      "  Train acc: 0.4, Val acc: 0.0\n",
      "iteration: 50 | loss: 0.765825\n",
      "iteration: 51 | loss: 2.127299\n",
      "iteration: 52 | loss: 3.426364\n",
      "iteration: 53 | loss: 1.314073\n",
      "iteration: 54 | loss: 1.678926\n",
      "iteration: 55 | loss: 1.631381\n",
      "iteration: 56 | loss: 1.156620\n",
      "iteration: 57 | loss: 1.521090\n",
      "iteration: 58 | loss: 1.635508\n",
      "iteration: 59 | loss: 1.595333\n",
      "iteration: 60 | loss: 1.868890\n",
      "iteration: 61 | loss: 1.004819\n",
      "iteration: 62 | loss: 1.246401\n",
      "iteration: 63 | loss: 0.718295\n",
      "iteration: 64 | loss: 1.494875\n",
      "iteration: 65 | loss: 2.139694\n",
      "iteration: 66 | loss: 1.525640\n",
      "iteration: 67 | loss: 1.768113\n",
      "iteration: 68 | loss: 1.585049\n",
      "iteration: 69 | loss: 1.187663\n",
      "iteration: 70 | loss: 1.045820\n",
      "iteration: 71 | loss: 1.052724\n",
      "iteration: 72 | loss: 1.224917\n",
      "iteration: 73 | loss: 1.949167\n",
      "iteration: 74 | loss: 0.965230\n",
      "  Train acc: 0.5, Val acc: 0.0\n",
      "iteration: 75 | loss: 0.871399\n",
      "iteration: 76 | loss: 1.554841\n",
      "iteration: 77 | loss: 1.538103\n",
      "iteration: 78 | loss: 1.343973\n",
      "iteration: 79 | loss: 1.714662\n",
      "iteration: 80 | loss: 1.140105\n",
      "iteration: 81 | loss: 2.313406\n",
      "iteration: 82 | loss: 1.028895\n",
      "iteration: 83 | loss: 1.327530\n",
      "iteration: 84 | loss: 1.110162\n",
      "iteration: 85 | loss: 1.200598\n",
      "iteration: 86 | loss: 0.928673\n",
      "iteration: 87 | loss: 0.807098\n",
      "iteration: 88 | loss: 1.365691\n",
      "iteration: 89 | loss: 0.682087\n",
      "iteration: 90 | loss: 0.735139\n",
      "iteration: 91 | loss: 0.334532\n",
      "iteration: 92 | loss: 1.861542\n",
      "iteration: 93 | loss: 0.669813\n",
      "iteration: 94 | loss: 1.218561\n",
      "iteration: 95 | loss: 1.271068\n",
      "iteration: 96 | loss: 0.991083\n",
      "iteration: 97 | loss: 1.420292\n",
      "iteration: 98 | loss: 0.902468\n",
      "iteration: 99 | loss: 0.831213\n",
      "  Train acc: 0.6, Val acc: 0.0\n",
      "iteration: 100 | loss: 1.119706\n",
      "iteration: 101 | loss: 0.636331\n",
      "iteration: 102 | loss: 0.765205\n",
      "iteration: 103 | loss: 0.739214\n",
      "iteration: 104 | loss: 0.968145\n",
      "iteration: 105 | loss: 0.580867\n",
      "iteration: 106 | loss: 1.259878\n",
      "iteration: 107 | loss: 1.020340\n",
      "iteration: 108 | loss: 1.018032\n",
      "iteration: 109 | loss: 0.661818\n",
      "iteration: 110 | loss: 1.148851\n",
      "iteration: 111 | loss: 0.449641\n",
      "iteration: 112 | loss: 1.181790\n",
      "iteration: 113 | loss: 0.498113\n",
      "iteration: 114 | loss: 0.713390\n",
      "iteration: 115 | loss: 0.098974\n",
      "iteration: 116 | loss: 1.505913\n",
      "iteration: 117 | loss: 0.735600\n",
      "iteration: 118 | loss: 1.085143\n",
      "iteration: 119 | loss: 0.605465\n",
      "iteration: 120 | loss: 1.021000\n",
      "iteration: 121 | loss: 0.629960\n",
      "iteration: 122 | loss: 0.447771\n",
      "iteration: 123 | loss: 1.230450\n",
      "iteration: 124 | loss: 0.332470\n",
      "  Train acc: 0.62, Val acc: 0.5\n",
      "iteration: 125 | loss: 0.724443\n",
      "iteration: 126 | loss: 0.199822\n",
      "iteration: 127 | loss: 0.809275\n",
      "iteration: 128 | loss: 1.341604\n",
      "iteration: 129 | loss: 1.051131\n",
      "iteration: 130 | loss: 0.674361\n",
      "iteration: 131 | loss: 0.655916\n",
      "iteration: 132 | loss: 0.963661\n",
      "iteration: 133 | loss: 1.393766\n",
      "iteration: 134 | loss: 0.469480\n",
      "iteration: 135 | loss: 0.888047\n",
      "iteration: 136 | loss: 0.444176\n",
      "iteration: 137 | loss: 0.284807\n",
      "iteration: 138 | loss: 1.013470\n",
      "iteration: 139 | loss: 0.416257\n",
      "iteration: 140 | loss: 0.702245\n",
      "iteration: 141 | loss: 1.046104\n",
      "iteration: 142 | loss: 0.727796\n",
      "iteration: 143 | loss: 0.701423\n",
      "iteration: 144 | loss: 0.754329\n",
      "iteration: 145 | loss: 0.128974\n",
      "iteration: 146 | loss: 0.860659\n",
      "iteration: 147 | loss: 0.306905\n",
      "iteration: 148 | loss: 0.534309\n",
      "iteration: 149 | loss: 0.813402\n",
      "  Train acc: 0.72, Val acc: 0.0\n",
      "iteration: 150 | loss: 0.582117\n",
      "iteration: 151 | loss: 1.170835\n",
      "iteration: 152 | loss: 0.767581\n",
      "iteration: 153 | loss: 0.680449\n",
      "iteration: 154 | loss: 0.815274\n",
      "iteration: 155 | loss: 0.212481\n",
      "iteration: 156 | loss: 0.683999\n",
      "iteration: 157 | loss: 0.157588\n",
      "iteration: 158 | loss: 0.865899\n",
      "iteration: 159 | loss: 0.500786\n",
      "iteration: 160 | loss: 0.351096\n",
      "iteration: 161 | loss: 0.264998\n",
      "iteration: 162 | loss: 0.478940\n",
      "iteration: 163 | loss: 0.238130\n",
      "iteration: 164 | loss: 0.915242\n",
      "iteration: 165 | loss: 0.372062\n",
      "iteration: 166 | loss: 1.045102\n",
      "iteration: 167 | loss: 0.637302\n",
      "iteration: 168 | loss: 0.296471\n",
      "iteration: 169 | loss: 0.225806\n",
      "iteration: 170 | loss: 0.489021\n",
      "iteration: 171 | loss: 0.891432\n",
      "iteration: 172 | loss: 0.390422\n",
      "iteration: 173 | loss: 0.574941\n",
      "iteration: 174 | loss: 0.879012\n",
      "  Train acc: 0.74, Val acc: 0.0\n",
      "iteration: 175 | loss: 0.634683\n",
      "iteration: 176 | loss: 0.364630\n",
      "iteration: 177 | loss: 0.239531\n",
      "iteration: 178 | loss: 0.528549\n",
      "iteration: 179 | loss: 0.490740\n",
      "iteration: 180 | loss: 1.007937\n",
      "iteration: 181 | loss: 0.923321\n",
      "iteration: 182 | loss: 0.629066\n",
      "iteration: 183 | loss: 0.698351\n",
      "iteration: 184 | loss: 0.736027\n",
      "iteration: 185 | loss: 0.683148\n",
      "iteration: 186 | loss: 0.598033\n",
      "iteration: 187 | loss: 0.654390\n",
      "iteration: 188 | loss: 0.655127\n",
      "iteration: 189 | loss: 0.674232\n",
      "iteration: 190 | loss: 1.208661\n",
      "iteration: 191 | loss: 0.820393\n",
      "iteration: 192 | loss: 0.804154\n",
      "iteration: 193 | loss: 0.349103\n",
      "iteration: 194 | loss: 0.532754\n",
      "iteration: 195 | loss: 0.847154\n",
      "iteration: 196 | loss: 0.683312\n",
      "iteration: 197 | loss: 0.319316\n",
      "iteration: 198 | loss: 0.660312\n",
      "iteration: 199 | loss: 0.097534\n",
      "  Train acc: 0.76, Val acc: 0.0\n",
      "iteration: 200 | loss: 1.283829\n",
      "iteration: 201 | loss: 0.180570\n",
      "iteration: 202 | loss: 0.133253\n",
      "iteration: 203 | loss: 0.124662\n",
      "iteration: 204 | loss: 0.579532\n",
      "iteration: 205 | loss: 0.821133\n",
      "iteration: 206 | loss: 0.518170\n",
      "iteration: 207 | loss: 0.415266\n",
      "iteration: 208 | loss: 0.263868\n",
      "iteration: 209 | loss: 0.446404\n",
      "iteration: 210 | loss: 0.311410\n",
      "iteration: 211 | loss: 0.633784\n",
      "iteration: 212 | loss: 0.519849\n",
      "iteration: 213 | loss: 0.324619\n",
      "iteration: 214 | loss: 0.257733\n",
      "iteration: 215 | loss: 0.174723\n",
      "iteration: 216 | loss: 0.685933\n",
      "iteration: 217 | loss: 0.294864\n",
      "iteration: 218 | loss: 0.540786\n",
      "iteration: 219 | loss: 0.958694\n",
      "iteration: 220 | loss: 0.583787\n",
      "iteration: 221 | loss: 0.130590\n",
      "iteration: 222 | loss: 0.523592\n",
      "iteration: 223 | loss: 0.290252\n",
      "iteration: 224 | loss: 0.111743\n",
      "  Train acc: 0.78, Val acc: 0.0\n",
      "iteration: 225 | loss: 0.032970\n",
      "iteration: 226 | loss: 0.880844\n",
      "iteration: 227 | loss: 0.401725\n",
      "iteration: 228 | loss: 0.017199\n",
      "iteration: 229 | loss: 1.052595\n",
      "iteration: 230 | loss: 0.570605\n",
      "iteration: 231 | loss: 0.403852\n",
      "iteration: 232 | loss: 0.963118\n",
      "iteration: 233 | loss: 0.335820\n",
      "iteration: 234 | loss: 0.285360\n",
      "iteration: 235 | loss: 0.327967\n",
      "iteration: 236 | loss: 0.628213\n",
      "iteration: 237 | loss: 0.603590\n",
      "iteration: 238 | loss: 0.638419\n",
      "iteration: 239 | loss: 0.809117\n",
      "iteration: 240 | loss: 0.783681\n",
      "iteration: 241 | loss: 0.700904\n",
      "iteration: 242 | loss: 0.635046\n",
      "iteration: 243 | loss: 0.419384\n",
      "iteration: 244 | loss: 0.080003\n",
      "iteration: 245 | loss: 0.468092\n",
      "iteration: 246 | loss: 0.527855\n",
      "iteration: 247 | loss: 0.681013\n",
      "iteration: 248 | loss: 0.511466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 249 | loss: 0.531386\n",
      "  Train acc: 0.8, Val acc: 0.0\n",
      "iteration: 250 | loss: 0.513792\n",
      "iteration: 251 | loss: 0.214184\n",
      "iteration: 252 | loss: 0.249254\n",
      "iteration: 253 | loss: 0.550567\n",
      "iteration: 254 | loss: 0.724800\n",
      "iteration: 255 | loss: 0.205419\n",
      "iteration: 256 | loss: 0.083044\n",
      "iteration: 257 | loss: 0.590907\n",
      "iteration: 258 | loss: 0.336534\n",
      "iteration: 259 | loss: 0.552708\n",
      "iteration: 260 | loss: 0.446549\n",
      "iteration: 261 | loss: 0.157745\n",
      "iteration: 262 | loss: 0.485331\n",
      "iteration: 263 | loss: 0.269396\n",
      "iteration: 264 | loss: 0.421416\n",
      "iteration: 265 | loss: 0.106953\n",
      "iteration: 266 | loss: 0.285330\n",
      "iteration: 267 | loss: 0.658759\n",
      "iteration: 268 | loss: 0.107822\n",
      "iteration: 269 | loss: 0.548022\n",
      "iteration: 270 | loss: 0.341790\n",
      "iteration: 271 | loss: 0.243226\n",
      "iteration: 272 | loss: 0.257172\n",
      "iteration: 273 | loss: 0.145311\n",
      "iteration: 274 | loss: 0.370376\n",
      "  Train acc: 0.86, Val acc: 0.0\n",
      "iteration: 275 | loss: 0.038115\n",
      "iteration: 276 | loss: 0.082076\n",
      "iteration: 277 | loss: 0.282590\n",
      "iteration: 278 | loss: 0.335711\n",
      "iteration: 279 | loss: 0.499346\n",
      "iteration: 280 | loss: 0.370365\n",
      "iteration: 281 | loss: 0.022661\n",
      "iteration: 282 | loss: 0.167502\n",
      "iteration: 283 | loss: 0.112867\n",
      "iteration: 284 | loss: 0.015059\n",
      "iteration: 285 | loss: 0.453937\n",
      "iteration: 286 | loss: 0.369385\n",
      "iteration: 287 | loss: 0.163473\n",
      "iteration: 288 | loss: 0.246840\n",
      "iteration: 289 | loss: 0.865102\n",
      "iteration: 290 | loss: 0.156555\n",
      "iteration: 291 | loss: 0.013282\n",
      "iteration: 292 | loss: 0.095034\n",
      "iteration: 293 | loss: 0.422888\n",
      "iteration: 294 | loss: 0.078458\n",
      "iteration: 295 | loss: 0.295533\n",
      "iteration: 296 | loss: 0.119211\n",
      "iteration: 297 | loss: 0.659263\n",
      "iteration: 298 | loss: 0.563879\n",
      "iteration: 299 | loss: 0.471266\n",
      "  Train acc: 0.86, Val acc: 0.0\n",
      "iteration: 300 | loss: 0.168092\n",
      "iteration: 301 | loss: 0.431824\n",
      "iteration: 302 | loss: 0.427506\n",
      "iteration: 303 | loss: 0.150521\n",
      "iteration: 304 | loss: 0.327099\n",
      "iteration: 305 | loss: 0.310456\n",
      "iteration: 306 | loss: 0.166222\n",
      "iteration: 307 | loss: 0.103575\n",
      "iteration: 308 | loss: 0.524341\n",
      "iteration: 309 | loss: 0.293401\n",
      "iteration: 310 | loss: 0.259784\n",
      "iteration: 311 | loss: 0.177524\n",
      "iteration: 312 | loss: 0.454833\n",
      "iteration: 313 | loss: 0.017541\n",
      "iteration: 314 | loss: 0.841477\n",
      "iteration: 315 | loss: 0.168892\n",
      "iteration: 316 | loss: 0.216032\n",
      "iteration: 317 | loss: 0.611000\n",
      "iteration: 318 | loss: 0.528352\n",
      "iteration: 319 | loss: 0.336304\n",
      "iteration: 320 | loss: 0.372911\n",
      "iteration: 321 | loss: 0.464199\n",
      "iteration: 322 | loss: 0.730724\n",
      "iteration: 323 | loss: 0.090457\n",
      "iteration: 324 | loss: 0.152349\n",
      "  Train acc: 0.9, Val acc: 0.0\n",
      "iteration: 325 | loss: 0.145162\n",
      "iteration: 326 | loss: 0.003560\n",
      "iteration: 327 | loss: 0.553256\n",
      "iteration: 328 | loss: 0.707478\n",
      "iteration: 329 | loss: 0.911965\n",
      "iteration: 330 | loss: 0.348073\n",
      "iteration: 331 | loss: 0.383863\n",
      "iteration: 332 | loss: 0.211017\n",
      "iteration: 333 | loss: 0.174349\n",
      "iteration: 334 | loss: 0.234808\n",
      "iteration: 335 | loss: 0.355497\n",
      "iteration: 336 | loss: 0.129723\n",
      "iteration: 337 | loss: 0.072195\n",
      "iteration: 338 | loss: 0.156414\n",
      "iteration: 339 | loss: 0.501907\n",
      "iteration: 340 | loss: 0.145809\n",
      "iteration: 341 | loss: 0.538781\n",
      "iteration: 342 | loss: 0.576198\n",
      "iteration: 343 | loss: 0.298453\n",
      "iteration: 344 | loss: 1.126323\n",
      "iteration: 345 | loss: 0.074886\n",
      "iteration: 346 | loss: 0.947687\n",
      "iteration: 347 | loss: 0.057214\n",
      "iteration: 348 | loss: 2.525493\n",
      "iteration: 349 | loss: 1.554033\n",
      "  Train acc: 0.76, Val acc: 0.0\n",
      "iteration: 350 | loss: 1.744912\n",
      "iteration: 351 | loss: 0.818494\n",
      "iteration: 352 | loss: 0.456187\n",
      "iteration: 353 | loss: 0.231047\n",
      "iteration: 354 | loss: 0.561711\n",
      "iteration: 355 | loss: 0.930136\n",
      "iteration: 356 | loss: 1.192487\n",
      "iteration: 357 | loss: 0.514726\n",
      "iteration: 358 | loss: 0.836058\n",
      "iteration: 359 | loss: 0.362704\n",
      "iteration: 360 | loss: 0.380558\n",
      "iteration: 361 | loss: 1.772145\n",
      "iteration: 362 | loss: 0.770778\n",
      "iteration: 363 | loss: 0.247664\n",
      "iteration: 364 | loss: 0.658991\n",
      "iteration: 365 | loss: 0.418650\n",
      "iteration: 366 | loss: 0.813649\n",
      "iteration: 367 | loss: 0.761254\n",
      "iteration: 368 | loss: 0.506881\n",
      "iteration: 369 | loss: 1.332198\n",
      "iteration: 370 | loss: 0.666629\n",
      "iteration: 371 | loss: 1.934780\n",
      "iteration: 372 | loss: 0.759614\n",
      "iteration: 373 | loss: 0.687737\n",
      "iteration: 374 | loss: 0.268416\n",
      "  Train acc: 0.8, Val acc: 0.0\n",
      "iteration: 375 | loss: 0.355205\n",
      "iteration: 376 | loss: 0.079186\n",
      "iteration: 377 | loss: 0.688610\n",
      "iteration: 378 | loss: 0.829821\n",
      "iteration: 379 | loss: 0.839882\n",
      "iteration: 380 | loss: 1.947495\n",
      "iteration: 381 | loss: 1.167087\n",
      "iteration: 382 | loss: 0.109366\n",
      "iteration: 383 | loss: 0.643952\n",
      "iteration: 384 | loss: 0.087533\n",
      "iteration: 385 | loss: 0.746423\n",
      "iteration: 386 | loss: 0.499890\n",
      "iteration: 387 | loss: 1.275993\n",
      "iteration: 388 | loss: 0.517199\n",
      "iteration: 389 | loss: 0.400463\n",
      "iteration: 390 | loss: 0.478339\n",
      "iteration: 391 | loss: 0.076042\n",
      "iteration: 392 | loss: 0.468179\n",
      "iteration: 393 | loss: 0.786875\n",
      "iteration: 394 | loss: 1.792608\n",
      "iteration: 395 | loss: 1.501857\n",
      "iteration: 396 | loss: 0.706871\n",
      "iteration: 397 | loss: 1.140543\n",
      "iteration: 398 | loss: 0.392542\n",
      "iteration: 399 | loss: 0.778119\n",
      "  Train acc: 0.76, Val acc: 0.0\n",
      "iteration: 400 | loss: 0.344791\n",
      "iteration: 401 | loss: 0.393947\n",
      "iteration: 402 | loss: 0.334658\n",
      "iteration: 403 | loss: 0.417241\n",
      "iteration: 404 | loss: 0.254169\n",
      "iteration: 405 | loss: 0.376702\n",
      "iteration: 406 | loss: 0.404378\n",
      "iteration: 407 | loss: 0.320571\n",
      "iteration: 408 | loss: 0.354317\n",
      "iteration: 409 | loss: 0.290201\n",
      "iteration: 410 | loss: 0.604827\n",
      "iteration: 411 | loss: 0.339432\n",
      "iteration: 412 | loss: 0.384347\n",
      "iteration: 413 | loss: 0.515124\n",
      "iteration: 414 | loss: 0.587242\n",
      "iteration: 415 | loss: 1.085222\n",
      "iteration: 416 | loss: 0.286944\n",
      "iteration: 417 | loss: 0.729094\n",
      "iteration: 418 | loss: 0.106963\n",
      "iteration: 419 | loss: 0.839450\n",
      "iteration: 420 | loss: 1.029703\n",
      "iteration: 421 | loss: 0.322282\n",
      "iteration: 422 | loss: 0.514167\n",
      "iteration: 423 | loss: 0.150384\n",
      "iteration: 424 | loss: 0.104523\n",
      "  Train acc: 0.74, Val acc: 0.0\n",
      "iteration: 425 | loss: 0.278162\n",
      "iteration: 426 | loss: 0.680356\n",
      "iteration: 427 | loss: 0.625590\n",
      "iteration: 428 | loss: 0.456858\n",
      "iteration: 429 | loss: 0.310000\n",
      "iteration: 430 | loss: 0.190184\n",
      "iteration: 431 | loss: 0.433527\n",
      "iteration: 432 | loss: 0.163420\n",
      "iteration: 433 | loss: 0.678107\n",
      "iteration: 434 | loss: 0.434571\n",
      "iteration: 435 | loss: 0.805342\n",
      "iteration: 436 | loss: 0.685696\n",
      "iteration: 437 | loss: 0.132029\n",
      "iteration: 438 | loss: 2.631209\n",
      "iteration: 439 | loss: 0.238697\n",
      "iteration: 440 | loss: 0.499282\n",
      "iteration: 441 | loss: 0.854284\n",
      "iteration: 442 | loss: 0.291148\n",
      "iteration: 443 | loss: 0.398396\n",
      "iteration: 444 | loss: 0.357599\n",
      "iteration: 445 | loss: 0.276427\n",
      "iteration: 446 | loss: 0.184851\n",
      "iteration: 447 | loss: 2.351478\n",
      "iteration: 448 | loss: 1.136884\n",
      "iteration: 449 | loss: 0.239206\n",
      "  Train acc: 0.78, Val acc: 0.0\n",
      "iteration: 450 | loss: 0.186180\n",
      "iteration: 451 | loss: 0.289903\n",
      "iteration: 452 | loss: 0.948941\n",
      "iteration: 453 | loss: 0.404782\n",
      "iteration: 454 | loss: 2.616383\n",
      "iteration: 455 | loss: 2.279501\n",
      "iteration: 456 | loss: 0.149043\n",
      "iteration: 457 | loss: 2.513372\n",
      "iteration: 458 | loss: 1.648327\n",
      "iteration: 459 | loss: 5.939993\n",
      "iteration: 460 | loss: 1.550048\n",
      "iteration: 461 | loss: 0.935963\n",
      "iteration: 462 | loss: 0.838391\n",
      "iteration: 463 | loss: 1.708553\n",
      "iteration: 464 | loss: 1.681691\n",
      "iteration: 465 | loss: 2.567938\n",
      "iteration: 466 | loss: 2.081811\n",
      "iteration: 467 | loss: 0.954837\n",
      "iteration: 468 | loss: 1.626082\n",
      "iteration: 469 | loss: 2.708400\n",
      "iteration: 470 | loss: 0.904911\n",
      "iteration: 471 | loss: 0.636718\n",
      "iteration: 472 | loss: 5.860618\n",
      "iteration: 473 | loss: 2.093215\n",
      "iteration: 474 | loss: 0.850435\n",
      "  Train acc: 0.72, Val acc: 0.0\n",
      "iteration: 475 | loss: 0.343043\n",
      "iteration: 476 | loss: 0.849624\n",
      "iteration: 477 | loss: 0.732139\n",
      "iteration: 478 | loss: 0.573042\n",
      "iteration: 479 | loss: 1.479613\n",
      "iteration: 480 | loss: 0.426035\n",
      "iteration: 481 | loss: 0.894140\n",
      "iteration: 482 | loss: 0.687452\n",
      "iteration: 483 | loss: 2.795284\n",
      "iteration: 484 | loss: 2.161890\n",
      "iteration: 485 | loss: 0.963575\n",
      "iteration: 486 | loss: 2.076900\n",
      "iteration: 487 | loss: 0.664598\n",
      "iteration: 488 | loss: 1.017259\n",
      "iteration: 489 | loss: 2.006136\n",
      "iteration: 490 | loss: 0.571412\n",
      "iteration: 491 | loss: 0.581033\n",
      "iteration: 492 | loss: 1.452436\n",
      "iteration: 493 | loss: 1.103861\n",
      "iteration: 494 | loss: 1.063691\n",
      "iteration: 495 | loss: 0.432134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 496 | loss: 1.859554\n",
      "iteration: 497 | loss: 0.660218\n",
      "iteration: 498 | loss: 0.581147\n",
      "iteration: 499 | loss: 0.630914\n",
      "  Train acc: 0.7, Val acc: 0.0\n",
      "iteration: 500 | loss: 0.951460\n",
      "iteration: 501 | loss: 0.496171\n",
      "iteration: 502 | loss: 0.748692\n",
      "iteration: 503 | loss: 0.743797\n",
      "iteration: 504 | loss: 0.810271\n",
      "iteration: 505 | loss: 0.767913\n",
      "iteration: 506 | loss: 0.509556\n",
      "iteration: 507 | loss: 1.080905\n",
      "iteration: 508 | loss: 0.744868\n",
      "iteration: 509 | loss: 0.489209\n",
      "iteration: 510 | loss: 0.496812\n",
      "iteration: 511 | loss: 0.674679\n",
      "iteration: 512 | loss: 0.361751\n",
      "iteration: 513 | loss: 1.369031\n",
      "iteration: 514 | loss: 0.655210\n",
      "iteration: 515 | loss: 0.540169\n",
      "iteration: 516 | loss: 0.752122\n",
      "iteration: 517 | loss: 0.937956\n",
      "iteration: 518 | loss: 0.767843\n",
      "iteration: 519 | loss: 0.414151\n",
      "iteration: 520 | loss: 0.831981\n",
      "iteration: 521 | loss: 0.831416\n",
      "iteration: 522 | loss: 0.123307\n",
      "iteration: 523 | loss: 0.073895\n",
      "iteration: 524 | loss: 0.654194\n",
      "  Train acc: 0.76, Val acc: 0.0\n",
      "iteration: 525 | loss: 0.656304\n",
      "iteration: 526 | loss: 0.228694\n",
      "iteration: 527 | loss: 0.218015\n",
      "iteration: 528 | loss: 1.786132\n",
      "iteration: 529 | loss: 0.188502\n",
      "iteration: 530 | loss: 1.391670\n",
      "iteration: 531 | loss: 0.001024\n",
      "iteration: 532 | loss: 0.328938\n",
      "iteration: 533 | loss: 0.492066\n",
      "iteration: 534 | loss: 0.946960\n",
      "iteration: 535 | loss: 0.079085\n",
      "iteration: 536 | loss: 0.461223\n",
      "iteration: 537 | loss: 0.264590\n",
      "iteration: 538 | loss: 0.474815\n",
      "iteration: 539 | loss: 0.619659\n",
      "iteration: 540 | loss: 0.258008\n",
      "iteration: 541 | loss: 0.372061\n",
      "iteration: 542 | loss: 0.211035\n",
      "iteration: 543 | loss: 1.115223\n",
      "iteration: 544 | loss: 1.074649\n",
      "iteration: 545 | loss: 0.242652\n",
      "iteration: 546 | loss: 1.023538\n",
      "iteration: 547 | loss: 0.372992\n",
      "iteration: 548 | loss: 0.120662\n",
      "iteration: 549 | loss: 0.569688\n",
      "  Train acc: 0.8, Val acc: 0.0\n",
      "iteration: 550 | loss: 0.503143\n",
      "iteration: 551 | loss: 0.324173\n",
      "iteration: 552 | loss: 0.701365\n",
      "iteration: 553 | loss: 0.132657\n",
      "iteration: 554 | loss: 0.403825\n",
      "iteration: 555 | loss: 0.218677\n",
      "iteration: 556 | loss: 0.241669\n",
      "iteration: 557 | loss: 0.337351\n",
      "iteration: 558 | loss: 0.441508\n",
      "iteration: 559 | loss: 0.772169\n",
      "iteration: 560 | loss: 0.318613\n",
      "iteration: 561 | loss: 0.020629\n",
      "iteration: 562 | loss: 0.572763\n",
      "iteration: 563 | loss: 0.985555\n",
      "iteration: 564 | loss: 0.088393\n",
      "iteration: 565 | loss: 0.761631\n",
      "iteration: 566 | loss: 1.225358\n",
      "iteration: 567 | loss: 0.328896\n",
      "iteration: 568 | loss: 0.474425\n",
      "iteration: 569 | loss: 0.583928\n",
      "iteration: 570 | loss: 0.031461\n",
      "iteration: 571 | loss: 0.295030\n",
      "iteration: 572 | loss: 0.996353\n",
      "iteration: 573 | loss: 0.005079\n",
      "iteration: 574 | loss: 0.377751\n",
      "  Train acc: 0.8, Val acc: 0.0\n",
      "iteration: 575 | loss: 0.001763\n",
      "iteration: 576 | loss: 0.508148\n",
      "iteration: 577 | loss: 0.260566\n",
      "iteration: 578 | loss: 0.182545\n",
      "iteration: 579 | loss: 0.438325\n",
      "iteration: 580 | loss: 0.237680\n",
      "iteration: 581 | loss: 0.806054\n",
      "iteration: 582 | loss: 0.769006\n",
      "iteration: 583 | loss: 0.421263\n",
      "iteration: 584 | loss: 0.962156\n",
      "iteration: 585 | loss: 0.118065\n",
      "iteration: 586 | loss: 0.934118\n",
      "iteration: 587 | loss: 0.279093\n",
      "iteration: 588 | loss: 0.013520\n",
      "iteration: 589 | loss: 0.287967\n",
      "iteration: 590 | loss: 3.675098\n",
      "iteration: 591 | loss: 0.003841\n",
      "iteration: 592 | loss: 0.131421\n",
      "iteration: 593 | loss: 0.670499\n",
      "iteration: 594 | loss: 0.230627\n",
      "iteration: 595 | loss: 0.655457\n",
      "iteration: 596 | loss: 0.646290\n",
      "iteration: 597 | loss: 0.712119\n",
      "iteration: 598 | loss: 0.413352\n",
      "iteration: 599 | loss: 0.369112\n",
      "  Train acc: 0.84, Val acc: 0.0\n",
      "iteration: 600 | loss: 0.289883\n",
      "iteration: 601 | loss: 0.416584\n",
      "iteration: 602 | loss: 0.568236\n",
      "iteration: 603 | loss: 0.528966\n",
      "iteration: 604 | loss: 0.692469\n",
      "iteration: 605 | loss: 0.233681\n",
      "iteration: 606 | loss: 0.167085\n",
      "iteration: 607 | loss: 0.260682\n",
      "iteration: 608 | loss: 0.423912\n",
      "iteration: 609 | loss: 0.257119\n",
      "iteration: 610 | loss: 1.073533\n",
      "iteration: 611 | loss: 0.577748\n",
      "iteration: 612 | loss: 0.681543\n",
      "iteration: 613 | loss: 0.515047\n",
      "iteration: 614 | loss: 0.399667\n",
      "iteration: 615 | loss: 0.412424\n",
      "iteration: 616 | loss: 0.723874\n",
      "iteration: 617 | loss: 0.365615\n",
      "iteration: 618 | loss: 0.557788\n",
      "iteration: 619 | loss: 0.548492\n",
      "iteration: 620 | loss: 1.253532\n",
      "iteration: 621 | loss: 0.063301\n",
      "iteration: 622 | loss: 0.682637\n",
      "iteration: 623 | loss: 0.205927\n",
      "iteration: 624 | loss: 0.362490\n",
      "  Train acc: 0.84, Val acc: 0.0\n",
      "iteration: 625 | loss: 0.181349\n",
      "iteration: 626 | loss: 1.210061\n",
      "iteration: 627 | loss: 1.753662\n",
      "iteration: 628 | loss: 0.505376\n",
      "iteration: 629 | loss: 0.270801\n",
      "iteration: 630 | loss: 0.285306\n",
      "iteration: 631 | loss: 0.189334\n",
      "iteration: 632 | loss: 0.995002\n",
      "iteration: 633 | loss: 0.239283\n",
      "iteration: 634 | loss: 0.405930\n",
      "iteration: 635 | loss: 0.174217\n",
      "iteration: 636 | loss: 0.194558\n",
      "iteration: 637 | loss: 0.102143\n",
      "iteration: 638 | loss: 0.710861\n",
      "iteration: 639 | loss: 0.168391\n",
      "iteration: 640 | loss: 0.350410\n",
      "iteration: 641 | loss: 0.189160\n",
      "iteration: 642 | loss: 0.001703\n",
      "iteration: 643 | loss: 0.276153\n",
      "iteration: 644 | loss: 0.515432\n",
      "iteration: 645 | loss: 0.247852\n",
      "iteration: 646 | loss: 0.528999\n",
      "iteration: 647 | loss: 0.415611\n",
      "iteration: 648 | loss: 0.461596\n",
      "iteration: 649 | loss: 0.763051\n",
      "  Train acc: 0.84, Val acc: 0.0\n",
      "iteration: 650 | loss: 0.027764\n",
      "iteration: 651 | loss: 0.434274\n",
      "iteration: 652 | loss: 0.803669\n",
      "iteration: 653 | loss: 0.002743\n",
      "iteration: 654 | loss: 0.594600\n",
      "iteration: 655 | loss: 0.912033\n",
      "iteration: 656 | loss: 0.801520\n",
      "iteration: 657 | loss: 0.248199\n",
      "iteration: 658 | loss: 0.224998\n",
      "iteration: 659 | loss: 0.248135\n",
      "iteration: 660 | loss: 0.225214\n",
      "iteration: 661 | loss: 0.531593\n",
      "iteration: 662 | loss: 0.001676\n",
      "iteration: 663 | loss: 0.351407\n",
      "iteration: 664 | loss: 0.583508\n",
      "iteration: 665 | loss: 0.629221\n",
      "iteration: 666 | loss: 0.346808\n",
      "iteration: 667 | loss: 0.220103\n",
      "iteration: 668 | loss: 0.420819\n",
      "iteration: 669 | loss: 0.460593\n",
      "iteration: 670 | loss: 0.660010\n",
      "iteration: 671 | loss: 0.108877\n",
      "iteration: 672 | loss: 0.052312\n",
      "iteration: 673 | loss: 0.442165\n",
      "iteration: 674 | loss: 0.554090\n",
      "  Train acc: 0.86, Val acc: 0.0\n",
      "iteration: 675 | loss: 0.427316\n",
      "iteration: 676 | loss: 0.547794\n",
      "iteration: 677 | loss: 0.051350\n",
      "iteration: 678 | loss: 0.482484\n",
      "iteration: 679 | loss: 0.496428\n",
      "iteration: 680 | loss: 0.172892\n",
      "iteration: 681 | loss: 0.255165\n",
      "iteration: 682 | loss: 0.267129\n",
      "iteration: 683 | loss: 0.605262\n",
      "iteration: 684 | loss: 0.214358\n",
      "iteration: 685 | loss: 0.753014\n",
      "iteration: 686 | loss: 0.649142\n",
      "iteration: 687 | loss: 0.187413\n",
      "iteration: 688 | loss: 0.271938\n",
      "iteration: 689 | loss: 0.617841\n",
      "iteration: 690 | loss: 0.065595\n",
      "iteration: 691 | loss: 0.307782\n",
      "iteration: 692 | loss: 0.709137\n",
      "iteration: 693 | loss: 0.058589\n",
      "iteration: 694 | loss: 0.596613\n",
      "iteration: 695 | loss: 0.727666\n",
      "iteration: 696 | loss: 0.665440\n",
      "iteration: 697 | loss: 0.825406\n",
      "iteration: 698 | loss: 0.548813\n",
      "iteration: 699 | loss: 0.482258\n",
      "  Train acc: 0.86, Val acc: 0.0\n",
      "iteration: 700 | loss: 0.445446\n",
      "iteration: 701 | loss: 0.622202\n",
      "iteration: 702 | loss: 0.166496\n",
      "iteration: 703 | loss: 0.310977\n",
      "iteration: 704 | loss: 0.568905\n",
      "iteration: 705 | loss: 0.244682\n",
      "iteration: 706 | loss: 0.080063\n",
      "iteration: 707 | loss: 0.255616\n",
      "iteration: 708 | loss: 0.294703\n",
      "iteration: 709 | loss: 0.288691\n",
      "iteration: 710 | loss: 0.874227\n",
      "iteration: 711 | loss: 0.266177\n",
      "iteration: 712 | loss: 0.220395\n",
      "iteration: 713 | loss: 0.200459\n",
      "iteration: 714 | loss: 0.051215\n",
      "iteration: 715 | loss: 2.087662\n",
      "iteration: 716 | loss: 0.512479\n",
      "iteration: 717 | loss: 0.521719\n",
      "iteration: 718 | loss: 0.938024\n",
      "iteration: 719 | loss: 0.337109\n",
      "iteration: 720 | loss: 0.920067\n",
      "iteration: 721 | loss: 0.940391\n",
      "iteration: 722 | loss: 0.329805\n",
      "iteration: 723 | loss: 0.846095\n",
      "iteration: 724 | loss: 0.652785\n",
      "  Train acc: 0.86, Val acc: 0.0\n",
      "iteration: 725 | loss: 0.273873\n",
      "iteration: 726 | loss: 0.622348\n",
      "iteration: 727 | loss: 1.277231\n",
      "iteration: 728 | loss: 0.209535\n",
      "iteration: 729 | loss: 1.089688\n",
      "iteration: 730 | loss: 0.404337\n",
      "iteration: 731 | loss: 0.532307\n",
      "iteration: 732 | loss: 0.040145\n",
      "iteration: 733 | loss: 0.826438\n",
      "iteration: 734 | loss: 0.028011\n",
      "iteration: 735 | loss: 0.195056\n",
      "iteration: 736 | loss: 0.660099\n",
      "iteration: 737 | loss: 0.373395\n",
      "iteration: 738 | loss: 0.923566\n",
      "iteration: 739 | loss: 0.805804\n",
      "iteration: 740 | loss: 0.665404\n",
      "iteration: 741 | loss: 0.829840\n",
      "iteration: 742 | loss: 0.847670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 743 | loss: 0.889433\n",
      "iteration: 744 | loss: 1.895021\n",
      "iteration: 745 | loss: 0.265901\n",
      "iteration: 746 | loss: 0.644026\n",
      "iteration: 747 | loss: 0.218096\n",
      "iteration: 748 | loss: 0.434214\n",
      "iteration: 749 | loss: 0.583987\n",
      "  Train acc: 0.82, Val acc: 0.0\n",
      "iteration: 750 | loss: 0.480801\n",
      "iteration: 751 | loss: 0.628088\n",
      "iteration: 752 | loss: 0.643956\n",
      "iteration: 753 | loss: 0.182135\n",
      "iteration: 754 | loss: 0.696876\n",
      "iteration: 755 | loss: 0.394249\n",
      "iteration: 756 | loss: 0.460228\n",
      "iteration: 757 | loss: 0.693845\n",
      "iteration: 758 | loss: 0.302152\n",
      "iteration: 759 | loss: 0.787643\n",
      "iteration: 760 | loss: 0.211483\n",
      "iteration: 761 | loss: 0.125408\n",
      "iteration: 762 | loss: 0.375895\n",
      "iteration: 763 | loss: 0.505900\n",
      "iteration: 764 | loss: 0.345507\n",
      "iteration: 765 | loss: 0.298287\n",
      "iteration: 766 | loss: 0.526395\n",
      "iteration: 767 | loss: 0.613975\n",
      "iteration: 768 | loss: 0.310190\n",
      "iteration: 769 | loss: 0.258664\n",
      "iteration: 770 | loss: 0.640557\n",
      "iteration: 771 | loss: 0.220333\n",
      "iteration: 772 | loss: 0.327357\n",
      "iteration: 773 | loss: 0.458193\n",
      "iteration: 774 | loss: 0.349665\n",
      "  Train acc: 0.82, Val acc: 0.0\n",
      "iteration: 775 | loss: 0.261573\n",
      "iteration: 776 | loss: 0.446629\n",
      "iteration: 777 | loss: 0.097064\n",
      "iteration: 778 | loss: 0.454041\n",
      "iteration: 779 | loss: 0.154302\n",
      "iteration: 780 | loss: 0.270417\n",
      "iteration: 781 | loss: 0.688843\n",
      "iteration: 782 | loss: 0.634289\n",
      "iteration: 783 | loss: 0.832668\n",
      "iteration: 784 | loss: 0.651255\n",
      "iteration: 785 | loss: 0.365691\n",
      "iteration: 786 | loss: 0.230691\n",
      "iteration: 787 | loss: 0.668559\n",
      "iteration: 788 | loss: 0.062004\n",
      "iteration: 789 | loss: 0.322459\n",
      "iteration: 790 | loss: 0.517615\n",
      "iteration: 791 | loss: 0.213374\n",
      "iteration: 792 | loss: 0.632355\n",
      "iteration: 793 | loss: 0.188307\n",
      "iteration: 794 | loss: 0.366858\n",
      "iteration: 795 | loss: 0.288065\n",
      "iteration: 796 | loss: 0.490266\n",
      "iteration: 797 | loss: 0.309688\n",
      "iteration: 798 | loss: 0.029114\n",
      "iteration: 799 | loss: 0.000616\n",
      "  Train acc: 0.8, Val acc: 0.0\n",
      "iteration: 800 | loss: 0.270122\n",
      "iteration: 801 | loss: 0.179332\n",
      "iteration: 802 | loss: 0.337318\n",
      "iteration: 803 | loss: 0.102279\n",
      "iteration: 804 | loss: 0.589448\n",
      "iteration: 805 | loss: 0.473919\n",
      "iteration: 806 | loss: 0.416597\n",
      "iteration: 807 | loss: 0.607954\n",
      "iteration: 808 | loss: 0.334234\n",
      "iteration: 809 | loss: 0.334480\n",
      "iteration: 810 | loss: 0.463976\n",
      "iteration: 811 | loss: 0.403239\n",
      "iteration: 812 | loss: 0.986936\n",
      "iteration: 813 | loss: 0.006586\n",
      "iteration: 814 | loss: 1.346031\n",
      "iteration: 815 | loss: 0.136276\n",
      "iteration: 816 | loss: 0.453726\n",
      "iteration: 817 | loss: 0.613992\n",
      "iteration: 818 | loss: 1.029281\n",
      "iteration: 819 | loss: 0.506917\n",
      "iteration: 820 | loss: 0.886955\n",
      "iteration: 821 | loss: 0.602530\n",
      "iteration: 822 | loss: 0.364821\n",
      "iteration: 823 | loss: 0.526950\n",
      "iteration: 824 | loss: 0.094241\n",
      "  Train acc: 0.78, Val acc: 0.0\n",
      "iteration: 825 | loss: 0.480487\n",
      "iteration: 826 | loss: 0.845952\n",
      "iteration: 827 | loss: 0.474628\n",
      "iteration: 828 | loss: 0.244143\n",
      "iteration: 829 | loss: 0.685959\n",
      "iteration: 830 | loss: 0.325492\n",
      "iteration: 831 | loss: 0.950475\n",
      "iteration: 832 | loss: 0.353817\n",
      "iteration: 833 | loss: 0.613470\n",
      "iteration: 834 | loss: 0.857306\n",
      "iteration: 835 | loss: 0.178296\n",
      "iteration: 836 | loss: 0.173812\n",
      "iteration: 837 | loss: 0.474989\n",
      "iteration: 838 | loss: 0.239142\n",
      "iteration: 839 | loss: 1.259118\n",
      "iteration: 840 | loss: 0.259437\n",
      "iteration: 841 | loss: 0.469805\n",
      "iteration: 842 | loss: 0.659632\n",
      "iteration: 843 | loss: 1.204499\n",
      "iteration: 844 | loss: 0.631301\n",
      "iteration: 845 | loss: 0.090951\n",
      "iteration: 846 | loss: 0.424469\n",
      "iteration: 847 | loss: 0.886899\n",
      "iteration: 848 | loss: 0.572975\n",
      "iteration: 849 | loss: 0.383010\n",
      "  Train acc: 0.8, Val acc: 0.0\n",
      "iteration: 850 | loss: 0.842380\n",
      "iteration: 851 | loss: 0.700758\n",
      "iteration: 852 | loss: 0.108930\n",
      "iteration: 853 | loss: 0.651670\n",
      "iteration: 854 | loss: 0.434867\n",
      "iteration: 855 | loss: 0.630604\n",
      "iteration: 856 | loss: 0.152785\n",
      "iteration: 857 | loss: 0.057765\n",
      "iteration: 858 | loss: 0.943300\n",
      "iteration: 859 | loss: 0.377155\n",
      "iteration: 860 | loss: 0.179562\n",
      "iteration: 861 | loss: 0.833518\n",
      "iteration: 862 | loss: 0.709381\n",
      "iteration: 863 | loss: 0.362554\n",
      "iteration: 864 | loss: 0.046610\n",
      "iteration: 865 | loss: 0.545504\n",
      "iteration: 866 | loss: 0.242840\n",
      "iteration: 867 | loss: 0.522244\n",
      "iteration: 868 | loss: 0.287592\n",
      "iteration: 869 | loss: 0.476602\n",
      "iteration: 870 | loss: 0.091321\n",
      "iteration: 871 | loss: 0.176192\n",
      "iteration: 872 | loss: 0.715297\n",
      "iteration: 873 | loss: 0.219288\n",
      "iteration: 874 | loss: 0.287550\n",
      "  Train acc: 0.82, Val acc: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Adam\n",
    "adam_net = ConvNet4(input_shape=(3,16,16), wt_scale=1e-2, verbose=False)\n",
    "adam_net.compile(\"Adam\", lr=0.01)\n",
    "\n",
    "adam_net.fit(x_dev, y_dev, x_val, y_val, mini_batch_sz=10, n_epochs=175, acc_freq=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train...\n",
      "875 iterations. 5 iter/epoch.\n",
      "iteration: 0 | loss: 2.303388\n",
      "iteration: 1 | loss: 2.298281\n",
      "iteration: 2 | loss: 2.303584\n",
      "iteration: 3 | loss: 2.301775\n",
      "iteration: 4 | loss: 2.301191\n",
      "iteration: 5 | loss: 2.296142\n",
      "iteration: 6 | loss: 2.292642\n",
      "iteration: 7 | loss: 2.300592\n",
      "iteration: 8 | loss: 2.287171\n",
      "iteration: 9 | loss: 2.287899\n",
      "iteration: 10 | loss: 2.286388\n",
      "iteration: 11 | loss: 2.281574\n",
      "iteration: 12 | loss: 2.283878\n",
      "iteration: 13 | loss: 2.298739\n",
      "iteration: 14 | loss: 2.300128\n",
      "iteration: 15 | loss: 2.269776\n",
      "iteration: 16 | loss: 2.293792\n",
      "iteration: 17 | loss: 2.278118\n",
      "iteration: 18 | loss: 2.274281\n",
      "iteration: 19 | loss: 2.259955\n",
      "iteration: 20 | loss: 2.258439\n",
      "iteration: 21 | loss: 2.315812\n",
      "iteration: 22 | loss: 2.279903\n",
      "iteration: 23 | loss: 2.234901\n",
      "iteration: 24 | loss: 2.278361\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 25 | loss: 2.304989\n",
      "iteration: 26 | loss: 2.282372\n",
      "iteration: 27 | loss: 2.283605\n",
      "iteration: 28 | loss: 2.283792\n",
      "iteration: 29 | loss: 2.223040\n",
      "iteration: 30 | loss: 2.281873\n",
      "iteration: 31 | loss: 2.235312\n",
      "iteration: 32 | loss: 2.244368\n",
      "iteration: 33 | loss: 2.270816\n",
      "iteration: 34 | loss: 2.189780\n",
      "iteration: 35 | loss: 2.334529\n",
      "iteration: 36 | loss: 2.204405\n",
      "iteration: 37 | loss: 2.222157\n",
      "iteration: 38 | loss: 2.261449\n",
      "iteration: 39 | loss: 2.219239\n",
      "iteration: 40 | loss: 2.333575\n",
      "iteration: 41 | loss: 2.173651\n",
      "iteration: 42 | loss: 2.198479\n",
      "iteration: 43 | loss: 2.294233\n",
      "iteration: 44 | loss: 2.260708\n",
      "iteration: 45 | loss: 2.276119\n",
      "iteration: 46 | loss: 2.243222\n",
      "iteration: 47 | loss: 2.279184\n",
      "iteration: 48 | loss: 2.226185\n",
      "iteration: 49 | loss: 2.202158\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 50 | loss: 2.116066\n",
      "iteration: 51 | loss: 2.252671\n",
      "iteration: 52 | loss: 2.346112\n",
      "iteration: 53 | loss: 2.268857\n",
      "iteration: 54 | loss: 2.262258\n",
      "iteration: 55 | loss: 2.232384\n",
      "iteration: 56 | loss: 2.164824\n",
      "iteration: 57 | loss: 2.133317\n",
      "iteration: 58 | loss: 2.193715\n",
      "iteration: 59 | loss: 2.266891\n",
      "iteration: 60 | loss: 2.271718\n",
      "iteration: 61 | loss: 2.080205\n",
      "iteration: 62 | loss: 2.263771\n",
      "iteration: 63 | loss: 2.300696\n",
      "iteration: 64 | loss: 2.205378\n",
      "iteration: 65 | loss: 2.112908\n",
      "iteration: 66 | loss: 2.301600\n",
      "iteration: 67 | loss: 2.301482\n",
      "iteration: 68 | loss: 2.235733\n",
      "iteration: 69 | loss: 2.200669\n",
      "iteration: 70 | loss: 2.398508\n",
      "iteration: 71 | loss: 2.218763\n",
      "iteration: 72 | loss: 2.230426\n",
      "iteration: 73 | loss: 2.179232\n",
      "iteration: 74 | loss: 2.139999\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 75 | loss: 2.089185\n",
      "iteration: 76 | loss: 2.111932\n",
      "iteration: 77 | loss: 2.297569\n",
      "iteration: 78 | loss: 2.117304\n",
      "iteration: 79 | loss: 2.297540\n",
      "iteration: 80 | loss: 2.249052\n",
      "iteration: 81 | loss: 2.530566\n",
      "iteration: 82 | loss: 2.334336\n",
      "iteration: 83 | loss: 2.107316\n",
      "iteration: 84 | loss: 2.011415\n",
      "iteration: 85 | loss: 2.340473\n",
      "iteration: 86 | loss: 2.222734\n",
      "iteration: 87 | loss: 2.147645\n",
      "iteration: 88 | loss: 2.349446\n",
      "iteration: 89 | loss: 2.290621\n",
      "iteration: 90 | loss: 2.386153\n",
      "iteration: 91 | loss: 2.255646\n",
      "iteration: 92 | loss: 2.036387\n",
      "iteration: 93 | loss: 2.225546\n",
      "iteration: 94 | loss: 2.244033\n",
      "iteration: 95 | loss: 2.334545\n",
      "iteration: 96 | loss: 2.158903\n",
      "iteration: 97 | loss: 2.263080\n",
      "iteration: 98 | loss: 2.073353\n",
      "iteration: 99 | loss: 2.326263\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 100 | loss: 2.248880\n",
      "iteration: 101 | loss: 2.118693\n",
      "iteration: 102 | loss: 2.249459\n",
      "iteration: 103 | loss: 2.411612\n",
      "iteration: 104 | loss: 2.240857\n",
      "iteration: 105 | loss: 2.155281\n",
      "iteration: 106 | loss: 2.099762\n",
      "iteration: 107 | loss: 2.339005\n",
      "iteration: 108 | loss: 2.168469\n",
      "iteration: 109 | loss: 2.110466\n",
      "iteration: 110 | loss: 2.275198\n",
      "iteration: 111 | loss: 2.315870\n",
      "iteration: 112 | loss: 2.243855\n",
      "iteration: 113 | loss: 2.237054\n",
      "iteration: 114 | loss: 2.072360\n",
      "iteration: 115 | loss: 2.123449\n",
      "iteration: 116 | loss: 2.110464\n",
      "iteration: 117 | loss: 2.114025\n",
      "iteration: 118 | loss: 2.095348\n",
      "iteration: 119 | loss: 2.332142\n",
      "iteration: 120 | loss: 2.253947\n",
      "iteration: 121 | loss: 2.372053\n",
      "iteration: 122 | loss: 2.191524\n",
      "iteration: 123 | loss: 2.166138\n",
      "iteration: 124 | loss: 2.326514\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 125 | loss: 1.892081\n",
      "iteration: 126 | loss: 2.233551\n",
      "iteration: 127 | loss: 2.213848\n",
      "iteration: 128 | loss: 2.191949\n",
      "iteration: 129 | loss: 2.362841\n",
      "iteration: 130 | loss: 2.216278\n",
      "iteration: 131 | loss: 1.950506\n",
      "iteration: 132 | loss: 2.316448\n",
      "iteration: 133 | loss: 2.118007\n",
      "iteration: 134 | loss: 2.179916\n",
      "iteration: 135 | loss: 1.966565\n",
      "iteration: 136 | loss: 2.261951\n",
      "iteration: 137 | loss: 2.227884\n",
      "iteration: 138 | loss: 2.235602\n",
      "iteration: 139 | loss: 2.271224\n",
      "iteration: 140 | loss: 2.116308\n",
      "iteration: 141 | loss: 2.255259\n",
      "iteration: 142 | loss: 2.265152\n",
      "iteration: 143 | loss: 2.237981\n",
      "iteration: 144 | loss: 2.038229\n",
      "iteration: 145 | loss: 2.070209\n",
      "iteration: 146 | loss: 2.066437\n",
      "iteration: 147 | loss: 2.014357\n",
      "iteration: 148 | loss: 2.369466\n",
      "iteration: 149 | loss: 2.247574\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 150 | loss: 2.319194\n",
      "iteration: 151 | loss: 1.976992\n",
      "iteration: 152 | loss: 2.445388\n",
      "iteration: 153 | loss: 2.294225\n",
      "iteration: 154 | loss: 2.307746\n",
      "iteration: 155 | loss: 2.323750\n",
      "iteration: 156 | loss: 2.210900\n",
      "iteration: 157 | loss: 2.079376\n",
      "iteration: 158 | loss: 2.021369\n",
      "iteration: 159 | loss: 2.021451\n",
      "iteration: 160 | loss: 1.945409\n",
      "iteration: 161 | loss: 2.121384\n",
      "iteration: 162 | loss: 2.035218\n",
      "iteration: 163 | loss: 2.250328\n",
      "iteration: 164 | loss: 1.845051\n",
      "iteration: 165 | loss: 1.946526\n",
      "iteration: 166 | loss: 2.325788\n",
      "iteration: 167 | loss: 2.207290\n",
      "iteration: 168 | loss: 2.040095\n",
      "iteration: 169 | loss: 2.322604\n",
      "iteration: 170 | loss: 2.279295\n",
      "iteration: 171 | loss: 2.476037\n",
      "iteration: 172 | loss: 2.126586\n",
      "iteration: 173 | loss: 2.133061\n",
      "iteration: 174 | loss: 2.090956\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 175 | loss: 2.118912\n",
      "iteration: 176 | loss: 1.846692\n",
      "iteration: 177 | loss: 2.401022\n",
      "iteration: 178 | loss: 2.330080\n",
      "iteration: 179 | loss: 2.219021\n",
      "iteration: 180 | loss: 2.452348\n",
      "iteration: 181 | loss: 2.006073\n",
      "iteration: 182 | loss: 2.222821\n",
      "iteration: 183 | loss: 1.956453\n",
      "iteration: 184 | loss: 1.908055\n",
      "iteration: 185 | loss: 1.862555\n",
      "iteration: 186 | loss: 2.108229\n",
      "iteration: 187 | loss: 1.844667\n",
      "iteration: 188 | loss: 1.849306\n",
      "iteration: 189 | loss: 2.114064\n",
      "iteration: 190 | loss: 1.893826\n",
      "iteration: 191 | loss: 2.033707\n",
      "iteration: 192 | loss: 2.304965\n",
      "iteration: 193 | loss: 2.332578\n",
      "iteration: 194 | loss: 2.185619\n",
      "iteration: 195 | loss: 2.146816\n",
      "iteration: 196 | loss: 2.375435\n",
      "iteration: 197 | loss: 2.081570\n",
      "iteration: 198 | loss: 1.681612\n",
      "iteration: 199 | loss: 1.967916\n",
      "  Train acc: 0.32, Val acc: 0.0\n",
      "iteration: 200 | loss: 2.321357\n",
      "iteration: 201 | loss: 2.268582\n",
      "iteration: 202 | loss: 1.897659\n",
      "iteration: 203 | loss: 1.984214\n",
      "iteration: 204 | loss: 1.812873\n",
      "iteration: 205 | loss: 1.860846\n",
      "iteration: 206 | loss: 1.849318\n",
      "iteration: 207 | loss: 1.933531\n",
      "iteration: 208 | loss: 1.583120\n",
      "iteration: 209 | loss: 1.877587\n",
      "iteration: 210 | loss: 1.904456\n",
      "iteration: 211 | loss: 1.949637\n",
      "iteration: 212 | loss: 2.187093\n",
      "iteration: 213 | loss: 1.850827\n",
      "iteration: 214 | loss: 1.722839\n",
      "iteration: 215 | loss: 2.129700\n",
      "iteration: 216 | loss: 2.130986\n",
      "iteration: 217 | loss: 1.503282\n",
      "iteration: 218 | loss: 1.311059\n",
      "iteration: 219 | loss: 1.949869\n",
      "iteration: 220 | loss: 2.135697\n",
      "iteration: 221 | loss: 1.997742\n",
      "iteration: 222 | loss: 1.679084\n",
      "iteration: 223 | loss: 1.595358\n",
      "iteration: 224 | loss: 1.804959\n",
      "  Train acc: 0.42, Val acc: 0.0\n",
      "iteration: 225 | loss: 1.876231\n",
      "iteration: 226 | loss: 1.582812\n",
      "iteration: 227 | loss: 1.906233\n",
      "iteration: 228 | loss: 1.866927\n",
      "iteration: 229 | loss: 1.572280\n",
      "iteration: 230 | loss: 1.593808\n",
      "iteration: 231 | loss: 1.403569\n",
      "iteration: 232 | loss: 1.511274\n",
      "iteration: 233 | loss: 1.398353\n",
      "iteration: 234 | loss: 0.891708\n",
      "iteration: 235 | loss: 1.209688\n",
      "iteration: 236 | loss: 1.744100\n",
      "iteration: 237 | loss: 1.730313\n",
      "iteration: 238 | loss: 2.074470\n",
      "iteration: 239 | loss: 0.742220\n",
      "iteration: 240 | loss: 3.315809\n",
      "iteration: 241 | loss: 1.927142\n",
      "iteration: 242 | loss: 1.240417\n",
      "iteration: 243 | loss: 1.299516\n",
      "iteration: 244 | loss: 1.290408\n",
      "iteration: 245 | loss: 1.399554\n",
      "iteration: 246 | loss: 1.852233\n",
      "iteration: 247 | loss: 1.499813\n",
      "iteration: 248 | loss: 1.816302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 249 | loss: 1.369068\n",
      "  Train acc: 0.44, Val acc: 0.0\n",
      "iteration: 250 | loss: 1.515274\n",
      "iteration: 251 | loss: 1.840173\n",
      "iteration: 252 | loss: 1.030678\n",
      "iteration: 253 | loss: 1.323466\n",
      "iteration: 254 | loss: 1.990374\n",
      "iteration: 255 | loss: 1.102575\n",
      "iteration: 256 | loss: 1.732923\n",
      "iteration: 257 | loss: 1.080395\n",
      "iteration: 258 | loss: 2.043656\n",
      "iteration: 259 | loss: 1.528329\n",
      "iteration: 260 | loss: 1.199331\n",
      "iteration: 261 | loss: 1.417523\n",
      "iteration: 262 | loss: 1.505601\n",
      "iteration: 263 | loss: 1.281148\n",
      "iteration: 264 | loss: 1.597979\n",
      "iteration: 265 | loss: 1.625816\n",
      "iteration: 266 | loss: 1.555456\n",
      "iteration: 267 | loss: 1.599379\n",
      "iteration: 268 | loss: 1.659737\n",
      "iteration: 269 | loss: 1.423126\n",
      "iteration: 270 | loss: 1.482484\n",
      "iteration: 271 | loss: 1.412737\n",
      "iteration: 272 | loss: 1.336268\n",
      "iteration: 273 | loss: 1.490853\n",
      "iteration: 274 | loss: 1.254568\n",
      "  Train acc: 0.48, Val acc: 0.0\n",
      "iteration: 275 | loss: 1.225690\n",
      "iteration: 276 | loss: 1.628925\n",
      "iteration: 277 | loss: 1.513931\n",
      "iteration: 278 | loss: 1.251826\n",
      "iteration: 279 | loss: 1.518864\n",
      "iteration: 280 | loss: 0.902811\n",
      "iteration: 281 | loss: 1.387168\n",
      "iteration: 282 | loss: 1.305055\n",
      "iteration: 283 | loss: 1.082423\n",
      "iteration: 284 | loss: 1.376750\n",
      "iteration: 285 | loss: 1.045316\n",
      "iteration: 286 | loss: 1.253149\n",
      "iteration: 287 | loss: 1.718091\n",
      "iteration: 288 | loss: 1.532749\n",
      "iteration: 289 | loss: 1.541356\n",
      "iteration: 290 | loss: 0.846993\n",
      "iteration: 291 | loss: 1.093620\n",
      "iteration: 292 | loss: 1.796099\n",
      "iteration: 293 | loss: 1.853835\n",
      "iteration: 294 | loss: 0.977429\n",
      "iteration: 295 | loss: 1.160175\n",
      "iteration: 296 | loss: 1.482121\n",
      "iteration: 297 | loss: 1.413935\n",
      "iteration: 298 | loss: 1.187970\n",
      "iteration: 299 | loss: 2.320112\n",
      "  Train acc: 0.54, Val acc: 0.0\n",
      "iteration: 300 | loss: 1.534491\n",
      "iteration: 301 | loss: 1.577660\n",
      "iteration: 302 | loss: 0.735011\n",
      "iteration: 303 | loss: 0.965631\n",
      "iteration: 304 | loss: 1.189689\n",
      "iteration: 305 | loss: 1.016720\n",
      "iteration: 306 | loss: 1.523093\n",
      "iteration: 307 | loss: 1.907268\n",
      "iteration: 308 | loss: 1.331822\n",
      "iteration: 309 | loss: 1.160320\n",
      "iteration: 310 | loss: 1.036823\n",
      "iteration: 311 | loss: 1.424189\n",
      "iteration: 312 | loss: 1.330339\n",
      "iteration: 313 | loss: 1.137968\n",
      "iteration: 314 | loss: 1.266355\n",
      "iteration: 315 | loss: 1.006977\n",
      "iteration: 316 | loss: 1.142082\n",
      "iteration: 317 | loss: 1.003112\n",
      "iteration: 318 | loss: 1.072350\n",
      "iteration: 319 | loss: 0.914317\n",
      "iteration: 320 | loss: 0.853244\n",
      "iteration: 321 | loss: 0.786063\n",
      "iteration: 322 | loss: 1.217782\n",
      "iteration: 323 | loss: 1.234805\n",
      "iteration: 324 | loss: 1.226286\n",
      "  Train acc: 0.68, Val acc: 0.0\n",
      "iteration: 325 | loss: 1.416863\n",
      "iteration: 326 | loss: 0.836905\n",
      "iteration: 327 | loss: 0.701891\n",
      "iteration: 328 | loss: 0.903567\n",
      "iteration: 329 | loss: 0.759762\n",
      "iteration: 330 | loss: 0.890691\n",
      "iteration: 331 | loss: 0.843314\n",
      "iteration: 332 | loss: 1.173703\n",
      "iteration: 333 | loss: 0.812084\n",
      "iteration: 334 | loss: 1.111773\n",
      "iteration: 335 | loss: 0.991476\n",
      "iteration: 336 | loss: 0.791479\n",
      "iteration: 337 | loss: 1.082077\n",
      "iteration: 338 | loss: 1.095641\n",
      "iteration: 339 | loss: 1.210654\n",
      "iteration: 340 | loss: 0.623859\n",
      "iteration: 341 | loss: 0.571689\n",
      "iteration: 342 | loss: 1.203421\n",
      "iteration: 343 | loss: 0.870748\n",
      "iteration: 344 | loss: 1.339387\n",
      "iteration: 345 | loss: 0.550871\n",
      "iteration: 346 | loss: 1.251055\n",
      "iteration: 347 | loss: 0.964701\n",
      "iteration: 348 | loss: 0.784356\n",
      "iteration: 349 | loss: 0.693716\n",
      "  Train acc: 0.72, Val acc: 0.0\n",
      "iteration: 350 | loss: 1.761057\n",
      "iteration: 351 | loss: 1.117672\n",
      "iteration: 352 | loss: 0.563381\n",
      "iteration: 353 | loss: 0.898068\n",
      "iteration: 354 | loss: 1.018876\n",
      "iteration: 355 | loss: 0.723719\n",
      "iteration: 356 | loss: 0.699863\n",
      "iteration: 357 | loss: 0.661866\n",
      "iteration: 358 | loss: 0.584583\n",
      "iteration: 359 | loss: 0.861101\n",
      "iteration: 360 | loss: 0.878320\n",
      "iteration: 361 | loss: 0.837093\n",
      "iteration: 362 | loss: 0.607208\n",
      "iteration: 363 | loss: 0.545721\n",
      "iteration: 364 | loss: 0.604564\n",
      "iteration: 365 | loss: 0.397879\n",
      "iteration: 366 | loss: 0.465528\n",
      "iteration: 367 | loss: 0.544053\n",
      "iteration: 368 | loss: 0.883812\n",
      "iteration: 369 | loss: 0.690969\n",
      "iteration: 370 | loss: 0.281280\n",
      "iteration: 371 | loss: 0.535756\n",
      "iteration: 372 | loss: 0.425548\n",
      "iteration: 373 | loss: 0.718047\n",
      "iteration: 374 | loss: 0.381688\n",
      "  Train acc: 0.78, Val acc: 0.0\n",
      "iteration: 375 | loss: 0.617669\n",
      "iteration: 376 | loss: 0.682300\n",
      "iteration: 377 | loss: 0.434213\n",
      "iteration: 378 | loss: 0.803574\n",
      "iteration: 379 | loss: 0.486923\n",
      "iteration: 380 | loss: 0.375368\n",
      "iteration: 381 | loss: 0.603766\n",
      "iteration: 382 | loss: 0.328603\n",
      "iteration: 383 | loss: 0.418020\n",
      "iteration: 384 | loss: 0.233173\n",
      "iteration: 385 | loss: 0.462878\n",
      "iteration: 386 | loss: 0.298617\n",
      "iteration: 387 | loss: 0.300907\n",
      "iteration: 388 | loss: 0.477942\n",
      "iteration: 389 | loss: 0.311744\n",
      "iteration: 390 | loss: 0.372838\n",
      "iteration: 391 | loss: 0.368517\n",
      "iteration: 392 | loss: 0.619484\n",
      "iteration: 393 | loss: 0.215450\n",
      "iteration: 394 | loss: 0.238090\n",
      "iteration: 395 | loss: 0.425558\n",
      "iteration: 396 | loss: 0.240067\n",
      "iteration: 397 | loss: 0.361598\n",
      "iteration: 398 | loss: 0.365171\n",
      "iteration: 399 | loss: 0.200112\n",
      "  Train acc: 0.92, Val acc: 0.0\n",
      "iteration: 400 | loss: 0.380186\n",
      "iteration: 401 | loss: 0.491737\n",
      "iteration: 402 | loss: 0.141050\n",
      "iteration: 403 | loss: 0.388734\n",
      "iteration: 404 | loss: 0.306931\n",
      "iteration: 405 | loss: 0.295810\n",
      "iteration: 406 | loss: 0.375856\n",
      "iteration: 407 | loss: 0.409335\n",
      "iteration: 408 | loss: 0.210642\n",
      "iteration: 409 | loss: 0.313236\n",
      "iteration: 410 | loss: 0.575358\n",
      "iteration: 411 | loss: 0.154338\n",
      "iteration: 412 | loss: 0.212482\n",
      "iteration: 413 | loss: 0.087135\n",
      "iteration: 414 | loss: 0.155942\n",
      "iteration: 415 | loss: 0.230616\n",
      "iteration: 416 | loss: 0.248319\n",
      "iteration: 417 | loss: 0.225157\n",
      "iteration: 418 | loss: 0.249971\n",
      "iteration: 419 | loss: 0.135746\n",
      "iteration: 420 | loss: 0.120391\n",
      "iteration: 421 | loss: 0.163526\n",
      "iteration: 422 | loss: 0.150350\n",
      "iteration: 423 | loss: 0.090668\n",
      "iteration: 424 | loss: 0.183586\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 425 | loss: 0.105948\n",
      "iteration: 426 | loss: 0.147593\n",
      "iteration: 427 | loss: 0.080375\n",
      "iteration: 428 | loss: 0.108103\n",
      "iteration: 429 | loss: 0.229978\n",
      "iteration: 430 | loss: 0.285665\n",
      "iteration: 431 | loss: 0.053004\n",
      "iteration: 432 | loss: 0.056421\n",
      "iteration: 433 | loss: 0.120643\n",
      "iteration: 434 | loss: 0.077404\n",
      "iteration: 435 | loss: 0.154056\n",
      "iteration: 436 | loss: 0.069432\n",
      "iteration: 437 | loss: 0.267962\n",
      "iteration: 438 | loss: 0.075421\n",
      "iteration: 439 | loss: 0.186234\n",
      "iteration: 440 | loss: 0.104608\n",
      "iteration: 441 | loss: 0.093333\n",
      "iteration: 442 | loss: 0.062179\n",
      "iteration: 443 | loss: 0.147739\n",
      "iteration: 444 | loss: 0.098776\n",
      "iteration: 445 | loss: 0.097287\n",
      "iteration: 446 | loss: 0.073665\n",
      "iteration: 447 | loss: 0.575951\n",
      "iteration: 448 | loss: 0.050372\n",
      "iteration: 449 | loss: 0.154139\n",
      "  Train acc: 0.94, Val acc: 0.0\n",
      "iteration: 450 | loss: 0.105121\n",
      "iteration: 451 | loss: 0.104392\n",
      "iteration: 452 | loss: 0.146462\n",
      "iteration: 453 | loss: 0.897154\n",
      "iteration: 454 | loss: 0.046629\n",
      "iteration: 455 | loss: 0.403745\n",
      "iteration: 456 | loss: 0.046472\n",
      "iteration: 457 | loss: 0.029923\n",
      "iteration: 458 | loss: 0.191936\n",
      "iteration: 459 | loss: 0.119867\n",
      "iteration: 460 | loss: 0.585192\n",
      "iteration: 461 | loss: 0.061447\n",
      "iteration: 462 | loss: 0.063306\n",
      "iteration: 463 | loss: 0.371202\n",
      "iteration: 464 | loss: 0.092382\n",
      "iteration: 465 | loss: 0.031470\n",
      "iteration: 466 | loss: 0.498019\n",
      "iteration: 467 | loss: 0.062286\n",
      "iteration: 468 | loss: 0.060726\n",
      "iteration: 469 | loss: 0.037805\n",
      "iteration: 470 | loss: 0.376288\n",
      "iteration: 471 | loss: 0.072091\n",
      "iteration: 472 | loss: 0.051726\n",
      "iteration: 473 | loss: 0.100400\n",
      "iteration: 474 | loss: 0.156636\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 475 | loss: 0.071552\n",
      "iteration: 476 | loss: 0.022106\n",
      "iteration: 477 | loss: 0.017636\n",
      "iteration: 478 | loss: 0.075303\n",
      "iteration: 479 | loss: 0.055190\n",
      "iteration: 480 | loss: 0.057190\n",
      "iteration: 481 | loss: 0.027377\n",
      "iteration: 482 | loss: 0.080545\n",
      "iteration: 483 | loss: 0.039388\n",
      "iteration: 484 | loss: 0.054422\n",
      "iteration: 485 | loss: 0.015532\n",
      "iteration: 486 | loss: 0.075983\n",
      "iteration: 487 | loss: 0.075381\n",
      "iteration: 488 | loss: 0.027759\n",
      "iteration: 489 | loss: 0.057601\n",
      "iteration: 490 | loss: 0.058247\n",
      "iteration: 491 | loss: 0.062946\n",
      "iteration: 492 | loss: 0.021614\n",
      "iteration: 493 | loss: 0.023952\n",
      "iteration: 494 | loss: 0.028008\n",
      "iteration: 495 | loss: 0.025503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 496 | loss: 0.027960\n",
      "iteration: 497 | loss: 0.027557\n",
      "iteration: 498 | loss: 0.025391\n",
      "iteration: 499 | loss: 0.030828\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 500 | loss: 0.031399\n",
      "iteration: 501 | loss: 0.040884\n",
      "iteration: 502 | loss: 0.052458\n",
      "iteration: 503 | loss: 0.050488\n",
      "iteration: 504 | loss: 0.037958\n",
      "iteration: 505 | loss: 0.031592\n",
      "iteration: 506 | loss: 0.014903\n",
      "iteration: 507 | loss: 0.017488\n",
      "iteration: 508 | loss: 0.018324\n",
      "iteration: 509 | loss: 0.048792\n",
      "iteration: 510 | loss: 0.017672\n",
      "iteration: 511 | loss: 0.023012\n",
      "iteration: 512 | loss: 0.017982\n",
      "iteration: 513 | loss: 0.008513\n",
      "iteration: 514 | loss: 0.009571\n",
      "iteration: 515 | loss: 0.015727\n",
      "iteration: 516 | loss: 0.015311\n",
      "iteration: 517 | loss: 0.032168\n",
      "iteration: 518 | loss: 0.015084\n",
      "iteration: 519 | loss: 0.012742\n",
      "iteration: 520 | loss: 0.022506\n",
      "iteration: 521 | loss: 0.018275\n",
      "iteration: 522 | loss: 0.027211\n",
      "iteration: 523 | loss: 0.022243\n",
      "iteration: 524 | loss: 0.012077\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 525 | loss: 0.024768\n",
      "iteration: 526 | loss: 0.024261\n",
      "iteration: 527 | loss: 0.004727\n",
      "iteration: 528 | loss: 0.013899\n",
      "iteration: 529 | loss: 0.012855\n",
      "iteration: 530 | loss: 0.022785\n",
      "iteration: 531 | loss: 0.007804\n",
      "iteration: 532 | loss: 0.012572\n",
      "iteration: 533 | loss: 0.025534\n",
      "iteration: 534 | loss: 0.013029\n",
      "iteration: 535 | loss: 0.008472\n",
      "iteration: 536 | loss: 0.006633\n",
      "iteration: 537 | loss: 0.014581\n",
      "iteration: 538 | loss: 0.057226\n",
      "iteration: 539 | loss: 0.012360\n",
      "iteration: 540 | loss: 0.008972\n",
      "iteration: 541 | loss: 0.017147\n",
      "iteration: 542 | loss: 0.016200\n",
      "iteration: 543 | loss: 0.013855\n",
      "iteration: 544 | loss: 0.016419\n",
      "iteration: 545 | loss: 0.037926\n",
      "iteration: 546 | loss: 0.014116\n",
      "iteration: 547 | loss: 0.007109\n",
      "iteration: 548 | loss: 0.017430\n",
      "iteration: 549 | loss: 0.006107\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 550 | loss: 0.015795\n",
      "iteration: 551 | loss: 0.018434\n",
      "iteration: 552 | loss: 0.009778\n",
      "iteration: 553 | loss: 0.009141\n",
      "iteration: 554 | loss: 0.011536\n",
      "iteration: 555 | loss: 0.018115\n",
      "iteration: 556 | loss: 0.015517\n",
      "iteration: 557 | loss: 0.013087\n",
      "iteration: 558 | loss: 0.012062\n",
      "iteration: 559 | loss: 0.008434\n",
      "iteration: 560 | loss: 0.007666\n",
      "iteration: 561 | loss: 0.010407\n",
      "iteration: 562 | loss: 0.007892\n",
      "iteration: 563 | loss: 0.013493\n",
      "iteration: 564 | loss: 0.011284\n",
      "iteration: 565 | loss: 0.007344\n",
      "iteration: 566 | loss: 0.008940\n",
      "iteration: 567 | loss: 0.008835\n",
      "iteration: 568 | loss: 0.015870\n",
      "iteration: 569 | loss: 0.008159\n",
      "iteration: 570 | loss: 0.013403\n",
      "iteration: 571 | loss: 0.010106\n",
      "iteration: 572 | loss: 0.018349\n",
      "iteration: 573 | loss: 0.003924\n",
      "iteration: 574 | loss: 0.009834\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 575 | loss: 0.016021\n",
      "iteration: 576 | loss: 0.008952\n",
      "iteration: 577 | loss: 0.007681\n",
      "iteration: 578 | loss: 0.014221\n",
      "iteration: 579 | loss: 0.006352\n",
      "iteration: 580 | loss: 0.008062\n",
      "iteration: 581 | loss: 0.010729\n",
      "iteration: 582 | loss: 0.010191\n",
      "iteration: 583 | loss: 0.011802\n",
      "iteration: 584 | loss: 0.006930\n",
      "iteration: 585 | loss: 0.009439\n",
      "iteration: 586 | loss: 0.008075\n",
      "iteration: 587 | loss: 0.007520\n",
      "iteration: 588 | loss: 0.013256\n",
      "iteration: 589 | loss: 0.010029\n",
      "iteration: 590 | loss: 0.005904\n",
      "iteration: 591 | loss: 0.006996\n",
      "iteration: 592 | loss: 0.005174\n",
      "iteration: 593 | loss: 0.014151\n",
      "iteration: 594 | loss: 0.015872\n",
      "iteration: 595 | loss: 0.014410\n",
      "iteration: 596 | loss: 0.007559\n",
      "iteration: 597 | loss: 0.007687\n",
      "iteration: 598 | loss: 0.007982\n",
      "iteration: 599 | loss: 0.006667\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 600 | loss: 0.005930\n",
      "iteration: 601 | loss: 0.008884\n",
      "iteration: 602 | loss: 0.003483\n",
      "iteration: 603 | loss: 0.005620\n",
      "iteration: 604 | loss: 0.007238\n",
      "iteration: 605 | loss: 0.015127\n",
      "iteration: 606 | loss: 0.007695\n",
      "iteration: 607 | loss: 0.003260\n",
      "iteration: 608 | loss: 0.008557\n",
      "iteration: 609 | loss: 0.005056\n",
      "iteration: 610 | loss: 0.004350\n",
      "iteration: 611 | loss: 0.006100\n",
      "iteration: 612 | loss: 0.009577\n",
      "iteration: 613 | loss: 0.007500\n",
      "iteration: 614 | loss: 0.008970\n",
      "iteration: 615 | loss: 0.004981\n",
      "iteration: 616 | loss: 0.008071\n",
      "iteration: 617 | loss: 0.007826\n",
      "iteration: 618 | loss: 0.004932\n",
      "iteration: 619 | loss: 0.005889\n",
      "iteration: 620 | loss: 0.005336\n",
      "iteration: 621 | loss: 0.005732\n",
      "iteration: 622 | loss: 0.002243\n",
      "iteration: 623 | loss: 0.004437\n",
      "iteration: 624 | loss: 0.007384\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 625 | loss: 0.007267\n",
      "iteration: 626 | loss: 0.008164\n",
      "iteration: 627 | loss: 0.006649\n",
      "iteration: 628 | loss: 0.005963\n",
      "iteration: 629 | loss: 0.007742\n",
      "iteration: 630 | loss: 0.008053\n",
      "iteration: 631 | loss: 0.005785\n",
      "iteration: 632 | loss: 0.005135\n",
      "iteration: 633 | loss: 0.009162\n",
      "iteration: 634 | loss: 0.005245\n",
      "iteration: 635 | loss: 0.006972\n",
      "iteration: 636 | loss: 0.003591\n",
      "iteration: 637 | loss: 0.004876\n",
      "iteration: 638 | loss: 0.003426\n",
      "iteration: 639 | loss: 0.004373\n",
      "iteration: 640 | loss: 0.005221\n",
      "iteration: 641 | loss: 0.003991\n",
      "iteration: 642 | loss: 0.007117\n",
      "iteration: 643 | loss: 0.006428\n",
      "iteration: 644 | loss: 0.007508\n",
      "iteration: 645 | loss: 0.005315\n",
      "iteration: 646 | loss: 0.006663\n",
      "iteration: 647 | loss: 0.005516\n",
      "iteration: 648 | loss: 0.008188\n",
      "iteration: 649 | loss: 0.008547\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 650 | loss: 0.005874\n",
      "iteration: 651 | loss: 0.007243\n",
      "iteration: 652 | loss: 0.004046\n",
      "iteration: 653 | loss: 0.006001\n",
      "iteration: 654 | loss: 0.008063\n",
      "iteration: 655 | loss: 0.008243\n",
      "iteration: 656 | loss: 0.008836\n",
      "iteration: 657 | loss: 0.006929\n",
      "iteration: 658 | loss: 0.009142\n",
      "iteration: 659 | loss: 0.004977\n",
      "iteration: 660 | loss: 0.007531\n",
      "iteration: 661 | loss: 0.009364\n",
      "iteration: 662 | loss: 0.006031\n",
      "iteration: 663 | loss: 0.005156\n",
      "iteration: 664 | loss: 0.003910\n",
      "iteration: 665 | loss: 0.003272\n",
      "iteration: 666 | loss: 0.004310\n",
      "iteration: 667 | loss: 0.004700\n",
      "iteration: 668 | loss: 0.003705\n",
      "iteration: 669 | loss: 0.005549\n",
      "iteration: 670 | loss: 0.007468\n",
      "iteration: 671 | loss: 0.010166\n",
      "iteration: 672 | loss: 0.003727\n",
      "iteration: 673 | loss: 0.004986\n",
      "iteration: 674 | loss: 0.005897\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 675 | loss: 0.006725\n",
      "iteration: 676 | loss: 0.004899\n",
      "iteration: 677 | loss: 0.006925\n",
      "iteration: 678 | loss: 0.007686\n",
      "iteration: 679 | loss: 0.004738\n",
      "iteration: 680 | loss: 0.007959\n",
      "iteration: 681 | loss: 0.006397\n",
      "iteration: 682 | loss: 0.004004\n",
      "iteration: 683 | loss: 0.006271\n",
      "iteration: 684 | loss: 0.005111\n",
      "iteration: 685 | loss: 0.003940\n",
      "iteration: 686 | loss: 0.006892\n",
      "iteration: 687 | loss: 0.003500\n",
      "iteration: 688 | loss: 0.004449\n",
      "iteration: 689 | loss: 0.004825\n",
      "iteration: 690 | loss: 0.003522\n",
      "iteration: 691 | loss: 0.003700\n",
      "iteration: 692 | loss: 0.003537\n",
      "iteration: 693 | loss: 0.004160\n",
      "iteration: 694 | loss: 0.004690\n",
      "iteration: 695 | loss: 0.003918\n",
      "iteration: 696 | loss: 0.004412\n",
      "iteration: 697 | loss: 0.003109\n",
      "iteration: 698 | loss: 0.002392\n",
      "iteration: 699 | loss: 0.003186\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 700 | loss: 0.003742\n",
      "iteration: 701 | loss: 0.002331\n",
      "iteration: 702 | loss: 0.004503\n",
      "iteration: 703 | loss: 0.003960\n",
      "iteration: 704 | loss: 0.006823\n",
      "iteration: 705 | loss: 0.002194\n",
      "iteration: 706 | loss: 0.003337\n",
      "iteration: 707 | loss: 0.006837\n",
      "iteration: 708 | loss: 0.004350\n",
      "iteration: 709 | loss: 0.004118\n",
      "iteration: 710 | loss: 0.003786\n",
      "iteration: 711 | loss: 0.004895\n",
      "iteration: 712 | loss: 0.003544\n",
      "iteration: 713 | loss: 0.004154\n",
      "iteration: 714 | loss: 0.004620\n",
      "iteration: 715 | loss: 0.003460\n",
      "iteration: 716 | loss: 0.003819\n",
      "iteration: 717 | loss: 0.003574\n",
      "iteration: 718 | loss: 0.005071\n",
      "iteration: 719 | loss: 0.003947\n",
      "iteration: 720 | loss: 0.002464\n",
      "iteration: 721 | loss: 0.005708\n",
      "iteration: 722 | loss: 0.003767\n",
      "iteration: 723 | loss: 0.004084\n",
      "iteration: 724 | loss: 0.004312\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 725 | loss: 0.001518\n",
      "iteration: 726 | loss: 0.003245\n",
      "iteration: 727 | loss: 0.005370\n",
      "iteration: 728 | loss: 0.004360\n",
      "iteration: 729 | loss: 0.003590\n",
      "iteration: 730 | loss: 0.003709\n",
      "iteration: 731 | loss: 0.005297\n",
      "iteration: 732 | loss: 0.004706\n",
      "iteration: 733 | loss: 0.005335\n",
      "iteration: 734 | loss: 0.003643\n",
      "iteration: 735 | loss: 0.005390\n",
      "iteration: 736 | loss: 0.004331\n",
      "iteration: 737 | loss: 0.004450\n",
      "iteration: 738 | loss: 0.004399\n",
      "iteration: 739 | loss: 0.006212\n",
      "iteration: 740 | loss: 0.002414\n",
      "iteration: 741 | loss: 0.002953\n",
      "iteration: 742 | loss: 0.002986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 743 | loss: 0.003949\n",
      "iteration: 744 | loss: 0.005428\n",
      "iteration: 745 | loss: 0.002553\n",
      "iteration: 746 | loss: 0.002421\n",
      "iteration: 747 | loss: 0.002849\n",
      "iteration: 748 | loss: 0.004107\n",
      "iteration: 749 | loss: 0.004694\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 750 | loss: 0.001823\n",
      "iteration: 751 | loss: 0.003597\n",
      "iteration: 752 | loss: 0.003604\n",
      "iteration: 753 | loss: 0.004984\n",
      "iteration: 754 | loss: 0.004537\n",
      "iteration: 755 | loss: 0.004250\n",
      "iteration: 756 | loss: 0.004476\n",
      "iteration: 757 | loss: 0.003150\n",
      "iteration: 758 | loss: 0.003527\n",
      "iteration: 759 | loss: 0.004229\n",
      "iteration: 760 | loss: 0.003495\n",
      "iteration: 761 | loss: 0.004178\n",
      "iteration: 762 | loss: 0.003731\n",
      "iteration: 763 | loss: 0.001788\n",
      "iteration: 764 | loss: 0.003985\n",
      "iteration: 765 | loss: 0.001882\n",
      "iteration: 766 | loss: 0.005767\n",
      "iteration: 767 | loss: 0.002673\n",
      "iteration: 768 | loss: 0.003564\n",
      "iteration: 769 | loss: 0.002574\n",
      "iteration: 770 | loss: 0.003059\n",
      "iteration: 771 | loss: 0.004899\n",
      "iteration: 772 | loss: 0.003631\n",
      "iteration: 773 | loss: 0.001074\n",
      "iteration: 774 | loss: 0.001519\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 775 | loss: 0.003158\n",
      "iteration: 776 | loss: 0.003999\n",
      "iteration: 777 | loss: 0.002399\n",
      "iteration: 778 | loss: 0.002461\n",
      "iteration: 779 | loss: 0.004596\n",
      "iteration: 780 | loss: 0.004801\n",
      "iteration: 781 | loss: 0.002164\n",
      "iteration: 782 | loss: 0.003520\n",
      "iteration: 783 | loss: 0.003986\n",
      "iteration: 784 | loss: 0.005295\n",
      "iteration: 785 | loss: 0.005053\n",
      "iteration: 786 | loss: 0.003178\n",
      "iteration: 787 | loss: 0.002631\n",
      "iteration: 788 | loss: 0.000961\n",
      "iteration: 789 | loss: 0.003600\n",
      "iteration: 790 | loss: 0.001480\n",
      "iteration: 791 | loss: 0.003710\n",
      "iteration: 792 | loss: 0.004628\n",
      "iteration: 793 | loss: 0.003418\n",
      "iteration: 794 | loss: 0.004194\n",
      "iteration: 795 | loss: 0.006860\n",
      "iteration: 796 | loss: 0.001715\n",
      "iteration: 797 | loss: 0.003976\n",
      "iteration: 798 | loss: 0.003296\n",
      "iteration: 799 | loss: 0.002981\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 800 | loss: 0.005289\n",
      "iteration: 801 | loss: 0.002699\n",
      "iteration: 802 | loss: 0.002781\n",
      "iteration: 803 | loss: 0.003209\n",
      "iteration: 804 | loss: 0.003622\n",
      "iteration: 805 | loss: 0.004100\n",
      "iteration: 806 | loss: 0.003893\n",
      "iteration: 807 | loss: 0.003362\n",
      "iteration: 808 | loss: 0.002555\n",
      "iteration: 809 | loss: 0.003675\n",
      "iteration: 810 | loss: 0.003743\n",
      "iteration: 811 | loss: 0.001860\n",
      "iteration: 812 | loss: 0.004331\n",
      "iteration: 813 | loss: 0.002182\n",
      "iteration: 814 | loss: 0.001885\n",
      "iteration: 815 | loss: 0.002265\n",
      "iteration: 816 | loss: 0.003416\n",
      "iteration: 817 | loss: 0.004980\n",
      "iteration: 818 | loss: 0.003109\n",
      "iteration: 819 | loss: 0.003013\n",
      "iteration: 820 | loss: 0.003525\n",
      "iteration: 821 | loss: 0.002306\n",
      "iteration: 822 | loss: 0.002534\n",
      "iteration: 823 | loss: 0.003185\n",
      "iteration: 824 | loss: 0.002165\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 825 | loss: 0.002948\n",
      "iteration: 826 | loss: 0.002120\n",
      "iteration: 827 | loss: 0.003167\n",
      "iteration: 828 | loss: 0.002787\n",
      "iteration: 829 | loss: 0.001768\n",
      "iteration: 830 | loss: 0.002648\n",
      "iteration: 831 | loss: 0.003126\n",
      "iteration: 832 | loss: 0.002339\n",
      "iteration: 833 | loss: 0.002969\n",
      "iteration: 834 | loss: 0.003417\n",
      "iteration: 835 | loss: 0.001357\n",
      "iteration: 836 | loss: 0.002232\n",
      "iteration: 837 | loss: 0.001732\n",
      "iteration: 838 | loss: 0.002702\n",
      "iteration: 839 | loss: 0.002491\n",
      "iteration: 840 | loss: 0.004156\n",
      "iteration: 841 | loss: 0.002796\n",
      "iteration: 842 | loss: 0.001896\n",
      "iteration: 843 | loss: 0.003547\n",
      "iteration: 844 | loss: 0.002289\n",
      "iteration: 845 | loss: 0.001915\n",
      "iteration: 846 | loss: 0.001946\n",
      "iteration: 847 | loss: 0.002477\n",
      "iteration: 848 | loss: 0.002772\n",
      "iteration: 849 | loss: 0.001822\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 850 | loss: 0.003243\n",
      "iteration: 851 | loss: 0.003550\n",
      "iteration: 852 | loss: 0.001717\n",
      "iteration: 853 | loss: 0.003157\n",
      "iteration: 854 | loss: 0.003336\n",
      "iteration: 855 | loss: 0.003821\n",
      "iteration: 856 | loss: 0.002108\n",
      "iteration: 857 | loss: 0.002635\n",
      "iteration: 858 | loss: 0.002413\n",
      "iteration: 859 | loss: 0.002450\n",
      "iteration: 860 | loss: 0.002787\n",
      "iteration: 861 | loss: 0.001655\n",
      "iteration: 862 | loss: 0.002231\n",
      "iteration: 863 | loss: 0.001923\n",
      "iteration: 864 | loss: 0.002552\n",
      "iteration: 865 | loss: 0.001419\n",
      "iteration: 866 | loss: 0.003699\n",
      "iteration: 867 | loss: 0.003077\n",
      "iteration: 868 | loss: 0.002332\n",
      "iteration: 869 | loss: 0.003018\n",
      "iteration: 870 | loss: 0.002745\n",
      "iteration: 871 | loss: 0.002586\n",
      "iteration: 872 | loss: 0.002523\n",
      "iteration: 873 | loss: 0.002049\n",
      "iteration: 874 | loss: 0.003023\n",
      "  Train acc: 1.0, Val acc: 0.0\n"
     ]
    }
   ],
   "source": [
    "# SGD-M\n",
    "sgdm_net = ConvNet4(input_shape=(3, 16, 16), wt_scale=1e-2, verbose=False)\n",
    "sgdm_net.compile(\"SGD-M\", lr=0.01)\n",
    "\n",
    "sgdm_net.fit(x_dev, y_dev, x_val, y_val, mini_batch_sz=10, n_epochs=175, acc_freq=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train...\n",
      "875 iterations. 5 iter/epoch.\n",
      "iteration: 0 | loss: 2.300644\n",
      "iteration: 1 | loss: 2.300449\n",
      "iteration: 2 | loss: 2.302743\n",
      "iteration: 3 | loss: 2.302921\n",
      "iteration: 4 | loss: 2.302095\n",
      "iteration: 5 | loss: 2.301102\n",
      "iteration: 6 | loss: 2.301231\n",
      "iteration: 7 | loss: 2.299756\n",
      "iteration: 8 | loss: 2.305006\n",
      "iteration: 9 | loss: 2.301651\n",
      "iteration: 10 | loss: 2.302470\n",
      "iteration: 11 | loss: 2.300187\n",
      "iteration: 12 | loss: 2.299066\n",
      "iteration: 13 | loss: 2.302951\n",
      "iteration: 14 | loss: 2.300320\n",
      "iteration: 15 | loss: 2.298186\n",
      "iteration: 16 | loss: 2.299013\n",
      "iteration: 17 | loss: 2.297645\n",
      "iteration: 18 | loss: 2.298742\n",
      "iteration: 19 | loss: 2.304108\n",
      "iteration: 20 | loss: 2.297130\n",
      "iteration: 21 | loss: 2.296136\n",
      "iteration: 22 | loss: 2.294908\n",
      "iteration: 23 | loss: 2.298993\n",
      "iteration: 24 | loss: 2.291690\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 25 | loss: 2.289306\n",
      "iteration: 26 | loss: 2.304126\n",
      "iteration: 27 | loss: 2.297591\n",
      "iteration: 28 | loss: 2.282178\n",
      "iteration: 29 | loss: 2.298603\n",
      "iteration: 30 | loss: 2.302607\n",
      "iteration: 31 | loss: 2.293271\n",
      "iteration: 32 | loss: 2.284159\n",
      "iteration: 33 | loss: 2.298112\n",
      "iteration: 34 | loss: 2.286482\n",
      "iteration: 35 | loss: 2.293628\n",
      "iteration: 36 | loss: 2.280569\n",
      "iteration: 37 | loss: 2.283306\n",
      "iteration: 38 | loss: 2.298012\n",
      "iteration: 39 | loss: 2.285897\n",
      "iteration: 40 | loss: 2.290353\n",
      "iteration: 41 | loss: 2.293339\n",
      "iteration: 42 | loss: 2.299007\n",
      "iteration: 43 | loss: 2.286632\n",
      "iteration: 44 | loss: 2.305861\n",
      "iteration: 45 | loss: 2.303870\n",
      "iteration: 46 | loss: 2.285126\n",
      "iteration: 47 | loss: 2.290368\n",
      "iteration: 48 | loss: 2.281962\n",
      "iteration: 49 | loss: 2.281682\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 50 | loss: 2.296283\n",
      "iteration: 51 | loss: 2.288219\n",
      "iteration: 52 | loss: 2.290960\n",
      "iteration: 53 | loss: 2.282458\n",
      "iteration: 54 | loss: 2.289883\n",
      "iteration: 55 | loss: 2.299935\n",
      "iteration: 56 | loss: 2.292675\n",
      "iteration: 57 | loss: 2.257813\n",
      "iteration: 58 | loss: 2.276557\n",
      "iteration: 59 | loss: 2.283827\n",
      "iteration: 60 | loss: 2.285916\n",
      "iteration: 61 | loss: 2.267767\n",
      "iteration: 62 | loss: 2.286229\n",
      "iteration: 63 | loss: 2.313020\n",
      "iteration: 64 | loss: 2.306168\n",
      "iteration: 65 | loss: 2.289477\n",
      "iteration: 66 | loss: 2.296931\n",
      "iteration: 67 | loss: 2.280675\n",
      "iteration: 68 | loss: 2.307689\n",
      "iteration: 69 | loss: 2.291160\n",
      "iteration: 70 | loss: 2.273318\n",
      "iteration: 71 | loss: 2.279414\n",
      "iteration: 72 | loss: 2.288883\n",
      "iteration: 73 | loss: 2.281290\n",
      "iteration: 74 | loss: 2.307981\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 75 | loss: 2.283734\n",
      "iteration: 76 | loss: 2.301918\n",
      "iteration: 77 | loss: 2.279915\n",
      "iteration: 78 | loss: 2.280000\n",
      "iteration: 79 | loss: 2.255374\n",
      "iteration: 80 | loss: 2.298460\n",
      "iteration: 81 | loss: 2.270889\n",
      "iteration: 82 | loss: 2.283471\n",
      "iteration: 83 | loss: 2.246820\n",
      "iteration: 84 | loss: 2.287837\n",
      "iteration: 85 | loss: 2.280331\n",
      "iteration: 86 | loss: 2.280850\n",
      "iteration: 87 | loss: 2.292866\n",
      "iteration: 88 | loss: 2.255278\n",
      "iteration: 89 | loss: 2.278376\n",
      "iteration: 90 | loss: 2.255933\n",
      "iteration: 91 | loss: 2.289911\n",
      "iteration: 92 | loss: 2.257301\n",
      "iteration: 93 | loss: 2.306128\n",
      "iteration: 94 | loss: 2.301856\n",
      "iteration: 95 | loss: 2.254136\n",
      "iteration: 96 | loss: 2.284915\n",
      "iteration: 97 | loss: 2.265569\n",
      "iteration: 98 | loss: 2.302710\n",
      "iteration: 99 | loss: 2.259265\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 100 | loss: 2.296446\n",
      "iteration: 101 | loss: 2.277544\n",
      "iteration: 102 | loss: 2.265712\n",
      "iteration: 103 | loss: 2.284717\n",
      "iteration: 104 | loss: 2.315909\n",
      "iteration: 105 | loss: 2.282755\n",
      "iteration: 106 | loss: 2.309183\n",
      "iteration: 107 | loss: 2.252053\n",
      "iteration: 108 | loss: 2.284146\n",
      "iteration: 109 | loss: 2.292500\n",
      "iteration: 110 | loss: 2.268571\n",
      "iteration: 111 | loss: 2.283505\n",
      "iteration: 112 | loss: 2.250909\n",
      "iteration: 113 | loss: 2.248760\n",
      "iteration: 114 | loss: 2.290728\n",
      "iteration: 115 | loss: 2.277949\n",
      "iteration: 116 | loss: 2.253328\n",
      "iteration: 117 | loss: 2.280332\n",
      "iteration: 118 | loss: 2.234617\n",
      "iteration: 119 | loss: 2.260813\n",
      "iteration: 120 | loss: 2.298919\n",
      "iteration: 121 | loss: 2.274750\n",
      "iteration: 122 | loss: 2.261325\n",
      "iteration: 123 | loss: 2.294528\n",
      "iteration: 124 | loss: 2.291655\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 125 | loss: 2.264473\n",
      "iteration: 126 | loss: 2.316806\n",
      "iteration: 127 | loss: 2.271125\n",
      "iteration: 128 | loss: 2.242152\n",
      "iteration: 129 | loss: 2.297801\n",
      "iteration: 130 | loss: 2.274650\n",
      "iteration: 131 | loss: 2.284463\n",
      "iteration: 132 | loss: 2.310783\n",
      "iteration: 133 | loss: 2.221958\n",
      "iteration: 134 | loss: 2.242630\n",
      "iteration: 135 | loss: 2.312824\n",
      "iteration: 136 | loss: 2.238213\n",
      "iteration: 137 | loss: 2.253317\n",
      "iteration: 138 | loss: 2.274888\n",
      "iteration: 139 | loss: 2.247727\n",
      "iteration: 140 | loss: 2.321264\n",
      "iteration: 141 | loss: 2.276669\n",
      "iteration: 142 | loss: 2.293885\n",
      "iteration: 143 | loss: 2.249655\n",
      "iteration: 144 | loss: 2.253842\n",
      "iteration: 145 | loss: 2.313044\n",
      "iteration: 146 | loss: 2.298811\n",
      "iteration: 147 | loss: 2.289893\n",
      "iteration: 148 | loss: 2.275172\n",
      "iteration: 149 | loss: 2.299148\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 150 | loss: 2.304109\n",
      "iteration: 151 | loss: 2.243109\n",
      "iteration: 152 | loss: 2.281412\n",
      "iteration: 153 | loss: 2.263436\n",
      "iteration: 154 | loss: 2.287106\n",
      "iteration: 155 | loss: 2.211646\n",
      "iteration: 156 | loss: 2.254786\n",
      "iteration: 157 | loss: 2.243524\n",
      "iteration: 158 | loss: 2.298260\n",
      "iteration: 159 | loss: 2.279713\n",
      "iteration: 160 | loss: 2.238224\n",
      "iteration: 161 | loss: 2.225424\n",
      "iteration: 162 | loss: 2.225853\n",
      "iteration: 163 | loss: 2.249838\n",
      "iteration: 164 | loss: 2.271597\n",
      "iteration: 165 | loss: 2.229714\n",
      "iteration: 166 | loss: 2.239519\n",
      "iteration: 167 | loss: 2.246939\n",
      "iteration: 168 | loss: 2.251575\n",
      "iteration: 169 | loss: 2.241274\n",
      "iteration: 170 | loss: 2.243149\n",
      "iteration: 171 | loss: 2.246310\n",
      "iteration: 172 | loss: 2.261746\n",
      "iteration: 173 | loss: 2.320323\n",
      "iteration: 174 | loss: 2.255165\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 175 | loss: 2.268307\n",
      "iteration: 176 | loss: 2.181057\n",
      "iteration: 177 | loss: 2.275991\n",
      "iteration: 178 | loss: 2.205966\n",
      "iteration: 179 | loss: 2.272154\n",
      "iteration: 180 | loss: 2.316180\n",
      "iteration: 181 | loss: 2.308706\n",
      "iteration: 182 | loss: 2.224771\n",
      "iteration: 183 | loss: 2.316039\n",
      "iteration: 184 | loss: 2.249131\n",
      "iteration: 185 | loss: 2.274175\n",
      "iteration: 186 | loss: 2.250996\n",
      "iteration: 187 | loss: 2.254429\n",
      "iteration: 188 | loss: 2.228367\n",
      "iteration: 189 | loss: 2.232265\n",
      "iteration: 190 | loss: 2.304162\n",
      "iteration: 191 | loss: 2.271411\n",
      "iteration: 192 | loss: 2.238799\n",
      "iteration: 193 | loss: 2.240191\n",
      "iteration: 194 | loss: 2.253821\n",
      "iteration: 195 | loss: 2.228502\n",
      "iteration: 196 | loss: 2.274300\n",
      "iteration: 197 | loss: 2.302919\n",
      "iteration: 198 | loss: 2.212854\n",
      "iteration: 199 | loss: 2.330286\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 200 | loss: 2.204126\n",
      "iteration: 201 | loss: 2.286525\n",
      "iteration: 202 | loss: 2.237783\n",
      "iteration: 203 | loss: 2.274623\n",
      "iteration: 204 | loss: 2.224015\n",
      "iteration: 205 | loss: 2.260049\n",
      "iteration: 206 | loss: 2.178857\n",
      "iteration: 207 | loss: 2.298847\n",
      "iteration: 208 | loss: 2.237335\n",
      "iteration: 209 | loss: 2.296975\n",
      "iteration: 210 | loss: 2.218022\n",
      "iteration: 211 | loss: 2.249949\n",
      "iteration: 212 | loss: 2.273173\n",
      "iteration: 213 | loss: 2.265979\n",
      "iteration: 214 | loss: 2.267127\n",
      "iteration: 215 | loss: 2.305768\n",
      "iteration: 216 | loss: 2.293991\n",
      "iteration: 217 | loss: 2.237391\n",
      "iteration: 218 | loss: 2.262274\n",
      "iteration: 219 | loss: 2.249653\n",
      "iteration: 220 | loss: 2.289398\n",
      "iteration: 221 | loss: 2.258007\n",
      "iteration: 222 | loss: 2.293085\n",
      "iteration: 223 | loss: 2.207496\n",
      "iteration: 224 | loss: 2.284685\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 225 | loss: 2.269465\n",
      "iteration: 226 | loss: 2.263547\n",
      "iteration: 227 | loss: 2.241929\n",
      "iteration: 228 | loss: 2.246569\n",
      "iteration: 229 | loss: 2.229156\n",
      "iteration: 230 | loss: 2.251833\n",
      "iteration: 231 | loss: 2.214776\n",
      "iteration: 232 | loss: 2.292774\n",
      "iteration: 233 | loss: 2.191898\n",
      "iteration: 234 | loss: 2.297096\n",
      "iteration: 235 | loss: 2.259128\n",
      "iteration: 236 | loss: 2.248982\n",
      "iteration: 237 | loss: 2.244760\n",
      "iteration: 238 | loss: 2.188380\n",
      "iteration: 239 | loss: 2.244326\n",
      "iteration: 240 | loss: 2.201912\n",
      "iteration: 241 | loss: 2.218228\n",
      "iteration: 242 | loss: 2.247118\n",
      "iteration: 243 | loss: 2.180341\n",
      "iteration: 244 | loss: 2.238272\n",
      "iteration: 245 | loss: 2.298958\n",
      "iteration: 246 | loss: 2.277121\n",
      "iteration: 247 | loss: 2.309679\n",
      "iteration: 248 | loss: 2.286759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 249 | loss: 2.283222\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 250 | loss: 2.294478\n",
      "iteration: 251 | loss: 2.325553\n",
      "iteration: 252 | loss: 2.211663\n",
      "iteration: 253 | loss: 2.224764\n",
      "iteration: 254 | loss: 2.301177\n",
      "iteration: 255 | loss: 2.185884\n",
      "iteration: 256 | loss: 2.275070\n",
      "iteration: 257 | loss: 2.223639\n",
      "iteration: 258 | loss: 2.252323\n",
      "iteration: 259 | loss: 2.312680\n",
      "iteration: 260 | loss: 2.246883\n",
      "iteration: 261 | loss: 2.195369\n",
      "iteration: 262 | loss: 2.263036\n",
      "iteration: 263 | loss: 2.310740\n",
      "iteration: 264 | loss: 2.208224\n",
      "iteration: 265 | loss: 2.246046\n",
      "iteration: 266 | loss: 2.290648\n",
      "iteration: 267 | loss: 2.216125\n",
      "iteration: 268 | loss: 2.249650\n",
      "iteration: 269 | loss: 2.253761\n",
      "iteration: 270 | loss: 2.239622\n",
      "iteration: 271 | loss: 2.303095\n",
      "iteration: 272 | loss: 2.208991\n",
      "iteration: 273 | loss: 2.254909\n",
      "iteration: 274 | loss: 2.277438\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 275 | loss: 2.261935\n",
      "iteration: 276 | loss: 2.302028\n",
      "iteration: 277 | loss: 2.281834\n",
      "iteration: 278 | loss: 2.243546\n",
      "iteration: 279 | loss: 2.223029\n",
      "iteration: 280 | loss: 2.250113\n",
      "iteration: 281 | loss: 2.160438\n",
      "iteration: 282 | loss: 2.339944\n",
      "iteration: 283 | loss: 2.259604\n",
      "iteration: 284 | loss: 2.212407\n",
      "iteration: 285 | loss: 2.265063\n",
      "iteration: 286 | loss: 2.287412\n",
      "iteration: 287 | loss: 2.213501\n",
      "iteration: 288 | loss: 2.295785\n",
      "iteration: 289 | loss: 2.172994\n",
      "iteration: 290 | loss: 2.234070\n",
      "iteration: 291 | loss: 2.270257\n",
      "iteration: 292 | loss: 2.142214\n",
      "iteration: 293 | loss: 2.187190\n",
      "iteration: 294 | loss: 2.162230\n",
      "iteration: 295 | loss: 2.285944\n",
      "iteration: 296 | loss: 2.294368\n",
      "iteration: 297 | loss: 2.237863\n",
      "iteration: 298 | loss: 2.222940\n",
      "iteration: 299 | loss: 2.214603\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 300 | loss: 2.235697\n",
      "iteration: 301 | loss: 2.252448\n",
      "iteration: 302 | loss: 2.248754\n",
      "iteration: 303 | loss: 2.205542\n",
      "iteration: 304 | loss: 2.233237\n",
      "iteration: 305 | loss: 2.206676\n",
      "iteration: 306 | loss: 2.294739\n",
      "iteration: 307 | loss: 2.242818\n",
      "iteration: 308 | loss: 2.216100\n",
      "iteration: 309 | loss: 2.290786\n",
      "iteration: 310 | loss: 2.211269\n",
      "iteration: 311 | loss: 2.169320\n",
      "iteration: 312 | loss: 2.219336\n",
      "iteration: 313 | loss: 2.202192\n",
      "iteration: 314 | loss: 2.231817\n",
      "iteration: 315 | loss: 2.337651\n",
      "iteration: 316 | loss: 2.178764\n",
      "iteration: 317 | loss: 2.224098\n",
      "iteration: 318 | loss: 2.338237\n",
      "iteration: 319 | loss: 2.238166\n",
      "iteration: 320 | loss: 2.288859\n",
      "iteration: 321 | loss: 2.280755\n",
      "iteration: 322 | loss: 2.239960\n",
      "iteration: 323 | loss: 2.309736\n",
      "iteration: 324 | loss: 2.276284\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 325 | loss: 2.241763\n",
      "iteration: 326 | loss: 2.267404\n",
      "iteration: 327 | loss: 2.299405\n",
      "iteration: 328 | loss: 2.218011\n",
      "iteration: 329 | loss: 2.270631\n",
      "iteration: 330 | loss: 2.190886\n",
      "iteration: 331 | loss: 2.229802\n",
      "iteration: 332 | loss: 2.285808\n",
      "iteration: 333 | loss: 2.253226\n",
      "iteration: 334 | loss: 2.215110\n",
      "iteration: 335 | loss: 2.194772\n",
      "iteration: 336 | loss: 2.249971\n",
      "iteration: 337 | loss: 2.257101\n",
      "iteration: 338 | loss: 2.185799\n",
      "iteration: 339 | loss: 2.296096\n",
      "iteration: 340 | loss: 2.235576\n",
      "iteration: 341 | loss: 2.253359\n",
      "iteration: 342 | loss: 2.149595\n",
      "iteration: 343 | loss: 2.148206\n",
      "iteration: 344 | loss: 2.273214\n",
      "iteration: 345 | loss: 2.254043\n",
      "iteration: 346 | loss: 2.251387\n",
      "iteration: 347 | loss: 2.227734\n",
      "iteration: 348 | loss: 2.217137\n",
      "iteration: 349 | loss: 2.236291\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 350 | loss: 2.234377\n",
      "iteration: 351 | loss: 2.202964\n",
      "iteration: 352 | loss: 2.213535\n",
      "iteration: 353 | loss: 2.288870\n",
      "iteration: 354 | loss: 2.253145\n",
      "iteration: 355 | loss: 2.262812\n",
      "iteration: 356 | loss: 2.284520\n",
      "iteration: 357 | loss: 2.255543\n",
      "iteration: 358 | loss: 2.244360\n",
      "iteration: 359 | loss: 2.268266\n",
      "iteration: 360 | loss: 2.203767\n",
      "iteration: 361 | loss: 2.221117\n",
      "iteration: 362 | loss: 2.297147\n",
      "iteration: 363 | loss: 2.316350\n",
      "iteration: 364 | loss: 2.237942\n",
      "iteration: 365 | loss: 2.299628\n",
      "iteration: 366 | loss: 2.180893\n",
      "iteration: 367 | loss: 2.217690\n",
      "iteration: 368 | loss: 2.233089\n",
      "iteration: 369 | loss: 2.072409\n",
      "iteration: 370 | loss: 2.205891\n",
      "iteration: 371 | loss: 2.281455\n",
      "iteration: 372 | loss: 2.231937\n",
      "iteration: 373 | loss: 2.176629\n",
      "iteration: 374 | loss: 2.258068\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 375 | loss: 2.192668\n",
      "iteration: 376 | loss: 2.226620\n",
      "iteration: 377 | loss: 2.341327\n",
      "iteration: 378 | loss: 2.272282\n",
      "iteration: 379 | loss: 2.271895\n",
      "iteration: 380 | loss: 2.318730\n",
      "iteration: 381 | loss: 2.234044\n",
      "iteration: 382 | loss: 2.325809\n",
      "iteration: 383 | loss: 2.193981\n",
      "iteration: 384 | loss: 2.200033\n",
      "iteration: 385 | loss: 2.198620\n",
      "iteration: 386 | loss: 2.258361\n",
      "iteration: 387 | loss: 2.198881\n",
      "iteration: 388 | loss: 2.162878\n",
      "iteration: 389 | loss: 2.168847\n",
      "iteration: 390 | loss: 2.143134\n",
      "iteration: 391 | loss: 2.176458\n",
      "iteration: 392 | loss: 2.158562\n",
      "iteration: 393 | loss: 2.196021\n",
      "iteration: 394 | loss: 2.143468\n",
      "iteration: 395 | loss: 2.299246\n",
      "iteration: 396 | loss: 2.248937\n",
      "iteration: 397 | loss: 2.185689\n",
      "iteration: 398 | loss: 2.194593\n",
      "iteration: 399 | loss: 2.239123\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 400 | loss: 2.217203\n",
      "iteration: 401 | loss: 2.300673\n",
      "iteration: 402 | loss: 2.242363\n",
      "iteration: 403 | loss: 2.191293\n",
      "iteration: 404 | loss: 2.299743\n",
      "iteration: 405 | loss: 2.280496\n",
      "iteration: 406 | loss: 2.270877\n",
      "iteration: 407 | loss: 2.337728\n",
      "iteration: 408 | loss: 2.304485\n",
      "iteration: 409 | loss: 2.208215\n",
      "iteration: 410 | loss: 2.222749\n",
      "iteration: 411 | loss: 2.174492\n",
      "iteration: 412 | loss: 2.192868\n",
      "iteration: 413 | loss: 2.222475\n",
      "iteration: 414 | loss: 2.251645\n",
      "iteration: 415 | loss: 2.223690\n",
      "iteration: 416 | loss: 2.164046\n",
      "iteration: 417 | loss: 2.234564\n",
      "iteration: 418 | loss: 2.241384\n",
      "iteration: 419 | loss: 2.215267\n",
      "iteration: 420 | loss: 2.230799\n",
      "iteration: 421 | loss: 2.137474\n",
      "iteration: 422 | loss: 2.125582\n",
      "iteration: 423 | loss: 2.217704\n",
      "iteration: 424 | loss: 2.211911\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 425 | loss: 2.264545\n",
      "iteration: 426 | loss: 2.235398\n",
      "iteration: 427 | loss: 2.152825\n",
      "iteration: 428 | loss: 2.120827\n",
      "iteration: 429 | loss: 2.308133\n",
      "iteration: 430 | loss: 2.203135\n",
      "iteration: 431 | loss: 2.331490\n",
      "iteration: 432 | loss: 2.322466\n",
      "iteration: 433 | loss: 2.282092\n",
      "iteration: 434 | loss: 2.212689\n",
      "iteration: 435 | loss: 2.362232\n",
      "iteration: 436 | loss: 2.296452\n",
      "iteration: 437 | loss: 2.323816\n",
      "iteration: 438 | loss: 2.247154\n",
      "iteration: 439 | loss: 2.351758\n",
      "iteration: 440 | loss: 2.233094\n",
      "iteration: 441 | loss: 2.181140\n",
      "iteration: 442 | loss: 2.287149\n",
      "iteration: 443 | loss: 2.106632\n",
      "iteration: 444 | loss: 2.176489\n",
      "iteration: 445 | loss: 2.244764\n",
      "iteration: 446 | loss: 2.201074\n",
      "iteration: 447 | loss: 2.282062\n",
      "iteration: 448 | loss: 2.178810\n",
      "iteration: 449 | loss: 2.176926\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 450 | loss: 2.204423\n",
      "iteration: 451 | loss: 2.235595\n",
      "iteration: 452 | loss: 2.296494\n",
      "iteration: 453 | loss: 2.261758\n",
      "iteration: 454 | loss: 2.078321\n",
      "iteration: 455 | loss: 2.299456\n",
      "iteration: 456 | loss: 2.265624\n",
      "iteration: 457 | loss: 2.217912\n",
      "iteration: 458 | loss: 2.192578\n",
      "iteration: 459 | loss: 2.181860\n",
      "iteration: 460 | loss: 2.127113\n",
      "iteration: 461 | loss: 2.222315\n",
      "iteration: 462 | loss: 2.205029\n",
      "iteration: 463 | loss: 2.327593\n",
      "iteration: 464 | loss: 2.033463\n",
      "iteration: 465 | loss: 2.195815\n",
      "iteration: 466 | loss: 2.339499\n",
      "iteration: 467 | loss: 2.189667\n",
      "iteration: 468 | loss: 2.301435\n",
      "iteration: 469 | loss: 2.227801\n",
      "iteration: 470 | loss: 2.225877\n",
      "iteration: 471 | loss: 2.301424\n",
      "iteration: 472 | loss: 2.297504\n",
      "iteration: 473 | loss: 2.186745\n",
      "iteration: 474 | loss: 2.249156\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 475 | loss: 2.204359\n",
      "iteration: 476 | loss: 2.176651\n",
      "iteration: 477 | loss: 2.182589\n",
      "iteration: 478 | loss: 2.195762\n",
      "iteration: 479 | loss: 2.212254\n",
      "iteration: 480 | loss: 2.272109\n",
      "iteration: 481 | loss: 2.338943\n",
      "iteration: 482 | loss: 2.096634\n",
      "iteration: 483 | loss: 2.376616\n",
      "iteration: 484 | loss: 2.183737\n",
      "iteration: 485 | loss: 2.312137\n",
      "iteration: 486 | loss: 2.186077\n",
      "iteration: 487 | loss: 2.346226\n",
      "iteration: 488 | loss: 2.196253\n",
      "iteration: 489 | loss: 2.227151\n",
      "iteration: 490 | loss: 2.192553\n",
      "iteration: 491 | loss: 2.072985\n",
      "iteration: 492 | loss: 2.275903\n",
      "iteration: 493 | loss: 2.366540\n",
      "iteration: 494 | loss: 2.259419\n",
      "iteration: 495 | loss: 2.233046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 496 | loss: 2.307845\n",
      "iteration: 497 | loss: 2.281409\n",
      "iteration: 498 | loss: 2.204108\n",
      "iteration: 499 | loss: 2.268675\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 500 | loss: 2.249083\n",
      "iteration: 501 | loss: 2.207824\n",
      "iteration: 502 | loss: 2.308731\n",
      "iteration: 503 | loss: 2.132689\n",
      "iteration: 504 | loss: 2.140427\n",
      "iteration: 505 | loss: 2.295780\n",
      "iteration: 506 | loss: 2.299408\n",
      "iteration: 507 | loss: 2.197550\n",
      "iteration: 508 | loss: 2.144609\n",
      "iteration: 509 | loss: 2.337089\n",
      "iteration: 510 | loss: 2.206476\n",
      "iteration: 511 | loss: 2.357511\n",
      "iteration: 512 | loss: 2.191283\n",
      "iteration: 513 | loss: 2.168654\n",
      "iteration: 514 | loss: 2.164884\n",
      "iteration: 515 | loss: 2.246240\n",
      "iteration: 516 | loss: 2.343055\n",
      "iteration: 517 | loss: 2.277666\n",
      "iteration: 518 | loss: 2.242343\n",
      "iteration: 519 | loss: 2.125611\n",
      "iteration: 520 | loss: 2.294891\n",
      "iteration: 521 | loss: 2.264566\n",
      "iteration: 522 | loss: 2.101880\n",
      "iteration: 523 | loss: 2.119111\n",
      "iteration: 524 | loss: 2.290252\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 525 | loss: 2.246140\n",
      "iteration: 526 | loss: 2.303065\n",
      "iteration: 527 | loss: 2.142010\n",
      "iteration: 528 | loss: 2.165950\n",
      "iteration: 529 | loss: 2.201279\n",
      "iteration: 530 | loss: 2.245554\n",
      "iteration: 531 | loss: 2.092381\n",
      "iteration: 532 | loss: 2.175721\n",
      "iteration: 533 | loss: 2.117692\n",
      "iteration: 534 | loss: 2.063699\n",
      "iteration: 535 | loss: 2.211244\n",
      "iteration: 536 | loss: 2.133265\n",
      "iteration: 537 | loss: 2.272759\n",
      "iteration: 538 | loss: 2.248677\n",
      "iteration: 539 | loss: 2.173347\n",
      "iteration: 540 | loss: 2.252674\n",
      "iteration: 541 | loss: 2.250513\n",
      "iteration: 542 | loss: 2.274926\n",
      "iteration: 543 | loss: 2.132358\n",
      "iteration: 544 | loss: 2.288645\n",
      "iteration: 545 | loss: 2.290518\n",
      "iteration: 546 | loss: 2.110486\n",
      "iteration: 547 | loss: 2.053720\n",
      "iteration: 548 | loss: 2.200409\n",
      "iteration: 549 | loss: 2.279171\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 550 | loss: 2.257532\n",
      "iteration: 551 | loss: 2.229736\n",
      "iteration: 552 | loss: 2.207867\n",
      "iteration: 553 | loss: 2.112160\n",
      "iteration: 554 | loss: 2.217414\n",
      "iteration: 555 | loss: 2.047447\n",
      "iteration: 556 | loss: 2.279040\n",
      "iteration: 557 | loss: 2.176539\n",
      "iteration: 558 | loss: 2.260312\n",
      "iteration: 559 | loss: 2.189960\n",
      "iteration: 560 | loss: 2.269344\n",
      "iteration: 561 | loss: 2.292879\n",
      "iteration: 562 | loss: 2.176460\n",
      "iteration: 563 | loss: 2.116139\n",
      "iteration: 564 | loss: 2.196871\n",
      "iteration: 565 | loss: 2.115057\n",
      "iteration: 566 | loss: 2.348507\n",
      "iteration: 567 | loss: 2.134309\n",
      "iteration: 568 | loss: 2.293659\n",
      "iteration: 569 | loss: 2.189762\n",
      "iteration: 570 | loss: 2.165500\n",
      "iteration: 571 | loss: 2.159985\n",
      "iteration: 572 | loss: 2.181164\n",
      "iteration: 573 | loss: 2.202268\n",
      "iteration: 574 | loss: 2.166597\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 575 | loss: 2.222276\n",
      "iteration: 576 | loss: 2.173094\n",
      "iteration: 577 | loss: 2.244752\n",
      "iteration: 578 | loss: 2.166592\n",
      "iteration: 579 | loss: 2.122045\n",
      "iteration: 580 | loss: 2.131050\n",
      "iteration: 581 | loss: 2.233091\n",
      "iteration: 582 | loss: 2.162665\n",
      "iteration: 583 | loss: 2.203767\n",
      "iteration: 584 | loss: 2.244696\n",
      "iteration: 585 | loss: 2.177990\n",
      "iteration: 586 | loss: 2.234095\n",
      "iteration: 587 | loss: 2.246724\n",
      "iteration: 588 | loss: 2.261815\n",
      "iteration: 589 | loss: 2.161646\n",
      "iteration: 590 | loss: 2.194902\n",
      "iteration: 591 | loss: 2.180626\n",
      "iteration: 592 | loss: 2.287477\n",
      "iteration: 593 | loss: 2.177364\n",
      "iteration: 594 | loss: 2.160899\n",
      "iteration: 595 | loss: 2.229243\n",
      "iteration: 596 | loss: 2.112831\n",
      "iteration: 597 | loss: 2.117963\n",
      "iteration: 598 | loss: 2.220988\n",
      "iteration: 599 | loss: 2.124598\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 600 | loss: 2.312552\n",
      "iteration: 601 | loss: 2.313417\n",
      "iteration: 602 | loss: 2.183060\n",
      "iteration: 603 | loss: 2.254798\n",
      "iteration: 604 | loss: 2.309252\n",
      "iteration: 605 | loss: 2.107054\n",
      "iteration: 606 | loss: 2.317865\n",
      "iteration: 607 | loss: 2.312187\n",
      "iteration: 608 | loss: 2.368303\n",
      "iteration: 609 | loss: 2.200303\n",
      "iteration: 610 | loss: 2.190497\n",
      "iteration: 611 | loss: 2.169867\n",
      "iteration: 612 | loss: 2.152819\n",
      "iteration: 613 | loss: 2.271102\n",
      "iteration: 614 | loss: 2.228739\n",
      "iteration: 615 | loss: 2.257023\n",
      "iteration: 616 | loss: 2.187812\n",
      "iteration: 617 | loss: 2.072682\n",
      "iteration: 618 | loss: 2.236155\n",
      "iteration: 619 | loss: 2.102496\n",
      "iteration: 620 | loss: 2.191216\n",
      "iteration: 621 | loss: 2.333983\n",
      "iteration: 622 | loss: 2.214875\n",
      "iteration: 623 | loss: 2.319075\n",
      "iteration: 624 | loss: 2.213192\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 625 | loss: 2.267032\n",
      "iteration: 626 | loss: 2.129109\n",
      "iteration: 627 | loss: 2.176317\n",
      "iteration: 628 | loss: 2.167049\n",
      "iteration: 629 | loss: 2.288630\n",
      "iteration: 630 | loss: 2.362098\n",
      "iteration: 631 | loss: 2.071806\n",
      "iteration: 632 | loss: 2.309879\n",
      "iteration: 633 | loss: 2.160985\n",
      "iteration: 634 | loss: 2.085645\n",
      "iteration: 635 | loss: 2.228265\n",
      "iteration: 636 | loss: 2.106657\n",
      "iteration: 637 | loss: 2.218284\n",
      "iteration: 638 | loss: 2.237892\n",
      "iteration: 639 | loss: 2.109504\n",
      "iteration: 640 | loss: 2.160769\n",
      "iteration: 641 | loss: 2.168755\n",
      "iteration: 642 | loss: 2.328075\n",
      "iteration: 643 | loss: 2.301009\n",
      "iteration: 644 | loss: 2.247157\n",
      "iteration: 645 | loss: 2.196488\n",
      "iteration: 646 | loss: 2.071131\n",
      "iteration: 647 | loss: 2.236982\n",
      "iteration: 648 | loss: 2.246583\n",
      "iteration: 649 | loss: 2.336155\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 650 | loss: 2.207521\n",
      "iteration: 651 | loss: 2.140099\n",
      "iteration: 652 | loss: 2.230355\n",
      "iteration: 653 | loss: 2.130624\n",
      "iteration: 654 | loss: 2.194765\n",
      "iteration: 655 | loss: 2.212954\n",
      "iteration: 656 | loss: 2.159446\n",
      "iteration: 657 | loss: 2.028921\n",
      "iteration: 658 | loss: 2.100036\n",
      "iteration: 659 | loss: 2.247223\n",
      "iteration: 660 | loss: 2.174473\n",
      "iteration: 661 | loss: 2.194416\n",
      "iteration: 662 | loss: 2.225090\n",
      "iteration: 663 | loss: 2.243835\n",
      "iteration: 664 | loss: 2.331344\n",
      "iteration: 665 | loss: 2.085081\n",
      "iteration: 666 | loss: 2.367059\n",
      "iteration: 667 | loss: 2.233417\n",
      "iteration: 668 | loss: 2.148173\n",
      "iteration: 669 | loss: 2.076280\n",
      "iteration: 670 | loss: 2.096197\n",
      "iteration: 671 | loss: 2.145121\n",
      "iteration: 672 | loss: 2.310298\n",
      "iteration: 673 | loss: 2.126367\n",
      "iteration: 674 | loss: 2.055035\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 675 | loss: 2.138180\n",
      "iteration: 676 | loss: 2.257829\n",
      "iteration: 677 | loss: 2.166860\n",
      "iteration: 678 | loss: 2.138457\n",
      "iteration: 679 | loss: 2.260426\n",
      "iteration: 680 | loss: 2.271900\n",
      "iteration: 681 | loss: 2.387995\n",
      "iteration: 682 | loss: 2.112662\n",
      "iteration: 683 | loss: 2.214555\n",
      "iteration: 684 | loss: 2.174775\n",
      "iteration: 685 | loss: 2.165292\n",
      "iteration: 686 | loss: 2.271114\n",
      "iteration: 687 | loss: 2.246419\n",
      "iteration: 688 | loss: 2.264632\n",
      "iteration: 689 | loss: 2.247709\n",
      "iteration: 690 | loss: 2.093104\n",
      "iteration: 691 | loss: 2.239826\n",
      "iteration: 692 | loss: 2.227286\n",
      "iteration: 693 | loss: 2.271087\n",
      "iteration: 694 | loss: 2.081084\n",
      "iteration: 695 | loss: 2.313030\n",
      "iteration: 696 | loss: 2.309996\n",
      "iteration: 697 | loss: 2.132430\n",
      "iteration: 698 | loss: 2.283308\n",
      "iteration: 699 | loss: 2.350936\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 700 | loss: 2.279899\n",
      "iteration: 701 | loss: 2.209717\n",
      "iteration: 702 | loss: 2.289555\n",
      "iteration: 703 | loss: 2.143060\n",
      "iteration: 704 | loss: 2.177510\n",
      "iteration: 705 | loss: 2.106769\n",
      "iteration: 706 | loss: 2.043699\n",
      "iteration: 707 | loss: 2.181902\n",
      "iteration: 708 | loss: 2.264705\n",
      "iteration: 709 | loss: 2.136254\n",
      "iteration: 710 | loss: 2.137940\n",
      "iteration: 711 | loss: 2.298787\n",
      "iteration: 712 | loss: 2.202382\n",
      "iteration: 713 | loss: 2.067896\n",
      "iteration: 714 | loss: 2.142875\n",
      "iteration: 715 | loss: 2.280483\n",
      "iteration: 716 | loss: 2.337721\n",
      "iteration: 717 | loss: 2.207291\n",
      "iteration: 718 | loss: 2.209058\n",
      "iteration: 719 | loss: 2.314982\n",
      "iteration: 720 | loss: 2.240109\n",
      "iteration: 721 | loss: 2.117088\n",
      "iteration: 722 | loss: 2.096213\n",
      "iteration: 723 | loss: 2.192138\n",
      "iteration: 724 | loss: 2.282594\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 725 | loss: 2.219172\n",
      "iteration: 726 | loss: 2.187527\n",
      "iteration: 727 | loss: 2.152377\n",
      "iteration: 728 | loss: 1.887246\n",
      "iteration: 729 | loss: 2.234737\n",
      "iteration: 730 | loss: 2.196360\n",
      "iteration: 731 | loss: 2.167610\n",
      "iteration: 732 | loss: 2.290512\n",
      "iteration: 733 | loss: 2.318384\n",
      "iteration: 734 | loss: 2.135247\n",
      "iteration: 735 | loss: 2.122908\n",
      "iteration: 736 | loss: 2.109429\n",
      "iteration: 737 | loss: 1.987998\n",
      "iteration: 738 | loss: 2.187205\n",
      "iteration: 739 | loss: 2.066727\n",
      "iteration: 740 | loss: 2.098444\n",
      "iteration: 741 | loss: 2.342053\n",
      "iteration: 742 | loss: 2.171573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 743 | loss: 2.143551\n",
      "iteration: 744 | loss: 2.191421\n",
      "iteration: 745 | loss: 2.069762\n",
      "iteration: 746 | loss: 1.995309\n",
      "iteration: 747 | loss: 2.239316\n",
      "iteration: 748 | loss: 2.319143\n",
      "iteration: 749 | loss: 2.234244\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 750 | loss: 2.016032\n",
      "iteration: 751 | loss: 2.074999\n",
      "iteration: 752 | loss: 2.186495\n",
      "iteration: 753 | loss: 2.040985\n",
      "iteration: 754 | loss: 2.154966\n",
      "iteration: 755 | loss: 2.147878\n",
      "iteration: 756 | loss: 2.165466\n",
      "iteration: 757 | loss: 2.171536\n",
      "iteration: 758 | loss: 2.243521\n",
      "iteration: 759 | loss: 2.170554\n",
      "iteration: 760 | loss: 2.123815\n",
      "iteration: 761 | loss: 2.293880\n",
      "iteration: 762 | loss: 2.356025\n",
      "iteration: 763 | loss: 2.262433\n",
      "iteration: 764 | loss: 2.305513\n",
      "iteration: 765 | loss: 2.233374\n",
      "iteration: 766 | loss: 2.030699\n",
      "iteration: 767 | loss: 2.296645\n",
      "iteration: 768 | loss: 2.187771\n",
      "iteration: 769 | loss: 2.074947\n",
      "iteration: 770 | loss: 2.266271\n",
      "iteration: 771 | loss: 2.107900\n",
      "iteration: 772 | loss: 2.339219\n",
      "iteration: 773 | loss: 2.229934\n",
      "iteration: 774 | loss: 2.074976\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 775 | loss: 2.066501\n",
      "iteration: 776 | loss: 2.179593\n",
      "iteration: 777 | loss: 2.233181\n",
      "iteration: 778 | loss: 2.137155\n",
      "iteration: 779 | loss: 2.142782\n",
      "iteration: 780 | loss: 2.174293\n",
      "iteration: 781 | loss: 2.210744\n",
      "iteration: 782 | loss: 2.253269\n",
      "iteration: 783 | loss: 2.091271\n",
      "iteration: 784 | loss: 2.182062\n",
      "iteration: 785 | loss: 2.317407\n",
      "iteration: 786 | loss: 2.214693\n",
      "iteration: 787 | loss: 2.358786\n",
      "iteration: 788 | loss: 2.279089\n",
      "iteration: 789 | loss: 2.327020\n",
      "iteration: 790 | loss: 2.120985\n",
      "iteration: 791 | loss: 2.183781\n",
      "iteration: 792 | loss: 1.957758\n",
      "iteration: 793 | loss: 2.096148\n",
      "iteration: 794 | loss: 2.231740\n",
      "iteration: 795 | loss: 2.405115\n",
      "iteration: 796 | loss: 2.118472\n",
      "iteration: 797 | loss: 2.172527\n",
      "iteration: 798 | loss: 2.297231\n",
      "iteration: 799 | loss: 2.209914\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 800 | loss: 2.120813\n",
      "iteration: 801 | loss: 2.116154\n",
      "iteration: 802 | loss: 2.302933\n",
      "iteration: 803 | loss: 2.147435\n",
      "iteration: 804 | loss: 2.221346\n",
      "iteration: 805 | loss: 2.099162\n",
      "iteration: 806 | loss: 1.904749\n",
      "iteration: 807 | loss: 2.102712\n",
      "iteration: 808 | loss: 2.203493\n",
      "iteration: 809 | loss: 2.271174\n",
      "iteration: 810 | loss: 2.197331\n",
      "iteration: 811 | loss: 2.327851\n",
      "iteration: 812 | loss: 2.343295\n",
      "iteration: 813 | loss: 2.195342\n",
      "iteration: 814 | loss: 2.304268\n",
      "iteration: 815 | loss: 2.277203\n",
      "iteration: 816 | loss: 2.297655\n",
      "iteration: 817 | loss: 2.158151\n",
      "iteration: 818 | loss: 2.219915\n",
      "iteration: 819 | loss: 2.065002\n",
      "iteration: 820 | loss: 2.162035\n",
      "iteration: 821 | loss: 1.944173\n",
      "iteration: 822 | loss: 2.180884\n",
      "iteration: 823 | loss: 2.104327\n",
      "iteration: 824 | loss: 2.116650\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 825 | loss: 2.245426\n",
      "iteration: 826 | loss: 2.185154\n",
      "iteration: 827 | loss: 1.968880\n",
      "iteration: 828 | loss: 2.229443\n",
      "iteration: 829 | loss: 2.170815\n",
      "iteration: 830 | loss: 1.988451\n",
      "iteration: 831 | loss: 2.161014\n",
      "iteration: 832 | loss: 2.252923\n",
      "iteration: 833 | loss: 2.201637\n",
      "iteration: 834 | loss: 2.176365\n",
      "iteration: 835 | loss: 2.066214\n",
      "iteration: 836 | loss: 2.139517\n",
      "iteration: 837 | loss: 2.348633\n",
      "iteration: 838 | loss: 1.865405\n",
      "iteration: 839 | loss: 2.180387\n",
      "iteration: 840 | loss: 2.208283\n",
      "iteration: 841 | loss: 2.297937\n",
      "iteration: 842 | loss: 2.205200\n",
      "iteration: 843 | loss: 2.155919\n",
      "iteration: 844 | loss: 2.113005\n",
      "iteration: 845 | loss: 2.157248\n",
      "iteration: 846 | loss: 2.196554\n",
      "iteration: 847 | loss: 2.227138\n",
      "iteration: 848 | loss: 2.177969\n",
      "iteration: 849 | loss: 2.215906\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 850 | loss: 2.335136\n",
      "iteration: 851 | loss: 2.260744\n",
      "iteration: 852 | loss: 2.274974\n",
      "iteration: 853 | loss: 2.064682\n",
      "iteration: 854 | loss: 2.160273\n",
      "iteration: 855 | loss: 2.281263\n",
      "iteration: 856 | loss: 2.162284\n",
      "iteration: 857 | loss: 2.088472\n",
      "iteration: 858 | loss: 2.092253\n",
      "iteration: 859 | loss: 1.942792\n",
      "iteration: 860 | loss: 2.312884\n",
      "iteration: 861 | loss: 2.157310\n",
      "iteration: 862 | loss: 1.993236\n",
      "iteration: 863 | loss: 2.007091\n",
      "iteration: 864 | loss: 1.952852\n",
      "iteration: 865 | loss: 2.353556\n",
      "iteration: 866 | loss: 2.231346\n",
      "iteration: 867 | loss: 2.202659\n",
      "iteration: 868 | loss: 2.248787\n",
      "iteration: 869 | loss: 2.403623\n",
      "iteration: 870 | loss: 2.102826\n",
      "iteration: 871 | loss: 2.258291\n",
      "iteration: 872 | loss: 2.201381\n",
      "iteration: 873 | loss: 2.228450\n",
      "iteration: 874 | loss: 2.099337\n",
      "  Train acc: 0.22, Val acc: 0.0\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "sgd_net = ConvNet4(input_shape=(3, 16, 16), wt_scale=1e-2, verbose=False)\n",
    "sgd_net.compile(\"SGD\", lr=0.01)\n",
    "\n",
    "sgd_net.fit(x_dev, y_dev, x_val, y_val, mini_batch_sz=10, n_epochs=175, acc_freq=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train...\n",
      "350 iterations. 2 iter/epoch.\n",
      "iteration: 0 | loss: 2.302394\n",
      "iteration: 1 | loss: 2.289343\n",
      "iteration: 2 | loss: 2.560386\n",
      "iteration: 3 | loss: 2.201041\n",
      "iteration: 4 | loss: 2.252718\n",
      "iteration: 5 | loss: 2.299486\n",
      "iteration: 6 | loss: 2.218758\n",
      "iteration: 7 | loss: 2.096990\n",
      "iteration: 8 | loss: 1.959623\n",
      "iteration: 9 | loss: 2.116974\n",
      "iteration: 10 | loss: 1.790073\n",
      "iteration: 11 | loss: 1.602166\n",
      "iteration: 12 | loss: 1.698958\n",
      "iteration: 13 | loss: 1.323915\n",
      "iteration: 14 | loss: 1.828522\n",
      "iteration: 15 | loss: 1.511120\n",
      "iteration: 16 | loss: 1.974256\n",
      "iteration: 17 | loss: 1.155097\n",
      "iteration: 18 | loss: 1.171849\n",
      "iteration: 19 | loss: 1.287568\n",
      "iteration: 20 | loss: 0.852638\n",
      "iteration: 21 | loss: 1.104119\n",
      "iteration: 22 | loss: 1.501038\n",
      "iteration: 23 | loss: 1.153956\n",
      "iteration: 24 | loss: 0.961434\n",
      "  Train acc: 0.48, Val acc: 0.0\n",
      "iteration: 25 | loss: 0.868586\n",
      "iteration: 26 | loss: 1.175321\n",
      "iteration: 27 | loss: 0.864003\n",
      "iteration: 28 | loss: 0.772628\n",
      "iteration: 29 | loss: 0.902221\n",
      "iteration: 30 | loss: 0.683438\n",
      "iteration: 31 | loss: 0.563736\n",
      "iteration: 32 | loss: 0.639948\n",
      "iteration: 33 | loss: 0.682363\n",
      "iteration: 34 | loss: 0.666981\n",
      "iteration: 35 | loss: 0.555288\n",
      "iteration: 36 | loss: 0.874981\n",
      "iteration: 37 | loss: 0.369254\n",
      "iteration: 38 | loss: 0.258869\n",
      "iteration: 39 | loss: 0.631659\n",
      "iteration: 40 | loss: 0.500963\n",
      "iteration: 41 | loss: 0.333027\n",
      "iteration: 42 | loss: 0.141039\n",
      "iteration: 43 | loss: 0.195749\n",
      "iteration: 44 | loss: 0.134525\n",
      "iteration: 45 | loss: 0.120853\n",
      "iteration: 46 | loss: 0.235913\n",
      "iteration: 47 | loss: 0.183806\n",
      "iteration: 48 | loss: 0.403623\n",
      "iteration: 49 | loss: 0.171756\n",
      "  Train acc: 0.94, Val acc: 0.0\n",
      "iteration: 50 | loss: 0.076848\n",
      "iteration: 51 | loss: 0.612664\n",
      "iteration: 52 | loss: 0.080784\n",
      "iteration: 53 | loss: 0.067560\n",
      "iteration: 54 | loss: 0.023752\n",
      "iteration: 55 | loss: 0.283524\n",
      "iteration: 56 | loss: 0.967599\n",
      "iteration: 57 | loss: 0.034999\n",
      "iteration: 58 | loss: 0.099126\n",
      "iteration: 59 | loss: 0.397114\n",
      "iteration: 60 | loss: 0.066478\n",
      "iteration: 61 | loss: 0.033048\n",
      "iteration: 62 | loss: 0.029937\n",
      "iteration: 63 | loss: 0.021636\n",
      "iteration: 64 | loss: 0.022837\n",
      "iteration: 65 | loss: 0.038761\n",
      "iteration: 66 | loss: 0.064013\n",
      "iteration: 67 | loss: 0.469054\n",
      "iteration: 68 | loss: 0.342131\n",
      "iteration: 69 | loss: 0.047576\n",
      "iteration: 70 | loss: 0.061360\n",
      "iteration: 71 | loss: 0.102571\n",
      "iteration: 72 | loss: 0.127393\n",
      "iteration: 73 | loss: 0.152064\n",
      "iteration: 74 | loss: 0.019506\n",
      "  Train acc: 0.98, Val acc: 0.0\n",
      "iteration: 75 | loss: 0.047378\n",
      "iteration: 76 | loss: 0.071349\n",
      "iteration: 77 | loss: 0.035555\n",
      "iteration: 78 | loss: 0.019988\n",
      "iteration: 79 | loss: 0.629122\n",
      "iteration: 80 | loss: 0.003916\n",
      "iteration: 81 | loss: 0.024814\n",
      "iteration: 82 | loss: 0.021920\n",
      "iteration: 83 | loss: 0.237821\n",
      "iteration: 84 | loss: 0.817810\n",
      "iteration: 85 | loss: 0.001716\n",
      "iteration: 86 | loss: 1.710659\n",
      "iteration: 87 | loss: 0.003844\n",
      "iteration: 88 | loss: 0.730546\n",
      "iteration: 89 | loss: 0.529651\n",
      "iteration: 90 | loss: 0.139815\n",
      "iteration: 91 | loss: 0.036787\n",
      "iteration: 92 | loss: 0.076601\n",
      "iteration: 93 | loss: 0.006844\n",
      "iteration: 94 | loss: 0.030005\n",
      "iteration: 95 | loss: 0.249033\n",
      "iteration: 96 | loss: 0.016767\n",
      "iteration: 97 | loss: 0.026663\n",
      "iteration: 98 | loss: 0.012563\n",
      "iteration: 99 | loss: 0.011726\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 100 | loss: 0.002298\n",
      "iteration: 101 | loss: 0.008190\n",
      "iteration: 102 | loss: 0.048628\n",
      "iteration: 103 | loss: 0.013128\n",
      "iteration: 104 | loss: 0.005050\n",
      "iteration: 105 | loss: 0.012100\n",
      "iteration: 106 | loss: 0.012601\n",
      "iteration: 107 | loss: 0.045278\n",
      "iteration: 108 | loss: 0.097975\n",
      "iteration: 109 | loss: 0.083334\n",
      "iteration: 110 | loss: 0.003378\n",
      "iteration: 111 | loss: 0.113361\n",
      "iteration: 112 | loss: 0.004393\n",
      "iteration: 113 | loss: 0.049143\n",
      "iteration: 114 | loss: 0.004846\n",
      "iteration: 115 | loss: 0.004661\n",
      "iteration: 116 | loss: 0.002706\n",
      "iteration: 117 | loss: 0.000924\n",
      "iteration: 118 | loss: 0.001564\n",
      "iteration: 119 | loss: 0.045123\n",
      "iteration: 120 | loss: 0.005156\n",
      "iteration: 121 | loss: 0.004738\n",
      "iteration: 122 | loss: 0.102509\n",
      "iteration: 123 | loss: 0.001812\n",
      "iteration: 124 | loss: 0.003580\n",
      "  Train acc: 1.0, Val acc: 0.5\n",
      "iteration: 125 | loss: 0.018030\n",
      "iteration: 126 | loss: 0.000397\n",
      "iteration: 127 | loss: 0.005822\n",
      "iteration: 128 | loss: 0.070174\n",
      "iteration: 129 | loss: 0.001283\n",
      "iteration: 130 | loss: 0.001407\n",
      "iteration: 131 | loss: 0.008768\n",
      "iteration: 132 | loss: 0.003589\n",
      "iteration: 133 | loss: 0.001128\n",
      "iteration: 134 | loss: 0.002681\n",
      "iteration: 135 | loss: 0.000667\n",
      "iteration: 136 | loss: 0.004463\n",
      "iteration: 137 | loss: 0.004284\n",
      "iteration: 138 | loss: 0.002149\n",
      "iteration: 139 | loss: 0.003832\n",
      "iteration: 140 | loss: 0.003860\n",
      "iteration: 141 | loss: 0.006779\n",
      "iteration: 142 | loss: 0.004693\n",
      "iteration: 143 | loss: 0.004262\n",
      "iteration: 144 | loss: 0.003719\n",
      "iteration: 145 | loss: 0.001524\n",
      "iteration: 146 | loss: 0.001504\n",
      "iteration: 147 | loss: 0.001269\n",
      "iteration: 148 | loss: 0.000472\n",
      "iteration: 149 | loss: 0.000642\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 150 | loss: 0.000307\n",
      "iteration: 151 | loss: 0.000660\n",
      "iteration: 152 | loss: 0.000416\n",
      "iteration: 153 | loss: 0.000485\n",
      "iteration: 154 | loss: 0.000502\n",
      "iteration: 155 | loss: 0.001214\n",
      "iteration: 156 | loss: 0.000076\n",
      "iteration: 157 | loss: 0.001321\n",
      "iteration: 158 | loss: 0.000259\n",
      "iteration: 159 | loss: 0.000224\n",
      "iteration: 160 | loss: 0.000423\n",
      "iteration: 161 | loss: 0.000223\n",
      "iteration: 162 | loss: 0.000334\n",
      "iteration: 163 | loss: 0.000368\n",
      "iteration: 164 | loss: 0.000365\n",
      "iteration: 165 | loss: 0.000192\n",
      "iteration: 166 | loss: 0.000322\n",
      "iteration: 167 | loss: 0.000166\n",
      "iteration: 168 | loss: 0.000162\n",
      "iteration: 169 | loss: 0.000092\n",
      "iteration: 170 | loss: 0.000120\n",
      "iteration: 171 | loss: 0.000157\n",
      "iteration: 172 | loss: 0.000283\n",
      "iteration: 173 | loss: 0.000193\n",
      "iteration: 174 | loss: 0.000090\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 175 | loss: 0.000198\n",
      "iteration: 176 | loss: 0.000133\n",
      "iteration: 177 | loss: 0.000075\n",
      "iteration: 178 | loss: 0.000126\n",
      "iteration: 179 | loss: 0.000156\n",
      "iteration: 180 | loss: 0.000056\n",
      "iteration: 181 | loss: 0.000072\n",
      "iteration: 182 | loss: 0.000192\n",
      "iteration: 183 | loss: 0.000183\n",
      "iteration: 184 | loss: 0.000125\n",
      "iteration: 185 | loss: 0.000108\n",
      "iteration: 186 | loss: 0.000075\n",
      "iteration: 187 | loss: 0.000088\n",
      "iteration: 188 | loss: 0.000045\n",
      "iteration: 189 | loss: 0.000096\n",
      "iteration: 190 | loss: 0.000139\n",
      "iteration: 191 | loss: 0.000084\n",
      "iteration: 192 | loss: 0.000100\n",
      "iteration: 193 | loss: 0.000042\n",
      "iteration: 194 | loss: 0.000057\n",
      "iteration: 195 | loss: 0.000070\n",
      "iteration: 196 | loss: 0.000037\n",
      "iteration: 197 | loss: 0.000103\n",
      "iteration: 198 | loss: 0.000062\n",
      "iteration: 199 | loss: 0.000062\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 200 | loss: 0.000068\n",
      "iteration: 201 | loss: 0.000106\n",
      "iteration: 202 | loss: 0.000106\n",
      "iteration: 203 | loss: 0.000090\n",
      "iteration: 204 | loss: 0.000096\n",
      "iteration: 205 | loss: 0.000052\n",
      "iteration: 206 | loss: 0.000045\n",
      "iteration: 207 | loss: 0.000041\n",
      "iteration: 208 | loss: 0.000089\n",
      "iteration: 209 | loss: 0.000097\n",
      "iteration: 210 | loss: 0.000071\n",
      "iteration: 211 | loss: 0.000059\n",
      "iteration: 212 | loss: 0.000109\n",
      "iteration: 213 | loss: 0.000024\n",
      "iteration: 214 | loss: 0.000040\n",
      "iteration: 215 | loss: 0.000078\n",
      "iteration: 216 | loss: 0.000073\n",
      "iteration: 217 | loss: 0.000062\n",
      "iteration: 218 | loss: 0.000051\n",
      "iteration: 219 | loss: 0.000055\n",
      "iteration: 220 | loss: 0.000059\n",
      "iteration: 221 | loss: 0.000090\n",
      "iteration: 222 | loss: 0.000085\n",
      "iteration: 223 | loss: 0.000066\n",
      "iteration: 224 | loss: 0.000060\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 225 | loss: 0.000063\n",
      "iteration: 226 | loss: 0.000093\n",
      "iteration: 227 | loss: 0.000041\n",
      "iteration: 228 | loss: 0.000073\n",
      "iteration: 229 | loss: 0.000040\n",
      "iteration: 230 | loss: 0.000046\n",
      "iteration: 231 | loss: 0.000044\n",
      "iteration: 232 | loss: 0.000045\n",
      "iteration: 233 | loss: 0.000042\n",
      "iteration: 234 | loss: 0.000052\n",
      "iteration: 235 | loss: 0.000096\n",
      "iteration: 236 | loss: 0.000037\n",
      "iteration: 237 | loss: 0.000059\n",
      "iteration: 238 | loss: 0.000029\n",
      "iteration: 239 | loss: 0.000068\n",
      "iteration: 240 | loss: 0.000060\n",
      "iteration: 241 | loss: 0.000050\n",
      "iteration: 242 | loss: 0.000036\n",
      "iteration: 243 | loss: 0.000056\n",
      "iteration: 244 | loss: 0.000059\n",
      "iteration: 245 | loss: 0.000041\n",
      "iteration: 246 | loss: 0.000103\n",
      "iteration: 247 | loss: 0.000062\n",
      "iteration: 248 | loss: 0.000043\n",
      "iteration: 249 | loss: 0.000062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 250 | loss: 0.000066\n",
      "iteration: 251 | loss: 0.000061\n",
      "iteration: 252 | loss: 0.000045\n",
      "iteration: 253 | loss: 0.000043\n",
      "iteration: 254 | loss: 0.000051\n",
      "iteration: 255 | loss: 0.000066\n",
      "iteration: 256 | loss: 0.000019\n",
      "iteration: 257 | loss: 0.000077\n",
      "iteration: 258 | loss: 0.000071\n",
      "iteration: 259 | loss: 0.000038\n",
      "iteration: 260 | loss: 0.000043\n",
      "iteration: 261 | loss: 0.000046\n",
      "iteration: 262 | loss: 0.000054\n",
      "iteration: 263 | loss: 0.000048\n",
      "iteration: 264 | loss: 0.000087\n",
      "iteration: 265 | loss: 0.000068\n",
      "iteration: 266 | loss: 0.000072\n",
      "iteration: 267 | loss: 0.000073\n",
      "iteration: 268 | loss: 0.000036\n",
      "iteration: 269 | loss: 0.000022\n",
      "iteration: 270 | loss: 0.000015\n",
      "iteration: 271 | loss: 0.000027\n",
      "iteration: 272 | loss: 0.000019\n",
      "iteration: 273 | loss: 0.000047\n",
      "iteration: 274 | loss: 0.000042\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 275 | loss: 0.000046\n",
      "iteration: 276 | loss: 0.000028\n",
      "iteration: 277 | loss: 0.000029\n",
      "iteration: 278 | loss: 0.000050\n",
      "iteration: 279 | loss: 0.000066\n",
      "iteration: 280 | loss: 0.000009\n",
      "iteration: 281 | loss: 0.000023\n",
      "iteration: 282 | loss: 0.000052\n",
      "iteration: 283 | loss: 0.000020\n",
      "iteration: 284 | loss: 0.000046\n",
      "iteration: 285 | loss: 0.000028\n",
      "iteration: 286 | loss: 0.000064\n",
      "iteration: 287 | loss: 0.000027\n",
      "iteration: 288 | loss: 0.000042\n",
      "iteration: 289 | loss: 0.000050\n",
      "iteration: 290 | loss: 0.000045\n",
      "iteration: 291 | loss: 0.000038\n",
      "iteration: 292 | loss: 0.000058\n",
      "iteration: 293 | loss: 0.000033\n",
      "iteration: 294 | loss: 0.000037\n",
      "iteration: 295 | loss: 0.000057\n",
      "iteration: 296 | loss: 0.000043\n",
      "iteration: 297 | loss: 0.000043\n",
      "iteration: 298 | loss: 0.000039\n",
      "iteration: 299 | loss: 0.000021\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 300 | loss: 0.000061\n",
      "iteration: 301 | loss: 0.000061\n",
      "iteration: 302 | loss: 0.000049\n",
      "iteration: 303 | loss: 0.000028\n",
      "iteration: 304 | loss: 0.000021\n",
      "iteration: 305 | loss: 0.000034\n",
      "iteration: 306 | loss: 0.000039\n",
      "iteration: 307 | loss: 0.000031\n",
      "iteration: 308 | loss: 0.000025\n",
      "iteration: 309 | loss: 0.000035\n",
      "iteration: 310 | loss: 0.000056\n",
      "iteration: 311 | loss: 0.000028\n",
      "iteration: 312 | loss: 0.000025\n",
      "iteration: 313 | loss: 0.000029\n",
      "iteration: 314 | loss: 0.000032\n",
      "iteration: 315 | loss: 0.000057\n",
      "iteration: 316 | loss: 0.000020\n",
      "iteration: 317 | loss: 0.000029\n",
      "iteration: 318 | loss: 0.000026\n",
      "iteration: 319 | loss: 0.000033\n",
      "iteration: 320 | loss: 0.000039\n",
      "iteration: 321 | loss: 0.000025\n",
      "iteration: 322 | loss: 0.000033\n",
      "iteration: 323 | loss: 0.000017\n",
      "iteration: 324 | loss: 0.000031\n",
      "  Train acc: 1.0, Val acc: 0.0\n",
      "iteration: 325 | loss: 0.000022\n",
      "iteration: 326 | loss: 0.000040\n",
      "iteration: 327 | loss: 0.000037\n",
      "iteration: 328 | loss: 0.000042\n",
      "iteration: 329 | loss: 0.000044\n",
      "iteration: 330 | loss: 0.000020\n",
      "iteration: 331 | loss: 0.000031\n",
      "iteration: 332 | loss: 0.000010\n",
      "iteration: 333 | loss: 0.000011\n",
      "iteration: 334 | loss: 0.000022\n",
      "iteration: 335 | loss: 0.000037\n",
      "iteration: 336 | loss: 0.000025\n",
      "iteration: 337 | loss: 0.000025\n",
      "iteration: 338 | loss: 0.000031\n",
      "iteration: 339 | loss: 0.000033\n",
      "iteration: 340 | loss: 0.000021\n",
      "iteration: 341 | loss: 0.000030\n",
      "iteration: 342 | loss: 0.000018\n",
      "iteration: 343 | loss: 0.000035\n",
      "iteration: 344 | loss: 0.000020\n",
      "iteration: 345 | loss: 0.000023\n",
      "iteration: 346 | loss: 0.000035\n",
      "iteration: 347 | loss: 0.000026\n",
      "iteration: 348 | loss: 0.000049\n",
      "iteration: 349 | loss: 0.000032\n",
      "  Train acc: 1.0, Val acc: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Adam\n",
    "adam_net1 = ConvNet4(input_shape=(3,16,16), wt_scale=1e-2, verbose=False)\n",
    "adam_net1.compile(\"Adam\", lr=0.01)\n",
    "\n",
    "adam_net1.fit(x_dev, y_dev, x_val, y_val, mini_batch_sz=25, n_epochs=175, acc_freq=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train...\n",
      "350 iterations. 2 iter/epoch.\n",
      "iteration: 0 | loss: 2.304933\n",
      "iteration: 1 | loss: 2.306702\n",
      "iteration: 2 | loss: 2.305906\n",
      "iteration: 3 | loss: 2.302006\n",
      "iteration: 4 | loss: 2.303285\n",
      "iteration: 5 | loss: 2.301002\n",
      "iteration: 6 | loss: 2.301451\n",
      "iteration: 7 | loss: 2.296944\n",
      "iteration: 8 | loss: 2.304722\n",
      "iteration: 9 | loss: 2.293031\n",
      "iteration: 10 | loss: 2.285095\n",
      "iteration: 11 | loss: 2.307556\n",
      "iteration: 12 | loss: 2.291599\n",
      "iteration: 13 | loss: 2.283635\n",
      "iteration: 14 | loss: 2.302177\n",
      "iteration: 15 | loss: 2.287204\n",
      "iteration: 16 | loss: 2.268892\n",
      "iteration: 17 | loss: 2.274487\n",
      "iteration: 18 | loss: 2.295921\n",
      "iteration: 19 | loss: 2.282877\n",
      "iteration: 20 | loss: 2.267628\n",
      "iteration: 21 | loss: 2.272638\n",
      "iteration: 22 | loss: 2.261905\n",
      "iteration: 23 | loss: 2.279710\n",
      "iteration: 24 | loss: 2.270039\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 25 | loss: 2.261498\n",
      "iteration: 26 | loss: 2.276715\n",
      "iteration: 27 | loss: 2.253795\n",
      "iteration: 28 | loss: 2.313954\n",
      "iteration: 29 | loss: 2.234661\n",
      "iteration: 30 | loss: 2.230081\n",
      "iteration: 31 | loss: 2.228293\n",
      "iteration: 32 | loss: 2.227685\n",
      "iteration: 33 | loss: 2.228337\n",
      "iteration: 34 | loss: 2.266987\n",
      "iteration: 35 | loss: 2.234785\n",
      "iteration: 36 | loss: 2.225500\n",
      "iteration: 37 | loss: 2.275536\n",
      "iteration: 38 | loss: 2.251242\n",
      "iteration: 39 | loss: 2.253862\n",
      "iteration: 40 | loss: 2.231249\n",
      "iteration: 41 | loss: 2.254024\n",
      "iteration: 42 | loss: 2.261133\n",
      "iteration: 43 | loss: 2.243713\n",
      "iteration: 44 | loss: 2.272921\n",
      "iteration: 45 | loss: 2.243100\n",
      "iteration: 46 | loss: 2.196861\n",
      "iteration: 47 | loss: 2.224883\n",
      "iteration: 48 | loss: 2.263902\n",
      "iteration: 49 | loss: 2.200651\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 50 | loss: 2.285146\n",
      "iteration: 51 | loss: 2.233477\n",
      "iteration: 52 | loss: 2.217572\n",
      "iteration: 53 | loss: 2.202353\n",
      "iteration: 54 | loss: 2.268077\n",
      "iteration: 55 | loss: 2.190339\n",
      "iteration: 56 | loss: 2.238327\n",
      "iteration: 57 | loss: 2.174652\n",
      "iteration: 58 | loss: 2.224257\n",
      "iteration: 59 | loss: 2.238244\n",
      "iteration: 60 | loss: 2.297810\n",
      "iteration: 61 | loss: 2.135986\n",
      "iteration: 62 | loss: 2.257435\n",
      "iteration: 63 | loss: 2.217766\n",
      "iteration: 64 | loss: 2.213807\n",
      "iteration: 65 | loss: 2.240965\n",
      "iteration: 66 | loss: 2.227707\n",
      "iteration: 67 | loss: 2.232352\n",
      "iteration: 68 | loss: 2.192793\n",
      "iteration: 69 | loss: 2.143524\n",
      "iteration: 70 | loss: 2.204580\n",
      "iteration: 71 | loss: 2.294565\n",
      "iteration: 72 | loss: 2.208992\n",
      "iteration: 73 | loss: 2.211280\n",
      "iteration: 74 | loss: 2.195059\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 75 | loss: 2.339048\n",
      "iteration: 76 | loss: 2.232497\n",
      "iteration: 77 | loss: 2.207277\n",
      "iteration: 78 | loss: 2.245642\n",
      "iteration: 79 | loss: 2.232530\n",
      "iteration: 80 | loss: 2.155418\n",
      "iteration: 81 | loss: 2.251588\n",
      "iteration: 82 | loss: 2.092699\n",
      "iteration: 83 | loss: 2.239956\n",
      "iteration: 84 | loss: 2.118296\n",
      "iteration: 85 | loss: 2.229285\n",
      "iteration: 86 | loss: 2.232627\n",
      "iteration: 87 | loss: 2.215099\n",
      "iteration: 88 | loss: 2.171348\n",
      "iteration: 89 | loss: 2.359724\n",
      "iteration: 90 | loss: 2.235854\n",
      "iteration: 91 | loss: 2.209959\n",
      "iteration: 92 | loss: 2.270683\n",
      "iteration: 93 | loss: 2.271463\n",
      "iteration: 94 | loss: 2.248289\n",
      "iteration: 95 | loss: 2.090241\n",
      "iteration: 96 | loss: 2.192048\n",
      "iteration: 97 | loss: 2.283148\n",
      "iteration: 98 | loss: 2.166242\n",
      "iteration: 99 | loss: 2.281700\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 100 | loss: 2.166563\n",
      "iteration: 101 | loss: 2.178169\n",
      "iteration: 102 | loss: 2.111118\n",
      "iteration: 103 | loss: 2.225331\n",
      "iteration: 104 | loss: 2.207641\n",
      "iteration: 105 | loss: 2.129088\n",
      "iteration: 106 | loss: 2.134147\n",
      "iteration: 107 | loss: 2.197465\n",
      "iteration: 108 | loss: 2.232456\n",
      "iteration: 109 | loss: 2.192883\n",
      "iteration: 110 | loss: 2.159595\n",
      "iteration: 111 | loss: 2.074537\n",
      "iteration: 112 | loss: 2.327419\n",
      "iteration: 113 | loss: 2.153398\n",
      "iteration: 114 | loss: 2.101842\n",
      "iteration: 115 | loss: 2.187081\n",
      "iteration: 116 | loss: 2.273548\n",
      "iteration: 117 | loss: 2.137681\n",
      "iteration: 118 | loss: 2.203315\n",
      "iteration: 119 | loss: 2.111233\n",
      "iteration: 120 | loss: 2.217936\n",
      "iteration: 121 | loss: 2.357769\n",
      "iteration: 122 | loss: 2.326826\n",
      "iteration: 123 | loss: 2.011985\n",
      "iteration: 124 | loss: 2.197735\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 125 | loss: 2.175899\n",
      "iteration: 126 | loss: 2.173128\n",
      "iteration: 127 | loss: 2.317458\n",
      "iteration: 128 | loss: 2.056625\n",
      "iteration: 129 | loss: 2.158247\n",
      "iteration: 130 | loss: 2.186399\n",
      "iteration: 131 | loss: 2.163856\n",
      "iteration: 132 | loss: 2.204880\n",
      "iteration: 133 | loss: 2.241510\n",
      "iteration: 134 | loss: 2.273013\n",
      "iteration: 135 | loss: 2.080100\n",
      "iteration: 136 | loss: 2.349583\n",
      "iteration: 137 | loss: 2.347105\n",
      "iteration: 138 | loss: 2.128988\n",
      "iteration: 139 | loss: 2.223977\n",
      "iteration: 140 | loss: 2.134315\n",
      "iteration: 141 | loss: 2.000314\n",
      "iteration: 142 | loss: 2.225065\n",
      "iteration: 143 | loss: 2.142592\n",
      "iteration: 144 | loss: 2.226506\n",
      "iteration: 145 | loss: 2.250647\n",
      "iteration: 146 | loss: 2.236428\n",
      "iteration: 147 | loss: 2.062223\n",
      "iteration: 148 | loss: 2.061624\n",
      "iteration: 149 | loss: 2.124879\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 150 | loss: 2.224476\n",
      "iteration: 151 | loss: 2.218154\n",
      "iteration: 152 | loss: 2.182990\n",
      "iteration: 153 | loss: 2.088710\n",
      "iteration: 154 | loss: 2.268451\n",
      "iteration: 155 | loss: 1.919365\n",
      "iteration: 156 | loss: 2.346157\n",
      "iteration: 157 | loss: 1.996724\n",
      "iteration: 158 | loss: 2.173613\n",
      "iteration: 159 | loss: 2.267133\n",
      "iteration: 160 | loss: 2.157308\n",
      "iteration: 161 | loss: 2.256873\n",
      "iteration: 162 | loss: 2.217203\n",
      "iteration: 163 | loss: 2.134415\n",
      "iteration: 164 | loss: 2.163102\n",
      "iteration: 165 | loss: 2.038429\n",
      "iteration: 166 | loss: 2.040795\n",
      "iteration: 167 | loss: 2.098170\n",
      "iteration: 168 | loss: 2.048776\n",
      "iteration: 169 | loss: 2.147296\n",
      "iteration: 170 | loss: 1.998219\n",
      "iteration: 171 | loss: 1.995366\n",
      "iteration: 172 | loss: 2.013834\n",
      "iteration: 173 | loss: 1.867588\n",
      "iteration: 174 | loss: 2.066437\n",
      "  Train acc: 0.24, Val acc: 0.0\n",
      "iteration: 175 | loss: 1.957851\n",
      "iteration: 176 | loss: 2.099830\n",
      "iteration: 177 | loss: 2.146535\n",
      "iteration: 178 | loss: 2.214545\n",
      "iteration: 179 | loss: 2.141218\n",
      "iteration: 180 | loss: 2.184505\n",
      "iteration: 181 | loss: 1.719403\n",
      "iteration: 182 | loss: 2.029937\n",
      "iteration: 183 | loss: 1.995613\n",
      "iteration: 184 | loss: 1.794303\n",
      "iteration: 185 | loss: 1.842002\n",
      "iteration: 186 | loss: 2.045984\n",
      "iteration: 187 | loss: 2.049704\n",
      "iteration: 188 | loss: 2.055098\n",
      "iteration: 189 | loss: 2.226600\n",
      "iteration: 190 | loss: 2.069538\n",
      "iteration: 191 | loss: 1.969349\n",
      "iteration: 192 | loss: 2.016763\n",
      "iteration: 193 | loss: 1.897886\n",
      "iteration: 194 | loss: 2.112810\n",
      "iteration: 195 | loss: 1.565602\n",
      "iteration: 196 | loss: 1.705950\n",
      "iteration: 197 | loss: 1.966173\n",
      "iteration: 198 | loss: 1.926736\n",
      "iteration: 199 | loss: 1.701655\n",
      "  Train acc: 0.4, Val acc: 0.0\n",
      "iteration: 200 | loss: 1.922087\n",
      "iteration: 201 | loss: 1.931982\n",
      "iteration: 202 | loss: 1.669752\n",
      "iteration: 203 | loss: 1.776396\n",
      "iteration: 204 | loss: 1.772643\n",
      "iteration: 205 | loss: 1.946239\n",
      "iteration: 206 | loss: 1.795506\n",
      "iteration: 207 | loss: 1.384886\n",
      "iteration: 208 | loss: 1.912484\n",
      "iteration: 209 | loss: 1.575621\n",
      "iteration: 210 | loss: 1.640931\n",
      "iteration: 211 | loss: 1.855462\n",
      "iteration: 212 | loss: 1.807239\n",
      "iteration: 213 | loss: 1.595337\n",
      "iteration: 214 | loss: 1.604601\n",
      "iteration: 215 | loss: 1.752581\n",
      "iteration: 216 | loss: 1.709628\n",
      "iteration: 217 | loss: 1.654688\n",
      "iteration: 218 | loss: 1.634617\n",
      "iteration: 219 | loss: 1.618910\n",
      "iteration: 220 | loss: 1.307139\n",
      "iteration: 221 | loss: 1.609536\n",
      "iteration: 222 | loss: 1.574589\n",
      "iteration: 223 | loss: 1.659838\n",
      "iteration: 224 | loss: 1.718827\n",
      "  Train acc: 0.38, Val acc: 0.0\n",
      "iteration: 225 | loss: 1.373801\n",
      "iteration: 226 | loss: 1.620583\n",
      "iteration: 227 | loss: 1.715098\n",
      "iteration: 228 | loss: 1.917660\n",
      "iteration: 229 | loss: 1.501271\n",
      "iteration: 230 | loss: 1.695935\n",
      "iteration: 231 | loss: 1.547736\n",
      "iteration: 232 | loss: 1.731773\n",
      "iteration: 233 | loss: 1.461478\n",
      "iteration: 234 | loss: 1.603795\n",
      "iteration: 235 | loss: 1.580296\n",
      "iteration: 236 | loss: 1.507083\n",
      "iteration: 237 | loss: 1.478301\n",
      "iteration: 238 | loss: 1.478384\n",
      "iteration: 239 | loss: 1.601715\n",
      "iteration: 240 | loss: 1.469404\n",
      "iteration: 241 | loss: 1.551044\n",
      "iteration: 242 | loss: 1.455439\n",
      "iteration: 243 | loss: 1.342441\n",
      "iteration: 244 | loss: 1.495030\n",
      "iteration: 245 | loss: 1.300458\n",
      "iteration: 246 | loss: 1.267237\n",
      "iteration: 247 | loss: 1.431502\n",
      "iteration: 248 | loss: 1.282132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 249 | loss: 1.426956\n",
      "  Train acc: 0.46, Val acc: 0.0\n",
      "iteration: 250 | loss: 1.423705\n",
      "iteration: 251 | loss: 1.468481\n",
      "iteration: 252 | loss: 1.101245\n",
      "iteration: 253 | loss: 1.470629\n",
      "iteration: 254 | loss: 1.658924\n",
      "iteration: 255 | loss: 1.304570\n",
      "iteration: 256 | loss: 1.357326\n",
      "iteration: 257 | loss: 1.399924\n",
      "iteration: 258 | loss: 1.633037\n",
      "iteration: 259 | loss: 1.705214\n",
      "iteration: 260 | loss: 1.449363\n",
      "iteration: 261 | loss: 1.318412\n",
      "iteration: 262 | loss: 1.177883\n",
      "iteration: 263 | loss: 1.628204\n",
      "iteration: 264 | loss: 1.386586\n",
      "iteration: 265 | loss: 1.146367\n",
      "iteration: 266 | loss: 1.307987\n",
      "iteration: 267 | loss: 1.200006\n",
      "iteration: 268 | loss: 1.146078\n",
      "iteration: 269 | loss: 1.431807\n",
      "iteration: 270 | loss: 1.073616\n",
      "iteration: 271 | loss: 1.351356\n",
      "iteration: 272 | loss: 1.043361\n",
      "iteration: 273 | loss: 1.016631\n",
      "iteration: 274 | loss: 1.239019\n",
      "  Train acc: 0.6, Val acc: 0.0\n",
      "iteration: 275 | loss: 1.267389\n",
      "iteration: 276 | loss: 1.283367\n",
      "iteration: 277 | loss: 0.993754\n",
      "iteration: 278 | loss: 1.154109\n",
      "iteration: 279 | loss: 1.084046\n",
      "iteration: 280 | loss: 1.093100\n",
      "iteration: 281 | loss: 1.058778\n",
      "iteration: 282 | loss: 1.202898\n",
      "iteration: 283 | loss: 1.034755\n",
      "iteration: 284 | loss: 1.124034\n",
      "iteration: 285 | loss: 0.795280\n",
      "iteration: 286 | loss: 1.181725\n",
      "iteration: 287 | loss: 0.909558\n",
      "iteration: 288 | loss: 0.813030\n",
      "iteration: 289 | loss: 1.224526\n",
      "iteration: 290 | loss: 1.169135\n",
      "iteration: 291 | loss: 0.949473\n",
      "iteration: 292 | loss: 1.118898\n",
      "iteration: 293 | loss: 1.107632\n",
      "iteration: 294 | loss: 1.037509\n",
      "iteration: 295 | loss: 1.139795\n",
      "iteration: 296 | loss: 0.978866\n",
      "iteration: 297 | loss: 1.127390\n",
      "iteration: 298 | loss: 0.808891\n",
      "iteration: 299 | loss: 1.024775\n",
      "  Train acc: 0.68, Val acc: 0.0\n",
      "iteration: 300 | loss: 1.051748\n",
      "iteration: 301 | loss: 0.824513\n",
      "iteration: 302 | loss: 0.868958\n",
      "iteration: 303 | loss: 0.707076\n",
      "iteration: 304 | loss: 0.731324\n",
      "iteration: 305 | loss: 1.155438\n",
      "iteration: 306 | loss: 0.992247\n",
      "iteration: 307 | loss: 0.936911\n",
      "iteration: 308 | loss: 0.906903\n",
      "iteration: 309 | loss: 0.602262\n",
      "iteration: 310 | loss: 0.616650\n",
      "iteration: 311 | loss: 1.044210\n",
      "iteration: 312 | loss: 0.861441\n",
      "iteration: 313 | loss: 1.099447\n",
      "iteration: 314 | loss: 0.642489\n",
      "iteration: 315 | loss: 0.752716\n",
      "iteration: 316 | loss: 0.877741\n",
      "iteration: 317 | loss: 0.714282\n",
      "iteration: 318 | loss: 0.789124\n",
      "iteration: 319 | loss: 0.596808\n",
      "iteration: 320 | loss: 0.799275\n",
      "iteration: 321 | loss: 0.715841\n",
      "iteration: 322 | loss: 0.739138\n",
      "iteration: 323 | loss: 0.721220\n",
      "iteration: 324 | loss: 0.418627\n",
      "  Train acc: 0.82, Val acc: 0.0\n",
      "iteration: 325 | loss: 0.761927\n",
      "iteration: 326 | loss: 0.667848\n",
      "iteration: 327 | loss: 0.776866\n",
      "iteration: 328 | loss: 0.374098\n",
      "iteration: 329 | loss: 0.423608\n",
      "iteration: 330 | loss: 0.550712\n",
      "iteration: 331 | loss: 0.705378\n",
      "iteration: 332 | loss: 0.424527\n",
      "iteration: 333 | loss: 0.524755\n",
      "iteration: 334 | loss: 0.625620\n",
      "iteration: 335 | loss: 0.384220\n",
      "iteration: 336 | loss: 0.468711\n",
      "iteration: 337 | loss: 0.354191\n",
      "iteration: 338 | loss: 0.390373\n",
      "iteration: 339 | loss: 0.594332\n",
      "iteration: 340 | loss: 0.614448\n",
      "iteration: 341 | loss: 0.334561\n",
      "iteration: 342 | loss: 0.495901\n",
      "iteration: 343 | loss: 0.264374\n",
      "iteration: 344 | loss: 0.512000\n",
      "iteration: 345 | loss: 0.386579\n",
      "iteration: 346 | loss: 0.351137\n",
      "iteration: 347 | loss: 0.345693\n",
      "iteration: 348 | loss: 0.200592\n",
      "iteration: 349 | loss: 0.233727\n",
      "  Train acc: 0.88, Val acc: 0.0\n"
     ]
    }
   ],
   "source": [
    "# SGD-M\n",
    "sgdm_net1 = ConvNet4(input_shape=(3, 16, 16), wt_scale=1e-2, verbose=False)\n",
    "sgdm_net1.compile(\"SGD-M\", lr=0.01)\n",
    "\n",
    "sgdm_net1.fit(x_dev, y_dev, x_val, y_val, mini_batch_sz=25, n_epochs=175, acc_freq=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train...\n",
      "350 iterations. 2 iter/epoch.\n",
      "iteration: 0 | loss: 2.303300\n",
      "iteration: 1 | loss: 2.304004\n",
      "iteration: 2 | loss: 2.302723\n",
      "iteration: 3 | loss: 2.303753\n",
      "iteration: 4 | loss: 2.303498\n",
      "iteration: 5 | loss: 2.302097\n",
      "iteration: 6 | loss: 2.305319\n",
      "iteration: 7 | loss: 2.303551\n",
      "iteration: 8 | loss: 2.299843\n",
      "iteration: 9 | loss: 2.300238\n",
      "iteration: 10 | loss: 2.299512\n",
      "iteration: 11 | loss: 2.299027\n",
      "iteration: 12 | loss: 2.300129\n",
      "iteration: 13 | loss: 2.298040\n",
      "iteration: 14 | loss: 2.298236\n",
      "iteration: 15 | loss: 2.295648\n",
      "iteration: 16 | loss: 2.299452\n",
      "iteration: 17 | loss: 2.296709\n",
      "iteration: 18 | loss: 2.300625\n",
      "iteration: 19 | loss: 2.296694\n",
      "iteration: 20 | loss: 2.297307\n",
      "iteration: 21 | loss: 2.296146\n",
      "iteration: 22 | loss: 2.302373\n",
      "iteration: 23 | loss: 2.292649\n",
      "iteration: 24 | loss: 2.298584\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 25 | loss: 2.302625\n",
      "iteration: 26 | loss: 2.300817\n",
      "iteration: 27 | loss: 2.291349\n",
      "iteration: 28 | loss: 2.284430\n",
      "iteration: 29 | loss: 2.290923\n",
      "iteration: 30 | loss: 2.290159\n",
      "iteration: 31 | loss: 2.294565\n",
      "iteration: 32 | loss: 2.290201\n",
      "iteration: 33 | loss: 2.291406\n",
      "iteration: 34 | loss: 2.290722\n",
      "iteration: 35 | loss: 2.294009\n",
      "iteration: 36 | loss: 2.289260\n",
      "iteration: 37 | loss: 2.289677\n",
      "iteration: 38 | loss: 2.284278\n",
      "iteration: 39 | loss: 2.286348\n",
      "iteration: 40 | loss: 2.282130\n",
      "iteration: 41 | loss: 2.290305\n",
      "iteration: 42 | loss: 2.299625\n",
      "iteration: 43 | loss: 2.288231\n",
      "iteration: 44 | loss: 2.286934\n",
      "iteration: 45 | loss: 2.280134\n",
      "iteration: 46 | loss: 2.296404\n",
      "iteration: 47 | loss: 2.281776\n",
      "iteration: 48 | loss: 2.297636\n",
      "iteration: 49 | loss: 2.278686\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 50 | loss: 2.303856\n",
      "iteration: 51 | loss: 2.281542\n",
      "iteration: 52 | loss: 2.283636\n",
      "iteration: 53 | loss: 2.282933\n",
      "iteration: 54 | loss: 2.279025\n",
      "iteration: 55 | loss: 2.293825\n",
      "iteration: 56 | loss: 2.290278\n",
      "iteration: 57 | loss: 2.297048\n",
      "iteration: 58 | loss: 2.287012\n",
      "iteration: 59 | loss: 2.298788\n",
      "iteration: 60 | loss: 2.290361\n",
      "iteration: 61 | loss: 2.285952\n",
      "iteration: 62 | loss: 2.295674\n",
      "iteration: 63 | loss: 2.291276\n",
      "iteration: 64 | loss: 2.287552\n",
      "iteration: 65 | loss: 2.286224\n",
      "iteration: 66 | loss: 2.279309\n",
      "iteration: 67 | loss: 2.291618\n",
      "iteration: 68 | loss: 2.280681\n",
      "iteration: 69 | loss: 2.291141\n",
      "iteration: 70 | loss: 2.279514\n",
      "iteration: 71 | loss: 2.283467\n",
      "iteration: 72 | loss: 2.271652\n",
      "iteration: 73 | loss: 2.283560\n",
      "iteration: 74 | loss: 2.260223\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 75 | loss: 2.280447\n",
      "iteration: 76 | loss: 2.264365\n",
      "iteration: 77 | loss: 2.268396\n",
      "iteration: 78 | loss: 2.267471\n",
      "iteration: 79 | loss: 2.288844\n",
      "iteration: 80 | loss: 2.284505\n",
      "iteration: 81 | loss: 2.275531\n",
      "iteration: 82 | loss: 2.276646\n",
      "iteration: 83 | loss: 2.275243\n",
      "iteration: 84 | loss: 2.269233\n",
      "iteration: 85 | loss: 2.278149\n",
      "iteration: 86 | loss: 2.290520\n",
      "iteration: 87 | loss: 2.281136\n",
      "iteration: 88 | loss: 2.283300\n",
      "iteration: 89 | loss: 2.267763\n",
      "iteration: 90 | loss: 2.278580\n",
      "iteration: 91 | loss: 2.280252\n",
      "iteration: 92 | loss: 2.270568\n",
      "iteration: 93 | loss: 2.304489\n",
      "iteration: 94 | loss: 2.258764\n",
      "iteration: 95 | loss: 2.287374\n",
      "iteration: 96 | loss: 2.272527\n",
      "iteration: 97 | loss: 2.267588\n",
      "iteration: 98 | loss: 2.284420\n",
      "iteration: 99 | loss: 2.286371\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 100 | loss: 2.269448\n",
      "iteration: 101 | loss: 2.297787\n",
      "iteration: 102 | loss: 2.275559\n",
      "iteration: 103 | loss: 2.276894\n",
      "iteration: 104 | loss: 2.276441\n",
      "iteration: 105 | loss: 2.255789\n",
      "iteration: 106 | loss: 2.262960\n",
      "iteration: 107 | loss: 2.297714\n",
      "iteration: 108 | loss: 2.279636\n",
      "iteration: 109 | loss: 2.261479\n",
      "iteration: 110 | loss: 2.241306\n",
      "iteration: 111 | loss: 2.273384\n",
      "iteration: 112 | loss: 2.268929\n",
      "iteration: 113 | loss: 2.269309\n",
      "iteration: 114 | loss: 2.307130\n",
      "iteration: 115 | loss: 2.280034\n",
      "iteration: 116 | loss: 2.303340\n",
      "iteration: 117 | loss: 2.251250\n",
      "iteration: 118 | loss: 2.267796\n",
      "iteration: 119 | loss: 2.296306\n",
      "iteration: 120 | loss: 2.279891\n",
      "iteration: 121 | loss: 2.263518\n",
      "iteration: 122 | loss: 2.262491\n",
      "iteration: 123 | loss: 2.262596\n",
      "iteration: 124 | loss: 2.270239\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 125 | loss: 2.246739\n",
      "iteration: 126 | loss: 2.265591\n",
      "iteration: 127 | loss: 2.284727\n",
      "iteration: 128 | loss: 2.275185\n",
      "iteration: 129 | loss: 2.259738\n",
      "iteration: 130 | loss: 2.259709\n",
      "iteration: 131 | loss: 2.224322\n",
      "iteration: 132 | loss: 2.270457\n",
      "iteration: 133 | loss: 2.284238\n",
      "iteration: 134 | loss: 2.274838\n",
      "iteration: 135 | loss: 2.279401\n",
      "iteration: 136 | loss: 2.235131\n",
      "iteration: 137 | loss: 2.282071\n",
      "iteration: 138 | loss: 2.280075\n",
      "iteration: 139 | loss: 2.265985\n",
      "iteration: 140 | loss: 2.258401\n",
      "iteration: 141 | loss: 2.280232\n",
      "iteration: 142 | loss: 2.265599\n",
      "iteration: 143 | loss: 2.280282\n",
      "iteration: 144 | loss: 2.300390\n",
      "iteration: 145 | loss: 2.281698\n",
      "iteration: 146 | loss: 2.280551\n",
      "iteration: 147 | loss: 2.265029\n",
      "iteration: 148 | loss: 2.257356\n",
      "iteration: 149 | loss: 2.250075\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 150 | loss: 2.258570\n",
      "iteration: 151 | loss: 2.278849\n",
      "iteration: 152 | loss: 2.258370\n",
      "iteration: 153 | loss: 2.285686\n",
      "iteration: 154 | loss: 2.263132\n",
      "iteration: 155 | loss: 2.258051\n",
      "iteration: 156 | loss: 2.291768\n",
      "iteration: 157 | loss: 2.275747\n",
      "iteration: 158 | loss: 2.238760\n",
      "iteration: 159 | loss: 2.239859\n",
      "iteration: 160 | loss: 2.239706\n",
      "iteration: 161 | loss: 2.275498\n",
      "iteration: 162 | loss: 2.274283\n",
      "iteration: 163 | loss: 2.279213\n",
      "iteration: 164 | loss: 2.262285\n",
      "iteration: 165 | loss: 2.263659\n",
      "iteration: 166 | loss: 2.253998\n",
      "iteration: 167 | loss: 2.272045\n",
      "iteration: 168 | loss: 2.245435\n",
      "iteration: 169 | loss: 2.260243\n",
      "iteration: 170 | loss: 2.227390\n",
      "iteration: 171 | loss: 2.253416\n",
      "iteration: 172 | loss: 2.224026\n",
      "iteration: 173 | loss: 2.246492\n",
      "iteration: 174 | loss: 2.240705\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 175 | loss: 2.246136\n",
      "iteration: 176 | loss: 2.272302\n",
      "iteration: 177 | loss: 2.261833\n",
      "iteration: 178 | loss: 2.266743\n",
      "iteration: 179 | loss: 2.245235\n",
      "iteration: 180 | loss: 2.272883\n",
      "iteration: 181 | loss: 2.241653\n",
      "iteration: 182 | loss: 2.259301\n",
      "iteration: 183 | loss: 2.242560\n",
      "iteration: 184 | loss: 2.261977\n",
      "iteration: 185 | loss: 2.276551\n",
      "iteration: 186 | loss: 2.227898\n",
      "iteration: 187 | loss: 2.251812\n",
      "iteration: 188 | loss: 2.259379\n",
      "iteration: 189 | loss: 2.251609\n",
      "iteration: 190 | loss: 2.246551\n",
      "iteration: 191 | loss: 2.263082\n",
      "iteration: 192 | loss: 2.289678\n",
      "iteration: 193 | loss: 2.251427\n",
      "iteration: 194 | loss: 2.252751\n",
      "iteration: 195 | loss: 2.231057\n",
      "iteration: 196 | loss: 2.223258\n",
      "iteration: 197 | loss: 2.300175\n",
      "iteration: 198 | loss: 2.259999\n",
      "iteration: 199 | loss: 2.269069\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 200 | loss: 2.262686\n",
      "iteration: 201 | loss: 2.262232\n",
      "iteration: 202 | loss: 2.259514\n",
      "iteration: 203 | loss: 2.283592\n",
      "iteration: 204 | loss: 2.273195\n",
      "iteration: 205 | loss: 2.282468\n",
      "iteration: 206 | loss: 2.215281\n",
      "iteration: 207 | loss: 2.228332\n",
      "iteration: 208 | loss: 2.245243\n",
      "iteration: 209 | loss: 2.253447\n",
      "iteration: 210 | loss: 2.254088\n",
      "iteration: 211 | loss: 2.244099\n",
      "iteration: 212 | loss: 2.249973\n",
      "iteration: 213 | loss: 2.237263\n",
      "iteration: 214 | loss: 2.256779\n",
      "iteration: 215 | loss: 2.267976\n",
      "iteration: 216 | loss: 2.279332\n",
      "iteration: 217 | loss: 2.308867\n",
      "iteration: 218 | loss: 2.321340\n",
      "iteration: 219 | loss: 2.262926\n",
      "iteration: 220 | loss: 2.235531\n",
      "iteration: 221 | loss: 2.252217\n",
      "iteration: 222 | loss: 2.247767\n",
      "iteration: 223 | loss: 2.253701\n",
      "iteration: 224 | loss: 2.247977\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 225 | loss: 2.211751\n",
      "iteration: 226 | loss: 2.238649\n",
      "iteration: 227 | loss: 2.263323\n",
      "iteration: 228 | loss: 2.274895\n",
      "iteration: 229 | loss: 2.206513\n",
      "iteration: 230 | loss: 2.225359\n",
      "iteration: 231 | loss: 2.214148\n",
      "iteration: 232 | loss: 2.283571\n",
      "iteration: 233 | loss: 2.241708\n",
      "iteration: 234 | loss: 2.237992\n",
      "iteration: 235 | loss: 2.248954\n",
      "iteration: 236 | loss: 2.204187\n",
      "iteration: 237 | loss: 2.235891\n",
      "iteration: 238 | loss: 2.274215\n",
      "iteration: 239 | loss: 2.248262\n",
      "iteration: 240 | loss: 2.258840\n",
      "iteration: 241 | loss: 2.231707\n",
      "iteration: 242 | loss: 2.232758\n",
      "iteration: 243 | loss: 2.219188\n",
      "iteration: 244 | loss: 2.262730\n",
      "iteration: 245 | loss: 2.272099\n",
      "iteration: 246 | loss: 2.202245\n",
      "iteration: 247 | loss: 2.260953\n",
      "iteration: 248 | loss: 2.264560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 249 | loss: 2.261842\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 250 | loss: 2.203348\n",
      "iteration: 251 | loss: 2.276705\n",
      "iteration: 252 | loss: 2.236087\n",
      "iteration: 253 | loss: 2.258068\n",
      "iteration: 254 | loss: 2.253169\n",
      "iteration: 255 | loss: 2.252038\n",
      "iteration: 256 | loss: 2.257000\n",
      "iteration: 257 | loss: 2.245904\n",
      "iteration: 258 | loss: 2.281026\n",
      "iteration: 259 | loss: 2.237116\n",
      "iteration: 260 | loss: 2.292474\n",
      "iteration: 261 | loss: 2.255903\n",
      "iteration: 262 | loss: 2.225045\n",
      "iteration: 263 | loss: 2.264307\n",
      "iteration: 264 | loss: 2.257256\n",
      "iteration: 265 | loss: 2.234325\n",
      "iteration: 266 | loss: 2.156227\n",
      "iteration: 267 | loss: 2.277790\n",
      "iteration: 268 | loss: 2.243404\n",
      "iteration: 269 | loss: 2.268074\n",
      "iteration: 270 | loss: 2.285757\n",
      "iteration: 271 | loss: 2.240848\n",
      "iteration: 272 | loss: 2.251083\n",
      "iteration: 273 | loss: 2.186613\n",
      "iteration: 274 | loss: 2.240333\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 275 | loss: 2.280030\n",
      "iteration: 276 | loss: 2.289022\n",
      "iteration: 277 | loss: 2.273629\n",
      "iteration: 278 | loss: 2.288121\n",
      "iteration: 279 | loss: 2.283332\n",
      "iteration: 280 | loss: 2.246711\n",
      "iteration: 281 | loss: 2.243164\n",
      "iteration: 282 | loss: 2.239787\n",
      "iteration: 283 | loss: 2.282738\n",
      "iteration: 284 | loss: 2.276889\n",
      "iteration: 285 | loss: 2.274203\n",
      "iteration: 286 | loss: 2.235420\n",
      "iteration: 287 | loss: 2.232832\n",
      "iteration: 288 | loss: 2.244042\n",
      "iteration: 289 | loss: 2.213473\n",
      "iteration: 290 | loss: 2.248193\n",
      "iteration: 291 | loss: 2.242819\n",
      "iteration: 292 | loss: 2.267295\n",
      "iteration: 293 | loss: 2.233464\n",
      "iteration: 294 | loss: 2.271655\n",
      "iteration: 295 | loss: 2.224268\n",
      "iteration: 296 | loss: 2.230633\n",
      "iteration: 297 | loss: 2.253479\n",
      "iteration: 298 | loss: 2.276303\n",
      "iteration: 299 | loss: 2.286425\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 300 | loss: 2.289688\n",
      "iteration: 301 | loss: 2.191903\n",
      "iteration: 302 | loss: 2.245808\n",
      "iteration: 303 | loss: 2.224397\n",
      "iteration: 304 | loss: 2.274363\n",
      "iteration: 305 | loss: 2.220114\n",
      "iteration: 306 | loss: 2.155262\n",
      "iteration: 307 | loss: 2.279672\n",
      "iteration: 308 | loss: 2.200788\n",
      "iteration: 309 | loss: 2.185832\n",
      "iteration: 310 | loss: 2.212788\n",
      "iteration: 311 | loss: 2.218717\n",
      "iteration: 312 | loss: 2.236351\n",
      "iteration: 313 | loss: 2.245422\n",
      "iteration: 314 | loss: 2.161306\n",
      "iteration: 315 | loss: 2.255427\n",
      "iteration: 316 | loss: 2.288128\n",
      "iteration: 317 | loss: 2.201874\n",
      "iteration: 318 | loss: 2.266921\n",
      "iteration: 319 | loss: 2.264932\n",
      "iteration: 320 | loss: 2.302314\n",
      "iteration: 321 | loss: 2.146485\n",
      "iteration: 322 | loss: 2.243561\n",
      "iteration: 323 | loss: 2.282715\n",
      "iteration: 324 | loss: 2.226006\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 325 | loss: 2.244996\n",
      "iteration: 326 | loss: 2.220398\n",
      "iteration: 327 | loss: 2.212019\n",
      "iteration: 328 | loss: 2.245761\n",
      "iteration: 329 | loss: 2.240181\n",
      "iteration: 330 | loss: 2.204646\n",
      "iteration: 331 | loss: 2.243540\n",
      "iteration: 332 | loss: 2.235778\n",
      "iteration: 333 | loss: 2.301322\n",
      "iteration: 334 | loss: 2.163252\n",
      "iteration: 335 | loss: 2.258123\n",
      "iteration: 336 | loss: 2.158798\n",
      "iteration: 337 | loss: 2.213251\n",
      "iteration: 338 | loss: 2.179840\n",
      "iteration: 339 | loss: 2.250969\n",
      "iteration: 340 | loss: 2.245327\n",
      "iteration: 341 | loss: 2.251667\n",
      "iteration: 342 | loss: 2.237686\n",
      "iteration: 343 | loss: 2.231525\n",
      "iteration: 344 | loss: 2.211076\n",
      "iteration: 345 | loss: 2.284067\n",
      "iteration: 346 | loss: 2.348673\n",
      "iteration: 347 | loss: 2.258106\n",
      "iteration: 348 | loss: 2.211918\n",
      "iteration: 349 | loss: 2.241915\n",
      "  Train acc: 0.22, Val acc: 0.0\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "sgd_net1 = ConvNet4(input_shape=(3, 16, 16), wt_scale=1e-2, verbose=False)\n",
    "sgd_net1.compile(\"SGD\", lr=0.01)\n",
    "\n",
    "sgd_net1.fit(x_dev, y_dev, x_val, y_val, mini_batch_sz=25, n_epochs=175, acc_freq=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: Why does decreasing the mini-batch size make the loss print-outs more erratic?\n",
    "\n",
    "**Answer**: When the mini-batch size is smaller, each forward and backward pass of the mini_batch occurs proportionally faster and hence, smaller mini-batch sizes result in more loss print outs. Further more, obtaining the loss for smaller sets of images tests only certain aspects of the network and hence the loss we get is more erratic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6d) Evaluate the different optimizers\n",
    "\n",
    "Make 2 \"high quality\" plots showing the following\n",
    "\n",
    "- Plot the accuracy (y axis) for the three optimizers as a function of training epoch (x axis).\n",
    "- Plot the loss (y axis) for the three optimizers as a function of training iteration (x axis).\n",
    "\n",
    "A high quality plot consists of:\n",
    "- A useful title\n",
    "- X and Y axis labels\n",
    "- A legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(0, 851, 25), adam_net.train_acc_history, label='Adam')\n",
    "plt.plot(range(0, 851, 25), sgdm_net.train_acc_history, label='SGD-M')\n",
    "plt.plot(range(0, 851, 25), sgd_net.train_acc_history, label='SGD')\n",
    "\n",
    "plt.xlabel('Training Iteration')\n",
    "plt.ylabel('Training Set Accuracy')\n",
    "plt.title(\"Accuracy Over Iterations - Batch Size = 10\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(adam_net.loss_history, label='Adam')\n",
    "plt.plot(sgdm_net.loss_history, label='SGD-M')\n",
    "plt.plot(sgd_net.loss_history, label='SGD')\n",
    "\n",
    "plt.xlabel('Training Iteration')\n",
    "plt.ylabel('Average Train Set Loss (Cross Entropy)')\n",
    "plt.title(\"Loss Over Iterations - Batch Size = 10\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(0, 352, 27), adam_net1.train_acc_history, label='Adam')\n",
    "plt.plot(range(0, 352, 27), sgdm_net1.train_acc_history, label='SGD-M')\n",
    "plt.plot(range(0, 352, 27), sgd_net1.train_acc_history, label='SGD')\n",
    "\n",
    "plt.xlabel('Training Iteration')\n",
    "plt.ylabel('Training Set Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy Over Iterations - Batch Size = 25\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The graph below should be labelled Loss Over Iterations - Batch Size = 25**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(adam_net1.loss_history, label='Adam')\n",
    "plt.plot(sgdm_net1.loss_history, label='SGD-M')\n",
    "plt.plot(sgd_net1.loss_history, label='SGD')\n",
    "\n",
    "plt.xlabel('Training Iteration')\n",
    "plt.ylabel('Average Train Set Loss (Cross Entropy)')\n",
    "plt.title(\"Loss Over Iterations - Batch Size = 10\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Impact of Batch Size on Loss & Accuracy for different Optimizers** In the above plots, we see differences, the first plot is done for models created with batch size = 10, while the second plot is done for models creating batch size = 25. We see that SGD-M is able to make quicker changes and develop faster momentum for larger number of iterations, thus manages to converge sooner for smaller batch sizes. This gives us an interesting insight into the momentum variable stacking up over iterations rather than size of data. We also see that adam is more succeptible to noisy loss values and thus performs better in the case that batch size is larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**: Which optimizer works best and why do think it is best?\n",
    "\n",
    "**Answer:** Adam seems to work the best, since it converges the fastest to a lower loss value (for bigger batch sizes). This could be because it is able to adapt and dynamically change the extent to which d_wts changes the networks weights. \n",
    "\n",
    "**Question 5**: What is happening with the training set accuracy and why?\n",
    "\n",
    "**Answer:** Accuracy increases for all optimizers over iterations. However, with vanilla SGD this happens very slowly. SGD-M starts off slow, but as the momentum stacks up the network closes in on the optimal solution faster. Adam's accuracy increases the fastest. It seems that Adam and SGD-M are converging to the same final accuracy value, although we know that this is not always the case when using different optimizers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Training convolutional neural network on STL-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7a) Load in STL-10 at 32x32 resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images are: (5000, 96, 96, 3)\n",
      "Labels are: (5000,)\n",
      "Resizing 5000 images to 32x32...Done!\n",
      "Saving Numpy arrays the images and labels to ./numpy...Done!\n",
      "imgs shape before transpose (5000, 32, 32, 3)\n",
      "imgs shape after transpose (5000, 3, 32, 32)\n",
      "Train data shape:  (4548, 3, 32, 32)\n",
      "Train labels shape:  (4548,)\n",
      "Test data shape:  (400, 3, 32, 32)\n",
      "Test labels shape:  (400,)\n",
      "Validation data shape:  (2, 3, 32, 32)\n",
      "Validation labels shape:  (2,)\n",
      "dev data shape:  (50, 3, 32, 32)\n",
      "dev labels shape:  (50,)\n"
     ]
    }
   ],
   "source": [
    "# Download the STL-10 dataset from the internet, convert it to Numpy ndarray, resize to 32x32\n",
    "# cache it locally on your computer for faster loading next time.\n",
    "load_stl10_dataset.purge_cached_dataset()\n",
    "stl_imgs, stl_labels = load_stl10_dataset.load(scale_fact=3)\n",
    "# preprocess\n",
    "stl_imgs, stl_labels = preprocess_data.preprocess_stl(stl_imgs, stl_labels)\n",
    "# create splits\n",
    "x_train, y_train, x_test, y_test, x_val, y_val, x_dev, y_dev = preprocess_data.create_splits(\n",
    "    stl_imgs, stl_labels, n_train_samps=4548, n_test_samps=400, n_valid_samps=2, n_dev_samps=50)\n",
    "\n",
    "print ('Train data shape: ', x_train.shape)\n",
    "print ('Train labels shape: ', y_train.shape)\n",
    "print ('Test data shape: ', x_test.shape)\n",
    "print ('Test labels shape: ', y_test.shape)\n",
    "print ('Validation data shape: ', x_val.shape)\n",
    "print ('Validation labels shape: ', y_val.shape)\n",
    "print ('dev data shape: ', x_dev.shape)\n",
    "print ('dev labels shape: ', y_dev.shape)\n",
    "\n",
    "classes = np.loadtxt(os.path.join('data', 'stl10_binary', 'class_names.txt'), dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7b) Set up accelerated convolution and max pooling layers\n",
    "\n",
    "As you may have noticed, we had to downsize STL-10 to 16x16 resolution to train the network on the dev set (N=50) in a reasonable amount of time. The training set is N=4000, how will we ever manage to process that amount of data!?\n",
    "\n",
    "On one hand, this is an unfortunate inevitable reality of working with large (\"big\") datasets: you can easily find a dataset that is too time consuming to process for any computer, despite how fast/many CPU/GPUs it has.\n",
    "\n",
    "On the other hand, we can do better for this project and STL-10 :) If you were to time (profile) different parts of the training process, you'd notice that largest bottleneck is convolution and max pooling operations (both forward/backward). You implemented those operations intuitively, which does not always yield the best performance. **By swapping out forward/backward convolution and maxpooling for implementations that use different algorithms (im2col, reshaping) that are compiled to C code, we will speed up training up by several orders of magnitude**.\n",
    "\n",
    "Follow these steps to subsitute in the \"accelerated\" convolution and max pooling layers.\n",
    "\n",
    "- Install the `cython` python package: `pip3 install cython` (or `pip3 install cython --user` if working in Davis 102)\n",
    "- Dowload files `im2col_cython.pyx`, `accelerated_layer.py`, `setup.py` from the project website. Put them in your base project folder.\n",
    "- Open terminal, `cd` to Project directory.\n",
    "- Compile the im2col functions: `python3 setup.py build_ext --inplace`. A `.c` and `.so` file should have appeared in your project folder.\n",
    "- Restart Jupyter Notebook kernel\n",
    "- Create a class called `Conv4NetAccel` in `network.py` by copy-pasting the contents of `Conv4Net`. Import `accelerated_layer` at the top and replace the `Conv2D` and `MaxPool2D` layers with `Conv2DAccel` and `MaxPool2DAccel`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7c) Training convolutional neural network on STL-10\n",
    "\n",
    "You are now ready to train on the entire training set.\n",
    "\n",
    "- Create a `Conv4NetAccel` object with hyperparameters of your choice.\n",
    "- Your goal is to achieve 45% accuracy on the test and/or validation set.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- I suggest using your intuition about hyperparameters and over/underfitting to guide your choice, rather than a grid search. This should not be overly challenging.\n",
    "- Use the best / most efficient optimizer based on your prior analysis.\n",
    "- It should take on the order of 1 sec per training iteration. If that's way off, seek help as something could be wrong with running the acclerated code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train...\n",
      "3620 iterations. 181 iter/epoch.\n",
      "iteration: 0 | loss: 2.301284\n",
      "iteration: 1 | loss: 2.302109\n",
      "iteration: 2 | loss: 2.296336\n",
      "iteration: 3 | loss: 2.304156\n",
      "iteration: 4 | loss: 2.303676\n",
      "iteration: 5 | loss: 2.286080\n",
      "iteration: 6 | loss: 2.267168\n",
      "iteration: 7 | loss: 2.281272\n",
      "iteration: 8 | loss: 2.276506\n",
      "iteration: 9 | loss: 2.238647\n",
      "iteration: 10 | loss: 2.179864\n",
      "iteration: 11 | loss: 2.231117\n",
      "iteration: 12 | loss: 2.239172\n",
      "iteration: 13 | loss: 2.211096\n",
      "iteration: 14 | loss: 2.134568\n",
      "iteration: 15 | loss: 2.212462\n",
      "iteration: 16 | loss: 2.230874\n",
      "iteration: 17 | loss: 2.112933\n",
      "iteration: 18 | loss: 2.121093\n",
      "iteration: 19 | loss: 2.053386\n",
      "iteration: 20 | loss: 1.900341\n",
      "iteration: 21 | loss: 1.814798\n",
      "iteration: 22 | loss: 2.413750\n",
      "iteration: 23 | loss: 2.036419\n",
      "iteration: 24 | loss: 2.069883\n",
      "  Train acc: 0.22, Val acc: 0.0\n",
      "iteration: 25 | loss: 1.944504\n",
      "iteration: 26 | loss: 1.858502\n",
      "iteration: 27 | loss: 1.995618\n",
      "iteration: 28 | loss: 1.998732\n",
      "iteration: 29 | loss: 2.049829\n",
      "iteration: 30 | loss: 1.861288\n",
      "iteration: 31 | loss: 1.690830\n",
      "iteration: 32 | loss: 1.735090\n",
      "iteration: 33 | loss: 1.923567\n",
      "iteration: 34 | loss: 1.929063\n",
      "iteration: 35 | loss: 2.008745\n",
      "iteration: 36 | loss: 1.992875\n",
      "iteration: 37 | loss: 1.684619\n",
      "iteration: 38 | loss: 1.808192\n",
      "iteration: 39 | loss: 1.713507\n",
      "iteration: 40 | loss: 1.896503\n",
      "iteration: 41 | loss: 1.971529\n",
      "iteration: 42 | loss: 2.042928\n",
      "iteration: 43 | loss: 2.293897\n",
      "iteration: 44 | loss: 1.991665\n",
      "iteration: 45 | loss: 2.013911\n",
      "iteration: 46 | loss: 1.636502\n",
      "iteration: 47 | loss: 1.825858\n",
      "iteration: 48 | loss: 1.966435\n",
      "iteration: 49 | loss: 1.783135\n",
      "  Train acc: 0.258, Val acc: 0.0\n",
      "iteration: 50 | loss: 2.023101\n",
      "iteration: 51 | loss: 1.984949\n",
      "iteration: 52 | loss: 2.055855\n",
      "iteration: 53 | loss: 1.866307\n",
      "iteration: 54 | loss: 1.849351\n",
      "iteration: 55 | loss: 1.847469\n",
      "iteration: 56 | loss: 2.025463\n",
      "iteration: 57 | loss: 1.748655\n",
      "iteration: 58 | loss: 2.062988\n",
      "iteration: 59 | loss: 1.611918\n",
      "iteration: 60 | loss: 1.980980\n",
      "iteration: 61 | loss: 2.091175\n",
      "iteration: 62 | loss: 2.082267\n",
      "iteration: 63 | loss: 2.029538\n",
      "iteration: 64 | loss: 1.868164\n",
      "iteration: 65 | loss: 1.777301\n",
      "iteration: 66 | loss: 1.880136\n",
      "iteration: 67 | loss: 1.725030\n",
      "iteration: 68 | loss: 1.896600\n",
      "iteration: 69 | loss: 1.746910\n",
      "iteration: 70 | loss: 1.911837\n",
      "iteration: 71 | loss: 2.031722\n",
      "iteration: 72 | loss: 1.889744\n",
      "iteration: 73 | loss: 2.180936\n",
      "iteration: 74 | loss: 1.909208\n",
      "  Train acc: 0.304, Val acc: 0.0\n",
      "iteration: 75 | loss: 1.742810\n",
      "iteration: 76 | loss: 1.708554\n",
      "iteration: 77 | loss: 1.693375\n",
      "iteration: 78 | loss: 1.614828\n",
      "iteration: 79 | loss: 1.946035\n",
      "iteration: 80 | loss: 1.870937\n",
      "iteration: 81 | loss: 1.729477\n",
      "iteration: 82 | loss: 1.651983\n",
      "iteration: 83 | loss: 1.954798\n",
      "iteration: 84 | loss: 1.797712\n",
      "iteration: 85 | loss: 1.794237\n",
      "iteration: 86 | loss: 1.984895\n",
      "iteration: 87 | loss: 1.742336\n",
      "iteration: 88 | loss: 1.624002\n",
      "iteration: 89 | loss: 1.558023\n",
      "iteration: 90 | loss: 1.504767\n",
      "iteration: 91 | loss: 2.050615\n",
      "iteration: 92 | loss: 1.999390\n",
      "iteration: 93 | loss: 1.774179\n",
      "iteration: 94 | loss: 1.647668\n",
      "iteration: 95 | loss: 2.103123\n",
      "iteration: 96 | loss: 1.633623\n",
      "iteration: 97 | loss: 1.646733\n",
      "iteration: 98 | loss: 1.838756\n",
      "iteration: 99 | loss: 1.702791\n",
      "  Train acc: 0.34, Val acc: 0.0\n",
      "iteration: 100 | loss: 1.692113\n",
      "iteration: 101 | loss: 1.689618\n",
      "iteration: 102 | loss: 1.709716\n",
      "iteration: 103 | loss: 2.035621\n",
      "iteration: 104 | loss: 1.618373\n",
      "iteration: 105 | loss: 1.585886\n",
      "iteration: 106 | loss: 1.642059\n",
      "iteration: 107 | loss: 1.541635\n",
      "iteration: 108 | loss: 1.576223\n",
      "iteration: 109 | loss: 1.487524\n",
      "iteration: 110 | loss: 1.618310\n",
      "iteration: 111 | loss: 1.791996\n",
      "iteration: 112 | loss: 1.884782\n",
      "iteration: 113 | loss: 1.880118\n",
      "iteration: 114 | loss: 1.844869\n",
      "iteration: 115 | loss: 1.720126\n",
      "iteration: 116 | loss: 1.546138\n",
      "iteration: 117 | loss: 1.656439\n",
      "iteration: 118 | loss: 1.757973\n",
      "iteration: 119 | loss: 1.253415\n",
      "iteration: 120 | loss: 1.685405\n",
      "iteration: 121 | loss: 2.167247\n",
      "iteration: 122 | loss: 1.542194\n",
      "iteration: 123 | loss: 1.984862\n",
      "iteration: 124 | loss: 1.716055\n",
      "  Train acc: 0.39, Val acc: 0.0\n",
      "iteration: 125 | loss: 1.469598\n",
      "iteration: 126 | loss: 1.456266\n",
      "iteration: 127 | loss: 1.648075\n",
      "iteration: 128 | loss: 1.851606\n",
      "iteration: 129 | loss: 1.507152\n",
      "iteration: 130 | loss: 1.637075\n",
      "iteration: 131 | loss: 1.600970\n",
      "iteration: 132 | loss: 1.694393\n",
      "iteration: 133 | loss: 1.654225\n",
      "iteration: 134 | loss: 1.578252\n",
      "iteration: 135 | loss: 1.611751\n",
      "iteration: 136 | loss: 1.690770\n",
      "iteration: 137 | loss: 1.705294\n",
      "iteration: 138 | loss: 1.858864\n",
      "iteration: 139 | loss: 1.630334\n",
      "iteration: 140 | loss: 1.520085\n",
      "iteration: 141 | loss: 1.710174\n",
      "iteration: 142 | loss: 1.444548\n",
      "iteration: 143 | loss: 1.614108\n",
      "iteration: 144 | loss: 1.597397\n",
      "iteration: 145 | loss: 1.880769\n",
      "iteration: 146 | loss: 2.093544\n",
      "iteration: 147 | loss: 1.482395\n",
      "iteration: 148 | loss: 1.586965\n",
      "iteration: 149 | loss: 1.691555\n",
      "  Train acc: 0.416, Val acc: 0.0\n",
      "iteration: 150 | loss: 1.519160\n",
      "iteration: 151 | loss: 1.482088\n",
      "iteration: 152 | loss: 1.401826\n",
      "iteration: 153 | loss: 1.633780\n",
      "iteration: 154 | loss: 1.583490\n",
      "iteration: 155 | loss: 1.513245\n",
      "iteration: 156 | loss: 1.753738\n",
      "iteration: 157 | loss: 1.643116\n",
      "iteration: 158 | loss: 2.025196\n",
      "iteration: 159 | loss: 1.458887\n",
      "iteration: 160 | loss: 1.224122\n",
      "iteration: 161 | loss: 1.429951\n",
      "iteration: 162 | loss: 1.581524\n",
      "iteration: 163 | loss: 1.725194\n",
      "iteration: 164 | loss: 1.425982\n",
      "iteration: 165 | loss: 1.357420\n",
      "iteration: 166 | loss: 1.451277\n",
      "iteration: 167 | loss: 1.400227\n",
      "iteration: 168 | loss: 1.505425\n",
      "iteration: 169 | loss: 1.709940\n",
      "iteration: 170 | loss: 1.386889\n",
      "iteration: 171 | loss: 1.489178\n",
      "iteration: 172 | loss: 1.490086\n",
      "iteration: 173 | loss: 1.573092\n",
      "iteration: 174 | loss: 1.351142\n",
      "  Train acc: 0.39, Val acc: 0.0\n",
      "iteration: 175 | loss: 1.884777\n",
      "iteration: 176 | loss: 1.742358\n",
      "iteration: 177 | loss: 1.720256\n",
      "iteration: 178 | loss: 1.528316\n",
      "iteration: 179 | loss: 1.739491\n",
      "iteration: 180 | loss: 1.231937\n",
      "iteration: 181 | loss: 1.365773\n",
      "iteration: 182 | loss: 1.249662\n",
      "iteration: 183 | loss: 1.508328\n",
      "iteration: 184 | loss: 1.558479\n",
      "iteration: 185 | loss: 1.382113\n",
      "iteration: 186 | loss: 1.428695\n",
      "iteration: 187 | loss: 1.157240\n",
      "iteration: 188 | loss: 1.464647\n",
      "iteration: 189 | loss: 1.122077\n",
      "iteration: 190 | loss: 1.743737\n",
      "iteration: 191 | loss: 1.230221\n",
      "iteration: 192 | loss: 1.292205\n",
      "iteration: 193 | loss: 1.914302\n",
      "iteration: 194 | loss: 1.581223\n",
      "iteration: 195 | loss: 1.938923\n",
      "iteration: 196 | loss: 1.687671\n",
      "iteration: 197 | loss: 1.655797\n",
      "iteration: 198 | loss: 1.259534\n",
      "iteration: 199 | loss: 1.798532\n",
      "  Train acc: 0.366, Val acc: 0.0\n",
      "iteration: 200 | loss: 1.612073\n",
      "iteration: 201 | loss: 1.720167\n",
      "iteration: 202 | loss: 1.625783\n",
      "iteration: 203 | loss: 1.436301\n",
      "iteration: 204 | loss: 1.483575\n",
      "iteration: 205 | loss: 1.690289\n",
      "iteration: 206 | loss: 1.570187\n",
      "iteration: 207 | loss: 1.374384\n",
      "iteration: 208 | loss: 1.713563\n",
      "iteration: 209 | loss: 1.505057\n",
      "iteration: 210 | loss: 1.679483\n",
      "iteration: 211 | loss: 1.517952\n",
      "iteration: 212 | loss: 1.847632\n",
      "iteration: 213 | loss: 1.829219\n",
      "iteration: 214 | loss: 1.683288\n",
      "iteration: 215 | loss: 1.391213\n",
      "iteration: 216 | loss: 1.641597\n",
      "iteration: 217 | loss: 1.276702\n",
      "iteration: 218 | loss: 1.446344\n",
      "iteration: 219 | loss: 1.421707\n",
      "iteration: 220 | loss: 1.742761\n",
      "iteration: 221 | loss: 1.572053\n",
      "iteration: 222 | loss: 1.378050\n",
      "iteration: 223 | loss: 1.735411\n",
      "iteration: 224 | loss: 1.771717\n",
      "  Train acc: 0.392, Val acc: 0.0\n",
      "iteration: 225 | loss: 1.804349\n",
      "iteration: 226 | loss: 1.496322\n",
      "iteration: 227 | loss: 1.672942\n",
      "iteration: 228 | loss: 1.535423\n",
      "iteration: 229 | loss: 1.253928\n",
      "iteration: 230 | loss: 1.594252\n",
      "iteration: 231 | loss: 1.666068\n",
      "iteration: 232 | loss: 1.802566\n",
      "iteration: 233 | loss: 1.363406\n",
      "iteration: 234 | loss: 1.376847\n",
      "iteration: 235 | loss: 1.510867\n",
      "iteration: 236 | loss: 1.641408\n",
      "iteration: 237 | loss: 1.551101\n",
      "iteration: 238 | loss: 1.913788\n",
      "iteration: 239 | loss: 1.670582\n",
      "iteration: 240 | loss: 1.329775\n",
      "iteration: 241 | loss: 1.511181\n",
      "iteration: 242 | loss: 1.184134\n",
      "iteration: 243 | loss: 1.457003\n",
      "iteration: 244 | loss: 1.499232\n",
      "iteration: 245 | loss: 1.608529\n",
      "iteration: 246 | loss: 1.633618\n",
      "iteration: 247 | loss: 1.611424\n",
      "iteration: 248 | loss: 1.622274\n",
      "iteration: 249 | loss: 1.418445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train acc: 0.444, Val acc: 0.0\n",
      "iteration: 250 | loss: 1.299751\n",
      "iteration: 251 | loss: 1.315879\n",
      "iteration: 252 | loss: 1.558714\n",
      "iteration: 253 | loss: 1.563832\n",
      "iteration: 254 | loss: 1.508371\n",
      "iteration: 255 | loss: 1.412986\n",
      "iteration: 256 | loss: 1.386223\n",
      "iteration: 257 | loss: 1.448244\n",
      "iteration: 258 | loss: 1.481134\n",
      "iteration: 259 | loss: 1.495072\n",
      "iteration: 260 | loss: 1.454987\n",
      "iteration: 261 | loss: 1.559469\n",
      "iteration: 262 | loss: 1.404653\n",
      "iteration: 263 | loss: 1.265466\n",
      "iteration: 264 | loss: 1.777141\n",
      "iteration: 265 | loss: 1.362598\n",
      "iteration: 266 | loss: 1.059294\n",
      "iteration: 267 | loss: 1.542713\n",
      "iteration: 268 | loss: 1.519024\n",
      "iteration: 269 | loss: 1.427112\n",
      "iteration: 270 | loss: 1.683756\n",
      "iteration: 271 | loss: 1.303169\n",
      "iteration: 272 | loss: 1.871197\n",
      "iteration: 273 | loss: 1.789834\n",
      "iteration: 274 | loss: 1.625481\n",
      "  Train acc: 0.448, Val acc: 0.0\n",
      "iteration: 275 | loss: 1.138947\n",
      "iteration: 276 | loss: 1.557726\n",
      "iteration: 277 | loss: 1.431702\n",
      "iteration: 278 | loss: 1.422966\n",
      "iteration: 279 | loss: 1.385975\n",
      "iteration: 280 | loss: 1.489477\n",
      "iteration: 281 | loss: 1.580074\n",
      "iteration: 282 | loss: 1.656382\n",
      "iteration: 283 | loss: 1.504878\n",
      "iteration: 284 | loss: 1.213060\n",
      "iteration: 285 | loss: 1.372909\n",
      "iteration: 286 | loss: 1.265923\n",
      "iteration: 287 | loss: 1.336094\n",
      "iteration: 288 | loss: 1.283539\n",
      "iteration: 289 | loss: 1.528988\n",
      "iteration: 290 | loss: 1.325927\n",
      "iteration: 291 | loss: 1.672751\n",
      "iteration: 292 | loss: 1.462381\n",
      "iteration: 293 | loss: 1.864362\n",
      "iteration: 294 | loss: 1.256794\n",
      "iteration: 295 | loss: 1.475726\n",
      "iteration: 296 | loss: 1.327903\n",
      "iteration: 297 | loss: 1.660172\n",
      "iteration: 298 | loss: 1.715136\n",
      "iteration: 299 | loss: 1.436306\n",
      "  Train acc: 0.436, Val acc: 0.5\n",
      "iteration: 300 | loss: 1.769545\n",
      "iteration: 301 | loss: 1.558129\n",
      "iteration: 302 | loss: 1.459029\n",
      "iteration: 303 | loss: 1.436524\n",
      "iteration: 304 | loss: 1.514899\n",
      "iteration: 305 | loss: 1.366525\n",
      "iteration: 306 | loss: 1.520318\n",
      "iteration: 307 | loss: 1.573496\n",
      "iteration: 308 | loss: 1.274554\n",
      "iteration: 309 | loss: 1.338910\n",
      "iteration: 310 | loss: 1.626788\n",
      "iteration: 311 | loss: 1.382547\n",
      "iteration: 312 | loss: 1.613501\n",
      "iteration: 313 | loss: 1.152915\n",
      "iteration: 314 | loss: 1.214390\n",
      "iteration: 315 | loss: 1.426608\n",
      "iteration: 316 | loss: 1.373908\n",
      "iteration: 317 | loss: 1.679693\n",
      "iteration: 318 | loss: 1.564155\n",
      "iteration: 319 | loss: 1.258031\n",
      "iteration: 320 | loss: 1.169289\n",
      "iteration: 321 | loss: 1.369316\n",
      "iteration: 322 | loss: 1.554470\n",
      "iteration: 323 | loss: 1.199794\n",
      "iteration: 324 | loss: 1.301513\n",
      "  Train acc: 0.448, Val acc: 0.5\n",
      "iteration: 325 | loss: 1.514770\n",
      "iteration: 326 | loss: 1.527786\n",
      "iteration: 327 | loss: 1.238985\n",
      "iteration: 328 | loss: 1.650961\n",
      "iteration: 329 | loss: 1.285564\n",
      "iteration: 330 | loss: 1.536851\n",
      "iteration: 331 | loss: 1.388674\n",
      "iteration: 332 | loss: 1.140588\n",
      "iteration: 333 | loss: 1.467468\n",
      "iteration: 334 | loss: 1.450530\n",
      "iteration: 335 | loss: 1.521429\n",
      "iteration: 336 | loss: 1.517903\n",
      "iteration: 337 | loss: 1.354988\n",
      "iteration: 338 | loss: 1.705328\n",
      "iteration: 339 | loss: 1.478802\n",
      "iteration: 340 | loss: 1.055262\n",
      "iteration: 341 | loss: 1.421541\n",
      "iteration: 342 | loss: 1.398651\n",
      "iteration: 343 | loss: 1.232744\n",
      "iteration: 344 | loss: 1.086582\n",
      "iteration: 345 | loss: 1.341149\n",
      "iteration: 346 | loss: 1.191267\n",
      "iteration: 347 | loss: 0.954851\n",
      "iteration: 348 | loss: 1.706375\n",
      "iteration: 349 | loss: 1.324276\n",
      "  Train acc: 0.456, Val acc: 0.5\n",
      "iteration: 350 | loss: 1.215146\n",
      "iteration: 351 | loss: 1.481725\n",
      "iteration: 352 | loss: 1.055282\n",
      "iteration: 353 | loss: 1.262527\n",
      "iteration: 354 | loss: 1.920474\n",
      "iteration: 355 | loss: 1.537311\n",
      "iteration: 356 | loss: 1.443331\n",
      "iteration: 357 | loss: 1.345288\n",
      "iteration: 358 | loss: 1.343844\n",
      "iteration: 359 | loss: 1.013012\n",
      "iteration: 360 | loss: 1.599327\n",
      "iteration: 361 | loss: 1.156902\n",
      "iteration: 362 | loss: 1.191033\n",
      "iteration: 363 | loss: 1.715527\n",
      "iteration: 364 | loss: 1.367674\n",
      "iteration: 365 | loss: 1.609927\n",
      "iteration: 366 | loss: 1.308823\n",
      "iteration: 367 | loss: 1.363127\n",
      "iteration: 368 | loss: 1.651328\n",
      "iteration: 369 | loss: 0.830868\n",
      "iteration: 370 | loss: 1.239737\n",
      "iteration: 371 | loss: 1.128603\n",
      "iteration: 372 | loss: 1.261341\n",
      "iteration: 373 | loss: 1.122028\n",
      "iteration: 374 | loss: 1.546809\n",
      "  Train acc: 0.428, Val acc: 0.5\n",
      "iteration: 375 | loss: 1.033014\n",
      "iteration: 376 | loss: 1.431409\n",
      "iteration: 377 | loss: 1.552272\n",
      "iteration: 378 | loss: 1.285146\n",
      "iteration: 379 | loss: 1.541394\n",
      "iteration: 380 | loss: 1.244743\n",
      "iteration: 381 | loss: 1.171681\n",
      "iteration: 382 | loss: 1.427279\n",
      "iteration: 383 | loss: 1.368662\n",
      "iteration: 384 | loss: 1.455472\n",
      "iteration: 385 | loss: 1.249393\n",
      "iteration: 386 | loss: 1.022150\n",
      "iteration: 387 | loss: 1.521112\n",
      "iteration: 388 | loss: 1.421357\n",
      "iteration: 389 | loss: 0.910070\n",
      "iteration: 390 | loss: 1.306019\n",
      "iteration: 391 | loss: 1.243194\n",
      "iteration: 392 | loss: 1.482291\n",
      "iteration: 393 | loss: 1.370077\n",
      "iteration: 394 | loss: 1.616248\n",
      "iteration: 395 | loss: 1.373084\n",
      "iteration: 396 | loss: 1.583104\n",
      "iteration: 397 | loss: 1.332257\n",
      "iteration: 398 | loss: 1.756821\n",
      "iteration: 399 | loss: 1.241967\n",
      "  Train acc: 0.456, Val acc: 0.0\n",
      "iteration: 400 | loss: 1.070746\n",
      "iteration: 401 | loss: 1.379854\n",
      "iteration: 402 | loss: 1.594675\n",
      "iteration: 403 | loss: 1.447624\n",
      "iteration: 404 | loss: 1.449024\n",
      "iteration: 405 | loss: 1.403811\n",
      "iteration: 406 | loss: 1.309944\n",
      "iteration: 407 | loss: 1.366284\n",
      "iteration: 408 | loss: 1.342664\n",
      "iteration: 409 | loss: 1.473921\n",
      "iteration: 410 | loss: 1.514027\n",
      "iteration: 411 | loss: 1.015200\n",
      "iteration: 412 | loss: 1.497273\n",
      "iteration: 413 | loss: 1.423655\n",
      "iteration: 414 | loss: 1.428458\n",
      "iteration: 415 | loss: 1.244461\n",
      "iteration: 416 | loss: 1.041863\n",
      "iteration: 417 | loss: 0.950549\n",
      "iteration: 418 | loss: 1.262752\n",
      "iteration: 419 | loss: 1.591869\n",
      "iteration: 420 | loss: 1.446821\n",
      "iteration: 421 | loss: 1.630719\n",
      "iteration: 422 | loss: 1.444243\n",
      "iteration: 423 | loss: 1.239445\n",
      "iteration: 424 | loss: 1.547157\n",
      "  Train acc: 0.496, Val acc: 0.0\n",
      "iteration: 425 | loss: 1.328612\n",
      "iteration: 426 | loss: 1.320995\n",
      "iteration: 427 | loss: 1.679391\n",
      "iteration: 428 | loss: 1.301235\n",
      "iteration: 429 | loss: 1.151698\n",
      "iteration: 430 | loss: 1.451070\n",
      "iteration: 431 | loss: 1.317164\n",
      "iteration: 432 | loss: 1.003852\n",
      "iteration: 433 | loss: 1.200640\n",
      "iteration: 434 | loss: 1.800572\n",
      "iteration: 435 | loss: 1.331004\n",
      "iteration: 436 | loss: 1.111032\n",
      "iteration: 437 | loss: 0.934007\n",
      "iteration: 438 | loss: 1.178272\n",
      "iteration: 439 | loss: 1.254110\n",
      "iteration: 440 | loss: 1.155804\n",
      "iteration: 441 | loss: 1.560957\n",
      "iteration: 442 | loss: 1.268063\n",
      "iteration: 443 | loss: 1.426674\n",
      "iteration: 444 | loss: 1.179079\n",
      "iteration: 445 | loss: 1.434404\n",
      "iteration: 446 | loss: 1.452119\n",
      "iteration: 447 | loss: 1.093493\n",
      "iteration: 448 | loss: 1.290204\n",
      "iteration: 449 | loss: 1.224340\n",
      "  Train acc: 0.494, Val acc: 0.5\n",
      "iteration: 450 | loss: 1.077081\n",
      "iteration: 451 | loss: 1.196124\n",
      "iteration: 452 | loss: 1.411203\n",
      "iteration: 453 | loss: 1.204327\n",
      "iteration: 454 | loss: 1.269321\n",
      "iteration: 455 | loss: 1.162202\n",
      "iteration: 456 | loss: 1.179913\n",
      "iteration: 457 | loss: 0.876809\n",
      "iteration: 458 | loss: 1.034138\n",
      "iteration: 459 | loss: 1.860971\n",
      "iteration: 460 | loss: 1.573542\n",
      "iteration: 461 | loss: 1.439410\n",
      "iteration: 462 | loss: 1.461695\n",
      "iteration: 463 | loss: 1.589400\n",
      "iteration: 464 | loss: 1.411041\n",
      "iteration: 465 | loss: 1.278090\n",
      "iteration: 466 | loss: 1.430797\n",
      "iteration: 467 | loss: 1.381580\n",
      "iteration: 468 | loss: 1.310128\n",
      "iteration: 469 | loss: 1.396057\n",
      "iteration: 470 | loss: 1.416949\n",
      "iteration: 471 | loss: 1.145224\n",
      "iteration: 472 | loss: 1.415758\n",
      "iteration: 473 | loss: 1.284052\n",
      "iteration: 474 | loss: 1.388803\n",
      "  Train acc: 0.494, Val acc: 0.5\n",
      "iteration: 475 | loss: 1.082714\n",
      "iteration: 476 | loss: 1.299678\n",
      "iteration: 477 | loss: 1.275705\n",
      "iteration: 478 | loss: 1.144090\n",
      "iteration: 479 | loss: 1.424052\n",
      "iteration: 480 | loss: 1.191537\n",
      "iteration: 481 | loss: 1.330620\n",
      "iteration: 482 | loss: 1.259493\n",
      "iteration: 483 | loss: 1.415692\n",
      "iteration: 484 | loss: 1.653449\n",
      "iteration: 485 | loss: 1.395063\n",
      "iteration: 486 | loss: 1.184238\n",
      "iteration: 487 | loss: 1.515033\n",
      "iteration: 488 | loss: 1.296171\n",
      "iteration: 489 | loss: 1.394615\n",
      "iteration: 490 | loss: 1.200995\n",
      "iteration: 491 | loss: 1.210486\n",
      "iteration: 492 | loss: 1.169178\n",
      "iteration: 493 | loss: 1.022533\n",
      "iteration: 494 | loss: 1.156862\n",
      "iteration: 495 | loss: 1.365815\n",
      "iteration: 496 | loss: 1.437048\n",
      "iteration: 497 | loss: 1.261567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 498 | loss: 1.541992\n",
      "iteration: 499 | loss: 1.365055\n",
      "  Train acc: 0.552, Val acc: 0.5\n",
      "iteration: 500 | loss: 1.367425\n",
      "iteration: 501 | loss: 1.292476\n",
      "iteration: 502 | loss: 1.120444\n",
      "iteration: 503 | loss: 1.612188\n",
      "iteration: 504 | loss: 1.059103\n",
      "iteration: 505 | loss: 0.918752\n",
      "iteration: 506 | loss: 1.289837\n",
      "iteration: 507 | loss: 1.189300\n",
      "iteration: 508 | loss: 1.292218\n",
      "iteration: 509 | loss: 1.366053\n",
      "iteration: 510 | loss: 1.255311\n",
      "iteration: 511 | loss: 1.135128\n",
      "iteration: 512 | loss: 1.182006\n",
      "iteration: 513 | loss: 1.517806\n",
      "iteration: 514 | loss: 1.270506\n",
      "iteration: 515 | loss: 1.299033\n",
      "iteration: 516 | loss: 1.244998\n",
      "iteration: 517 | loss: 1.229405\n",
      "iteration: 518 | loss: 1.153226\n",
      "iteration: 519 | loss: 0.936601\n",
      "iteration: 520 | loss: 1.359198\n",
      "iteration: 521 | loss: 1.066634\n",
      "iteration: 522 | loss: 1.136057\n",
      "iteration: 523 | loss: 1.191299\n",
      "iteration: 524 | loss: 1.087649\n",
      "  Train acc: 0.55, Val acc: 0.5\n",
      "iteration: 525 | loss: 1.307213\n",
      "iteration: 526 | loss: 1.053039\n",
      "iteration: 527 | loss: 1.831756\n",
      "iteration: 528 | loss: 1.414546\n",
      "iteration: 529 | loss: 1.033545\n",
      "iteration: 530 | loss: 0.782467\n",
      "iteration: 531 | loss: 1.009671\n",
      "iteration: 532 | loss: 1.143504\n",
      "iteration: 533 | loss: 1.348699\n",
      "iteration: 534 | loss: 1.413339\n",
      "iteration: 535 | loss: 0.903436\n",
      "iteration: 536 | loss: 1.357504\n",
      "iteration: 537 | loss: 1.259075\n",
      "iteration: 538 | loss: 1.207896\n",
      "iteration: 539 | loss: 1.324554\n",
      "iteration: 540 | loss: 1.156750\n",
      "iteration: 541 | loss: 1.025155\n",
      "iteration: 542 | loss: 1.433670\n",
      "iteration: 543 | loss: 1.144802\n",
      "iteration: 544 | loss: 1.005102\n",
      "iteration: 545 | loss: 0.867821\n",
      "iteration: 546 | loss: 1.269645\n",
      "iteration: 547 | loss: 1.294898\n",
      "iteration: 548 | loss: 0.753856\n",
      "iteration: 549 | loss: 0.862259\n",
      "  Train acc: 0.556, Val acc: 0.5\n",
      "iteration: 550 | loss: 1.512303\n",
      "iteration: 551 | loss: 1.235658\n",
      "iteration: 552 | loss: 1.067796\n",
      "iteration: 553 | loss: 1.265949\n",
      "iteration: 554 | loss: 1.069412\n",
      "iteration: 555 | loss: 1.245260\n",
      "iteration: 556 | loss: 1.322901\n",
      "iteration: 557 | loss: 0.850066\n",
      "iteration: 558 | loss: 1.279388\n",
      "iteration: 559 | loss: 1.506523\n",
      "iteration: 560 | loss: 1.073473\n",
      "iteration: 561 | loss: 1.177521\n",
      "iteration: 562 | loss: 1.007805\n",
      "iteration: 563 | loss: 1.272991\n",
      "iteration: 564 | loss: 0.957451\n",
      "iteration: 565 | loss: 1.042169\n",
      "iteration: 566 | loss: 1.514332\n",
      "iteration: 567 | loss: 0.982106\n",
      "iteration: 568 | loss: 1.104931\n",
      "iteration: 569 | loss: 1.609642\n",
      "iteration: 570 | loss: 1.148820\n",
      "iteration: 571 | loss: 1.553818\n",
      "iteration: 572 | loss: 1.109928\n",
      "iteration: 573 | loss: 0.998349\n",
      "iteration: 574 | loss: 1.016260\n",
      "  Train acc: 0.526, Val acc: 0.5\n",
      "iteration: 575 | loss: 1.374099\n",
      "iteration: 576 | loss: 1.411713\n",
      "iteration: 577 | loss: 1.161979\n",
      "iteration: 578 | loss: 1.313747\n",
      "iteration: 579 | loss: 1.205388\n",
      "iteration: 580 | loss: 1.009122\n",
      "iteration: 581 | loss: 1.263133\n",
      "iteration: 582 | loss: 1.348737\n",
      "iteration: 583 | loss: 1.000485\n",
      "iteration: 584 | loss: 1.064483\n",
      "iteration: 585 | loss: 1.324103\n",
      "iteration: 586 | loss: 1.623712\n",
      "iteration: 587 | loss: 1.243070\n",
      "iteration: 588 | loss: 1.185837\n",
      "iteration: 589 | loss: 1.351155\n",
      "iteration: 590 | loss: 1.327017\n",
      "iteration: 591 | loss: 1.362937\n",
      "iteration: 592 | loss: 1.114524\n",
      "iteration: 593 | loss: 0.923117\n",
      "iteration: 594 | loss: 1.404154\n",
      "iteration: 595 | loss: 1.159953\n",
      "iteration: 596 | loss: 1.166069\n",
      "iteration: 597 | loss: 1.331216\n",
      "iteration: 598 | loss: 1.329592\n",
      "iteration: 599 | loss: 1.348918\n",
      "  Train acc: 0.55, Val acc: 0.5\n",
      "iteration: 600 | loss: 1.357258\n",
      "iteration: 601 | loss: 0.923013\n",
      "iteration: 602 | loss: 1.237124\n",
      "iteration: 603 | loss: 0.888390\n",
      "iteration: 604 | loss: 1.072790\n",
      "iteration: 605 | loss: 1.396597\n",
      "iteration: 606 | loss: 1.083973\n",
      "iteration: 607 | loss: 0.874644\n",
      "iteration: 608 | loss: 1.286344\n",
      "iteration: 609 | loss: 1.225713\n",
      "iteration: 610 | loss: 1.173049\n",
      "iteration: 611 | loss: 1.395589\n",
      "iteration: 612 | loss: 1.228080\n",
      "iteration: 613 | loss: 1.155183\n",
      "iteration: 614 | loss: 1.320142\n",
      "iteration: 615 | loss: 1.046370\n",
      "iteration: 616 | loss: 1.196253\n",
      "iteration: 617 | loss: 1.664520\n",
      "iteration: 618 | loss: 1.044206\n",
      "iteration: 619 | loss: 1.146670\n",
      "iteration: 620 | loss: 1.289611\n",
      "iteration: 621 | loss: 1.102123\n",
      "iteration: 622 | loss: 0.996895\n",
      "iteration: 623 | loss: 1.033350\n",
      "iteration: 624 | loss: 1.301486\n",
      "  Train acc: 0.546, Val acc: 0.5\n",
      "iteration: 625 | loss: 1.368580\n",
      "iteration: 626 | loss: 1.301876\n",
      "iteration: 627 | loss: 0.997780\n",
      "iteration: 628 | loss: 1.381884\n",
      "iteration: 629 | loss: 1.073767\n",
      "iteration: 630 | loss: 0.834849\n",
      "iteration: 631 | loss: 1.267377\n",
      "iteration: 632 | loss: 0.909778\n",
      "iteration: 633 | loss: 1.194607\n",
      "iteration: 634 | loss: 0.934238\n",
      "iteration: 635 | loss: 1.468213\n",
      "iteration: 636 | loss: 0.742791\n",
      "iteration: 637 | loss: 1.124799\n",
      "iteration: 638 | loss: 1.407773\n",
      "iteration: 639 | loss: 1.324645\n",
      "iteration: 640 | loss: 1.149291\n",
      "iteration: 641 | loss: 1.326976\n",
      "iteration: 642 | loss: 1.150900\n",
      "iteration: 643 | loss: 0.981161\n",
      "iteration: 644 | loss: 1.108251\n",
      "iteration: 645 | loss: 1.665518\n",
      "iteration: 646 | loss: 0.974929\n",
      "iteration: 647 | loss: 0.773502\n",
      "iteration: 648 | loss: 1.072207\n",
      "iteration: 649 | loss: 1.043985\n",
      "  Train acc: 0.58, Val acc: 0.5\n",
      "iteration: 650 | loss: 1.055608\n",
      "iteration: 651 | loss: 1.318693\n",
      "iteration: 652 | loss: 1.311960\n",
      "iteration: 653 | loss: 1.074399\n",
      "iteration: 654 | loss: 1.023352\n",
      "iteration: 655 | loss: 1.393909\n",
      "iteration: 656 | loss: 1.314152\n",
      "iteration: 657 | loss: 0.989199\n",
      "iteration: 658 | loss: 1.054168\n",
      "iteration: 659 | loss: 1.659418\n",
      "iteration: 660 | loss: 1.346976\n",
      "iteration: 661 | loss: 1.316241\n",
      "iteration: 662 | loss: 1.112889\n",
      "iteration: 663 | loss: 1.397341\n",
      "iteration: 664 | loss: 1.304767\n",
      "iteration: 665 | loss: 0.966244\n",
      "iteration: 666 | loss: 1.257941\n",
      "iteration: 667 | loss: 1.082097\n",
      "iteration: 668 | loss: 1.311732\n",
      "iteration: 669 | loss: 1.076110\n",
      "iteration: 670 | loss: 0.975438\n",
      "iteration: 671 | loss: 0.951566\n",
      "iteration: 672 | loss: 1.193538\n",
      "iteration: 673 | loss: 1.171632\n",
      "iteration: 674 | loss: 1.150234\n",
      "  Train acc: 0.552, Val acc: 0.5\n",
      "iteration: 675 | loss: 1.558235\n",
      "iteration: 676 | loss: 1.061712\n",
      "iteration: 677 | loss: 1.048857\n",
      "iteration: 678 | loss: 0.850278\n",
      "iteration: 679 | loss: 1.299571\n",
      "iteration: 680 | loss: 1.463838\n",
      "iteration: 681 | loss: 1.018664\n",
      "iteration: 682 | loss: 1.139358\n",
      "iteration: 683 | loss: 0.954437\n",
      "iteration: 684 | loss: 0.919087\n",
      "iteration: 685 | loss: 0.962851\n",
      "iteration: 686 | loss: 1.335396\n",
      "iteration: 687 | loss: 1.036600\n",
      "iteration: 688 | loss: 0.975510\n",
      "iteration: 689 | loss: 1.265508\n",
      "iteration: 690 | loss: 1.093793\n",
      "iteration: 691 | loss: 1.465437\n",
      "iteration: 692 | loss: 1.074802\n",
      "iteration: 693 | loss: 0.887322\n",
      "iteration: 694 | loss: 0.805162\n",
      "iteration: 695 | loss: 1.126960\n",
      "iteration: 696 | loss: 1.045477\n",
      "iteration: 697 | loss: 1.203058\n",
      "iteration: 698 | loss: 1.155486\n",
      "iteration: 699 | loss: 1.183642\n",
      "  Train acc: 0.562, Val acc: 0.5\n",
      "iteration: 700 | loss: 1.051710\n",
      "iteration: 701 | loss: 1.262846\n",
      "iteration: 702 | loss: 1.048482\n",
      "iteration: 703 | loss: 1.231749\n",
      "iteration: 704 | loss: 1.404498\n",
      "iteration: 705 | loss: 1.001441\n",
      "iteration: 706 | loss: 1.031396\n",
      "iteration: 707 | loss: 1.436334\n",
      "iteration: 708 | loss: 1.025089\n",
      "iteration: 709 | loss: 0.773275\n",
      "iteration: 710 | loss: 1.340845\n",
      "iteration: 711 | loss: 1.161762\n",
      "iteration: 712 | loss: 1.127353\n",
      "iteration: 713 | loss: 1.330441\n",
      "iteration: 714 | loss: 1.195859\n",
      "iteration: 715 | loss: 0.905034\n",
      "iteration: 716 | loss: 1.342096\n",
      "iteration: 717 | loss: 1.144078\n",
      "iteration: 718 | loss: 0.871125\n",
      "iteration: 719 | loss: 0.967388\n",
      "iteration: 720 | loss: 1.035570\n",
      "iteration: 721 | loss: 1.119713\n",
      "iteration: 722 | loss: 1.051585\n",
      "iteration: 723 | loss: 1.395003\n",
      "iteration: 724 | loss: 1.318261\n",
      "  Train acc: 0.612, Val acc: 0.5\n",
      "iteration: 725 | loss: 1.172698\n",
      "iteration: 726 | loss: 1.210540\n",
      "iteration: 727 | loss: 0.942737\n",
      "iteration: 728 | loss: 1.009991\n",
      "iteration: 729 | loss: 0.847679\n",
      "iteration: 730 | loss: 1.018704\n",
      "iteration: 731 | loss: 0.973515\n",
      "iteration: 732 | loss: 1.275871\n",
      "iteration: 733 | loss: 0.854913\n",
      "iteration: 734 | loss: 1.181767\n",
      "iteration: 735 | loss: 1.121588\n",
      "iteration: 736 | loss: 1.215422\n",
      "iteration: 737 | loss: 1.068447\n",
      "iteration: 738 | loss: 1.096004\n",
      "iteration: 739 | loss: 1.047987\n",
      "iteration: 740 | loss: 0.727773\n",
      "iteration: 741 | loss: 1.282252\n",
      "iteration: 742 | loss: 0.779172\n",
      "iteration: 743 | loss: 1.056065\n",
      "iteration: 744 | loss: 1.566636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 745 | loss: 0.887410\n",
      "iteration: 746 | loss: 1.188892\n",
      "iteration: 747 | loss: 1.282582\n",
      "iteration: 748 | loss: 1.039988\n",
      "iteration: 749 | loss: 1.678201\n",
      "  Train acc: 0.586, Val acc: 0.5\n",
      "iteration: 750 | loss: 1.199501\n",
      "iteration: 751 | loss: 1.182259\n",
      "iteration: 752 | loss: 1.469178\n",
      "iteration: 753 | loss: 0.924357\n",
      "iteration: 754 | loss: 1.029372\n",
      "iteration: 755 | loss: 0.862176\n",
      "iteration: 756 | loss: 1.224005\n",
      "iteration: 757 | loss: 1.303027\n",
      "iteration: 758 | loss: 0.968726\n",
      "iteration: 759 | loss: 1.225652\n",
      "iteration: 760 | loss: 1.318071\n",
      "iteration: 761 | loss: 1.225472\n",
      "iteration: 762 | loss: 1.272752\n",
      "iteration: 763 | loss: 1.222610\n",
      "iteration: 764 | loss: 1.262914\n",
      "iteration: 765 | loss: 0.941366\n",
      "iteration: 766 | loss: 1.042775\n",
      "iteration: 767 | loss: 1.121240\n",
      "iteration: 768 | loss: 1.370308\n",
      "iteration: 769 | loss: 1.120622\n",
      "iteration: 770 | loss: 0.930023\n",
      "iteration: 771 | loss: 1.313308\n",
      "iteration: 772 | loss: 1.234285\n",
      "iteration: 773 | loss: 1.168176\n",
      "iteration: 774 | loss: 0.947747\n",
      "  Train acc: 0.59, Val acc: 0.5\n",
      "iteration: 775 | loss: 1.050697\n",
      "iteration: 776 | loss: 1.061307\n",
      "iteration: 777 | loss: 0.816677\n",
      "iteration: 778 | loss: 1.453479\n",
      "iteration: 779 | loss: 1.310088\n",
      "iteration: 780 | loss: 0.930941\n",
      "iteration: 781 | loss: 1.174666\n",
      "iteration: 782 | loss: 1.130186\n",
      "iteration: 783 | loss: 1.008911\n",
      "iteration: 784 | loss: 0.956991\n",
      "iteration: 785 | loss: 1.057429\n",
      "iteration: 786 | loss: 1.093273\n",
      "iteration: 787 | loss: 1.164517\n",
      "iteration: 788 | loss: 1.316319\n",
      "iteration: 789 | loss: 1.263653\n",
      "iteration: 790 | loss: 1.142276\n",
      "iteration: 791 | loss: 1.133431\n",
      "iteration: 792 | loss: 0.906735\n",
      "iteration: 793 | loss: 0.990205\n",
      "iteration: 794 | loss: 0.892485\n",
      "iteration: 795 | loss: 0.785835\n",
      "iteration: 796 | loss: 0.958438\n",
      "iteration: 797 | loss: 0.972612\n",
      "iteration: 798 | loss: 1.257507\n",
      "iteration: 799 | loss: 1.387635\n",
      "  Train acc: 0.594, Val acc: 0.5\n",
      "iteration: 800 | loss: 1.208574\n",
      "iteration: 801 | loss: 1.206808\n",
      "iteration: 802 | loss: 0.953138\n",
      "iteration: 803 | loss: 0.784498\n",
      "iteration: 804 | loss: 1.097782\n",
      "iteration: 805 | loss: 1.180934\n",
      "iteration: 806 | loss: 1.000121\n",
      "iteration: 807 | loss: 1.030414\n",
      "iteration: 808 | loss: 1.067865\n",
      "iteration: 809 | loss: 1.084352\n",
      "iteration: 810 | loss: 1.021426\n",
      "iteration: 811 | loss: 0.869434\n",
      "iteration: 812 | loss: 0.836344\n",
      "iteration: 813 | loss: 1.124678\n",
      "iteration: 814 | loss: 1.096078\n",
      "iteration: 815 | loss: 1.470424\n",
      "iteration: 816 | loss: 0.860455\n",
      "iteration: 817 | loss: 0.857400\n",
      "iteration: 818 | loss: 0.745878\n",
      "iteration: 819 | loss: 1.060058\n",
      "iteration: 820 | loss: 1.102999\n",
      "iteration: 821 | loss: 1.208216\n",
      "iteration: 822 | loss: 0.814297\n",
      "iteration: 823 | loss: 0.807544\n",
      "iteration: 824 | loss: 0.872893\n",
      "  Train acc: 0.628, Val acc: 0.5\n",
      "iteration: 825 | loss: 1.001049\n",
      "iteration: 826 | loss: 1.269915\n",
      "iteration: 827 | loss: 1.002517\n",
      "iteration: 828 | loss: 1.156345\n",
      "iteration: 829 | loss: 1.356755\n",
      "iteration: 830 | loss: 0.871383\n",
      "iteration: 831 | loss: 0.983627\n",
      "iteration: 832 | loss: 1.208193\n",
      "iteration: 833 | loss: 0.988668\n",
      "iteration: 834 | loss: 1.163344\n",
      "iteration: 835 | loss: 0.919604\n",
      "iteration: 836 | loss: 1.131793\n",
      "iteration: 837 | loss: 1.422435\n",
      "iteration: 838 | loss: 1.014163\n",
      "iteration: 839 | loss: 1.272049\n",
      "iteration: 840 | loss: 1.200849\n",
      "iteration: 841 | loss: 1.461634\n",
      "iteration: 842 | loss: 1.174144\n",
      "iteration: 843 | loss: 0.850884\n",
      "iteration: 844 | loss: 0.694580\n",
      "iteration: 845 | loss: 1.094711\n",
      "iteration: 846 | loss: 1.037541\n",
      "iteration: 847 | loss: 0.978044\n",
      "iteration: 848 | loss: 1.146170\n",
      "iteration: 849 | loss: 1.102036\n",
      "  Train acc: 0.674, Val acc: 0.5\n",
      "iteration: 850 | loss: 0.825627\n",
      "iteration: 851 | loss: 0.945457\n",
      "iteration: 852 | loss: 0.975678\n",
      "iteration: 853 | loss: 1.117128\n",
      "iteration: 854 | loss: 1.025150\n",
      "iteration: 855 | loss: 1.011900\n",
      "iteration: 856 | loss: 1.063430\n",
      "iteration: 857 | loss: 1.090083\n",
      "iteration: 858 | loss: 1.199579\n",
      "iteration: 859 | loss: 0.915380\n",
      "iteration: 860 | loss: 0.647039\n",
      "iteration: 861 | loss: 0.813435\n",
      "iteration: 862 | loss: 1.277768\n",
      "iteration: 863 | loss: 0.887108\n",
      "iteration: 864 | loss: 1.623246\n",
      "iteration: 865 | loss: 0.987136\n",
      "iteration: 866 | loss: 0.757911\n",
      "iteration: 867 | loss: 1.059376\n",
      "iteration: 868 | loss: 1.116339\n",
      "iteration: 869 | loss: 1.087038\n",
      "iteration: 870 | loss: 1.116456\n",
      "iteration: 871 | loss: 0.965320\n",
      "iteration: 872 | loss: 0.610545\n",
      "iteration: 873 | loss: 0.829829\n",
      "iteration: 874 | loss: 1.046718\n",
      "  Train acc: 0.642, Val acc: 0.5\n",
      "iteration: 875 | loss: 1.027509\n",
      "iteration: 876 | loss: 1.270881\n",
      "iteration: 877 | loss: 0.737613\n",
      "iteration: 878 | loss: 1.206454\n",
      "iteration: 879 | loss: 0.925225\n",
      "iteration: 880 | loss: 1.032836\n",
      "iteration: 881 | loss: 0.778104\n",
      "iteration: 882 | loss: 0.973334\n",
      "iteration: 883 | loss: 1.079576\n",
      "iteration: 884 | loss: 0.954821\n",
      "iteration: 885 | loss: 0.654312\n",
      "iteration: 886 | loss: 1.264252\n",
      "iteration: 887 | loss: 0.662577\n",
      "iteration: 888 | loss: 1.173506\n",
      "iteration: 889 | loss: 0.629115\n",
      "iteration: 890 | loss: 1.445409\n",
      "iteration: 891 | loss: 1.178213\n",
      "iteration: 892 | loss: 0.688273\n",
      "iteration: 893 | loss: 0.960648\n",
      "iteration: 894 | loss: 0.761191\n",
      "iteration: 895 | loss: 1.082417\n",
      "iteration: 896 | loss: 1.137431\n",
      "iteration: 897 | loss: 0.825066\n",
      "iteration: 898 | loss: 1.161215\n",
      "iteration: 899 | loss: 1.489083\n",
      "  Train acc: 0.658, Val acc: 0.5\n",
      "iteration: 900 | loss: 1.052294\n",
      "iteration: 901 | loss: 1.022660\n",
      "iteration: 902 | loss: 0.904299\n",
      "iteration: 903 | loss: 1.353889\n",
      "iteration: 904 | loss: 1.076175\n",
      "iteration: 905 | loss: 0.859787\n",
      "iteration: 906 | loss: 0.867494\n",
      "iteration: 907 | loss: 0.992393\n",
      "iteration: 908 | loss: 1.139390\n",
      "iteration: 909 | loss: 0.906146\n",
      "iteration: 910 | loss: 1.158998\n",
      "iteration: 911 | loss: 0.613788\n",
      "iteration: 912 | loss: 0.858903\n",
      "iteration: 913 | loss: 0.982391\n",
      "iteration: 914 | loss: 0.869295\n",
      "iteration: 915 | loss: 1.061296\n",
      "iteration: 916 | loss: 1.206110\n",
      "iteration: 917 | loss: 0.796867\n",
      "iteration: 918 | loss: 0.813958\n",
      "iteration: 919 | loss: 0.637250\n",
      "iteration: 920 | loss: 1.280840\n",
      "iteration: 921 | loss: 0.811067\n",
      "iteration: 922 | loss: 0.875288\n",
      "iteration: 923 | loss: 0.982603\n",
      "iteration: 924 | loss: 0.809416\n",
      "  Train acc: 0.64, Val acc: 0.5\n",
      "iteration: 925 | loss: 1.581928\n",
      "iteration: 926 | loss: 0.562002\n",
      "iteration: 927 | loss: 0.952097\n",
      "iteration: 928 | loss: 0.812821\n",
      "iteration: 929 | loss: 0.870557\n",
      "iteration: 930 | loss: 0.987076\n",
      "iteration: 931 | loss: 0.909570\n",
      "iteration: 932 | loss: 0.959094\n",
      "iteration: 933 | loss: 1.178382\n",
      "iteration: 934 | loss: 0.862179\n",
      "iteration: 935 | loss: 0.879809\n",
      "iteration: 936 | loss: 0.981494\n",
      "iteration: 937 | loss: 0.891716\n",
      "iteration: 938 | loss: 1.340125\n",
      "iteration: 939 | loss: 0.967516\n",
      "iteration: 940 | loss: 0.961843\n",
      "iteration: 941 | loss: 0.823404\n",
      "iteration: 942 | loss: 1.313794\n",
      "iteration: 943 | loss: 0.791670\n",
      "iteration: 944 | loss: 0.771997\n",
      "iteration: 945 | loss: 0.989668\n",
      "iteration: 946 | loss: 0.882222\n",
      "iteration: 947 | loss: 1.602156\n",
      "iteration: 948 | loss: 0.943777\n",
      "iteration: 949 | loss: 1.130210\n",
      "  Train acc: 0.65, Val acc: 0.5\n",
      "iteration: 950 | loss: 1.243580\n",
      "iteration: 951 | loss: 0.904786\n",
      "iteration: 952 | loss: 1.020262\n",
      "iteration: 953 | loss: 0.814617\n",
      "iteration: 954 | loss: 0.942268\n",
      "iteration: 955 | loss: 0.838369\n",
      "iteration: 956 | loss: 1.041466\n",
      "iteration: 957 | loss: 0.619843\n",
      "iteration: 958 | loss: 0.834882\n",
      "iteration: 959 | loss: 0.985176\n",
      "iteration: 960 | loss: 0.974524\n",
      "iteration: 961 | loss: 1.006752\n",
      "iteration: 962 | loss: 0.880034\n",
      "iteration: 963 | loss: 1.095139\n",
      "iteration: 964 | loss: 1.015539\n",
      "iteration: 965 | loss: 1.137690\n",
      "iteration: 966 | loss: 1.093512\n",
      "iteration: 967 | loss: 0.950156\n",
      "iteration: 968 | loss: 0.872385\n",
      "iteration: 969 | loss: 1.176318\n",
      "iteration: 970 | loss: 1.007291\n",
      "iteration: 971 | loss: 0.950109\n",
      "iteration: 972 | loss: 0.767772\n",
      "iteration: 973 | loss: 1.054870\n",
      "iteration: 974 | loss: 0.670078\n",
      "  Train acc: 0.648, Val acc: 0.5\n",
      "iteration: 975 | loss: 1.046288\n",
      "iteration: 976 | loss: 0.825197\n",
      "iteration: 977 | loss: 0.800273\n",
      "iteration: 978 | loss: 0.814289\n",
      "iteration: 979 | loss: 0.971698\n",
      "iteration: 980 | loss: 1.081749\n",
      "iteration: 981 | loss: 0.924484\n",
      "iteration: 982 | loss: 0.767116\n",
      "iteration: 983 | loss: 0.986712\n",
      "iteration: 984 | loss: 0.794271\n",
      "iteration: 985 | loss: 0.920596\n",
      "iteration: 986 | loss: 0.860870\n",
      "iteration: 987 | loss: 0.985308\n",
      "iteration: 988 | loss: 0.883906\n",
      "iteration: 989 | loss: 0.738310\n",
      "iteration: 990 | loss: 0.847698\n",
      "iteration: 991 | loss: 0.936711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 992 | loss: 0.640540\n",
      "iteration: 993 | loss: 0.789525\n",
      "iteration: 994 | loss: 0.618122\n",
      "iteration: 995 | loss: 1.309614\n",
      "iteration: 996 | loss: 0.750846\n",
      "iteration: 997 | loss: 0.824753\n",
      "iteration: 998 | loss: 0.868529\n",
      "iteration: 999 | loss: 1.007109\n",
      "  Train acc: 0.666, Val acc: 0.5\n",
      "iteration: 1000 | loss: 1.004677\n",
      "iteration: 1001 | loss: 0.786307\n",
      "iteration: 1002 | loss: 0.806393\n",
      "iteration: 1003 | loss: 1.055626\n",
      "iteration: 1004 | loss: 0.536022\n",
      "iteration: 1005 | loss: 0.655144\n",
      "iteration: 1006 | loss: 1.149509\n",
      "iteration: 1007 | loss: 0.854266\n",
      "iteration: 1008 | loss: 0.982078\n",
      "iteration: 1009 | loss: 0.964411\n",
      "iteration: 1010 | loss: 0.681751\n",
      "iteration: 1011 | loss: 0.618195\n",
      "iteration: 1012 | loss: 0.995018\n",
      "iteration: 1013 | loss: 1.510879\n",
      "iteration: 1014 | loss: 0.917657\n",
      "iteration: 1015 | loss: 0.605564\n",
      "iteration: 1016 | loss: 0.875494\n",
      "iteration: 1017 | loss: 0.833348\n",
      "iteration: 1018 | loss: 0.861756\n",
      "iteration: 1019 | loss: 0.993240\n",
      "iteration: 1020 | loss: 0.505316\n",
      "iteration: 1021 | loss: 0.509804\n",
      "iteration: 1022 | loss: 0.919751\n",
      "iteration: 1023 | loss: 0.781937\n",
      "iteration: 1024 | loss: 0.764840\n",
      "  Train acc: 0.704, Val acc: 0.5\n",
      "iteration: 1025 | loss: 1.078987\n",
      "iteration: 1026 | loss: 0.865957\n",
      "iteration: 1027 | loss: 0.972175\n",
      "iteration: 1028 | loss: 0.844053\n",
      "iteration: 1029 | loss: 0.925116\n",
      "iteration: 1030 | loss: 0.490886\n",
      "iteration: 1031 | loss: 0.904782\n",
      "iteration: 1032 | loss: 0.997039\n",
      "iteration: 1033 | loss: 0.962283\n",
      "iteration: 1034 | loss: 0.866909\n",
      "iteration: 1035 | loss: 0.609706\n",
      "iteration: 1036 | loss: 0.991969\n",
      "iteration: 1037 | loss: 0.704600\n",
      "iteration: 1038 | loss: 0.656813\n",
      "iteration: 1039 | loss: 0.907636\n",
      "iteration: 1040 | loss: 0.850577\n",
      "iteration: 1041 | loss: 1.183637\n",
      "iteration: 1042 | loss: 0.894085\n",
      "iteration: 1043 | loss: 0.741489\n",
      "iteration: 1044 | loss: 0.687553\n",
      "iteration: 1045 | loss: 0.770965\n",
      "iteration: 1046 | loss: 0.870988\n",
      "iteration: 1047 | loss: 0.778530\n",
      "iteration: 1048 | loss: 0.533529\n",
      "iteration: 1049 | loss: 0.722742\n",
      "  Train acc: 0.716, Val acc: 0.5\n",
      "iteration: 1050 | loss: 0.888323\n",
      "iteration: 1051 | loss: 0.692690\n",
      "iteration: 1052 | loss: 0.683663\n",
      "iteration: 1053 | loss: 0.931040\n",
      "iteration: 1054 | loss: 0.744113\n",
      "iteration: 1055 | loss: 0.902933\n",
      "iteration: 1056 | loss: 0.874776\n",
      "iteration: 1057 | loss: 1.253753\n",
      "iteration: 1058 | loss: 1.069803\n",
      "iteration: 1059 | loss: 0.954559\n",
      "iteration: 1060 | loss: 1.287729\n",
      "iteration: 1061 | loss: 1.186364\n",
      "iteration: 1062 | loss: 0.694389\n",
      "iteration: 1063 | loss: 0.777695\n",
      "iteration: 1064 | loss: 0.710345\n",
      "iteration: 1065 | loss: 0.779299\n",
      "iteration: 1066 | loss: 0.471702\n",
      "iteration: 1067 | loss: 0.790328\n",
      "iteration: 1068 | loss: 0.907618\n",
      "iteration: 1069 | loss: 0.625163\n",
      "iteration: 1070 | loss: 1.001953\n",
      "iteration: 1071 | loss: 0.878537\n",
      "iteration: 1072 | loss: 0.765358\n",
      "iteration: 1073 | loss: 1.003908\n",
      "iteration: 1074 | loss: 0.991351\n",
      "  Train acc: 0.724, Val acc: 0.5\n",
      "iteration: 1075 | loss: 0.965315\n",
      "iteration: 1076 | loss: 1.181975\n",
      "iteration: 1077 | loss: 1.025325\n",
      "iteration: 1078 | loss: 0.702889\n",
      "iteration: 1079 | loss: 0.890533\n",
      "iteration: 1080 | loss: 1.095549\n",
      "iteration: 1081 | loss: 0.821233\n",
      "iteration: 1082 | loss: 0.663069\n",
      "iteration: 1083 | loss: 0.634544\n",
      "iteration: 1084 | loss: 0.526335\n",
      "iteration: 1085 | loss: 0.701068\n",
      "iteration: 1086 | loss: 1.149691\n",
      "iteration: 1087 | loss: 0.776185\n",
      "iteration: 1088 | loss: 0.591081\n",
      "iteration: 1089 | loss: 0.553894\n",
      "iteration: 1090 | loss: 0.604638\n",
      "iteration: 1091 | loss: 0.767353\n",
      "iteration: 1092 | loss: 0.782851\n",
      "iteration: 1093 | loss: 0.600300\n",
      "iteration: 1094 | loss: 0.663451\n",
      "iteration: 1095 | loss: 1.195667\n",
      "iteration: 1096 | loss: 0.719892\n",
      "iteration: 1097 | loss: 0.856572\n",
      "iteration: 1098 | loss: 0.606225\n",
      "iteration: 1099 | loss: 0.927860\n",
      "  Train acc: 0.728, Val acc: 0.5\n",
      "iteration: 1100 | loss: 1.173160\n",
      "iteration: 1101 | loss: 0.774503\n",
      "iteration: 1102 | loss: 0.589683\n",
      "iteration: 1103 | loss: 0.703272\n",
      "iteration: 1104 | loss: 0.636301\n",
      "iteration: 1105 | loss: 0.771056\n",
      "iteration: 1106 | loss: 1.286422\n",
      "iteration: 1107 | loss: 0.810753\n",
      "iteration: 1108 | loss: 0.544207\n",
      "iteration: 1109 | loss: 0.947933\n",
      "iteration: 1110 | loss: 0.645594\n",
      "iteration: 1111 | loss: 0.671467\n",
      "iteration: 1112 | loss: 0.798648\n",
      "iteration: 1113 | loss: 0.841849\n",
      "iteration: 1114 | loss: 0.680428\n",
      "iteration: 1115 | loss: 0.779857\n",
      "iteration: 1116 | loss: 0.655116\n",
      "iteration: 1117 | loss: 0.607496\n",
      "iteration: 1118 | loss: 1.017019\n",
      "iteration: 1119 | loss: 0.546770\n",
      "iteration: 1120 | loss: 0.386992\n",
      "iteration: 1121 | loss: 0.805879\n",
      "iteration: 1122 | loss: 1.154167\n",
      "iteration: 1123 | loss: 0.931170\n",
      "iteration: 1124 | loss: 0.962981\n",
      "  Train acc: 0.73, Val acc: 0.5\n",
      "iteration: 1125 | loss: 0.808051\n",
      "iteration: 1126 | loss: 0.975689\n",
      "iteration: 1127 | loss: 0.730727\n",
      "iteration: 1128 | loss: 0.751393\n",
      "iteration: 1129 | loss: 1.145666\n",
      "iteration: 1130 | loss: 0.753040\n",
      "iteration: 1131 | loss: 1.132851\n",
      "iteration: 1132 | loss: 1.065591\n",
      "iteration: 1133 | loss: 1.112806\n",
      "iteration: 1134 | loss: 0.828179\n",
      "iteration: 1135 | loss: 0.715933\n",
      "iteration: 1136 | loss: 0.690662\n",
      "iteration: 1137 | loss: 0.632528\n",
      "iteration: 1138 | loss: 0.984420\n",
      "iteration: 1139 | loss: 1.064519\n",
      "iteration: 1140 | loss: 0.964293\n",
      "iteration: 1141 | loss: 0.641719\n",
      "iteration: 1142 | loss: 0.760871\n",
      "iteration: 1143 | loss: 0.556931\n",
      "iteration: 1144 | loss: 0.398432\n",
      "iteration: 1145 | loss: 1.059677\n",
      "iteration: 1146 | loss: 0.710502\n",
      "iteration: 1147 | loss: 0.725388\n",
      "iteration: 1148 | loss: 0.637921\n",
      "iteration: 1149 | loss: 0.617168\n",
      "  Train acc: 0.668, Val acc: 0.5\n",
      "iteration: 1150 | loss: 0.866563\n",
      "iteration: 1151 | loss: 0.700902\n",
      "iteration: 1152 | loss: 0.841386\n",
      "iteration: 1153 | loss: 0.941200\n",
      "iteration: 1154 | loss: 0.420042\n",
      "iteration: 1155 | loss: 0.838449\n",
      "iteration: 1156 | loss: 0.859181\n",
      "iteration: 1157 | loss: 0.786940\n",
      "iteration: 1158 | loss: 0.508944\n",
      "iteration: 1159 | loss: 0.616783\n",
      "iteration: 1160 | loss: 0.605157\n",
      "iteration: 1161 | loss: 0.664066\n",
      "iteration: 1162 | loss: 0.717123\n",
      "iteration: 1163 | loss: 0.725710\n",
      "iteration: 1164 | loss: 1.174048\n",
      "iteration: 1165 | loss: 0.882882\n",
      "iteration: 1166 | loss: 0.931047\n",
      "iteration: 1167 | loss: 0.553427\n",
      "iteration: 1168 | loss: 0.661740\n",
      "iteration: 1169 | loss: 0.985117\n",
      "iteration: 1170 | loss: 0.668887\n",
      "iteration: 1171 | loss: 1.162929\n",
      "iteration: 1172 | loss: 0.792409\n",
      "iteration: 1173 | loss: 0.758486\n",
      "iteration: 1174 | loss: 0.715142\n",
      "  Train acc: 0.686, Val acc: 0.5\n",
      "iteration: 1175 | loss: 0.723289\n",
      "iteration: 1176 | loss: 1.047643\n",
      "iteration: 1177 | loss: 0.605890\n",
      "iteration: 1178 | loss: 0.748898\n",
      "iteration: 1179 | loss: 0.975036\n",
      "iteration: 1180 | loss: 0.958830\n",
      "iteration: 1181 | loss: 0.564918\n",
      "iteration: 1182 | loss: 0.407114\n",
      "iteration: 1183 | loss: 0.487930\n",
      "iteration: 1184 | loss: 0.825852\n",
      "iteration: 1185 | loss: 0.896680\n",
      "iteration: 1186 | loss: 0.768325\n",
      "iteration: 1187 | loss: 0.564500\n",
      "iteration: 1188 | loss: 0.815747\n",
      "iteration: 1189 | loss: 0.797175\n",
      "iteration: 1190 | loss: 0.754477\n",
      "iteration: 1191 | loss: 1.186350\n",
      "iteration: 1192 | loss: 0.908009\n",
      "iteration: 1193 | loss: 0.912185\n",
      "iteration: 1194 | loss: 0.871331\n",
      "iteration: 1195 | loss: 0.850834\n",
      "iteration: 1196 | loss: 0.617747\n",
      "iteration: 1197 | loss: 0.525224\n",
      "iteration: 1198 | loss: 0.912073\n",
      "iteration: 1199 | loss: 0.456709\n",
      "  Train acc: 0.754, Val acc: 0.5\n",
      "iteration: 1200 | loss: 0.681139\n",
      "iteration: 1201 | loss: 0.754655\n",
      "iteration: 1202 | loss: 0.683260\n",
      "iteration: 1203 | loss: 0.915310\n",
      "iteration: 1204 | loss: 0.834243\n",
      "iteration: 1205 | loss: 0.690171\n",
      "iteration: 1206 | loss: 0.712072\n",
      "iteration: 1207 | loss: 0.668444\n",
      "iteration: 1208 | loss: 0.576422\n",
      "iteration: 1209 | loss: 0.777469\n",
      "iteration: 1210 | loss: 0.753135\n",
      "iteration: 1211 | loss: 0.668997\n",
      "iteration: 1212 | loss: 0.610308\n",
      "iteration: 1213 | loss: 0.837938\n",
      "iteration: 1214 | loss: 0.527700\n",
      "iteration: 1215 | loss: 0.590422\n",
      "iteration: 1216 | loss: 0.848499\n",
      "iteration: 1217 | loss: 0.622043\n",
      "iteration: 1218 | loss: 0.761130\n",
      "iteration: 1219 | loss: 1.038658\n",
      "iteration: 1220 | loss: 1.010703\n",
      "iteration: 1221 | loss: 0.647312\n",
      "iteration: 1222 | loss: 0.719447\n",
      "iteration: 1223 | loss: 0.775387\n",
      "iteration: 1224 | loss: 0.629868\n",
      "  Train acc: 0.754, Val acc: 0.5\n",
      "iteration: 1225 | loss: 0.786626\n",
      "iteration: 1226 | loss: 0.821915\n",
      "iteration: 1227 | loss: 0.538456\n",
      "iteration: 1228 | loss: 0.709148\n",
      "iteration: 1229 | loss: 0.712745\n",
      "iteration: 1230 | loss: 0.987120\n",
      "iteration: 1231 | loss: 0.732232\n",
      "iteration: 1232 | loss: 0.773775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1233 | loss: 0.807279\n",
      "iteration: 1234 | loss: 0.966993\n",
      "iteration: 1235 | loss: 0.633940\n",
      "iteration: 1236 | loss: 0.747514\n",
      "iteration: 1237 | loss: 0.776890\n",
      "iteration: 1238 | loss: 1.017320\n",
      "iteration: 1239 | loss: 0.689136\n",
      "iteration: 1240 | loss: 0.565427\n",
      "iteration: 1241 | loss: 0.788608\n",
      "iteration: 1242 | loss: 0.562480\n",
      "iteration: 1243 | loss: 1.132282\n",
      "iteration: 1244 | loss: 0.731293\n",
      "iteration: 1245 | loss: 0.740860\n",
      "iteration: 1246 | loss: 0.747523\n",
      "iteration: 1247 | loss: 0.448821\n",
      "iteration: 1248 | loss: 0.938304\n",
      "iteration: 1249 | loss: 0.693829\n",
      "  Train acc: 0.772, Val acc: 0.5\n",
      "iteration: 1250 | loss: 0.759189\n",
      "iteration: 1251 | loss: 0.927304\n",
      "iteration: 1252 | loss: 0.583526\n",
      "iteration: 1253 | loss: 0.834859\n",
      "iteration: 1254 | loss: 0.861881\n",
      "iteration: 1255 | loss: 0.959263\n",
      "iteration: 1256 | loss: 0.745490\n",
      "iteration: 1257 | loss: 0.898120\n",
      "iteration: 1258 | loss: 0.989428\n",
      "iteration: 1259 | loss: 0.852741\n",
      "iteration: 1260 | loss: 0.666048\n",
      "iteration: 1261 | loss: 0.510730\n",
      "iteration: 1262 | loss: 0.638774\n",
      "iteration: 1263 | loss: 0.827061\n",
      "iteration: 1264 | loss: 0.700508\n",
      "iteration: 1265 | loss: 0.670674\n",
      "iteration: 1266 | loss: 0.579796\n",
      "iteration: 1267 | loss: 0.659547\n",
      "iteration: 1268 | loss: 0.544564\n",
      "iteration: 1269 | loss: 0.901777\n",
      "iteration: 1270 | loss: 0.655893\n",
      "iteration: 1271 | loss: 0.632667\n",
      "iteration: 1272 | loss: 0.943384\n",
      "iteration: 1273 | loss: 0.721521\n",
      "iteration: 1274 | loss: 0.477016\n",
      "  Train acc: 0.788, Val acc: 0.5\n",
      "iteration: 1275 | loss: 0.863866\n",
      "iteration: 1276 | loss: 0.794196\n",
      "iteration: 1277 | loss: 0.581657\n",
      "iteration: 1278 | loss: 0.576430\n",
      "iteration: 1279 | loss: 0.681325\n",
      "iteration: 1280 | loss: 0.800516\n",
      "iteration: 1281 | loss: 0.768442\n",
      "iteration: 1282 | loss: 0.697637\n",
      "iteration: 1283 | loss: 0.563662\n",
      "iteration: 1284 | loss: 0.495227\n",
      "iteration: 1285 | loss: 0.706417\n",
      "iteration: 1286 | loss: 0.752641\n",
      "iteration: 1287 | loss: 0.639243\n",
      "iteration: 1288 | loss: 0.518502\n",
      "iteration: 1289 | loss: 0.816937\n",
      "iteration: 1290 | loss: 0.877214\n",
      "iteration: 1291 | loss: 0.719155\n",
      "iteration: 1292 | loss: 1.066228\n",
      "iteration: 1293 | loss: 0.534724\n",
      "iteration: 1294 | loss: 0.729422\n",
      "iteration: 1295 | loss: 0.939916\n",
      "iteration: 1296 | loss: 0.662650\n",
      "iteration: 1297 | loss: 0.538010\n",
      "iteration: 1298 | loss: 1.018495\n",
      "iteration: 1299 | loss: 0.454826\n",
      "  Train acc: 0.75, Val acc: 0.5\n",
      "iteration: 1300 | loss: 0.683599\n",
      "iteration: 1301 | loss: 0.462870\n",
      "iteration: 1302 | loss: 0.587138\n",
      "iteration: 1303 | loss: 0.930958\n",
      "iteration: 1304 | loss: 0.836332\n",
      "iteration: 1305 | loss: 0.357944\n",
      "iteration: 1306 | loss: 0.960103\n",
      "iteration: 1307 | loss: 0.639335\n",
      "iteration: 1308 | loss: 0.664160\n",
      "iteration: 1309 | loss: 0.793423\n",
      "iteration: 1310 | loss: 0.872945\n",
      "iteration: 1311 | loss: 0.412929\n",
      "iteration: 1312 | loss: 0.714774\n",
      "iteration: 1313 | loss: 0.845719\n",
      "iteration: 1314 | loss: 0.662925\n",
      "iteration: 1315 | loss: 0.838242\n",
      "iteration: 1316 | loss: 0.798025\n",
      "iteration: 1317 | loss: 0.620701\n",
      "iteration: 1318 | loss: 0.576299\n",
      "iteration: 1319 | loss: 0.790132\n",
      "iteration: 1320 | loss: 0.801899\n",
      "iteration: 1321 | loss: 0.737457\n",
      "iteration: 1322 | loss: 0.473514\n",
      "iteration: 1323 | loss: 0.933059\n",
      "iteration: 1324 | loss: 0.808870\n",
      "  Train acc: 0.788, Val acc: 0.5\n",
      "iteration: 1325 | loss: 0.618812\n",
      "iteration: 1326 | loss: 1.020867\n",
      "iteration: 1327 | loss: 0.447003\n",
      "iteration: 1328 | loss: 0.366174\n",
      "iteration: 1329 | loss: 0.752278\n",
      "iteration: 1330 | loss: 0.374908\n",
      "iteration: 1331 | loss: 0.572614\n",
      "iteration: 1332 | loss: 0.665854\n",
      "iteration: 1333 | loss: 0.523631\n",
      "iteration: 1334 | loss: 0.607931\n",
      "iteration: 1335 | loss: 0.590641\n",
      "iteration: 1336 | loss: 0.886911\n",
      "iteration: 1337 | loss: 0.631784\n",
      "iteration: 1338 | loss: 0.533367\n",
      "iteration: 1339 | loss: 0.671296\n",
      "iteration: 1340 | loss: 0.440599\n",
      "iteration: 1341 | loss: 0.660131\n",
      "iteration: 1342 | loss: 0.743969\n",
      "iteration: 1343 | loss: 1.173329\n",
      "iteration: 1344 | loss: 0.617832\n",
      "iteration: 1345 | loss: 0.448027\n",
      "iteration: 1346 | loss: 0.790387\n",
      "iteration: 1347 | loss: 0.284895\n",
      "iteration: 1348 | loss: 0.672825\n",
      "iteration: 1349 | loss: 0.512219\n",
      "  Train acc: 0.774, Val acc: 0.5\n",
      "iteration: 1350 | loss: 0.692939\n",
      "iteration: 1351 | loss: 0.491023\n",
      "iteration: 1352 | loss: 0.616980\n",
      "iteration: 1353 | loss: 0.535434\n",
      "iteration: 1354 | loss: 0.485811\n",
      "iteration: 1355 | loss: 0.543136\n",
      "iteration: 1356 | loss: 0.908215\n",
      "iteration: 1357 | loss: 0.652647\n",
      "iteration: 1358 | loss: 0.727751\n",
      "iteration: 1359 | loss: 0.756011\n",
      "iteration: 1360 | loss: 0.462651\n",
      "iteration: 1361 | loss: 0.588435\n",
      "iteration: 1362 | loss: 0.936590\n",
      "iteration: 1363 | loss: 0.663408\n",
      "iteration: 1364 | loss: 0.740228\n",
      "iteration: 1365 | loss: 0.427990\n",
      "iteration: 1366 | loss: 0.797590\n",
      "iteration: 1367 | loss: 0.492115\n",
      "iteration: 1368 | loss: 0.692683\n",
      "iteration: 1369 | loss: 0.519682\n",
      "iteration: 1370 | loss: 0.479160\n",
      "iteration: 1371 | loss: 0.732649\n",
      "iteration: 1372 | loss: 0.614374\n",
      "iteration: 1373 | loss: 0.933399\n",
      "iteration: 1374 | loss: 0.695396\n",
      "  Train acc: 0.802, Val acc: 0.5\n",
      "iteration: 1375 | loss: 1.262103\n",
      "iteration: 1376 | loss: 0.543450\n",
      "iteration: 1377 | loss: 0.453361\n",
      "iteration: 1378 | loss: 0.256633\n",
      "iteration: 1379 | loss: 0.401418\n",
      "iteration: 1380 | loss: 0.739741\n",
      "iteration: 1381 | loss: 0.598615\n",
      "iteration: 1382 | loss: 0.893707\n",
      "iteration: 1383 | loss: 0.688836\n",
      "iteration: 1384 | loss: 0.756773\n",
      "iteration: 1385 | loss: 0.276946\n",
      "iteration: 1386 | loss: 0.775551\n",
      "iteration: 1387 | loss: 0.594721\n",
      "iteration: 1388 | loss: 0.527357\n",
      "iteration: 1389 | loss: 0.516781\n",
      "iteration: 1390 | loss: 0.494709\n",
      "iteration: 1391 | loss: 0.669269\n",
      "iteration: 1392 | loss: 0.647516\n",
      "iteration: 1393 | loss: 0.442741\n",
      "iteration: 1394 | loss: 0.554372\n",
      "iteration: 1395 | loss: 1.127698\n",
      "iteration: 1396 | loss: 0.375913\n",
      "iteration: 1397 | loss: 0.709349\n",
      "iteration: 1398 | loss: 0.933605\n",
      "iteration: 1399 | loss: 0.685713\n",
      "  Train acc: 0.8, Val acc: 0.5\n",
      "iteration: 1400 | loss: 0.644180\n",
      "iteration: 1401 | loss: 0.586975\n",
      "iteration: 1402 | loss: 0.680775\n",
      "iteration: 1403 | loss: 0.552943\n",
      "iteration: 1404 | loss: 0.656923\n",
      "iteration: 1405 | loss: 0.712028\n",
      "iteration: 1406 | loss: 0.653188\n",
      "iteration: 1407 | loss: 0.887962\n",
      "iteration: 1408 | loss: 0.663330\n",
      "iteration: 1409 | loss: 0.647001\n",
      "iteration: 1410 | loss: 0.527355\n",
      "iteration: 1411 | loss: 0.516309\n",
      "iteration: 1412 | loss: 0.502942\n",
      "iteration: 1413 | loss: 0.713677\n",
      "iteration: 1414 | loss: 0.470796\n",
      "iteration: 1415 | loss: 0.777184\n",
      "iteration: 1416 | loss: 0.666893\n",
      "iteration: 1417 | loss: 0.791234\n",
      "iteration: 1418 | loss: 0.542927\n",
      "iteration: 1419 | loss: 0.572783\n",
      "iteration: 1420 | loss: 0.748436\n",
      "iteration: 1421 | loss: 0.571997\n",
      "iteration: 1422 | loss: 0.700067\n",
      "iteration: 1423 | loss: 0.753805\n",
      "iteration: 1424 | loss: 0.685682\n",
      "  Train acc: 0.78, Val acc: 0.5\n",
      "iteration: 1425 | loss: 0.631548\n",
      "iteration: 1426 | loss: 0.512019\n",
      "iteration: 1427 | loss: 0.484905\n",
      "iteration: 1428 | loss: 0.623022\n",
      "iteration: 1429 | loss: 1.040663\n",
      "iteration: 1430 | loss: 1.076712\n",
      "iteration: 1431 | loss: 0.537881\n",
      "iteration: 1432 | loss: 0.578211\n",
      "iteration: 1433 | loss: 0.434795\n",
      "iteration: 1434 | loss: 0.820754\n",
      "iteration: 1435 | loss: 0.721555\n",
      "iteration: 1436 | loss: 0.580751\n",
      "iteration: 1437 | loss: 0.717983\n",
      "iteration: 1438 | loss: 0.636741\n",
      "iteration: 1439 | loss: 0.490464\n",
      "iteration: 1440 | loss: 0.312632\n",
      "iteration: 1441 | loss: 0.695075\n",
      "iteration: 1442 | loss: 0.576835\n",
      "iteration: 1443 | loss: 0.529051\n",
      "iteration: 1444 | loss: 0.749162\n",
      "iteration: 1445 | loss: 0.371706\n",
      "iteration: 1446 | loss: 0.662941\n",
      "iteration: 1447 | loss: 0.463872\n",
      "iteration: 1448 | loss: 0.644846\n",
      "iteration: 1449 | loss: 0.475140\n",
      "  Train acc: 0.822, Val acc: 0.5\n",
      "iteration: 1450 | loss: 0.559833\n",
      "iteration: 1451 | loss: 0.456924\n",
      "iteration: 1452 | loss: 0.475577\n",
      "iteration: 1453 | loss: 0.513231\n",
      "iteration: 1454 | loss: 0.554153\n",
      "iteration: 1455 | loss: 0.658585\n",
      "iteration: 1456 | loss: 0.543371\n",
      "iteration: 1457 | loss: 0.388632\n",
      "iteration: 1458 | loss: 0.637295\n",
      "iteration: 1459 | loss: 0.986187\n",
      "iteration: 1460 | loss: 0.766006\n",
      "iteration: 1461 | loss: 0.728257\n",
      "iteration: 1462 | loss: 0.543004\n",
      "iteration: 1463 | loss: 0.409584\n",
      "iteration: 1464 | loss: 0.709647\n",
      "iteration: 1465 | loss: 0.690934\n",
      "iteration: 1466 | loss: 0.372183\n",
      "iteration: 1467 | loss: 0.609419\n",
      "iteration: 1468 | loss: 0.540051\n",
      "iteration: 1469 | loss: 0.337721\n",
      "iteration: 1470 | loss: 0.664120\n",
      "iteration: 1471 | loss: 1.184529\n",
      "iteration: 1472 | loss: 0.537978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1473 | loss: 0.723037\n",
      "iteration: 1474 | loss: 0.699956\n",
      "  Train acc: 0.774, Val acc: 0.5\n",
      "iteration: 1475 | loss: 0.856508\n",
      "iteration: 1476 | loss: 0.483057\n",
      "iteration: 1477 | loss: 0.488042\n",
      "iteration: 1478 | loss: 0.394789\n",
      "iteration: 1479 | loss: 0.538657\n",
      "iteration: 1480 | loss: 0.366578\n",
      "iteration: 1481 | loss: 0.905739\n",
      "iteration: 1482 | loss: 0.604025\n",
      "iteration: 1483 | loss: 0.646661\n",
      "iteration: 1484 | loss: 0.378601\n",
      "iteration: 1485 | loss: 0.716376\n",
      "iteration: 1486 | loss: 0.785686\n",
      "iteration: 1487 | loss: 0.567065\n",
      "iteration: 1488 | loss: 0.455510\n",
      "iteration: 1489 | loss: 0.449413\n",
      "iteration: 1490 | loss: 0.477388\n",
      "iteration: 1491 | loss: 0.641148\n",
      "iteration: 1492 | loss: 1.069103\n",
      "iteration: 1493 | loss: 0.955027\n",
      "iteration: 1494 | loss: 0.537838\n",
      "iteration: 1495 | loss: 0.712392\n",
      "iteration: 1496 | loss: 0.345344\n",
      "iteration: 1497 | loss: 0.359990\n",
      "iteration: 1498 | loss: 0.447388\n",
      "iteration: 1499 | loss: 0.250397\n",
      "  Train acc: 0.834, Val acc: 0.5\n",
      "iteration: 1500 | loss: 0.512675\n",
      "iteration: 1501 | loss: 0.435934\n",
      "iteration: 1502 | loss: 0.784319\n",
      "iteration: 1503 | loss: 0.509812\n",
      "iteration: 1504 | loss: 0.407608\n",
      "iteration: 1505 | loss: 0.720385\n",
      "iteration: 1506 | loss: 0.500317\n",
      "iteration: 1507 | loss: 0.451573\n",
      "iteration: 1508 | loss: 0.378535\n",
      "iteration: 1509 | loss: 0.621066\n",
      "iteration: 1510 | loss: 0.449105\n",
      "iteration: 1511 | loss: 0.464965\n",
      "iteration: 1512 | loss: 0.508948\n",
      "iteration: 1513 | loss: 0.608512\n",
      "iteration: 1514 | loss: 0.592233\n",
      "iteration: 1515 | loss: 0.830251\n",
      "iteration: 1516 | loss: 0.676733\n",
      "iteration: 1517 | loss: 0.179585\n",
      "iteration: 1518 | loss: 0.408022\n",
      "iteration: 1519 | loss: 0.472247\n",
      "iteration: 1520 | loss: 0.579044\n",
      "iteration: 1521 | loss: 0.356323\n",
      "iteration: 1522 | loss: 0.936131\n",
      "iteration: 1523 | loss: 0.568782\n",
      "iteration: 1524 | loss: 0.413165\n",
      "  Train acc: 0.848, Val acc: 0.5\n",
      "iteration: 1525 | loss: 0.406232\n",
      "iteration: 1526 | loss: 0.629176\n",
      "iteration: 1527 | loss: 0.551227\n",
      "iteration: 1528 | loss: 0.405096\n",
      "iteration: 1529 | loss: 1.050720\n",
      "iteration: 1530 | loss: 0.454198\n",
      "iteration: 1531 | loss: 0.784921\n",
      "iteration: 1532 | loss: 0.345169\n",
      "iteration: 1533 | loss: 0.417079\n",
      "iteration: 1534 | loss: 0.546637\n",
      "iteration: 1535 | loss: 0.267914\n",
      "iteration: 1536 | loss: 0.330590\n",
      "iteration: 1537 | loss: 0.618705\n",
      "iteration: 1538 | loss: 0.440025\n",
      "iteration: 1539 | loss: 0.385843\n",
      "iteration: 1540 | loss: 0.594160\n",
      "iteration: 1541 | loss: 0.468210\n",
      "iteration: 1542 | loss: 0.663682\n",
      "iteration: 1543 | loss: 0.747360\n",
      "iteration: 1544 | loss: 0.461575\n",
      "iteration: 1545 | loss: 0.669829\n",
      "iteration: 1546 | loss: 0.262235\n",
      "iteration: 1547 | loss: 0.707208\n",
      "iteration: 1548 | loss: 0.482300\n",
      "iteration: 1549 | loss: 0.503223\n",
      "  Train acc: 0.838, Val acc: 0.5\n",
      "iteration: 1550 | loss: 0.412443\n",
      "iteration: 1551 | loss: 0.400188\n",
      "iteration: 1552 | loss: 0.564581\n",
      "iteration: 1553 | loss: 0.399511\n",
      "iteration: 1554 | loss: 0.704680\n",
      "iteration: 1555 | loss: 0.794776\n",
      "iteration: 1556 | loss: 0.542384\n",
      "iteration: 1557 | loss: 0.494079\n",
      "iteration: 1558 | loss: 0.645203\n",
      "iteration: 1559 | loss: 0.406026\n",
      "iteration: 1560 | loss: 0.605192\n",
      "iteration: 1561 | loss: 0.757827\n",
      "iteration: 1562 | loss: 0.424699\n",
      "iteration: 1563 | loss: 0.874822\n",
      "iteration: 1564 | loss: 0.681796\n",
      "iteration: 1565 | loss: 0.716105\n",
      "iteration: 1566 | loss: 0.436061\n",
      "iteration: 1567 | loss: 0.639691\n",
      "iteration: 1568 | loss: 0.358257\n",
      "iteration: 1569 | loss: 0.425715\n",
      "iteration: 1570 | loss: 0.582774\n",
      "iteration: 1571 | loss: 0.347111\n",
      "iteration: 1572 | loss: 0.375285\n",
      "iteration: 1573 | loss: 0.376711\n",
      "iteration: 1574 | loss: 0.652640\n",
      "  Train acc: 0.828, Val acc: 0.5\n",
      "iteration: 1575 | loss: 0.442494\n",
      "iteration: 1576 | loss: 0.557678\n",
      "iteration: 1577 | loss: 0.391287\n",
      "iteration: 1578 | loss: 0.471918\n",
      "iteration: 1579 | loss: 0.332066\n",
      "iteration: 1580 | loss: 0.311550\n",
      "iteration: 1581 | loss: 0.362854\n",
      "iteration: 1582 | loss: 0.544617\n",
      "iteration: 1583 | loss: 0.658228\n",
      "iteration: 1584 | loss: 0.510828\n",
      "iteration: 1585 | loss: 0.359343\n",
      "iteration: 1586 | loss: 0.358344\n",
      "iteration: 1587 | loss: 0.570402\n",
      "iteration: 1588 | loss: 0.351157\n",
      "iteration: 1589 | loss: 0.298101\n",
      "iteration: 1590 | loss: 0.358488\n",
      "iteration: 1591 | loss: 0.341099\n",
      "iteration: 1592 | loss: 0.465396\n",
      "iteration: 1593 | loss: 0.545895\n",
      "iteration: 1594 | loss: 0.300646\n",
      "iteration: 1595 | loss: 0.621583\n",
      "iteration: 1596 | loss: 0.427288\n",
      "iteration: 1597 | loss: 0.391766\n",
      "iteration: 1598 | loss: 0.814530\n",
      "iteration: 1599 | loss: 0.657489\n",
      "  Train acc: 0.864, Val acc: 0.5\n",
      "iteration: 1600 | loss: 0.437730\n",
      "iteration: 1601 | loss: 0.618030\n",
      "iteration: 1602 | loss: 0.505914\n",
      "iteration: 1603 | loss: 0.481833\n",
      "iteration: 1604 | loss: 0.506991\n",
      "iteration: 1605 | loss: 0.418927\n",
      "iteration: 1606 | loss: 0.528964\n",
      "iteration: 1607 | loss: 0.710718\n",
      "iteration: 1608 | loss: 0.384094\n",
      "iteration: 1609 | loss: 0.904202\n",
      "iteration: 1610 | loss: 0.556225\n",
      "iteration: 1611 | loss: 0.302978\n",
      "iteration: 1612 | loss: 0.728146\n",
      "iteration: 1613 | loss: 0.591497\n",
      "iteration: 1614 | loss: 0.324590\n",
      "iteration: 1615 | loss: 0.600624\n",
      "iteration: 1616 | loss: 0.686689\n",
      "iteration: 1617 | loss: 0.672791\n",
      "iteration: 1618 | loss: 0.514950\n",
      "iteration: 1619 | loss: 0.444443\n",
      "iteration: 1620 | loss: 0.495718\n",
      "iteration: 1621 | loss: 0.406483\n",
      "iteration: 1622 | loss: 0.595611\n",
      "iteration: 1623 | loss: 0.456504\n",
      "iteration: 1624 | loss: 0.519710\n",
      "  Train acc: 0.782, Val acc: 0.5\n",
      "iteration: 1625 | loss: 0.172906\n",
      "iteration: 1626 | loss: 0.424490\n",
      "iteration: 1627 | loss: 0.610059\n",
      "iteration: 1628 | loss: 0.235627\n",
      "iteration: 1629 | loss: 0.532153\n",
      "iteration: 1630 | loss: 0.569779\n",
      "iteration: 1631 | loss: 0.663000\n",
      "iteration: 1632 | loss: 0.460762\n",
      "iteration: 1633 | loss: 0.345467\n",
      "iteration: 1634 | loss: 0.297181\n",
      "iteration: 1635 | loss: 0.504793\n",
      "iteration: 1636 | loss: 0.575283\n",
      "iteration: 1637 | loss: 0.671813\n",
      "iteration: 1638 | loss: 0.588907\n",
      "iteration: 1639 | loss: 0.344514\n",
      "iteration: 1640 | loss: 0.426970\n",
      "iteration: 1641 | loss: 0.648409\n",
      "iteration: 1642 | loss: 0.414676\n",
      "iteration: 1643 | loss: 0.402272\n",
      "iteration: 1644 | loss: 0.508704\n",
      "iteration: 1645 | loss: 0.241352\n",
      "iteration: 1646 | loss: 0.322797\n",
      "iteration: 1647 | loss: 0.427718\n",
      "iteration: 1648 | loss: 0.528762\n",
      "iteration: 1649 | loss: 0.620550\n",
      "  Train acc: 0.844, Val acc: 0.5\n",
      "iteration: 1650 | loss: 0.412058\n",
      "iteration: 1651 | loss: 0.667403\n",
      "iteration: 1652 | loss: 0.373420\n",
      "iteration: 1653 | loss: 0.575447\n",
      "iteration: 1654 | loss: 0.526499\n",
      "iteration: 1655 | loss: 0.548914\n",
      "iteration: 1656 | loss: 0.493397\n",
      "iteration: 1657 | loss: 0.268523\n",
      "iteration: 1658 | loss: 0.890368\n",
      "iteration: 1659 | loss: 0.404555\n",
      "iteration: 1660 | loss: 0.380371\n",
      "iteration: 1661 | loss: 0.440559\n",
      "iteration: 1662 | loss: 0.321077\n",
      "iteration: 1663 | loss: 0.643802\n",
      "iteration: 1664 | loss: 0.401768\n",
      "iteration: 1665 | loss: 0.285000\n",
      "iteration: 1666 | loss: 0.361370\n",
      "iteration: 1667 | loss: 0.330654\n",
      "iteration: 1668 | loss: 0.522091\n",
      "iteration: 1669 | loss: 0.328359\n",
      "iteration: 1670 | loss: 0.575477\n",
      "iteration: 1671 | loss: 0.264740\n",
      "iteration: 1672 | loss: 0.319097\n",
      "iteration: 1673 | loss: 0.434204\n",
      "iteration: 1674 | loss: 0.637690\n",
      "  Train acc: 0.806, Val acc: 0.5\n",
      "iteration: 1675 | loss: 0.467251\n",
      "iteration: 1676 | loss: 0.550516\n",
      "iteration: 1677 | loss: 0.384483\n",
      "iteration: 1678 | loss: 0.549567\n",
      "iteration: 1679 | loss: 0.413935\n",
      "iteration: 1680 | loss: 0.661673\n",
      "iteration: 1681 | loss: 0.480298\n",
      "iteration: 1682 | loss: 0.305041\n",
      "iteration: 1683 | loss: 0.279943\n",
      "iteration: 1684 | loss: 0.579469\n",
      "iteration: 1685 | loss: 0.312898\n",
      "iteration: 1686 | loss: 0.436209\n",
      "iteration: 1687 | loss: 0.271734\n",
      "iteration: 1688 | loss: 0.801397\n",
      "iteration: 1689 | loss: 0.469060\n",
      "iteration: 1690 | loss: 0.343466\n",
      "iteration: 1691 | loss: 0.343345\n",
      "iteration: 1692 | loss: 0.708782\n",
      "iteration: 1693 | loss: 0.807668\n",
      "iteration: 1694 | loss: 0.670673\n",
      "iteration: 1695 | loss: 0.363871\n",
      "iteration: 1696 | loss: 0.337456\n",
      "iteration: 1697 | loss: 0.494449\n",
      "iteration: 1698 | loss: 0.371486\n",
      "iteration: 1699 | loss: 0.254702\n",
      "  Train acc: 0.866, Val acc: 0.5\n",
      "iteration: 1700 | loss: 0.281951\n",
      "iteration: 1701 | loss: 0.982176\n",
      "iteration: 1702 | loss: 0.803026\n",
      "iteration: 1703 | loss: 0.442228\n",
      "iteration: 1704 | loss: 0.513964\n",
      "iteration: 1705 | loss: 0.638683\n",
      "iteration: 1706 | loss: 0.518317\n",
      "iteration: 1707 | loss: 0.365979\n",
      "iteration: 1708 | loss: 0.494797\n",
      "iteration: 1709 | loss: 0.684496\n",
      "iteration: 1710 | loss: 0.271478\n",
      "iteration: 1711 | loss: 0.249353\n",
      "iteration: 1712 | loss: 0.383415\n",
      "iteration: 1713 | loss: 0.461165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1714 | loss: 0.300714\n",
      "iteration: 1715 | loss: 0.348166\n",
      "iteration: 1716 | loss: 0.786221\n",
      "iteration: 1717 | loss: 0.980112\n",
      "iteration: 1718 | loss: 0.558077\n",
      "iteration: 1719 | loss: 0.475864\n",
      "iteration: 1720 | loss: 0.268884\n",
      "iteration: 1721 | loss: 0.237923\n",
      "iteration: 1722 | loss: 0.401939\n",
      "iteration: 1723 | loss: 0.387365\n",
      "iteration: 1724 | loss: 0.503022\n",
      "  Train acc: 0.886, Val acc: 0.5\n",
      "iteration: 1725 | loss: 1.034063\n",
      "iteration: 1726 | loss: 0.334875\n",
      "iteration: 1727 | loss: 0.474702\n",
      "iteration: 1728 | loss: 0.727333\n",
      "iteration: 1729 | loss: 0.525884\n",
      "iteration: 1730 | loss: 0.434056\n",
      "iteration: 1731 | loss: 0.416803\n",
      "iteration: 1732 | loss: 0.489136\n",
      "iteration: 1733 | loss: 0.464163\n",
      "iteration: 1734 | loss: 0.512907\n",
      "iteration: 1735 | loss: 0.324635\n",
      "iteration: 1736 | loss: 0.284796\n",
      "iteration: 1737 | loss: 0.640932\n",
      "iteration: 1738 | loss: 0.671253\n",
      "iteration: 1739 | loss: 0.486594\n",
      "iteration: 1740 | loss: 0.246279\n",
      "iteration: 1741 | loss: 0.732085\n",
      "iteration: 1742 | loss: 0.375838\n",
      "iteration: 1743 | loss: 0.471475\n",
      "iteration: 1744 | loss: 0.481511\n",
      "iteration: 1745 | loss: 0.586041\n",
      "iteration: 1746 | loss: 0.251429\n",
      "iteration: 1747 | loss: 0.253338\n",
      "iteration: 1748 | loss: 0.204722\n",
      "iteration: 1749 | loss: 0.282977\n",
      "  Train acc: 0.868, Val acc: 0.5\n",
      "iteration: 1750 | loss: 0.338901\n",
      "iteration: 1751 | loss: 0.253258\n",
      "iteration: 1752 | loss: 0.368534\n",
      "iteration: 1753 | loss: 0.381895\n",
      "iteration: 1754 | loss: 0.201452\n",
      "iteration: 1755 | loss: 0.388444\n",
      "iteration: 1756 | loss: 0.647109\n",
      "iteration: 1757 | loss: 0.296573\n",
      "iteration: 1758 | loss: 0.426946\n",
      "iteration: 1759 | loss: 0.697643\n",
      "iteration: 1760 | loss: 0.693511\n",
      "iteration: 1761 | loss: 0.287464\n",
      "iteration: 1762 | loss: 0.329850\n",
      "iteration: 1763 | loss: 0.436127\n",
      "iteration: 1764 | loss: 0.409024\n",
      "iteration: 1765 | loss: 0.498562\n",
      "iteration: 1766 | loss: 0.412682\n",
      "iteration: 1767 | loss: 0.370838\n",
      "iteration: 1768 | loss: 0.191331\n",
      "iteration: 1769 | loss: 0.542250\n",
      "iteration: 1770 | loss: 0.253239\n",
      "iteration: 1771 | loss: 0.602246\n",
      "iteration: 1772 | loss: 0.380792\n",
      "iteration: 1773 | loss: 0.490732\n",
      "iteration: 1774 | loss: 0.602710\n",
      "  Train acc: 0.838, Val acc: 0.5\n",
      "iteration: 1775 | loss: 0.727875\n",
      "iteration: 1776 | loss: 0.443933\n",
      "iteration: 1777 | loss: 0.385463\n",
      "iteration: 1778 | loss: 0.447363\n",
      "iteration: 1779 | loss: 0.399713\n",
      "iteration: 1780 | loss: 0.255241\n",
      "iteration: 1781 | loss: 0.491502\n",
      "iteration: 1782 | loss: 0.485190\n",
      "iteration: 1783 | loss: 0.279491\n",
      "iteration: 1784 | loss: 0.569883\n",
      "iteration: 1785 | loss: 0.262854\n",
      "iteration: 1786 | loss: 0.425176\n",
      "iteration: 1787 | loss: 0.555677\n",
      "iteration: 1788 | loss: 0.471728\n",
      "iteration: 1789 | loss: 0.262530\n",
      "iteration: 1790 | loss: 0.325617\n",
      "iteration: 1791 | loss: 0.388400\n",
      "iteration: 1792 | loss: 0.445572\n",
      "iteration: 1793 | loss: 0.383237\n",
      "iteration: 1794 | loss: 0.718712\n",
      "iteration: 1795 | loss: 0.331039\n",
      "iteration: 1796 | loss: 0.170140\n",
      "iteration: 1797 | loss: 0.315556\n",
      "iteration: 1798 | loss: 0.301953\n",
      "iteration: 1799 | loss: 0.406432\n",
      "  Train acc: 0.852, Val acc: 0.5\n",
      "iteration: 1800 | loss: 0.666247\n",
      "iteration: 1801 | loss: 0.192227\n",
      "iteration: 1802 | loss: 0.339040\n",
      "iteration: 1803 | loss: 0.438560\n",
      "iteration: 1804 | loss: 0.422859\n",
      "iteration: 1805 | loss: 0.560764\n",
      "iteration: 1806 | loss: 0.285050\n",
      "iteration: 1807 | loss: 0.285832\n",
      "iteration: 1808 | loss: 0.333395\n",
      "iteration: 1809 | loss: 0.231704\n",
      "iteration: 1810 | loss: 0.090881\n",
      "iteration: 1811 | loss: 0.568069\n",
      "iteration: 1812 | loss: 0.340837\n",
      "iteration: 1813 | loss: 0.361896\n",
      "iteration: 1814 | loss: 0.753129\n",
      "iteration: 1815 | loss: 0.259825\n",
      "iteration: 1816 | loss: 0.338132\n",
      "iteration: 1817 | loss: 0.106981\n",
      "iteration: 1818 | loss: 0.687438\n",
      "iteration: 1819 | loss: 0.661564\n",
      "iteration: 1820 | loss: 0.203955\n",
      "iteration: 1821 | loss: 0.355086\n",
      "iteration: 1822 | loss: 0.467832\n",
      "iteration: 1823 | loss: 0.166675\n",
      "iteration: 1824 | loss: 0.401106\n",
      "  Train acc: 0.864, Val acc: 0.5\n",
      "iteration: 1825 | loss: 0.512027\n",
      "iteration: 1826 | loss: 0.333070\n",
      "iteration: 1827 | loss: 0.207050\n",
      "iteration: 1828 | loss: 0.398251\n",
      "iteration: 1829 | loss: 0.818796\n",
      "iteration: 1830 | loss: 0.503191\n",
      "iteration: 1831 | loss: 0.177050\n",
      "iteration: 1832 | loss: 0.372593\n",
      "iteration: 1833 | loss: 0.432536\n",
      "iteration: 1834 | loss: 0.663607\n",
      "iteration: 1835 | loss: 0.496065\n",
      "iteration: 1836 | loss: 0.327454\n",
      "iteration: 1837 | loss: 0.204694\n",
      "iteration: 1838 | loss: 0.359721\n",
      "iteration: 1839 | loss: 0.362804\n",
      "iteration: 1840 | loss: 0.276740\n",
      "iteration: 1841 | loss: 0.669827\n",
      "iteration: 1842 | loss: 0.124857\n",
      "iteration: 1843 | loss: 0.527167\n",
      "iteration: 1844 | loss: 0.392841\n",
      "iteration: 1845 | loss: 0.357482\n",
      "iteration: 1846 | loss: 0.422122\n",
      "iteration: 1847 | loss: 0.308555\n",
      "iteration: 1848 | loss: 0.569175\n",
      "iteration: 1849 | loss: 0.610793\n",
      "  Train acc: 0.876, Val acc: 0.5\n",
      "iteration: 1850 | loss: 0.287252\n",
      "iteration: 1851 | loss: 0.714131\n",
      "iteration: 1852 | loss: 0.600691\n",
      "iteration: 1853 | loss: 0.157482\n",
      "iteration: 1854 | loss: 0.259194\n",
      "iteration: 1855 | loss: 0.201484\n",
      "iteration: 1856 | loss: 0.295840\n",
      "iteration: 1857 | loss: 0.310571\n",
      "iteration: 1858 | loss: 0.214766\n",
      "iteration: 1859 | loss: 0.614308\n",
      "iteration: 1860 | loss: 0.392047\n",
      "iteration: 1861 | loss: 0.313616\n",
      "iteration: 1862 | loss: 0.160610\n",
      "iteration: 1863 | loss: 0.162065\n",
      "iteration: 1864 | loss: 0.365425\n",
      "iteration: 1865 | loss: 0.487940\n",
      "iteration: 1866 | loss: 0.198567\n",
      "iteration: 1867 | loss: 0.165001\n",
      "iteration: 1868 | loss: 0.248280\n",
      "iteration: 1869 | loss: 0.232486\n",
      "iteration: 1870 | loss: 0.501953\n",
      "iteration: 1871 | loss: 0.301653\n",
      "iteration: 1872 | loss: 0.236893\n",
      "iteration: 1873 | loss: 0.581800\n",
      "iteration: 1874 | loss: 0.240961\n",
      "  Train acc: 0.914, Val acc: 0.5\n",
      "iteration: 1875 | loss: 0.154621\n",
      "iteration: 1876 | loss: 0.561515\n",
      "iteration: 1877 | loss: 0.324035\n",
      "iteration: 1878 | loss: 0.296592\n",
      "iteration: 1879 | loss: 0.415046\n",
      "iteration: 1880 | loss: 0.475760\n",
      "iteration: 1881 | loss: 0.391302\n",
      "iteration: 1882 | loss: 0.314618\n",
      "iteration: 1883 | loss: 0.205912\n",
      "iteration: 1884 | loss: 0.538430\n",
      "iteration: 1885 | loss: 0.208345\n",
      "iteration: 1886 | loss: 0.347625\n",
      "iteration: 1887 | loss: 0.502603\n",
      "iteration: 1888 | loss: 0.224502\n",
      "iteration: 1889 | loss: 0.334564\n",
      "iteration: 1890 | loss: 0.409692\n",
      "iteration: 1891 | loss: 0.426440\n",
      "iteration: 1892 | loss: 0.298073\n",
      "iteration: 1893 | loss: 0.215554\n",
      "iteration: 1894 | loss: 0.613196\n",
      "iteration: 1895 | loss: 0.342996\n",
      "iteration: 1896 | loss: 0.674677\n",
      "iteration: 1897 | loss: 0.390877\n",
      "iteration: 1898 | loss: 0.266046\n",
      "iteration: 1899 | loss: 0.448274\n",
      "  Train acc: 0.894, Val acc: 0.5\n",
      "iteration: 1900 | loss: 0.275171\n",
      "iteration: 1901 | loss: 0.537870\n",
      "iteration: 1902 | loss: 0.482491\n",
      "iteration: 1903 | loss: 0.247134\n",
      "iteration: 1904 | loss: 0.234188\n",
      "iteration: 1905 | loss: 0.400415\n",
      "iteration: 1906 | loss: 0.319180\n",
      "iteration: 1907 | loss: 0.333305\n",
      "iteration: 1908 | loss: 0.319425\n",
      "iteration: 1909 | loss: 0.570338\n",
      "iteration: 1910 | loss: 0.605666\n",
      "iteration: 1911 | loss: 0.281590\n",
      "iteration: 1912 | loss: 0.400724\n",
      "iteration: 1913 | loss: 0.479482\n",
      "iteration: 1914 | loss: 0.471465\n",
      "iteration: 1915 | loss: 0.180774\n",
      "iteration: 1916 | loss: 0.377116\n",
      "iteration: 1917 | loss: 0.340712\n",
      "iteration: 1918 | loss: 0.465105\n",
      "iteration: 1919 | loss: 0.147623\n",
      "iteration: 1920 | loss: 0.368659\n",
      "iteration: 1921 | loss: 0.837448\n",
      "iteration: 1922 | loss: 0.199705\n",
      "iteration: 1923 | loss: 0.214222\n",
      "iteration: 1924 | loss: 0.261935\n",
      "  Train acc: 0.896, Val acc: 0.5\n",
      "iteration: 1925 | loss: 0.444770\n",
      "iteration: 1926 | loss: 0.327857\n",
      "iteration: 1927 | loss: 0.519720\n",
      "iteration: 1928 | loss: 0.323239\n",
      "iteration: 1929 | loss: 0.401995\n",
      "iteration: 1930 | loss: 0.192598\n",
      "iteration: 1931 | loss: 0.293622\n",
      "iteration: 1932 | loss: 0.331336\n",
      "iteration: 1933 | loss: 0.324676\n",
      "iteration: 1934 | loss: 0.296411\n",
      "iteration: 1935 | loss: 0.510129\n",
      "iteration: 1936 | loss: 0.255814\n",
      "iteration: 1937 | loss: 0.264208\n",
      "iteration: 1938 | loss: 0.302611\n",
      "iteration: 1939 | loss: 0.350532\n",
      "iteration: 1940 | loss: 0.558652\n",
      "iteration: 1941 | loss: 0.241759\n",
      "iteration: 1942 | loss: 0.498705\n",
      "iteration: 1943 | loss: 0.247512\n",
      "iteration: 1944 | loss: 0.268464\n",
      "iteration: 1945 | loss: 0.330893\n",
      "iteration: 1946 | loss: 0.234689\n",
      "iteration: 1947 | loss: 0.380923\n",
      "iteration: 1948 | loss: 0.236622\n",
      "iteration: 1949 | loss: 0.495507\n",
      "  Train acc: 0.894, Val acc: 0.5\n",
      "iteration: 1950 | loss: 0.312336\n",
      "iteration: 1951 | loss: 0.463820\n",
      "iteration: 1952 | loss: 0.450406\n",
      "iteration: 1953 | loss: 0.320799\n",
      "iteration: 1954 | loss: 0.411565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1955 | loss: 0.252840\n",
      "iteration: 1956 | loss: 0.453897\n",
      "iteration: 1957 | loss: 0.352766\n",
      "iteration: 1958 | loss: 0.169443\n",
      "iteration: 1959 | loss: 0.461970\n",
      "iteration: 1960 | loss: 0.224293\n",
      "iteration: 1961 | loss: 0.487476\n",
      "iteration: 1962 | loss: 0.274250\n",
      "iteration: 1963 | loss: 0.248009\n",
      "iteration: 1964 | loss: 0.454736\n",
      "iteration: 1965 | loss: 0.138587\n",
      "iteration: 1966 | loss: 0.246433\n",
      "iteration: 1967 | loss: 0.387530\n",
      "iteration: 1968 | loss: 0.209187\n",
      "iteration: 1969 | loss: 0.136633\n",
      "iteration: 1970 | loss: 0.238502\n",
      "iteration: 1971 | loss: 0.318343\n",
      "iteration: 1972 | loss: 0.904197\n",
      "iteration: 1973 | loss: 0.363836\n",
      "iteration: 1974 | loss: 0.406768\n",
      "  Train acc: 0.916, Val acc: 0.5\n",
      "iteration: 1975 | loss: 0.519641\n",
      "iteration: 1976 | loss: 0.309756\n",
      "iteration: 1977 | loss: 0.525064\n",
      "iteration: 1978 | loss: 0.265938\n",
      "iteration: 1979 | loss: 0.280373\n",
      "iteration: 1980 | loss: 0.215821\n",
      "iteration: 1981 | loss: 0.164657\n",
      "iteration: 1982 | loss: 0.262863\n",
      "iteration: 1983 | loss: 0.279484\n",
      "iteration: 1984 | loss: 0.244612\n",
      "iteration: 1985 | loss: 0.244865\n",
      "iteration: 1986 | loss: 0.123819\n",
      "iteration: 1987 | loss: 0.375015\n",
      "iteration: 1988 | loss: 0.206337\n",
      "iteration: 1989 | loss: 0.419842\n",
      "iteration: 1990 | loss: 0.120662\n",
      "iteration: 1991 | loss: 0.631839\n",
      "iteration: 1992 | loss: 0.213900\n",
      "iteration: 1993 | loss: 0.470646\n",
      "iteration: 1994 | loss: 0.427146\n",
      "iteration: 1995 | loss: 0.396312\n",
      "iteration: 1996 | loss: 0.435226\n",
      "iteration: 1997 | loss: 0.561472\n",
      "iteration: 1998 | loss: 0.215240\n",
      "iteration: 1999 | loss: 0.299465\n",
      "  Train acc: 0.892, Val acc: 0.5\n",
      "iteration: 2000 | loss: 0.273075\n",
      "iteration: 2001 | loss: 0.279081\n",
      "iteration: 2002 | loss: 0.240643\n",
      "iteration: 2003 | loss: 0.233390\n",
      "iteration: 2004 | loss: 0.381773\n",
      "iteration: 2005 | loss: 0.368251\n",
      "iteration: 2006 | loss: 0.159715\n",
      "iteration: 2007 | loss: 0.282184\n",
      "iteration: 2008 | loss: 0.308842\n",
      "iteration: 2009 | loss: 0.345558\n",
      "iteration: 2010 | loss: 0.374628\n",
      "iteration: 2011 | loss: 0.199164\n",
      "iteration: 2012 | loss: 0.445971\n",
      "iteration: 2013 | loss: 0.249987\n",
      "iteration: 2014 | loss: 0.267202\n",
      "iteration: 2015 | loss: 0.197580\n",
      "iteration: 2016 | loss: 0.222513\n",
      "iteration: 2017 | loss: 0.321420\n",
      "iteration: 2018 | loss: 0.312805\n",
      "iteration: 2019 | loss: 0.498017\n",
      "iteration: 2020 | loss: 0.454337\n",
      "iteration: 2021 | loss: 0.183787\n",
      "iteration: 2022 | loss: 0.420281\n",
      "iteration: 2023 | loss: 0.358916\n",
      "iteration: 2024 | loss: 0.361903\n",
      "  Train acc: 0.91, Val acc: 0.5\n",
      "iteration: 2025 | loss: 0.373482\n",
      "iteration: 2026 | loss: 0.136486\n",
      "iteration: 2027 | loss: 0.126748\n",
      "iteration: 2028 | loss: 0.305521\n",
      "iteration: 2029 | loss: 0.196988\n",
      "iteration: 2030 | loss: 0.107191\n",
      "iteration: 2031 | loss: 0.311763\n",
      "iteration: 2032 | loss: 0.360943\n",
      "iteration: 2033 | loss: 0.485750\n",
      "iteration: 2034 | loss: 0.263694\n",
      "iteration: 2035 | loss: 0.280422\n",
      "iteration: 2036 | loss: 0.157060\n",
      "iteration: 2037 | loss: 0.507362\n",
      "iteration: 2038 | loss: 0.219904\n",
      "iteration: 2039 | loss: 0.431647\n",
      "iteration: 2040 | loss: 0.313960\n",
      "iteration: 2041 | loss: 0.515184\n",
      "iteration: 2042 | loss: 0.240963\n",
      "iteration: 2043 | loss: 0.560896\n",
      "iteration: 2044 | loss: 0.316976\n",
      "iteration: 2045 | loss: 0.345976\n",
      "iteration: 2046 | loss: 0.350557\n",
      "iteration: 2047 | loss: 0.150113\n",
      "iteration: 2048 | loss: 0.498880\n",
      "iteration: 2049 | loss: 0.334134\n",
      "  Train acc: 0.88, Val acc: 0.5\n",
      "iteration: 2050 | loss: 0.110142\n",
      "iteration: 2051 | loss: 0.311202\n",
      "iteration: 2052 | loss: 0.189953\n",
      "iteration: 2053 | loss: 0.140833\n",
      "iteration: 2054 | loss: 0.391764\n",
      "iteration: 2055 | loss: 0.402750\n",
      "iteration: 2056 | loss: 0.267689\n",
      "iteration: 2057 | loss: 0.338928\n",
      "iteration: 2058 | loss: 0.215576\n",
      "iteration: 2059 | loss: 0.293261\n",
      "iteration: 2060 | loss: 0.157167\n",
      "iteration: 2061 | loss: 0.306834\n",
      "iteration: 2062 | loss: 0.398064\n",
      "iteration: 2063 | loss: 0.284274\n",
      "iteration: 2064 | loss: 0.288546\n",
      "iteration: 2065 | loss: 0.829775\n",
      "iteration: 2066 | loss: 0.305000\n",
      "iteration: 2067 | loss: 0.445643\n",
      "iteration: 2068 | loss: 0.331287\n",
      "iteration: 2069 | loss: 0.490604\n",
      "iteration: 2070 | loss: 0.301470\n",
      "iteration: 2071 | loss: 0.238705\n",
      "iteration: 2072 | loss: 0.397019\n",
      "iteration: 2073 | loss: 0.126396\n",
      "iteration: 2074 | loss: 0.272330\n",
      "  Train acc: 0.906, Val acc: 0.5\n",
      "iteration: 2075 | loss: 0.323028\n",
      "iteration: 2076 | loss: 0.219224\n",
      "iteration: 2077 | loss: 0.394971\n",
      "iteration: 2078 | loss: 0.404372\n",
      "iteration: 2079 | loss: 0.200150\n",
      "iteration: 2080 | loss: 0.196367\n",
      "iteration: 2081 | loss: 0.139638\n",
      "iteration: 2082 | loss: 0.194476\n",
      "iteration: 2083 | loss: 0.159247\n",
      "iteration: 2084 | loss: 0.156261\n",
      "iteration: 2085 | loss: 0.122304\n",
      "iteration: 2086 | loss: 0.182813\n",
      "iteration: 2087 | loss: 0.267237\n",
      "iteration: 2088 | loss: 0.241496\n",
      "iteration: 2089 | loss: 0.246273\n",
      "iteration: 2090 | loss: 0.221098\n",
      "iteration: 2091 | loss: 0.191952\n",
      "iteration: 2092 | loss: 0.322972\n",
      "iteration: 2093 | loss: 0.400335\n",
      "iteration: 2094 | loss: 0.094806\n",
      "iteration: 2095 | loss: 0.262194\n",
      "iteration: 2096 | loss: 0.140656\n",
      "iteration: 2097 | loss: 0.158590\n",
      "iteration: 2098 | loss: 0.165002\n",
      "iteration: 2099 | loss: 0.278347\n",
      "  Train acc: 0.912, Val acc: 0.5\n",
      "iteration: 2100 | loss: 0.217575\n",
      "iteration: 2101 | loss: 0.169121\n",
      "iteration: 2102 | loss: 0.300657\n",
      "iteration: 2103 | loss: 0.251750\n",
      "iteration: 2104 | loss: 0.082676\n",
      "iteration: 2105 | loss: 0.120441\n",
      "iteration: 2106 | loss: 0.220677\n",
      "iteration: 2107 | loss: 0.467723\n",
      "iteration: 2108 | loss: 0.374683\n",
      "iteration: 2109 | loss: 0.115023\n",
      "iteration: 2110 | loss: 0.121562\n",
      "iteration: 2111 | loss: 0.137549\n",
      "iteration: 2112 | loss: 0.468525\n",
      "iteration: 2113 | loss: 0.345862\n",
      "iteration: 2114 | loss: 0.265642\n",
      "iteration: 2115 | loss: 0.413205\n",
      "iteration: 2116 | loss: 0.246906\n",
      "iteration: 2117 | loss: 0.208573\n",
      "iteration: 2118 | loss: 0.166811\n",
      "iteration: 2119 | loss: 0.489273\n",
      "iteration: 2120 | loss: 0.245494\n",
      "iteration: 2121 | loss: 0.256444\n",
      "iteration: 2122 | loss: 0.192019\n",
      "iteration: 2123 | loss: 0.060270\n",
      "iteration: 2124 | loss: 0.766962\n",
      "  Train acc: 0.902, Val acc: 0.5\n",
      "iteration: 2125 | loss: 0.450478\n",
      "iteration: 2126 | loss: 0.201406\n",
      "iteration: 2127 | loss: 0.391409\n",
      "iteration: 2128 | loss: 0.252215\n",
      "iteration: 2129 | loss: 0.156496\n",
      "iteration: 2130 | loss: 0.146651\n",
      "iteration: 2131 | loss: 0.250330\n",
      "iteration: 2132 | loss: 0.514942\n",
      "iteration: 2133 | loss: 0.341348\n",
      "iteration: 2134 | loss: 0.180245\n",
      "iteration: 2135 | loss: 0.264524\n",
      "iteration: 2136 | loss: 0.097960\n",
      "iteration: 2137 | loss: 0.163134\n",
      "iteration: 2138 | loss: 0.196183\n",
      "iteration: 2139 | loss: 0.395274\n",
      "iteration: 2140 | loss: 0.349918\n",
      "iteration: 2141 | loss: 0.568407\n",
      "iteration: 2142 | loss: 0.423961\n",
      "iteration: 2143 | loss: 0.199988\n",
      "iteration: 2144 | loss: 0.415396\n",
      "iteration: 2145 | loss: 0.241313\n",
      "iteration: 2146 | loss: 0.348744\n",
      "iteration: 2147 | loss: 0.280809\n",
      "iteration: 2148 | loss: 0.197001\n",
      "iteration: 2149 | loss: 0.257068\n",
      "  Train acc: 0.926, Val acc: 0.5\n",
      "iteration: 2150 | loss: 0.148596\n",
      "iteration: 2151 | loss: 0.559220\n",
      "iteration: 2152 | loss: 0.099377\n",
      "iteration: 2153 | loss: 0.208644\n",
      "iteration: 2154 | loss: 0.105208\n",
      "iteration: 2155 | loss: 0.120604\n",
      "iteration: 2156 | loss: 0.232829\n",
      "iteration: 2157 | loss: 0.413093\n",
      "iteration: 2158 | loss: 0.154003\n",
      "iteration: 2159 | loss: 0.203936\n",
      "iteration: 2160 | loss: 0.278144\n",
      "iteration: 2161 | loss: 0.216958\n",
      "iteration: 2162 | loss: 0.180455\n",
      "iteration: 2163 | loss: 0.301458\n",
      "iteration: 2164 | loss: 0.125255\n",
      "iteration: 2165 | loss: 0.269190\n",
      "iteration: 2166 | loss: 0.087291\n",
      "iteration: 2167 | loss: 0.198966\n",
      "iteration: 2168 | loss: 0.255291\n",
      "iteration: 2169 | loss: 0.179828\n",
      "iteration: 2170 | loss: 0.761891\n",
      "iteration: 2171 | loss: 0.221272\n",
      "iteration: 2172 | loss: 0.189367\n",
      "iteration: 2173 | loss: 0.182111\n",
      "iteration: 2174 | loss: 0.218636\n",
      "  Train acc: 0.928, Val acc: 0.5\n",
      "iteration: 2175 | loss: 0.292453\n",
      "iteration: 2176 | loss: 0.311609\n",
      "iteration: 2177 | loss: 0.189611\n",
      "iteration: 2178 | loss: 0.280321\n",
      "iteration: 2179 | loss: 0.323918\n",
      "iteration: 2180 | loss: 0.339158\n",
      "iteration: 2181 | loss: 0.150898\n",
      "iteration: 2182 | loss: 0.479481\n",
      "iteration: 2183 | loss: 0.056958\n",
      "iteration: 2184 | loss: 0.176568\n",
      "iteration: 2185 | loss: 0.208513\n",
      "iteration: 2186 | loss: 0.264969\n",
      "iteration: 2187 | loss: 0.321935\n",
      "iteration: 2188 | loss: 0.473452\n",
      "iteration: 2189 | loss: 0.157116\n",
      "iteration: 2190 | loss: 0.107347\n",
      "iteration: 2191 | loss: 0.225137\n",
      "iteration: 2192 | loss: 0.183470\n",
      "iteration: 2193 | loss: 0.139815\n",
      "iteration: 2194 | loss: 0.546316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2195 | loss: 0.184530\n",
      "iteration: 2196 | loss: 0.308192\n",
      "iteration: 2197 | loss: 0.226903\n",
      "iteration: 2198 | loss: 0.669891\n",
      "iteration: 2199 | loss: 0.193786\n",
      "  Train acc: 0.954, Val acc: 0.5\n",
      "iteration: 2200 | loss: 0.295964\n",
      "iteration: 2201 | loss: 0.141449\n",
      "iteration: 2202 | loss: 0.309466\n",
      "iteration: 2203 | loss: 0.258242\n",
      "iteration: 2204 | loss: 0.393802\n",
      "iteration: 2205 | loss: 0.154905\n",
      "iteration: 2206 | loss: 0.140400\n",
      "iteration: 2207 | loss: 0.298790\n",
      "iteration: 2208 | loss: 0.159456\n",
      "iteration: 2209 | loss: 0.354061\n",
      "iteration: 2210 | loss: 0.174321\n",
      "iteration: 2211 | loss: 0.203143\n",
      "iteration: 2212 | loss: 0.470980\n",
      "iteration: 2213 | loss: 0.255057\n",
      "iteration: 2214 | loss: 0.278205\n",
      "iteration: 2215 | loss: 0.086002\n",
      "iteration: 2216 | loss: 0.374442\n",
      "iteration: 2217 | loss: 0.076870\n",
      "iteration: 2218 | loss: 0.436650\n",
      "iteration: 2219 | loss: 0.117772\n",
      "iteration: 2220 | loss: 0.156466\n",
      "iteration: 2221 | loss: 0.241405\n",
      "iteration: 2222 | loss: 0.317261\n",
      "iteration: 2223 | loss: 0.328658\n",
      "iteration: 2224 | loss: 0.248562\n",
      "  Train acc: 0.934, Val acc: 0.5\n",
      "iteration: 2225 | loss: 0.224193\n",
      "iteration: 2226 | loss: 0.319949\n",
      "iteration: 2227 | loss: 0.473984\n",
      "iteration: 2228 | loss: 0.463864\n",
      "iteration: 2229 | loss: 0.196397\n",
      "iteration: 2230 | loss: 0.147517\n",
      "iteration: 2231 | loss: 0.193285\n",
      "iteration: 2232 | loss: 0.176024\n",
      "iteration: 2233 | loss: 0.100083\n",
      "iteration: 2234 | loss: 0.149180\n",
      "iteration: 2235 | loss: 0.280889\n",
      "iteration: 2236 | loss: 0.135566\n",
      "iteration: 2237 | loss: 0.263956\n",
      "iteration: 2238 | loss: 0.369740\n",
      "iteration: 2239 | loss: 0.196864\n",
      "iteration: 2240 | loss: 0.393014\n",
      "iteration: 2241 | loss: 0.085844\n",
      "iteration: 2242 | loss: 0.189922\n",
      "iteration: 2243 | loss: 0.099644\n",
      "iteration: 2244 | loss: 0.396223\n",
      "iteration: 2245 | loss: 0.204469\n",
      "iteration: 2246 | loss: 0.279352\n",
      "iteration: 2247 | loss: 0.156753\n",
      "iteration: 2248 | loss: 0.117697\n",
      "iteration: 2249 | loss: 0.082698\n",
      "  Train acc: 0.936, Val acc: 0.5\n",
      "iteration: 2250 | loss: 0.292555\n",
      "iteration: 2251 | loss: 0.214950\n",
      "iteration: 2252 | loss: 0.108573\n",
      "iteration: 2253 | loss: 0.322349\n",
      "iteration: 2254 | loss: 0.439871\n",
      "iteration: 2255 | loss: 0.544267\n",
      "iteration: 2256 | loss: 0.083439\n",
      "iteration: 2257 | loss: 0.347125\n",
      "iteration: 2258 | loss: 0.229639\n",
      "iteration: 2259 | loss: 0.218366\n",
      "iteration: 2260 | loss: 0.270474\n",
      "iteration: 2261 | loss: 0.494151\n",
      "iteration: 2262 | loss: 0.442551\n",
      "iteration: 2263 | loss: 0.137661\n",
      "iteration: 2264 | loss: 0.308428\n",
      "iteration: 2265 | loss: 0.436450\n",
      "iteration: 2266 | loss: 0.220251\n",
      "iteration: 2267 | loss: 0.139913\n",
      "iteration: 2268 | loss: 0.129505\n",
      "iteration: 2269 | loss: 0.254921\n",
      "iteration: 2270 | loss: 0.337758\n",
      "iteration: 2271 | loss: 0.172708\n",
      "iteration: 2272 | loss: 0.226631\n",
      "iteration: 2273 | loss: 0.236541\n",
      "iteration: 2274 | loss: 0.123972\n",
      "  Train acc: 0.94, Val acc: 0.5\n",
      "iteration: 2275 | loss: 0.150315\n",
      "iteration: 2276 | loss: 0.206658\n",
      "iteration: 2277 | loss: 0.200614\n",
      "iteration: 2278 | loss: 0.147697\n",
      "iteration: 2279 | loss: 0.175510\n",
      "iteration: 2280 | loss: 0.166001\n",
      "iteration: 2281 | loss: 0.273567\n",
      "iteration: 2282 | loss: 0.138725\n",
      "iteration: 2283 | loss: 0.083533\n",
      "iteration: 2284 | loss: 0.358611\n",
      "iteration: 2285 | loss: 0.287050\n",
      "iteration: 2286 | loss: 0.174336\n",
      "iteration: 2287 | loss: 0.255991\n",
      "iteration: 2288 | loss: 0.150697\n",
      "iteration: 2289 | loss: 0.318095\n",
      "iteration: 2290 | loss: 0.541889\n",
      "iteration: 2291 | loss: 0.178661\n",
      "iteration: 2292 | loss: 0.065465\n",
      "iteration: 2293 | loss: 0.193030\n",
      "iteration: 2294 | loss: 0.154171\n",
      "iteration: 2295 | loss: 0.176363\n",
      "iteration: 2296 | loss: 0.211580\n",
      "iteration: 2297 | loss: 0.400971\n",
      "iteration: 2298 | loss: 0.151255\n",
      "iteration: 2299 | loss: 0.116717\n",
      "  Train acc: 0.928, Val acc: 0.5\n",
      "iteration: 2300 | loss: 0.280292\n",
      "iteration: 2301 | loss: 0.341267\n",
      "iteration: 2302 | loss: 0.115092\n",
      "iteration: 2303 | loss: 0.337825\n",
      "iteration: 2304 | loss: 0.105035\n",
      "iteration: 2305 | loss: 0.292031\n",
      "iteration: 2306 | loss: 0.336983\n",
      "iteration: 2307 | loss: 0.203801\n",
      "iteration: 2308 | loss: 0.146793\n",
      "iteration: 2309 | loss: 0.241022\n",
      "iteration: 2310 | loss: 0.230659\n",
      "iteration: 2311 | loss: 0.144975\n",
      "iteration: 2312 | loss: 0.236028\n",
      "iteration: 2313 | loss: 0.210101\n",
      "iteration: 2314 | loss: 0.047567\n",
      "iteration: 2315 | loss: 0.195691\n",
      "iteration: 2316 | loss: 0.186748\n",
      "iteration: 2317 | loss: 0.165207\n",
      "iteration: 2318 | loss: 0.129650\n",
      "iteration: 2319 | loss: 0.210370\n",
      "iteration: 2320 | loss: 0.318750\n",
      "iteration: 2321 | loss: 0.087172\n",
      "iteration: 2322 | loss: 0.239833\n",
      "iteration: 2323 | loss: 0.215775\n",
      "iteration: 2324 | loss: 0.505346\n",
      "  Train acc: 0.922, Val acc: 0.5\n",
      "iteration: 2325 | loss: 0.181398\n",
      "iteration: 2326 | loss: 0.171226\n",
      "iteration: 2327 | loss: 0.244915\n",
      "iteration: 2328 | loss: 0.377671\n",
      "iteration: 2329 | loss: 0.098189\n",
      "iteration: 2330 | loss: 0.044410\n",
      "iteration: 2331 | loss: 0.399908\n",
      "iteration: 2332 | loss: 0.090056\n",
      "iteration: 2333 | loss: 0.380405\n",
      "iteration: 2334 | loss: 0.493382\n",
      "iteration: 2335 | loss: 0.246983\n",
      "iteration: 2336 | loss: 0.143593\n",
      "iteration: 2337 | loss: 0.211114\n",
      "iteration: 2338 | loss: 0.161273\n",
      "iteration: 2339 | loss: 0.192060\n",
      "iteration: 2340 | loss: 0.192023\n",
      "iteration: 2341 | loss: 0.188744\n",
      "iteration: 2342 | loss: 0.198768\n",
      "iteration: 2343 | loss: 0.237810\n",
      "iteration: 2344 | loss: 0.169708\n",
      "iteration: 2345 | loss: 0.103469\n",
      "iteration: 2346 | loss: 0.184409\n",
      "iteration: 2347 | loss: 0.107874\n",
      "iteration: 2348 | loss: 0.284402\n",
      "iteration: 2349 | loss: 0.251493\n",
      "  Train acc: 0.93, Val acc: 0.5\n",
      "iteration: 2350 | loss: 0.126957\n",
      "iteration: 2351 | loss: 0.350733\n",
      "iteration: 2352 | loss: 0.099989\n",
      "iteration: 2353 | loss: 0.350451\n",
      "iteration: 2354 | loss: 0.488477\n",
      "iteration: 2355 | loss: 0.123071\n",
      "iteration: 2356 | loss: 0.046892\n",
      "iteration: 2357 | loss: 0.175235\n",
      "iteration: 2358 | loss: 0.165327\n",
      "iteration: 2359 | loss: 0.252282\n",
      "iteration: 2360 | loss: 0.110563\n",
      "iteration: 2361 | loss: 0.087934\n",
      "iteration: 2362 | loss: 0.318236\n",
      "iteration: 2363 | loss: 0.164014\n",
      "iteration: 2364 | loss: 0.239805\n",
      "iteration: 2365 | loss: 0.250708\n",
      "iteration: 2366 | loss: 0.131833\n",
      "iteration: 2367 | loss: 0.143433\n",
      "iteration: 2368 | loss: 0.187768\n",
      "iteration: 2369 | loss: 0.226549\n",
      "iteration: 2370 | loss: 0.217139\n",
      "iteration: 2371 | loss: 0.154815\n",
      "iteration: 2372 | loss: 0.349222\n",
      "iteration: 2373 | loss: 0.227056\n",
      "iteration: 2374 | loss: 0.278009\n",
      "  Train acc: 0.944, Val acc: 0.5\n",
      "iteration: 2375 | loss: 0.252288\n",
      "iteration: 2376 | loss: 0.229259\n",
      "iteration: 2377 | loss: 0.271015\n",
      "iteration: 2378 | loss: 0.166569\n",
      "iteration: 2379 | loss: 0.470620\n",
      "iteration: 2380 | loss: 0.299127\n",
      "iteration: 2381 | loss: 0.216100\n",
      "iteration: 2382 | loss: 0.084588\n",
      "iteration: 2383 | loss: 0.555568\n",
      "iteration: 2384 | loss: 0.229705\n",
      "iteration: 2385 | loss: 0.325146\n",
      "iteration: 2386 | loss: 0.190184\n",
      "iteration: 2387 | loss: 0.197978\n",
      "iteration: 2388 | loss: 0.253451\n",
      "iteration: 2389 | loss: 0.249128\n",
      "iteration: 2390 | loss: 0.123781\n",
      "iteration: 2391 | loss: 0.114895\n",
      "iteration: 2392 | loss: 0.156996\n",
      "iteration: 2393 | loss: 0.290481\n",
      "iteration: 2394 | loss: 0.222651\n",
      "iteration: 2395 | loss: 0.233758\n",
      "iteration: 2396 | loss: 0.100506\n",
      "iteration: 2397 | loss: 0.127536\n",
      "iteration: 2398 | loss: 0.100222\n",
      "iteration: 2399 | loss: 0.487077\n",
      "  Train acc: 0.91, Val acc: 0.5\n",
      "iteration: 2400 | loss: 0.424273\n",
      "iteration: 2401 | loss: 0.132522\n",
      "iteration: 2402 | loss: 0.250789\n",
      "iteration: 2403 | loss: 0.196542\n",
      "iteration: 2404 | loss: 0.488848\n",
      "iteration: 2405 | loss: 0.139466\n",
      "iteration: 2406 | loss: 0.163881\n",
      "iteration: 2407 | loss: 0.182765\n",
      "iteration: 2408 | loss: 0.253938\n",
      "iteration: 2409 | loss: 0.216332\n",
      "iteration: 2410 | loss: 0.193407\n",
      "iteration: 2411 | loss: 0.089872\n",
      "iteration: 2412 | loss: 0.140986\n",
      "iteration: 2413 | loss: 0.503760\n",
      "iteration: 2414 | loss: 0.169042\n",
      "iteration: 2415 | loss: 0.283014\n",
      "iteration: 2416 | loss: 0.269195\n",
      "iteration: 2417 | loss: 0.333521\n",
      "iteration: 2418 | loss: 0.198806\n",
      "iteration: 2419 | loss: 0.136019\n",
      "iteration: 2420 | loss: 0.174797\n",
      "iteration: 2421 | loss: 0.184585\n",
      "iteration: 2422 | loss: 0.244554\n",
      "iteration: 2423 | loss: 0.329813\n",
      "iteration: 2424 | loss: 0.100550\n",
      "  Train acc: 0.952, Val acc: 0.5\n",
      "iteration: 2425 | loss: 0.130026\n",
      "iteration: 2426 | loss: 0.084124\n",
      "iteration: 2427 | loss: 0.320888\n",
      "iteration: 2428 | loss: 0.369440\n",
      "iteration: 2429 | loss: 0.159569\n",
      "iteration: 2430 | loss: 0.318328\n",
      "iteration: 2431 | loss: 0.146108\n",
      "iteration: 2432 | loss: 0.145495\n",
      "iteration: 2433 | loss: 0.138301\n",
      "iteration: 2434 | loss: 0.187341\n",
      "iteration: 2435 | loss: 0.588155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2436 | loss: 0.188822\n",
      "iteration: 2437 | loss: 0.071605\n",
      "iteration: 2438 | loss: 0.074704\n",
      "iteration: 2439 | loss: 0.087850\n",
      "iteration: 2440 | loss: 0.073582\n",
      "iteration: 2441 | loss: 0.119920\n",
      "iteration: 2442 | loss: 0.306543\n",
      "iteration: 2443 | loss: 0.242717\n",
      "iteration: 2444 | loss: 0.186752\n",
      "iteration: 2445 | loss: 0.174837\n",
      "iteration: 2446 | loss: 0.117472\n",
      "iteration: 2447 | loss: 0.284229\n",
      "iteration: 2448 | loss: 0.455124\n",
      "iteration: 2449 | loss: 0.139959\n",
      "  Train acc: 0.952, Val acc: 0.5\n",
      "iteration: 2450 | loss: 0.186477\n",
      "iteration: 2451 | loss: 0.273759\n",
      "iteration: 2452 | loss: 0.092687\n",
      "iteration: 2453 | loss: 0.563192\n",
      "iteration: 2454 | loss: 0.094597\n",
      "iteration: 2455 | loss: 0.069960\n",
      "iteration: 2456 | loss: 0.151247\n",
      "iteration: 2457 | loss: 0.291768\n",
      "iteration: 2458 | loss: 0.288327\n",
      "iteration: 2459 | loss: 0.143315\n",
      "iteration: 2460 | loss: 0.179353\n",
      "iteration: 2461 | loss: 0.114132\n",
      "iteration: 2462 | loss: 0.145369\n",
      "iteration: 2463 | loss: 0.150503\n",
      "iteration: 2464 | loss: 0.212344\n",
      "iteration: 2465 | loss: 0.255262\n",
      "iteration: 2466 | loss: 0.186543\n",
      "iteration: 2467 | loss: 0.283355\n",
      "iteration: 2468 | loss: 0.161710\n",
      "iteration: 2469 | loss: 0.186581\n",
      "iteration: 2470 | loss: 0.079691\n",
      "iteration: 2471 | loss: 0.127247\n",
      "iteration: 2472 | loss: 0.127647\n",
      "iteration: 2473 | loss: 0.136208\n",
      "iteration: 2474 | loss: 0.200374\n",
      "  Train acc: 0.968, Val acc: 0.5\n",
      "iteration: 2475 | loss: 0.499560\n",
      "iteration: 2476 | loss: 0.047699\n",
      "iteration: 2477 | loss: 0.050609\n",
      "iteration: 2478 | loss: 0.218185\n",
      "iteration: 2479 | loss: 0.055783\n",
      "iteration: 2480 | loss: 0.215436\n",
      "iteration: 2481 | loss: 0.134669\n",
      "iteration: 2482 | loss: 0.132824\n",
      "iteration: 2483 | loss: 0.101771\n",
      "iteration: 2484 | loss: 0.102061\n",
      "iteration: 2485 | loss: 0.203509\n",
      "iteration: 2486 | loss: 0.241480\n",
      "iteration: 2487 | loss: 0.066586\n",
      "iteration: 2488 | loss: 0.050692\n",
      "iteration: 2489 | loss: 0.294237\n",
      "iteration: 2490 | loss: 0.157452\n",
      "iteration: 2491 | loss: 0.264179\n",
      "iteration: 2492 | loss: 0.145845\n",
      "iteration: 2493 | loss: 0.112622\n",
      "iteration: 2494 | loss: 0.108820\n",
      "iteration: 2495 | loss: 0.253506\n",
      "iteration: 2496 | loss: 0.387998\n",
      "iteration: 2497 | loss: 0.100647\n",
      "iteration: 2498 | loss: 0.135734\n",
      "iteration: 2499 | loss: 0.102319\n",
      "  Train acc: 0.966, Val acc: 0.5\n",
      "iteration: 2500 | loss: 0.101867\n",
      "iteration: 2501 | loss: 0.119151\n",
      "iteration: 2502 | loss: 0.185777\n",
      "iteration: 2503 | loss: 0.232915\n",
      "iteration: 2504 | loss: 0.186633\n",
      "iteration: 2505 | loss: 0.025407\n",
      "iteration: 2506 | loss: 0.167083\n",
      "iteration: 2507 | loss: 0.312014\n",
      "iteration: 2508 | loss: 0.140335\n",
      "iteration: 2509 | loss: 0.074059\n",
      "iteration: 2510 | loss: 0.111963\n",
      "iteration: 2511 | loss: 0.157212\n",
      "iteration: 2512 | loss: 0.090360\n",
      "iteration: 2513 | loss: 0.193816\n",
      "iteration: 2514 | loss: 0.155591\n",
      "iteration: 2515 | loss: 0.044343\n",
      "iteration: 2516 | loss: 0.069383\n",
      "iteration: 2517 | loss: 0.141073\n",
      "iteration: 2518 | loss: 0.133063\n",
      "iteration: 2519 | loss: 0.177610\n",
      "iteration: 2520 | loss: 0.236873\n",
      "iteration: 2521 | loss: 0.076088\n",
      "iteration: 2522 | loss: 0.187242\n",
      "iteration: 2523 | loss: 0.146133\n",
      "iteration: 2524 | loss: 0.148846\n",
      "  Train acc: 0.95, Val acc: 0.5\n",
      "iteration: 2525 | loss: 0.089903\n",
      "iteration: 2526 | loss: 0.071701\n",
      "iteration: 2527 | loss: 0.175985\n",
      "iteration: 2528 | loss: 0.112845\n",
      "iteration: 2529 | loss: 0.075048\n",
      "iteration: 2530 | loss: 0.139812\n",
      "iteration: 2531 | loss: 0.211780\n",
      "iteration: 2532 | loss: 0.043587\n",
      "iteration: 2533 | loss: 0.074285\n",
      "iteration: 2534 | loss: 0.157640\n",
      "iteration: 2535 | loss: 0.165545\n",
      "iteration: 2536 | loss: 0.134419\n",
      "iteration: 2537 | loss: 0.118186\n",
      "iteration: 2538 | loss: 0.401843\n",
      "iteration: 2539 | loss: 0.168071\n",
      "iteration: 2540 | loss: 0.185020\n",
      "iteration: 2541 | loss: 0.174873\n",
      "iteration: 2542 | loss: 0.119373\n",
      "iteration: 2543 | loss: 0.222679\n",
      "iteration: 2544 | loss: 0.162849\n",
      "iteration: 2545 | loss: 0.115858\n",
      "iteration: 2546 | loss: 0.099872\n",
      "iteration: 2547 | loss: 0.227086\n",
      "iteration: 2548 | loss: 0.093644\n",
      "iteration: 2549 | loss: 0.167827\n",
      "  Train acc: 0.96, Val acc: 0.5\n",
      "iteration: 2550 | loss: 0.182031\n",
      "iteration: 2551 | loss: 0.076834\n",
      "iteration: 2552 | loss: 0.186808\n",
      "iteration: 2553 | loss: 0.134337\n",
      "iteration: 2554 | loss: 0.104878\n",
      "iteration: 2555 | loss: 0.113880\n",
      "iteration: 2556 | loss: 0.076506\n",
      "iteration: 2557 | loss: 0.122837\n",
      "iteration: 2558 | loss: 0.069744\n",
      "iteration: 2559 | loss: 0.139376\n",
      "iteration: 2560 | loss: 0.242685\n",
      "iteration: 2561 | loss: 0.087203\n",
      "iteration: 2562 | loss: 0.159710\n",
      "iteration: 2563 | loss: 0.324861\n",
      "iteration: 2564 | loss: 0.081985\n",
      "iteration: 2565 | loss: 0.062975\n",
      "iteration: 2566 | loss: 0.072267\n",
      "iteration: 2567 | loss: 0.156930\n",
      "iteration: 2568 | loss: 0.044251\n",
      "iteration: 2569 | loss: 0.217880\n",
      "iteration: 2570 | loss: 0.117866\n",
      "iteration: 2571 | loss: 0.123896\n",
      "iteration: 2572 | loss: 0.103209\n",
      "iteration: 2573 | loss: 0.151321\n",
      "iteration: 2574 | loss: 0.090903\n",
      "  Train acc: 0.956, Val acc: 0.5\n",
      "iteration: 2575 | loss: 0.299443\n",
      "iteration: 2576 | loss: 0.029658\n",
      "iteration: 2577 | loss: 0.199991\n",
      "iteration: 2578 | loss: 0.178940\n",
      "iteration: 2579 | loss: 0.123857\n",
      "iteration: 2580 | loss: 0.056678\n",
      "iteration: 2581 | loss: 0.239368\n",
      "iteration: 2582 | loss: 0.112693\n",
      "iteration: 2583 | loss: 0.101905\n",
      "iteration: 2584 | loss: 0.288070\n",
      "iteration: 2585 | loss: 0.058899\n",
      "iteration: 2586 | loss: 0.067864\n",
      "iteration: 2587 | loss: 0.078063\n",
      "iteration: 2588 | loss: 0.076557\n",
      "iteration: 2589 | loss: 0.270990\n",
      "iteration: 2590 | loss: 0.083278\n",
      "iteration: 2591 | loss: 0.106516\n",
      "iteration: 2592 | loss: 0.060346\n",
      "iteration: 2593 | loss: 0.104653\n",
      "iteration: 2594 | loss: 0.176647\n",
      "iteration: 2595 | loss: 0.235742\n",
      "iteration: 2596 | loss: 0.138953\n",
      "iteration: 2597 | loss: 0.112336\n",
      "iteration: 2598 | loss: 0.095320\n",
      "iteration: 2599 | loss: 0.118784\n",
      "  Train acc: 0.964, Val acc: 0.5\n",
      "iteration: 2600 | loss: 0.160284\n",
      "iteration: 2601 | loss: 0.094913\n",
      "iteration: 2602 | loss: 0.268439\n",
      "iteration: 2603 | loss: 0.046948\n",
      "iteration: 2604 | loss: 0.046931\n",
      "iteration: 2605 | loss: 0.086720\n",
      "iteration: 2606 | loss: 0.129728\n",
      "iteration: 2607 | loss: 0.155041\n",
      "iteration: 2608 | loss: 0.056524\n",
      "iteration: 2609 | loss: 0.155997\n",
      "iteration: 2610 | loss: 0.167702\n",
      "iteration: 2611 | loss: 0.077004\n",
      "iteration: 2612 | loss: 0.457218\n",
      "iteration: 2613 | loss: 0.206490\n",
      "iteration: 2614 | loss: 0.108945\n",
      "iteration: 2615 | loss: 0.195847\n",
      "iteration: 2616 | loss: 0.113125\n",
      "iteration: 2617 | loss: 0.194211\n",
      "iteration: 2618 | loss: 0.047062\n",
      "iteration: 2619 | loss: 0.056204\n",
      "iteration: 2620 | loss: 0.047193\n",
      "iteration: 2621 | loss: 0.101778\n",
      "iteration: 2622 | loss: 0.119544\n",
      "iteration: 2623 | loss: 0.146963\n",
      "iteration: 2624 | loss: 0.099660\n",
      "  Train acc: 0.972, Val acc: 0.5\n",
      "iteration: 2625 | loss: 0.082436\n",
      "iteration: 2626 | loss: 0.115709\n",
      "iteration: 2627 | loss: 0.026291\n",
      "iteration: 2628 | loss: 0.075231\n",
      "iteration: 2629 | loss: 0.239190\n",
      "iteration: 2630 | loss: 0.068914\n",
      "iteration: 2631 | loss: 0.298007\n",
      "iteration: 2632 | loss: 0.246185\n",
      "iteration: 2633 | loss: 0.063780\n",
      "iteration: 2634 | loss: 0.198933\n",
      "iteration: 2635 | loss: 0.206286\n",
      "iteration: 2636 | loss: 0.164291\n",
      "iteration: 2637 | loss: 0.115051\n",
      "iteration: 2638 | loss: 0.048300\n",
      "iteration: 2639 | loss: 0.127286\n",
      "iteration: 2640 | loss: 0.183506\n",
      "iteration: 2641 | loss: 0.106833\n",
      "iteration: 2642 | loss: 0.056707\n",
      "iteration: 2643 | loss: 0.035100\n",
      "iteration: 2644 | loss: 0.101073\n",
      "iteration: 2645 | loss: 0.158074\n",
      "iteration: 2646 | loss: 0.101670\n",
      "iteration: 2647 | loss: 0.065241\n",
      "iteration: 2648 | loss: 0.032136\n",
      "iteration: 2649 | loss: 0.089178\n",
      "  Train acc: 0.96, Val acc: 0.5\n",
      "iteration: 2650 | loss: 0.110126\n",
      "iteration: 2651 | loss: 0.207056\n",
      "iteration: 2652 | loss: 0.036595\n",
      "iteration: 2653 | loss: 0.118156\n",
      "iteration: 2654 | loss: 0.167333\n",
      "iteration: 2655 | loss: 0.047449\n",
      "iteration: 2656 | loss: 0.144296\n",
      "iteration: 2657 | loss: 0.040860\n",
      "iteration: 2658 | loss: 0.115348\n",
      "iteration: 2659 | loss: 0.139172\n",
      "iteration: 2660 | loss: 0.076315\n",
      "iteration: 2661 | loss: 0.116482\n",
      "iteration: 2662 | loss: 0.072259\n",
      "iteration: 2663 | loss: 0.134888\n",
      "iteration: 2664 | loss: 0.060660\n",
      "iteration: 2665 | loss: 0.057593\n",
      "iteration: 2666 | loss: 0.050071\n",
      "iteration: 2667 | loss: 0.029155\n",
      "iteration: 2668 | loss: 0.085100\n",
      "iteration: 2669 | loss: 0.100999\n",
      "iteration: 2670 | loss: 0.148895\n",
      "iteration: 2671 | loss: 0.038016\n",
      "iteration: 2672 | loss: 0.240832\n",
      "iteration: 2673 | loss: 0.089303\n",
      "iteration: 2674 | loss: 0.189458\n",
      "  Train acc: 0.972, Val acc: 0.5\n",
      "iteration: 2675 | loss: 0.087790\n",
      "iteration: 2676 | loss: 0.025416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2677 | loss: 0.076673\n",
      "iteration: 2678 | loss: 0.111274\n",
      "iteration: 2679 | loss: 0.070424\n",
      "iteration: 2680 | loss: 0.026282\n",
      "iteration: 2681 | loss: 0.254222\n",
      "iteration: 2682 | loss: 0.093150\n",
      "iteration: 2683 | loss: 0.019694\n",
      "iteration: 2684 | loss: 0.065563\n",
      "iteration: 2685 | loss: 0.058551\n",
      "iteration: 2686 | loss: 0.055688\n",
      "iteration: 2687 | loss: 0.098594\n",
      "iteration: 2688 | loss: 0.171453\n",
      "iteration: 2689 | loss: 0.131250\n",
      "iteration: 2690 | loss: 0.130739\n",
      "iteration: 2691 | loss: 0.076403\n",
      "iteration: 2692 | loss: 0.074236\n",
      "iteration: 2693 | loss: 0.040502\n",
      "iteration: 2694 | loss: 0.108332\n",
      "iteration: 2695 | loss: 0.053421\n",
      "iteration: 2696 | loss: 0.066877\n",
      "iteration: 2697 | loss: 0.180899\n",
      "iteration: 2698 | loss: 0.275941\n",
      "iteration: 2699 | loss: 0.062394\n",
      "  Train acc: 0.958, Val acc: 0.5\n",
      "iteration: 2700 | loss: 0.074674\n",
      "iteration: 2701 | loss: 0.128466\n",
      "iteration: 2702 | loss: 0.077581\n",
      "iteration: 2703 | loss: 0.042717\n",
      "iteration: 2704 | loss: 0.147217\n",
      "iteration: 2705 | loss: 0.115631\n",
      "iteration: 2706 | loss: 0.086484\n",
      "iteration: 2707 | loss: 0.138150\n",
      "iteration: 2708 | loss: 0.227614\n",
      "iteration: 2709 | loss: 0.075191\n",
      "iteration: 2710 | loss: 0.179135\n",
      "iteration: 2711 | loss: 0.129354\n",
      "iteration: 2712 | loss: 0.048776\n",
      "iteration: 2713 | loss: 0.062657\n",
      "iteration: 2714 | loss: 0.086035\n",
      "iteration: 2715 | loss: 0.122778\n",
      "iteration: 2716 | loss: 0.039828\n",
      "iteration: 2717 | loss: 0.049756\n",
      "iteration: 2718 | loss: 0.085681\n",
      "iteration: 2719 | loss: 0.074255\n",
      "iteration: 2720 | loss: 0.286878\n",
      "iteration: 2721 | loss: 0.171167\n",
      "iteration: 2722 | loss: 0.077936\n",
      "iteration: 2723 | loss: 0.155929\n",
      "iteration: 2724 | loss: 0.059617\n",
      "  Train acc: 0.972, Val acc: 0.5\n",
      "iteration: 2725 | loss: 0.063599\n",
      "iteration: 2726 | loss: 0.090231\n",
      "iteration: 2727 | loss: 0.123643\n",
      "iteration: 2728 | loss: 0.222744\n",
      "iteration: 2729 | loss: 0.048461\n",
      "iteration: 2730 | loss: 0.075893\n",
      "iteration: 2731 | loss: 0.104440\n",
      "iteration: 2732 | loss: 0.045837\n",
      "iteration: 2733 | loss: 0.034655\n",
      "iteration: 2734 | loss: 0.235436\n",
      "iteration: 2735 | loss: 0.161943\n",
      "iteration: 2736 | loss: 0.069357\n",
      "iteration: 2737 | loss: 0.029775\n",
      "iteration: 2738 | loss: 0.097285\n",
      "iteration: 2739 | loss: 0.106842\n",
      "iteration: 2740 | loss: 0.103665\n",
      "iteration: 2741 | loss: 0.351150\n",
      "iteration: 2742 | loss: 0.181841\n",
      "iteration: 2743 | loss: 0.116302\n",
      "iteration: 2744 | loss: 0.042186\n",
      "iteration: 2745 | loss: 0.149858\n",
      "iteration: 2746 | loss: 0.095975\n",
      "iteration: 2747 | loss: 0.162724\n",
      "iteration: 2748 | loss: 0.094542\n",
      "iteration: 2749 | loss: 0.086843\n",
      "  Train acc: 0.97, Val acc: 0.5\n",
      "iteration: 2750 | loss: 0.088192\n",
      "iteration: 2751 | loss: 0.125394\n",
      "iteration: 2752 | loss: 0.023419\n",
      "iteration: 2753 | loss: 0.161967\n",
      "iteration: 2754 | loss: 0.032322\n",
      "iteration: 2755 | loss: 0.083548\n",
      "iteration: 2756 | loss: 0.042592\n",
      "iteration: 2757 | loss: 0.083746\n",
      "iteration: 2758 | loss: 0.087488\n",
      "iteration: 2759 | loss: 0.040850\n",
      "iteration: 2760 | loss: 0.138751\n",
      "iteration: 2761 | loss: 0.074252\n",
      "iteration: 2762 | loss: 0.151085\n",
      "iteration: 2763 | loss: 0.041233\n",
      "iteration: 2764 | loss: 0.077563\n",
      "iteration: 2765 | loss: 0.040649\n",
      "iteration: 2766 | loss: 0.068189\n",
      "iteration: 2767 | loss: 0.076176\n",
      "iteration: 2768 | loss: 0.119711\n",
      "iteration: 2769 | loss: 0.031385\n",
      "iteration: 2770 | loss: 0.059535\n",
      "iteration: 2771 | loss: 0.074006\n",
      "iteration: 2772 | loss: 0.152904\n",
      "iteration: 2773 | loss: 0.237188\n",
      "iteration: 2774 | loss: 0.226149\n",
      "  Train acc: 0.982, Val acc: 0.5\n",
      "iteration: 2775 | loss: 0.046502\n",
      "iteration: 2776 | loss: 0.069684\n",
      "iteration: 2777 | loss: 0.108221\n",
      "iteration: 2778 | loss: 0.150904\n",
      "iteration: 2779 | loss: 0.190140\n",
      "iteration: 2780 | loss: 0.076228\n",
      "iteration: 2781 | loss: 0.195960\n",
      "iteration: 2782 | loss: 0.105501\n",
      "iteration: 2783 | loss: 0.202738\n",
      "iteration: 2784 | loss: 0.031585\n",
      "iteration: 2785 | loss: 0.065175\n",
      "iteration: 2786 | loss: 0.046431\n",
      "iteration: 2787 | loss: 0.084165\n",
      "iteration: 2788 | loss: 0.096163\n",
      "iteration: 2789 | loss: 0.068064\n",
      "iteration: 2790 | loss: 0.121285\n",
      "iteration: 2791 | loss: 0.216802\n",
      "iteration: 2792 | loss: 0.112017\n",
      "iteration: 2793 | loss: 0.175699\n",
      "iteration: 2794 | loss: 0.319757\n",
      "iteration: 2795 | loss: 0.187803\n",
      "iteration: 2796 | loss: 0.062853\n",
      "iteration: 2797 | loss: 0.158184\n",
      "iteration: 2798 | loss: 0.102207\n",
      "iteration: 2799 | loss: 0.113963\n",
      "  Train acc: 0.954, Val acc: 0.5\n",
      "iteration: 2800 | loss: 0.195132\n",
      "iteration: 2801 | loss: 0.128015\n",
      "iteration: 2802 | loss: 0.145788\n",
      "iteration: 2803 | loss: 0.080651\n",
      "iteration: 2804 | loss: 0.296942\n",
      "iteration: 2805 | loss: 0.109771\n",
      "iteration: 2806 | loss: 0.175169\n",
      "iteration: 2807 | loss: 0.078891\n",
      "iteration: 2808 | loss: 0.104631\n",
      "iteration: 2809 | loss: 0.116450\n",
      "iteration: 2810 | loss: 0.186652\n",
      "iteration: 2811 | loss: 0.090768\n",
      "iteration: 2812 | loss: 0.036551\n",
      "iteration: 2813 | loss: 0.042821\n",
      "iteration: 2814 | loss: 0.035756\n",
      "iteration: 2815 | loss: 0.055361\n",
      "iteration: 2816 | loss: 0.047977\n",
      "iteration: 2817 | loss: 0.037622\n",
      "iteration: 2818 | loss: 0.053190\n",
      "iteration: 2819 | loss: 0.126769\n",
      "iteration: 2820 | loss: 0.144013\n",
      "iteration: 2821 | loss: 0.101164\n",
      "iteration: 2822 | loss: 0.080585\n",
      "iteration: 2823 | loss: 0.139643\n",
      "iteration: 2824 | loss: 0.080454\n",
      "  Train acc: 0.976, Val acc: 0.5\n",
      "iteration: 2825 | loss: 0.066275\n",
      "iteration: 2826 | loss: 0.108719\n",
      "iteration: 2827 | loss: 0.149719\n",
      "iteration: 2828 | loss: 0.163499\n",
      "iteration: 2829 | loss: 0.038411\n",
      "iteration: 2830 | loss: 0.090521\n",
      "iteration: 2831 | loss: 0.058057\n",
      "iteration: 2832 | loss: 0.153799\n",
      "iteration: 2833 | loss: 0.162994\n",
      "iteration: 2834 | loss: 0.040099\n",
      "iteration: 2835 | loss: 0.077042\n",
      "iteration: 2836 | loss: 0.159932\n",
      "iteration: 2837 | loss: 0.047690\n",
      "iteration: 2838 | loss: 0.051094\n",
      "iteration: 2839 | loss: 0.046291\n",
      "iteration: 2840 | loss: 0.015039\n",
      "iteration: 2841 | loss: 0.137148\n",
      "iteration: 2842 | loss: 0.169007\n",
      "iteration: 2843 | loss: 0.087985\n",
      "iteration: 2844 | loss: 0.043565\n",
      "iteration: 2845 | loss: 0.077176\n",
      "iteration: 2846 | loss: 0.175840\n",
      "iteration: 2847 | loss: 0.067281\n",
      "iteration: 2848 | loss: 0.108364\n",
      "iteration: 2849 | loss: 0.090582\n",
      "  Train acc: 0.97, Val acc: 0.5\n",
      "iteration: 2850 | loss: 0.124456\n",
      "iteration: 2851 | loss: 0.094781\n",
      "iteration: 2852 | loss: 0.183503\n",
      "iteration: 2853 | loss: 0.065262\n",
      "iteration: 2854 | loss: 0.126564\n",
      "iteration: 2855 | loss: 0.082447\n",
      "iteration: 2856 | loss: 0.036642\n",
      "iteration: 2857 | loss: 0.145038\n",
      "iteration: 2858 | loss: 0.041601\n",
      "iteration: 2859 | loss: 0.035385\n",
      "iteration: 2860 | loss: 0.058941\n",
      "iteration: 2861 | loss: 0.031181\n",
      "iteration: 2862 | loss: 0.206843\n",
      "iteration: 2863 | loss: 0.070784\n",
      "iteration: 2864 | loss: 0.106770\n",
      "iteration: 2865 | loss: 0.059228\n",
      "iteration: 2866 | loss: 0.225417\n",
      "iteration: 2867 | loss: 0.062841\n",
      "iteration: 2868 | loss: 0.040292\n",
      "iteration: 2869 | loss: 0.026831\n",
      "iteration: 2870 | loss: 0.060959\n",
      "iteration: 2871 | loss: 0.032553\n",
      "iteration: 2872 | loss: 0.066488\n",
      "iteration: 2873 | loss: 0.141615\n",
      "iteration: 2874 | loss: 0.041632\n",
      "  Train acc: 0.98, Val acc: 0.5\n",
      "iteration: 2875 | loss: 0.140894\n",
      "iteration: 2876 | loss: 0.085146\n",
      "iteration: 2877 | loss: 0.074668\n",
      "iteration: 2878 | loss: 0.048573\n",
      "iteration: 2879 | loss: 0.017339\n",
      "iteration: 2880 | loss: 0.098096\n",
      "iteration: 2881 | loss: 0.250549\n",
      "iteration: 2882 | loss: 0.131179\n",
      "iteration: 2883 | loss: 0.035787\n",
      "iteration: 2884 | loss: 0.071215\n",
      "iteration: 2885 | loss: 0.050947\n",
      "iteration: 2886 | loss: 0.051851\n",
      "iteration: 2887 | loss: 0.051375\n",
      "iteration: 2888 | loss: 0.059001\n",
      "iteration: 2889 | loss: 0.146550\n",
      "iteration: 2890 | loss: 0.049564\n",
      "iteration: 2891 | loss: 0.286131\n",
      "iteration: 2892 | loss: 0.045910\n",
      "iteration: 2893 | loss: 0.137778\n",
      "iteration: 2894 | loss: 0.070790\n",
      "iteration: 2895 | loss: 0.218049\n",
      "iteration: 2896 | loss: 0.100250\n",
      "iteration: 2897 | loss: 0.053694\n",
      "iteration: 2898 | loss: 0.141824\n",
      "iteration: 2899 | loss: 0.038331\n",
      "  Train acc: 0.964, Val acc: 0.5\n",
      "iteration: 2900 | loss: 0.078361\n",
      "iteration: 2901 | loss: 0.040977\n",
      "iteration: 2902 | loss: 0.082231\n",
      "iteration: 2903 | loss: 0.502774\n",
      "iteration: 2904 | loss: 0.017844\n",
      "iteration: 2905 | loss: 0.091156\n",
      "iteration: 2906 | loss: 0.253339\n",
      "iteration: 2907 | loss: 0.031134\n",
      "iteration: 2908 | loss: 0.074171\n",
      "iteration: 2909 | loss: 0.119878\n",
      "iteration: 2910 | loss: 0.209578\n",
      "iteration: 2911 | loss: 0.075282\n",
      "iteration: 2912 | loss: 0.082102\n",
      "iteration: 2913 | loss: 0.032284\n",
      "iteration: 2914 | loss: 0.036701\n",
      "iteration: 2915 | loss: 0.086690\n",
      "iteration: 2916 | loss: 0.099490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2917 | loss: 0.043233\n",
      "iteration: 2918 | loss: 0.020108\n",
      "iteration: 2919 | loss: 0.277487\n",
      "iteration: 2920 | loss: 0.083026\n",
      "iteration: 2921 | loss: 0.040415\n",
      "iteration: 2922 | loss: 0.024644\n",
      "iteration: 2923 | loss: 0.079921\n",
      "iteration: 2924 | loss: 0.191009\n",
      "  Train acc: 0.978, Val acc: 0.5\n",
      "iteration: 2925 | loss: 0.102817\n",
      "iteration: 2926 | loss: 0.084732\n",
      "iteration: 2927 | loss: 0.027122\n",
      "iteration: 2928 | loss: 0.073666\n",
      "iteration: 2929 | loss: 0.089737\n",
      "iteration: 2930 | loss: 0.176842\n",
      "iteration: 2931 | loss: 0.056042\n",
      "iteration: 2932 | loss: 0.017516\n",
      "iteration: 2933 | loss: 0.033381\n",
      "iteration: 2934 | loss: 0.053556\n",
      "iteration: 2935 | loss: 0.111774\n",
      "iteration: 2936 | loss: 0.034958\n",
      "iteration: 2937 | loss: 0.036744\n",
      "iteration: 2938 | loss: 0.461037\n",
      "iteration: 2939 | loss: 0.061845\n",
      "iteration: 2940 | loss: 0.040524\n",
      "iteration: 2941 | loss: 0.351189\n",
      "iteration: 2942 | loss: 0.054059\n",
      "iteration: 2943 | loss: 0.187084\n",
      "iteration: 2944 | loss: 0.076278\n",
      "iteration: 2945 | loss: 0.111412\n",
      "iteration: 2946 | loss: 0.091123\n",
      "iteration: 2947 | loss: 0.147945\n",
      "iteration: 2948 | loss: 0.062632\n",
      "iteration: 2949 | loss: 0.231647\n",
      "  Train acc: 0.974, Val acc: 0.5\n",
      "iteration: 2950 | loss: 0.023396\n",
      "iteration: 2951 | loss: 0.021213\n",
      "iteration: 2952 | loss: 0.100868\n",
      "iteration: 2953 | loss: 0.144156\n",
      "iteration: 2954 | loss: 0.090242\n",
      "iteration: 2955 | loss: 0.082154\n",
      "iteration: 2956 | loss: 0.018258\n",
      "iteration: 2957 | loss: 0.120322\n",
      "iteration: 2958 | loss: 0.064150\n",
      "iteration: 2959 | loss: 0.088445\n",
      "iteration: 2960 | loss: 0.045957\n",
      "iteration: 2961 | loss: 0.094735\n",
      "iteration: 2962 | loss: 0.051698\n",
      "iteration: 2963 | loss: 0.065633\n",
      "iteration: 2964 | loss: 0.251016\n",
      "iteration: 2965 | loss: 0.057436\n",
      "iteration: 2966 | loss: 0.073873\n",
      "iteration: 2967 | loss: 0.091239\n",
      "iteration: 2968 | loss: 0.051133\n",
      "iteration: 2969 | loss: 0.324532\n",
      "iteration: 2970 | loss: 0.070051\n",
      "iteration: 2971 | loss: 0.100965\n",
      "iteration: 2972 | loss: 0.073479\n",
      "iteration: 2973 | loss: 0.046974\n",
      "iteration: 2974 | loss: 0.108069\n",
      "  Train acc: 0.964, Val acc: 0.5\n",
      "iteration: 2975 | loss: 0.133853\n",
      "iteration: 2976 | loss: 0.118986\n",
      "iteration: 2977 | loss: 0.084472\n",
      "iteration: 2978 | loss: 0.035044\n",
      "iteration: 2979 | loss: 0.209575\n",
      "iteration: 2980 | loss: 0.085555\n",
      "iteration: 2981 | loss: 0.379737\n",
      "iteration: 2982 | loss: 0.060596\n",
      "iteration: 2983 | loss: 0.118233\n",
      "iteration: 2984 | loss: 0.070615\n",
      "iteration: 2985 | loss: 0.038255\n",
      "iteration: 2986 | loss: 0.206417\n",
      "iteration: 2987 | loss: 0.061385\n",
      "iteration: 2988 | loss: 0.087629\n",
      "iteration: 2989 | loss: 0.069218\n",
      "iteration: 2990 | loss: 0.137355\n",
      "iteration: 2991 | loss: 0.041281\n",
      "iteration: 2992 | loss: 0.068052\n",
      "iteration: 2993 | loss: 0.030083\n",
      "iteration: 2994 | loss: 0.196495\n",
      "iteration: 2995 | loss: 0.091067\n",
      "iteration: 2996 | loss: 0.067706\n",
      "iteration: 2997 | loss: 0.027067\n",
      "iteration: 2998 | loss: 0.038329\n",
      "iteration: 2999 | loss: 0.186812\n",
      "  Train acc: 0.988, Val acc: 0.5\n",
      "iteration: 3000 | loss: 0.026869\n",
      "iteration: 3001 | loss: 0.116609\n",
      "iteration: 3002 | loss: 0.055720\n",
      "iteration: 3003 | loss: 0.047752\n",
      "iteration: 3004 | loss: 0.103331\n",
      "iteration: 3005 | loss: 0.078751\n",
      "iteration: 3006 | loss: 0.074106\n",
      "iteration: 3007 | loss: 0.046469\n",
      "iteration: 3008 | loss: 0.054704\n",
      "iteration: 3009 | loss: 0.123213\n",
      "iteration: 3010 | loss: 0.181815\n",
      "iteration: 3011 | loss: 0.067583\n",
      "iteration: 3012 | loss: 0.215539\n",
      "iteration: 3013 | loss: 0.158059\n",
      "iteration: 3014 | loss: 0.083740\n",
      "iteration: 3015 | loss: 0.015626\n",
      "iteration: 3016 | loss: 0.031011\n",
      "iteration: 3017 | loss: 0.093482\n",
      "iteration: 3018 | loss: 0.057572\n",
      "iteration: 3019 | loss: 0.065358\n",
      "iteration: 3020 | loss: 0.059666\n",
      "iteration: 3021 | loss: 0.099937\n",
      "iteration: 3022 | loss: 0.035974\n",
      "iteration: 3023 | loss: 0.165469\n",
      "iteration: 3024 | loss: 0.204450\n",
      "  Train acc: 0.97, Val acc: 0.5\n",
      "iteration: 3025 | loss: 0.106472\n",
      "iteration: 3026 | loss: 0.060109\n",
      "iteration: 3027 | loss: 0.049855\n",
      "iteration: 3028 | loss: 0.055365\n",
      "iteration: 3029 | loss: 0.173917\n",
      "iteration: 3030 | loss: 0.086139\n",
      "iteration: 3031 | loss: 0.103319\n",
      "iteration: 3032 | loss: 0.375406\n",
      "iteration: 3033 | loss: 0.044663\n",
      "iteration: 3034 | loss: 0.075003\n",
      "iteration: 3035 | loss: 0.020034\n",
      "iteration: 3036 | loss: 0.106039\n",
      "iteration: 3037 | loss: 0.078367\n",
      "iteration: 3038 | loss: 0.090595\n",
      "iteration: 3039 | loss: 0.039260\n",
      "iteration: 3040 | loss: 0.134279\n",
      "iteration: 3041 | loss: 0.082774\n",
      "iteration: 3042 | loss: 0.067286\n",
      "iteration: 3043 | loss: 0.037514\n",
      "iteration: 3044 | loss: 0.070131\n",
      "iteration: 3045 | loss: 0.060014\n",
      "iteration: 3046 | loss: 0.125418\n",
      "iteration: 3047 | loss: 0.165690\n",
      "iteration: 3048 | loss: 0.239117\n",
      "iteration: 3049 | loss: 0.035914\n",
      "  Train acc: 0.972, Val acc: 0.5\n",
      "iteration: 3050 | loss: 0.090876\n",
      "iteration: 3051 | loss: 0.047870\n",
      "iteration: 3052 | loss: 0.061940\n",
      "iteration: 3053 | loss: 0.102792\n",
      "iteration: 3054 | loss: 0.184421\n",
      "iteration: 3055 | loss: 0.146688\n",
      "iteration: 3056 | loss: 0.197688\n",
      "iteration: 3057 | loss: 0.096945\n",
      "iteration: 3058 | loss: 0.083482\n",
      "iteration: 3059 | loss: 0.031687\n",
      "iteration: 3060 | loss: 0.041834\n",
      "iteration: 3061 | loss: 0.144602\n",
      "iteration: 3062 | loss: 0.023080\n",
      "iteration: 3063 | loss: 0.122756\n",
      "iteration: 3064 | loss: 0.051402\n",
      "iteration: 3065 | loss: 0.093022\n",
      "iteration: 3066 | loss: 0.060776\n",
      "iteration: 3067 | loss: 0.216801\n",
      "iteration: 3068 | loss: 0.036069\n",
      "iteration: 3069 | loss: 0.070017\n",
      "iteration: 3070 | loss: 0.296246\n",
      "iteration: 3071 | loss: 0.055669\n",
      "iteration: 3072 | loss: 0.160290\n",
      "iteration: 3073 | loss: 0.101707\n",
      "iteration: 3074 | loss: 0.047527\n",
      "  Train acc: 0.986, Val acc: 0.5\n",
      "iteration: 3075 | loss: 0.045697\n",
      "iteration: 3076 | loss: 0.058576\n",
      "iteration: 3077 | loss: 0.019786\n",
      "iteration: 3078 | loss: 0.133972\n",
      "iteration: 3079 | loss: 0.102052\n",
      "iteration: 3080 | loss: 0.049497\n",
      "iteration: 3081 | loss: 0.096171\n",
      "iteration: 3082 | loss: 0.088203\n",
      "iteration: 3083 | loss: 0.066974\n",
      "iteration: 3084 | loss: 0.213425\n",
      "iteration: 3085 | loss: 0.070554\n",
      "iteration: 3086 | loss: 0.027240\n",
      "iteration: 3087 | loss: 0.049648\n",
      "iteration: 3088 | loss: 0.102626\n",
      "iteration: 3089 | loss: 0.041034\n",
      "iteration: 3090 | loss: 0.044154\n",
      "iteration: 3091 | loss: 0.091671\n",
      "iteration: 3092 | loss: 0.037922\n",
      "iteration: 3093 | loss: 0.118454\n",
      "iteration: 3094 | loss: 0.082597\n",
      "iteration: 3095 | loss: 0.068789\n",
      "iteration: 3096 | loss: 0.075954\n",
      "iteration: 3097 | loss: 0.136136\n",
      "iteration: 3098 | loss: 0.095584\n",
      "iteration: 3099 | loss: 0.206714\n",
      "  Train acc: 0.98, Val acc: 0.5\n",
      "iteration: 3100 | loss: 0.071707\n",
      "iteration: 3101 | loss: 0.149008\n",
      "iteration: 3102 | loss: 0.148263\n",
      "iteration: 3103 | loss: 0.081802\n",
      "iteration: 3104 | loss: 0.046234\n",
      "iteration: 3105 | loss: 0.100629\n",
      "iteration: 3106 | loss: 0.023725\n",
      "iteration: 3107 | loss: 0.017651\n",
      "iteration: 3108 | loss: 0.060227\n",
      "iteration: 3109 | loss: 0.067944\n",
      "iteration: 3110 | loss: 0.026283\n",
      "iteration: 3111 | loss: 0.061817\n",
      "iteration: 3112 | loss: 0.061255\n",
      "iteration: 3113 | loss: 0.233794\n",
      "iteration: 3114 | loss: 0.081298\n",
      "iteration: 3115 | loss: 0.018387\n",
      "iteration: 3116 | loss: 0.022020\n",
      "iteration: 3117 | loss: 0.029861\n",
      "iteration: 3118 | loss: 0.050347\n",
      "iteration: 3119 | loss: 0.077293\n",
      "iteration: 3120 | loss: 0.098971\n",
      "iteration: 3121 | loss: 0.142200\n",
      "iteration: 3122 | loss: 0.049116\n",
      "iteration: 3123 | loss: 0.059164\n",
      "iteration: 3124 | loss: 0.019484\n",
      "  Train acc: 0.978, Val acc: 0.5\n",
      "iteration: 3125 | loss: 0.208046\n",
      "iteration: 3126 | loss: 0.240427\n",
      "iteration: 3127 | loss: 0.090026\n",
      "iteration: 3128 | loss: 0.027036\n",
      "iteration: 3129 | loss: 0.080100\n",
      "iteration: 3130 | loss: 0.047916\n",
      "iteration: 3131 | loss: 0.028376\n",
      "iteration: 3132 | loss: 0.116431\n",
      "iteration: 3133 | loss: 0.212606\n",
      "iteration: 3134 | loss: 0.076812\n",
      "iteration: 3135 | loss: 0.059403\n",
      "iteration: 3136 | loss: 0.062645\n",
      "iteration: 3137 | loss: 0.135717\n",
      "iteration: 3138 | loss: 0.170048\n",
      "iteration: 3139 | loss: 0.158049\n",
      "iteration: 3140 | loss: 0.045723\n",
      "iteration: 3141 | loss: 0.055457\n",
      "iteration: 3142 | loss: 0.027783\n",
      "iteration: 3143 | loss: 0.035476\n",
      "iteration: 3144 | loss: 0.034946\n",
      "iteration: 3145 | loss: 0.042834\n",
      "iteration: 3146 | loss: 0.029108\n",
      "iteration: 3147 | loss: 0.016784\n",
      "iteration: 3148 | loss: 0.011152\n",
      "iteration: 3149 | loss: 0.045604\n",
      "  Train acc: 0.974, Val acc: 0.5\n",
      "iteration: 3150 | loss: 0.051988\n",
      "iteration: 3151 | loss: 0.074286\n",
      "iteration: 3152 | loss: 0.079080\n",
      "iteration: 3153 | loss: 0.086709\n",
      "iteration: 3154 | loss: 0.044611\n",
      "iteration: 3155 | loss: 0.142555\n",
      "iteration: 3156 | loss: 0.103269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3157 | loss: 0.038702\n",
      "iteration: 3158 | loss: 0.037870\n",
      "iteration: 3159 | loss: 0.101570\n",
      "iteration: 3160 | loss: 0.022615\n",
      "iteration: 3161 | loss: 0.017135\n",
      "iteration: 3162 | loss: 0.033482\n",
      "iteration: 3163 | loss: 0.138018\n",
      "iteration: 3164 | loss: 0.173376\n",
      "iteration: 3165 | loss: 0.187812\n",
      "iteration: 3166 | loss: 0.023182\n",
      "iteration: 3167 | loss: 0.048924\n",
      "iteration: 3168 | loss: 0.036977\n",
      "iteration: 3169 | loss: 0.058997\n",
      "iteration: 3170 | loss: 0.129533\n",
      "iteration: 3171 | loss: 0.077655\n",
      "iteration: 3172 | loss: 0.119673\n",
      "iteration: 3173 | loss: 0.203933\n",
      "iteration: 3174 | loss: 0.046898\n",
      "  Train acc: 0.98, Val acc: 0.5\n",
      "iteration: 3175 | loss: 0.081082\n",
      "iteration: 3176 | loss: 0.087581\n",
      "iteration: 3177 | loss: 0.080584\n",
      "iteration: 3178 | loss: 0.026317\n",
      "iteration: 3179 | loss: 0.063540\n",
      "iteration: 3180 | loss: 0.043881\n",
      "iteration: 3181 | loss: 0.090470\n",
      "iteration: 3182 | loss: 0.080238\n",
      "iteration: 3183 | loss: 0.026957\n",
      "iteration: 3184 | loss: 0.074032\n",
      "iteration: 3185 | loss: 0.098613\n",
      "iteration: 3186 | loss: 0.022388\n",
      "iteration: 3187 | loss: 0.146340\n",
      "iteration: 3188 | loss: 0.060780\n",
      "iteration: 3189 | loss: 0.022407\n",
      "iteration: 3190 | loss: 0.172929\n",
      "iteration: 3191 | loss: 0.096994\n",
      "iteration: 3192 | loss: 0.140358\n",
      "iteration: 3193 | loss: 0.032912\n",
      "iteration: 3194 | loss: 0.080883\n",
      "iteration: 3195 | loss: 0.063430\n",
      "iteration: 3196 | loss: 0.062054\n",
      "iteration: 3197 | loss: 0.107765\n",
      "iteration: 3198 | loss: 0.142641\n",
      "iteration: 3199 | loss: 0.119849\n",
      "  Train acc: 0.958, Val acc: 0.5\n",
      "iteration: 3200 | loss: 0.027678\n",
      "iteration: 3201 | loss: 0.020154\n",
      "iteration: 3202 | loss: 0.118281\n",
      "iteration: 3203 | loss: 0.028885\n",
      "iteration: 3204 | loss: 0.146072\n",
      "iteration: 3205 | loss: 0.065196\n",
      "iteration: 3206 | loss: 0.053784\n",
      "iteration: 3207 | loss: 0.040953\n",
      "iteration: 3208 | loss: 0.635940\n",
      "iteration: 3209 | loss: 0.215591\n",
      "iteration: 3210 | loss: 0.051650\n",
      "iteration: 3211 | loss: 0.029111\n",
      "iteration: 3212 | loss: 0.057895\n",
      "iteration: 3213 | loss: 0.054282\n",
      "iteration: 3214 | loss: 0.067158\n",
      "iteration: 3215 | loss: 0.042986\n",
      "iteration: 3216 | loss: 0.049794\n",
      "iteration: 3217 | loss: 0.492710\n",
      "iteration: 3218 | loss: 0.050916\n",
      "iteration: 3219 | loss: 0.043992\n",
      "iteration: 3220 | loss: 0.150416\n",
      "iteration: 3221 | loss: 0.030526\n",
      "iteration: 3222 | loss: 0.020330\n",
      "iteration: 3223 | loss: 0.085777\n",
      "iteration: 3224 | loss: 0.063420\n",
      "  Train acc: 0.984, Val acc: 0.5\n",
      "iteration: 3225 | loss: 0.079523\n",
      "iteration: 3226 | loss: 0.066820\n",
      "iteration: 3227 | loss: 0.079401\n",
      "iteration: 3228 | loss: 0.053354\n",
      "iteration: 3229 | loss: 0.075366\n",
      "iteration: 3230 | loss: 0.117547\n",
      "iteration: 3231 | loss: 0.050272\n",
      "iteration: 3232 | loss: 0.031226\n",
      "iteration: 3233 | loss: 0.050241\n",
      "iteration: 3234 | loss: 0.040686\n",
      "iteration: 3235 | loss: 0.126971\n",
      "iteration: 3236 | loss: 0.062816\n",
      "iteration: 3237 | loss: 0.038468\n",
      "iteration: 3238 | loss: 0.071949\n",
      "iteration: 3239 | loss: 0.036186\n",
      "iteration: 3240 | loss: 0.030182\n",
      "iteration: 3241 | loss: 0.040728\n",
      "iteration: 3242 | loss: 0.026728\n",
      "iteration: 3243 | loss: 0.018973\n",
      "iteration: 3244 | loss: 0.044123\n",
      "iteration: 3245 | loss: 0.033148\n",
      "iteration: 3246 | loss: 0.054301\n",
      "iteration: 3247 | loss: 0.075363\n",
      "iteration: 3248 | loss: 0.018676\n",
      "iteration: 3249 | loss: 0.017523\n",
      "  Train acc: 0.992, Val acc: 0.5\n",
      "iteration: 3250 | loss: 0.045708\n",
      "iteration: 3251 | loss: 0.085609\n",
      "iteration: 3252 | loss: 0.017527\n",
      "iteration: 3253 | loss: 0.049038\n",
      "iteration: 3254 | loss: 0.022471\n",
      "iteration: 3255 | loss: 0.050132\n",
      "iteration: 3256 | loss: 0.043349\n",
      "iteration: 3257 | loss: 0.083311\n",
      "iteration: 3258 | loss: 0.107868\n",
      "iteration: 3259 | loss: 0.026466\n",
      "iteration: 3260 | loss: 0.083345\n",
      "iteration: 3261 | loss: 0.015024\n",
      "iteration: 3262 | loss: 0.061957\n",
      "iteration: 3263 | loss: 0.037170\n",
      "iteration: 3264 | loss: 0.030261\n",
      "iteration: 3265 | loss: 0.080689\n",
      "iteration: 3266 | loss: 0.044081\n",
      "iteration: 3267 | loss: 0.283720\n",
      "iteration: 3268 | loss: 0.043292\n",
      "iteration: 3269 | loss: 0.026158\n",
      "iteration: 3270 | loss: 0.037605\n",
      "iteration: 3271 | loss: 0.045285\n",
      "iteration: 3272 | loss: 0.093111\n",
      "iteration: 3273 | loss: 0.101573\n",
      "iteration: 3274 | loss: 0.078906\n",
      "  Train acc: 0.978, Val acc: 0.5\n",
      "iteration: 3275 | loss: 0.209099\n",
      "iteration: 3276 | loss: 0.131306\n",
      "iteration: 3277 | loss: 0.052477\n",
      "iteration: 3278 | loss: 0.074198\n",
      "iteration: 3279 | loss: 0.046256\n",
      "iteration: 3280 | loss: 0.092231\n",
      "iteration: 3281 | loss: 0.049552\n",
      "iteration: 3282 | loss: 0.157341\n",
      "iteration: 3283 | loss: 0.021244\n",
      "iteration: 3284 | loss: 0.036034\n",
      "iteration: 3285 | loss: 0.083670\n",
      "iteration: 3286 | loss: 0.035984\n",
      "iteration: 3287 | loss: 0.033699\n",
      "iteration: 3288 | loss: 0.097851\n",
      "iteration: 3289 | loss: 0.084529\n",
      "iteration: 3290 | loss: 0.058512\n",
      "iteration: 3291 | loss: 0.013241\n",
      "iteration: 3292 | loss: 0.025012\n",
      "iteration: 3293 | loss: 0.036976\n",
      "iteration: 3294 | loss: 0.037141\n",
      "iteration: 3295 | loss: 0.044079\n",
      "iteration: 3296 | loss: 0.086207\n",
      "iteration: 3297 | loss: 0.021691\n",
      "iteration: 3298 | loss: 0.098501\n",
      "iteration: 3299 | loss: 0.015140\n",
      "  Train acc: 0.996, Val acc: 0.5\n",
      "iteration: 3300 | loss: 0.117385\n",
      "iteration: 3301 | loss: 0.018975\n",
      "iteration: 3302 | loss: 0.022473\n",
      "iteration: 3303 | loss: 0.027607\n",
      "iteration: 3304 | loss: 0.066354\n",
      "iteration: 3305 | loss: 0.112427\n",
      "iteration: 3306 | loss: 0.015564\n",
      "iteration: 3307 | loss: 0.070381\n",
      "iteration: 3308 | loss: 0.035891\n",
      "iteration: 3309 | loss: 0.106645\n",
      "iteration: 3310 | loss: 0.041379\n",
      "iteration: 3311 | loss: 0.042230\n",
      "iteration: 3312 | loss: 0.040876\n",
      "iteration: 3313 | loss: 0.059077\n",
      "iteration: 3314 | loss: 0.065759\n",
      "iteration: 3315 | loss: 0.008526\n",
      "iteration: 3316 | loss: 0.045264\n",
      "iteration: 3317 | loss: 0.003709\n",
      "iteration: 3318 | loss: 0.352785\n",
      "iteration: 3319 | loss: 0.058115\n",
      "iteration: 3320 | loss: 0.023560\n",
      "iteration: 3321 | loss: 0.046491\n",
      "iteration: 3322 | loss: 0.026877\n",
      "iteration: 3323 | loss: 0.060010\n",
      "iteration: 3324 | loss: 0.043225\n",
      "  Train acc: 0.99, Val acc: 0.5\n",
      "iteration: 3325 | loss: 0.103196\n",
      "iteration: 3326 | loss: 0.038604\n",
      "iteration: 3327 | loss: 0.030381\n",
      "iteration: 3328 | loss: 0.032395\n",
      "iteration: 3329 | loss: 0.017605\n",
      "iteration: 3330 | loss: 0.124122\n",
      "iteration: 3331 | loss: 0.126214\n",
      "iteration: 3332 | loss: 0.016472\n",
      "iteration: 3333 | loss: 0.041089\n",
      "iteration: 3334 | loss: 0.145772\n",
      "iteration: 3335 | loss: 0.164324\n",
      "iteration: 3336 | loss: 0.023486\n",
      "iteration: 3337 | loss: 0.054854\n",
      "iteration: 3338 | loss: 0.044529\n",
      "iteration: 3339 | loss: 0.050231\n",
      "iteration: 3340 | loss: 0.024619\n",
      "iteration: 3341 | loss: 0.029639\n",
      "iteration: 3342 | loss: 0.016563\n",
      "iteration: 3343 | loss: 0.207230\n",
      "iteration: 3344 | loss: 0.037646\n",
      "iteration: 3345 | loss: 0.017807\n",
      "iteration: 3346 | loss: 0.004665\n",
      "iteration: 3347 | loss: 0.042820\n",
      "iteration: 3348 | loss: 0.046005\n",
      "iteration: 3349 | loss: 0.012397\n",
      "  Train acc: 0.99, Val acc: 0.5\n",
      "iteration: 3350 | loss: 0.023287\n",
      "iteration: 3351 | loss: 0.051138\n",
      "iteration: 3352 | loss: 0.049365\n",
      "iteration: 3353 | loss: 0.015991\n",
      "iteration: 3354 | loss: 0.064854\n",
      "iteration: 3355 | loss: 0.011766\n",
      "iteration: 3356 | loss: 0.191027\n",
      "iteration: 3357 | loss: 0.012449\n",
      "iteration: 3358 | loss: 0.045465\n",
      "iteration: 3359 | loss: 0.037802\n",
      "iteration: 3360 | loss: 0.026352\n",
      "iteration: 3361 | loss: 0.198586\n",
      "iteration: 3362 | loss: 0.128840\n",
      "iteration: 3363 | loss: 0.015125\n",
      "iteration: 3364 | loss: 0.007477\n",
      "iteration: 3365 | loss: 0.011124\n",
      "iteration: 3366 | loss: 0.092407\n",
      "iteration: 3367 | loss: 0.010096\n",
      "iteration: 3368 | loss: 0.056889\n",
      "iteration: 3369 | loss: 0.051174\n",
      "iteration: 3370 | loss: 0.072933\n",
      "iteration: 3371 | loss: 0.143445\n",
      "iteration: 3372 | loss: 0.034955\n",
      "iteration: 3373 | loss: 0.050472\n",
      "iteration: 3374 | loss: 0.030072\n",
      "  Train acc: 0.97, Val acc: 0.5\n",
      "iteration: 3375 | loss: 0.045464\n",
      "iteration: 3376 | loss: 0.031060\n",
      "iteration: 3377 | loss: 0.179530\n",
      "iteration: 3378 | loss: 0.016149\n",
      "iteration: 3379 | loss: 0.049251\n",
      "iteration: 3380 | loss: 0.031235\n",
      "iteration: 3381 | loss: 0.019324\n",
      "iteration: 3382 | loss: 0.028689\n",
      "iteration: 3383 | loss: 0.104593\n",
      "iteration: 3384 | loss: 0.093180\n",
      "iteration: 3385 | loss: 0.021288\n",
      "iteration: 3386 | loss: 0.026527\n",
      "iteration: 3387 | loss: 0.133856\n",
      "iteration: 3388 | loss: 0.048603\n",
      "iteration: 3389 | loss: 0.037811\n",
      "iteration: 3390 | loss: 0.076903\n",
      "iteration: 3391 | loss: 0.063348\n",
      "iteration: 3392 | loss: 0.053002\n",
      "iteration: 3393 | loss: 0.050403\n",
      "iteration: 3394 | loss: 0.224916\n",
      "iteration: 3395 | loss: 0.030614\n",
      "iteration: 3396 | loss: 0.066479\n",
      "iteration: 3397 | loss: 0.039728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3398 | loss: 0.031131\n",
      "iteration: 3399 | loss: 0.025458\n",
      "  Train acc: 0.994, Val acc: 0.5\n",
      "iteration: 3400 | loss: 0.011835\n",
      "iteration: 3401 | loss: 0.032634\n",
      "iteration: 3402 | loss: 0.082772\n",
      "iteration: 3403 | loss: 0.058779\n",
      "iteration: 3404 | loss: 0.058903\n",
      "iteration: 3405 | loss: 0.040285\n",
      "iteration: 3406 | loss: 0.032081\n",
      "iteration: 3407 | loss: 0.035411\n",
      "iteration: 3408 | loss: 0.031825\n",
      "iteration: 3409 | loss: 0.093168\n",
      "iteration: 3410 | loss: 0.094908\n",
      "iteration: 3411 | loss: 0.035852\n",
      "iteration: 3412 | loss: 0.106571\n",
      "iteration: 3413 | loss: 0.032616\n",
      "iteration: 3414 | loss: 0.034714\n",
      "iteration: 3415 | loss: 0.009226\n",
      "iteration: 3416 | loss: 0.020204\n",
      "iteration: 3417 | loss: 0.029563\n",
      "iteration: 3418 | loss: 0.005911\n",
      "iteration: 3419 | loss: 0.113010\n",
      "iteration: 3420 | loss: 0.045796\n",
      "iteration: 3421 | loss: 0.026855\n",
      "iteration: 3422 | loss: 0.042362\n",
      "iteration: 3423 | loss: 0.119643\n",
      "iteration: 3424 | loss: 0.038923\n",
      "  Train acc: 0.992, Val acc: 0.5\n",
      "iteration: 3425 | loss: 0.028875\n",
      "iteration: 3426 | loss: 0.005733\n",
      "iteration: 3427 | loss: 0.049989\n",
      "iteration: 3428 | loss: 0.018938\n",
      "iteration: 3429 | loss: 0.016706\n",
      "iteration: 3430 | loss: 0.013857\n",
      "iteration: 3431 | loss: 0.031902\n",
      "iteration: 3432 | loss: 0.014806\n",
      "iteration: 3433 | loss: 0.053907\n",
      "iteration: 3434 | loss: 0.009033\n",
      "iteration: 3435 | loss: 0.039571\n",
      "iteration: 3436 | loss: 0.031313\n",
      "iteration: 3437 | loss: 0.028807\n",
      "iteration: 3438 | loss: 0.007133\n",
      "iteration: 3439 | loss: 0.011983\n",
      "iteration: 3440 | loss: 0.039539\n",
      "iteration: 3441 | loss: 0.037012\n",
      "iteration: 3442 | loss: 0.007450\n",
      "iteration: 3443 | loss: 0.014229\n",
      "iteration: 3444 | loss: 0.017203\n",
      "iteration: 3445 | loss: 0.035211\n",
      "iteration: 3446 | loss: 0.032122\n",
      "iteration: 3447 | loss: 0.013470\n",
      "iteration: 3448 | loss: 0.032787\n",
      "iteration: 3449 | loss: 0.096735\n",
      "  Train acc: 0.994, Val acc: 0.5\n",
      "iteration: 3450 | loss: 0.044803\n",
      "iteration: 3451 | loss: 0.009107\n",
      "iteration: 3452 | loss: 0.036931\n",
      "iteration: 3453 | loss: 0.013854\n",
      "iteration: 3454 | loss: 0.028341\n",
      "iteration: 3455 | loss: 0.008257\n",
      "iteration: 3456 | loss: 0.008802\n",
      "iteration: 3457 | loss: 0.042587\n",
      "iteration: 3458 | loss: 0.009386\n",
      "iteration: 3459 | loss: 0.031351\n",
      "iteration: 3460 | loss: 0.008695\n",
      "iteration: 3461 | loss: 0.028998\n",
      "iteration: 3462 | loss: 0.009179\n",
      "iteration: 3463 | loss: 0.006722\n",
      "iteration: 3464 | loss: 0.021125\n",
      "iteration: 3465 | loss: 0.040214\n",
      "iteration: 3466 | loss: 0.048238\n",
      "iteration: 3467 | loss: 0.028342\n",
      "iteration: 3468 | loss: 0.017750\n",
      "iteration: 3469 | loss: 0.014037\n",
      "iteration: 3470 | loss: 0.033605\n",
      "iteration: 3471 | loss: 0.032864\n",
      "iteration: 3472 | loss: 0.010116\n",
      "iteration: 3473 | loss: 0.009831\n",
      "iteration: 3474 | loss: 0.038762\n",
      "  Train acc: 0.984, Val acc: 0.5\n",
      "iteration: 3475 | loss: 0.013147\n",
      "iteration: 3476 | loss: 0.020174\n",
      "iteration: 3477 | loss: 0.020033\n",
      "iteration: 3478 | loss: 0.042550\n",
      "iteration: 3479 | loss: 0.011189\n",
      "iteration: 3480 | loss: 0.031579\n",
      "iteration: 3481 | loss: 0.018651\n",
      "iteration: 3482 | loss: 0.029593\n",
      "iteration: 3483 | loss: 0.023608\n",
      "iteration: 3484 | loss: 0.009980\n",
      "iteration: 3485 | loss: 0.025481\n",
      "iteration: 3486 | loss: 0.009744\n",
      "iteration: 3487 | loss: 0.031838\n",
      "iteration: 3488 | loss: 0.037918\n",
      "iteration: 3489 | loss: 0.022568\n",
      "iteration: 3490 | loss: 0.391041\n",
      "iteration: 3491 | loss: 0.011749\n",
      "iteration: 3492 | loss: 0.008271\n",
      "iteration: 3493 | loss: 0.025344\n",
      "iteration: 3494 | loss: 0.027306\n",
      "iteration: 3495 | loss: 0.068659\n",
      "iteration: 3496 | loss: 0.023911\n",
      "iteration: 3497 | loss: 0.032619\n",
      "iteration: 3498 | loss: 0.250682\n",
      "iteration: 3499 | loss: 0.026748\n",
      "  Train acc: 0.988, Val acc: 0.5\n",
      "iteration: 3500 | loss: 0.017656\n",
      "iteration: 3501 | loss: 0.178975\n",
      "iteration: 3502 | loss: 0.018084\n",
      "iteration: 3503 | loss: 0.061699\n",
      "iteration: 3504 | loss: 0.022068\n",
      "iteration: 3505 | loss: 0.011435\n",
      "iteration: 3506 | loss: 0.024945\n",
      "iteration: 3507 | loss: 0.018150\n",
      "iteration: 3508 | loss: 0.027477\n",
      "iteration: 3509 | loss: 0.142295\n",
      "iteration: 3510 | loss: 0.071162\n",
      "iteration: 3511 | loss: 0.007351\n",
      "iteration: 3512 | loss: 0.046651\n",
      "iteration: 3513 | loss: 0.030815\n",
      "iteration: 3514 | loss: 0.042855\n",
      "iteration: 3515 | loss: 0.129503\n",
      "iteration: 3516 | loss: 0.014578\n",
      "iteration: 3517 | loss: 0.029750\n",
      "iteration: 3518 | loss: 0.021026\n",
      "iteration: 3519 | loss: 0.014576\n",
      "iteration: 3520 | loss: 0.036859\n",
      "iteration: 3521 | loss: 0.026485\n",
      "iteration: 3522 | loss: 0.096256\n",
      "iteration: 3523 | loss: 0.116662\n",
      "iteration: 3524 | loss: 0.073480\n",
      "  Train acc: 0.992, Val acc: 0.5\n",
      "iteration: 3525 | loss: 0.022992\n",
      "iteration: 3526 | loss: 0.026611\n",
      "iteration: 3527 | loss: 0.048487\n",
      "iteration: 3528 | loss: 0.019476\n",
      "iteration: 3529 | loss: 0.109277\n",
      "iteration: 3530 | loss: 0.016802\n",
      "iteration: 3531 | loss: 0.027230\n",
      "iteration: 3532 | loss: 0.010796\n",
      "iteration: 3533 | loss: 0.024049\n",
      "iteration: 3534 | loss: 0.043170\n",
      "iteration: 3535 | loss: 0.009704\n",
      "iteration: 3536 | loss: 0.027436\n",
      "iteration: 3537 | loss: 0.021344\n",
      "iteration: 3538 | loss: 0.076702\n",
      "iteration: 3539 | loss: 0.011932\n",
      "iteration: 3540 | loss: 0.048785\n",
      "iteration: 3541 | loss: 0.088447\n",
      "iteration: 3542 | loss: 0.110396\n",
      "iteration: 3543 | loss: 0.153673\n",
      "iteration: 3544 | loss: 0.027236\n",
      "iteration: 3545 | loss: 0.065544\n",
      "iteration: 3546 | loss: 0.023209\n",
      "iteration: 3547 | loss: 0.017938\n",
      "iteration: 3548 | loss: 0.011963\n",
      "iteration: 3549 | loss: 0.081848\n",
      "  Train acc: 0.984, Val acc: 0.5\n",
      "iteration: 3550 | loss: 0.011717\n",
      "iteration: 3551 | loss: 0.054847\n",
      "iteration: 3552 | loss: 0.024753\n",
      "iteration: 3553 | loss: 0.014795\n",
      "iteration: 3554 | loss: 0.019029\n",
      "iteration: 3555 | loss: 0.021633\n",
      "iteration: 3556 | loss: 0.017227\n",
      "iteration: 3557 | loss: 0.056423\n",
      "iteration: 3558 | loss: 0.018364\n",
      "iteration: 3559 | loss: 0.045166\n",
      "iteration: 3560 | loss: 0.013599\n",
      "iteration: 3561 | loss: 0.034073\n",
      "iteration: 3562 | loss: 0.057608\n",
      "iteration: 3563 | loss: 0.059796\n",
      "iteration: 3564 | loss: 0.017993\n",
      "iteration: 3565 | loss: 0.022087\n",
      "iteration: 3566 | loss: 0.062784\n",
      "iteration: 3567 | loss: 0.032755\n",
      "iteration: 3568 | loss: 0.028942\n",
      "iteration: 3569 | loss: 0.035151\n",
      "iteration: 3570 | loss: 0.077992\n",
      "iteration: 3571 | loss: 0.018763\n",
      "iteration: 3572 | loss: 0.126417\n",
      "iteration: 3573 | loss: 0.005363\n",
      "iteration: 3574 | loss: 0.052869\n",
      "  Train acc: 0.986, Val acc: 0.5\n",
      "iteration: 3575 | loss: 0.039360\n",
      "iteration: 3576 | loss: 0.016250\n",
      "iteration: 3577 | loss: 0.037502\n",
      "iteration: 3578 | loss: 0.034959\n",
      "iteration: 3579 | loss: 0.123459\n",
      "iteration: 3580 | loss: 0.039583\n",
      "iteration: 3581 | loss: 0.060786\n",
      "iteration: 3582 | loss: 0.019064\n",
      "iteration: 3583 | loss: 0.031250\n",
      "iteration: 3584 | loss: 0.056188\n",
      "iteration: 3585 | loss: 0.033645\n",
      "iteration: 3586 | loss: 0.017095\n",
      "iteration: 3587 | loss: 0.010730\n",
      "iteration: 3588 | loss: 0.058250\n",
      "iteration: 3589 | loss: 0.209252\n",
      "iteration: 3590 | loss: 0.080747\n",
      "iteration: 3591 | loss: 0.030096\n",
      "iteration: 3592 | loss: 0.051712\n",
      "iteration: 3593 | loss: 0.070540\n",
      "iteration: 3594 | loss: 0.014241\n",
      "iteration: 3595 | loss: 0.017433\n",
      "iteration: 3596 | loss: 0.028128\n",
      "iteration: 3597 | loss: 0.088219\n",
      "iteration: 3598 | loss: 0.033388\n",
      "iteration: 3599 | loss: 0.062346\n",
      "  Train acc: 0.982, Val acc: 0.5\n",
      "iteration: 3600 | loss: 0.040289\n",
      "iteration: 3601 | loss: 0.011977\n",
      "iteration: 3602 | loss: 0.086038\n",
      "iteration: 3603 | loss: 0.055700\n",
      "iteration: 3604 | loss: 0.030026\n",
      "iteration: 3605 | loss: 0.089579\n",
      "iteration: 3606 | loss: 0.011332\n",
      "iteration: 3607 | loss: 0.034971\n",
      "iteration: 3608 | loss: 0.139832\n",
      "iteration: 3609 | loss: 0.093754\n",
      "iteration: 3610 | loss: 0.015176\n",
      "iteration: 3611 | loss: 0.047602\n",
      "iteration: 3612 | loss: 0.053128\n",
      "iteration: 3613 | loss: 0.016629\n",
      "iteration: 3614 | loss: 0.031415\n",
      "iteration: 3615 | loss: 0.044697\n",
      "iteration: 3616 | loss: 0.042471\n",
      "iteration: 3617 | loss: 0.056963\n",
      "iteration: 3618 | loss: 0.028936\n",
      "iteration: 3619 | loss: 0.058038\n"
     ]
    }
   ],
   "source": [
    "from network import convNet4Accel\n",
    "\n",
    "# Adam\n",
    "adam_net_accel = convNet4Accel(input_shape=(3, 32, 32), wt_scale=1e-2, verbose=False)\n",
    "adam_net_accel.compile(\"Adam\")\n",
    "\n",
    "adam_net_accel.fit(x_train, y_train, x_val, y_val, mini_batch_sz=25, n_epochs=20, acc_freq=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5175"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam_net_accel.accuracy(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7d) Analysis of STL-10 training quality\n",
    "\n",
    "Use your trained network that achieves 45%+ accuracy on the test set to make \"high quality\" plots showing the following \n",
    "\n",
    "- Plot the accuracy of the training and validation sets as a function of training epoch. You may have to convert iterations to epochs.\n",
    "- Plot the loss as a function of training iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(adam_net_accel.validation_acc_history, label='Train')\n",
    "\n",
    "\n",
    "plt.plot(adam_net_accel.train_acc_history, label='Test')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Train Accuracy vs Validation Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEtCAYAAAAFsGeyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd1xT5/4H8E/CFAFBGQqCoJg4EBXcE3DjqFpXVZy1WK/WVq21v169bfVae22rgrXW0dq666hWWxcqKIobceJCEGTKniEh5/cHJCZkh0BC8n2/Xn3VnPOcc54c4HzPs1kMwzAghBBistj6zgAhhBD9okBACCEmjgIBIYSYOAoEhBBi4igQEEKIiaNAQAghJo4CQQNx/fp1cLlccLlcfWel3pSVlWHPnj2YM2cO+vfvD19fXwQEBGDChAmIiIhAVlaWvrNYK6GhoeByuYiIiJC7/8WLF/WcI829evUKfD5fapvoe+3Zs0dPuSKaokBADNLly5cxdOhQrF69GleuXAEAcLlc2NnZ4cGDB9i8eTOGDBmCQ4cO6TmnupeUlIRZs2Zh06ZN+s6KQnw+Hxs3bsTIkSNRUVGh7+yQWjLXdwYIqemff/7Bp59+CoFAgIEDB+KTTz5B+/btxfvT0tKwY8cO7N27F//+97+RnJyMZcuW6THHunXixAnExsZi2LBh+s6KQpmZmfjpp5/k7vv2229RVlYGZ2fnes4V0RaVCIhBSUxMxBdffAGBQID3338f27ZtkwoCAODm5oZVq1bhm2++AQBs374dly5d0kd2iRxubm5o06YN7O3t9Z0VoiYKBMSgREREoLS0FAEBASrf8sePH4933nkHAPCf//wHAoGgPrJIiNGhQGACCgsLERERgdGjR6Nz587o2rUrxo8fjx07dqC8vFzuMefOncP777+PoKAg+Pr6ol+/fliwYAFiYmJ0kl6e3NxcnDlzBgAwZ84csFgslccsWrQIQFV1UXR0NABg06ZN4HK5mD9/vsLjPvvsM3C5XKxfv15qe0pKClatWoXg4GD4+vqiZ8+eCAsLQ2xsrMw5UlNTweVyMWrUKDx//hyTJ09Gp06d0K9fP60bSrlcLjZv3gwAOHPmDLhcLkJDQ6XSFBcXY/PmzeKfp7+/P6ZMmYI//vgDlZWVMucMDg4Gl8vFq1ev8Mknn6BLly7o3r07li9fLnXObdu2YcqUKejZsyc6duyIHj16YPr06Th06BCEQqE47YoVKzBo0CDxZ39/f3C5XKSmpgJQ3lj88OFDLF26VNz436tXL8yfPx9Xr16VSSt5fwUCAbZv345Ro0bBz88PPXv2xIIFC3D//n2591EXv4+mhAKBkUtKSsI777yDzZs348WLF/Dy8kLLli3x6NEjrF+/HpMmTUJ2drbUMdu2bcPChQtx+fJlsNlscLlcCIVCnD9/HnPnzpX5A9c0vSK3bt1CZWUl2Gw2evfurdYxHh4e4HA4ACCuHho7diwAICYmBgUFBTLH8Hg8REZGAoC4RAFUNVCPGTMGBw8eRG5uLtq2bQtra2tERUVh1qxZ4gd0TUVFRZg7dy6ePn0KHx8fFBUVoU2bNmrlvyZ/f3+0aNECAODg4AB/f3/x9wOqHo7jx49HREQEEhMT0bJlS7i6uiIuLg4rV65EWFiYwsbbTz/9FGfOnIGXlxfMzMzg5uYGoCqIjh07Ft9//z0ePnwIJycntG3bFpWVlbh58yb+/e9/48svvxSfx8vLC76+vuLPXbt2hb+/P6ysrJR+t71792LixIk4efIkeDwe2rVrB3Nzc1y8eBGzZ8/G//73P7nHCQQChIWF4bvvvkNeXh7atGmD0tJSnD9/HlOnTsXdu3el0uvq99GkMKRBuHbtGsPhcBgOh6P2MRUVFcywYcMYDofDTJ8+nUlPTxfvS0xMZEaPHs1wOBxm6tSp4u15eXlMx44dmU6dOjE3btwQbxcIBMxPP/3EcDgcpkuXLkxpaalW6ZXZtGkTw+FwmMGDB6v9HRmGYT799FOGw+Ew7733nnjbpEmTGA6Hw/zxxx8y6U+dOsVwOBxmzJgx4m0pKSmMv78/w+FwmI0bNzI8Hk+8LzIyUrzv3LlzUseIfiZDhw5l3rx5I74nQqFQZb6nT5/OcDgcJjw8XGp7eHg4w+FwmEWLFkltFwgEzNixYxkOh8PMnz+fyc7OFu979uwZM2LECIbD4TBr1qyROi4oKIjhcDiMr68vc+fOHYZhqn43ioqKGIZhmIULFzIcDoeZNm0ak5OTIz6Ox+Mx69atYzgcDsPlcpmsrCy53724uFju99q9e7d427Vr1xgul8twuVxm69atDJ/PZxiGYYRCIfPnn38yvr6+Mj8vyWt06dKF+fvvv8X7MjMzmZCQEIbD4TDz5s0Tb9fl76MpoRKBEfv777/x8uVLODk5YcuWLWjevLl4n7e3N7Zt2wYbGxvcunVLXK2SlJQEPp8Pb29vdO/eXZzezMwM8+fPx5AhQzB8+HDk5+drlV4ZUZomTZpo9D2bNWsGoKpqSWTMmDEAqnog1fT3338DkC4N7Ny5E8XFxRg7diwWL14MS0tL8b5BgwZh6dKlAKCwVDBnzhxxPhwcHNSq1tLU2bNn8ejRI3h5eWHjxo1wcnIS7/Px8cHGjRvBZrOxf/9+5OTkyBw/dOhQdO3aFQBgYWEBW1tb8Hg8xMfHg8Vi4auvvkLTpk3F6S0tLbFs2TJYWlqCYRgkJiZqnfctW7aAYRhMnjwZYWFhMDev6rDIYrEwduxY8f0NDw+XW7314YcfIiQkRPzZxcUFH3zwAQBIlQh0+ftoSigQGDHRw3306NGws7OT2d+8eXMMGTIEABAVFQUAcHd3h5mZGRISEvDdd98hJSVF6pjNmzfjm2++EVdfaJpeGdEDwMLCQqPvaWZmBgBgJJbWCAkJgYWFBa5fvy71UCwuLkZ0dDTYbDZGjhwp3n7x4kUAkNomaeTIkWCxWHj8+LHcgWxdunTRKM/auHDhAgBgyJAhcqthOBwOOBwO+Hw+rl27plYerayscOnSJdy9e1dudRaPxxMHZkXtSaqUlJTg1q1bAICpU6fKTTN58mRYWloiKysLDx8+lNk/cOBAmW3e3t4Aqn6mIrr8fTQlNI7AiCUlJQGATPdLSR06dMDx48fFaZ2dnREaGopdu3Zh+/bt2L59O7y8vNCvXz8MHDgQvXv3lnpQa5peGVdXVwBVjduaEL3dOTo6irc5Ojpi4MCBiIyMxOnTpzFt2jQAVW/VPB4Pffv2FV+vuLgY6enpAIANGzYo7B9vZmYGgUCApKQkuLi4SO2rjz7zopHGp0+fxu3bt+WmycjIAAC8fPlSZp+yPFpbWyM1NRVxcXFITk5Gamoqnj17hidPnohHDks2GGsiJSUFAoEAFhYWaNu2rdw0jRo1QuvWrZGQkICkpCT4+flJ7Rf9rGrmGYBUCUKXv4+mhAKBESspKQEANG7cWGEa0T5RWgD4/PPP0bFjR+zbtw93795FUlISkpKSsGfPHjg6OmLJkiWYNGmS1ukV8fLyAgAkJyejvLxc/IeuSkJCAgBINaoCVVU/kZGR+Pvvv8WBQFQtJKo6qvndHz16pPJ6RUVFMttUNZTqgujNNyUlReZNtyZN8piWlob//ve/OH/+vFSpytnZGcOGDcPly5flNrqrS3R/GzVqBDZbcSWEjY2NVHpJmjy8dfX7aEooEBgx0R+WZNG5JtEDQ5RWZMyYMRgzZgxycnJw7do1XLlyBRcvXkRubi5WrlyJpk2bYvDgwVqnl2fAgAGwtrZGeXk5YmJiVKYHqka4Pn78GADQr18/qX2BgYFo0qQJ7ty5g4yMDFhYWCA2NhaNGjUSV4kBVQ8okWvXrkmVLAyJKJ/h4eE6G3VcVlaGWbNmITk5GS1btsR7770HX19ftGnTRlyCqHlfNSV62SgrK4NQKFQYDES/pzV/F7Whi99HU0JtBEZMVIcqelDKI6qP9fT0BFD1x/ro0SNxNUSzZs0wcuRIrF27FtHR0ejTpw8A4K+//tIqvTK2trYYOnQoAGDr1q1yGw1r2rZtGwQCAZydnREUFCS1z9LSEsOHDwfDMDh//jzOnDmDyspKDB48WKqUZG9vL24kVTTRW2VlJa5evYrk5GS18lUXWrVqBUD5ZHRxcXF4+vSp2vX5kZGRSE5OhoODAw4fPoz3338fvXr1EgcBHo9X64ZVDw8PmJubg8/n4+nTp3LTlJaWiquzRN9TG7r8fTQlFAiMmKiB7eTJk3KrCjIyMnD+/HkAb9/6du/ejXHjxmHt2rUy6S0tLREQEADgbX2xpulVWb58ORwcHHD//n2sXbtWqqqipn/++Qd79+4FACxbtkxu9YFoTMGFCxdw7tw5ANK9hURE9+rAgQNyr3XixAnMnj0bY8eORWlpqVrfRVuiHkc1v3tgYCAA4NixY+DxeDLHpaSkYPr06Rg9ejTi4uLUutbr168BVE0LIa8kdPz4cXEbgWQAlHyrV/YzAqpKBN26dQMA7N+/X26aP/74A3w+Hw4ODujYsaNaeZdH17+PpoICQQNUWFio9D/RQyIkJATe3t548+YNFixYIG5IBKoaEz/44AOUlZWha9eu4pGiI0aMgJmZGWJiYrB9+3apaRuePn2KgwcPAqiqxtEmvSrOzs5Yt24drKyssGfPHoSFheHJkydSabKysrBu3TosXbpU3CVR9MCvyd/fH56enrh+/Tpu3rwJZ2dn8VuhpPfffx9WVlY4ceIENmzYIPWgjYmJwddffw0AmDhxotweWLokKq2kpaVJbR81ahS8vLyQnJyMRYsWSQ0ETEpKwoIFCyAQCNC+fXu1B+SJ2mWePHki7pUEVM0ueujQIakHquQ9kay+qZlPeRYsWAA2m42DBw+KS3FAVRA5duwYvv/+ewDARx99VKvGXF3/PpoKaiNogCT7R8uzcOFCLFq0CJaWlvjxxx/x/vvv48aNGxg0aBB8fHwgFArx7NkzMAwDLpeLDRs2iLtgenh44PPPP8eaNWvw3XffYfv27WjZsiVKSkqQnJwMhmEQGBiI8ePHa5VeHUFBQdizZw8WLVqE6OhoREdHo3nz5nB2dkZRUZH4vBYWFli8eDHCwsKUnm/MmDHi/v8jR44Uf1dJPj4++Pbbb7F8+XJs3boVu3fvhre3N/Ly8sRvzX369KmXWU5Fa048ePAAw4YNA5fLRXh4uPjnOXfuXERHRyMwMBA+Pj7g8/lISkpCZWUlmjdvji1btqh9rcGDB6Njx454+PAhPvzwQ3h4eMDe3h4pKSkoLCyEg4MDPD098eTJE6lusw4ODmjevDkyMjIwffp0eHh4YN26dQp7BfXs2RNffPEF/vvf/+L777/Hzp074enpifT0dHFAmzlzprhRX1t18ftoCigQGLk2bdrg2LFj+PXXXxEZGYmkpCRYWFigU6dOGDVqFKZMmSLTmyQ0NBRubm44cOAAHjx4gCdPnoiL9++88w7effddqaoBTdOrw8/PD2fOnMHRo0dx7tw5PH78GI8ePUKjRo3QqVMn9O/fH5MnT5bbrbAm0RQbgHRvoZpGjBgBDoeDX375BbGxsXjy5In4Xo0ePRpTp06tl66Hffr0wZIlS7Bv3z68fv0aAoFA3Mjq4+OD48ePY9euXTh//rw4AHh6eiIoKAjz5s2TGhSmirm5OXbv3o2dO3fi7NmzSE1NxZs3b+Dm5oYJEyZg9uzZuHDhAv7zn//gwoULmD17tvjY8PBwrF69Gk+fPkVKSgpevXqlMBAAwPTp0+Hn54ddu3bhxo0bePz4MZo2bYphw4bhvffeU7sUo0pd/D4aOxajqoKPEEKIUaOwSAghJo4CASGEmDgKBIQQYuIoEBBCiImjQEAIISauQXYfzc6WHSWrLltbKxQXy47KJNqh+6lbdD91i+6nNGdn+YMhTa5EYG4uO5iIaI/up27R/dQtup/qMblAQAghRBoFAkIIMXEUCAghxMRRICCEEBNHgYAQQkwcBQJCCDFxFAgIIcTEmWQgCNgSi4UnFa/jSwghpsQkA0FKIQ9/PMjUdzYIIcQgmGQgIIQQ8hYFAkIIMXEUCAghxMRRICCEEBNHgYAQQkwcBQJCCDFxFAgIIcTENcgVyrQ17dA9nHuRK/5cWC6ArZUZ2CyWHnNFCCH6ZVIlAskgAAA+G2Ow4WqynnJDCCGGwaQCQXgIV2bbiYRsPeSEEEIMh0kFAjO2bBUQ1QoRQkydSQWC8R1cZbaxQJGAEGLaTCoQyCsREEKIqTOpQEAIIUSWyQcCaiMghJg6CgT6zgAhhOgZBQKKBIQQE2fygQAAtt9KxfDfbus7G4QQohcmHwhYYOGLyOe4k14k3hadlIvPzj7VY64IIaT+mHwgkGfigXv49U6avrNBCCH1wuQDAbUREEJMHQUCfWeAEEL0zOQCwReDfKQ+U4mAEGLqTGo9AgBobGmmcN/d9ELwKpl6zA0hhOifyZUIhnKcpT4/zyl7u++3Oxi9J078+VlOCb449wwMQ8GBEGK8TC4Q1Jx4roAnUJh26qH72H77NZLyy+s6W4QQojcGUTWUnZ2NiIgIREdHIycnB02aNEHv3r2xePFieHh46PRamixLKSoI0KSlhBBjpvdAkJ2djYkTJyI9PR19+/ZFSEgIXr58iZMnT+Ly5cs4ePAgvLy8dHY9Mw0e6qIqIYoDhBBjpvdAEBERgfT0dKxYsQKzZ88Wb//rr7/w6aefYt26ddi6davOrqdRiaD6/yzqWkQIMWJ6byOIjIxE06ZNMXPmTKntY8aMgaenJ2JiYiAUCnV2PU0CgbA6EvB1eH1CCDE0ei0RVFZWIiwsDObm5mCzZWOSpaUl+Hw++Hw+rKysdHJNTVYpY6rLBL1+voEni/vCsZGFTvJACCGGRK+BwMzMTKYkIPLixQskJibC09NTZ0EA0KzhV7LXaHZJBQUCQohR0nvVkDxCoRCrV6+GUCjEpEmTdHpubdoICCHEmOm9sbgmhmGwatUqxMbGwtfXV26JwdbWCubmikcIK8MvqVA7bRn/bduAnX0jODjYaHVNY2Zmxqb7okN0P3WL7qd6DCoQCAQCrFy5EkePHoWHhwe2bNkCS0tLmXTFxTytr8FoEEAKJQabFRWWId/SIAtQeuXgYIP8/FJ9Z8No0P3ULbqf0pyd7eRuN5hAUFZWhsWLFyM6OhpeXl749ddf4erqqvPrmFFXUEIIkWIQgaCgoADz5s1DfHw8OnTogB07dqBZs2Z1ci1N2ggIIcQU6L2ug8fjISwsDPHx8ejRowd2795dZ0EAAOT0UlXbhcRcuKyLwvMcKmoSQoyH3gPBDz/8gLi4OHTt2hXbt2+Hra1tnV6vNlVDxx5nAQBupBZodNypp2+QmEvBgxBimPRaNZSdnY29e/cCAFq3bo3t27fLTffBBx/obCxBbaqGDtzPAAAIqgcYzPnzAZLzy3F+djelx808+gAAkLUiUOtrE0JIXdFrIIiPjwefzwcAHDlyRGG6mTNn6jAQ1P4cPEFVt9KTT97U/mSEEKJneg0EgwcPxpMnT+r1mppMMSFp99108b9pnRpCiDHRextBfdO2jeDnW6nifzNyxhxfS8lHQnaJ1vkihBB9MYjuo/WJrYO6IXklgjF77wIAbCzYCB/ZDmPauWhwPgb/i0nCjC5uaGGnu3mVCCFEHSZXItCFM89z8CCzWO6+Ur4Qq6MSNTpffEYRvr+SjLDjj3SRPUII0QgFAi1ceZWP4F9v6ex8onUPygXS6x5UChm8zCvT2XUIIUQeCgR1QNPKJ1GzRc22h28uvUTPn68jOZ+CASGk7lAgMACKAseVV/kAgMxi9WdMJYQQTZlkIFjY00PfWQAAlAsqsfzMUxRUz3JasxGapkUihNQHkwwEU/1a6DsLAID99zKwKy4N62OSALxtKyCEkPpkkoFA12/aV5LzpD6X8CvVOk704K8UKk9H8YEQUpcoEOjAuP3xUp+zS/jgK3m6i/bVzEfNxmLRboaGMhNC6pBpBgKN+/VojqcgENxILYD7+ku4lPS2FCHuNUTPe0KIHphkIKgXCh7qsSlVPYGik3LF4Uj85l/nmSKEEFkmGQjqo6pFF1egXkOEkPpgkoFAUA/dc+TFmuySt+MBWGDJthEwNdsIKBIQQuqeSQYCfn0EAjB4llMCl3VR4m3/ufBCan/NBz1VDRFC9MEkA0FlvQQCYNedtBrbGLnv+Koai6kRmRBSl0xuGmoA6ODSuM6vEXb8EQqrRwxLknym77idqnAfoPmcRcqce56DUn4l3mmv/vTYhBDTYJIlAnM2Gy8+6Ven17j4Mg+304qkttV8s3/ypmpBe1EVkaJGbEUFgktJeYjPKEJSfhm23kgRL6Epz7TD9zGPprkmhMhhkiUCALCzqv+v/ji7BB2cZUsjkt1Ht99KRaC3I9o2a6yy19CEA1UD2TybWONVQTlWXXiBMzP90bWFvW4zTggxaiZZItCXxxJLWUq+/Ise+EIG+CLyOYb/fkej8xZJVEHdel1YqzwSQkwPBQI9kTe1tLA6OhTxpOcqkqwyqhQyyClVPC11bRuWi3kCcT4IIabBpANBwuK+9X7Nx2+qSgWHHmbK7JN8/r7KL5M74njtpUS0D7+qMBjUnK9IE6X8SrTeEIMvJbq5EkKMn0kHgqaNLOr9mkceZincJ/km3m3rdaQV8aT2e/9wGRHXUgAAeWWyPZKA2pUIiiuqSiKH5QQpAIh6mStVDUUIMQ4mHQgA4MnivniyuC/CQ7h6y4PozT+1UPrBn1PGl/pcUqF6euu6qtTJLOZh0sF7+IB6HhFidEy215CIo6hUYIAT+7ydhlp2n2QVkGTWa1MiUHQH1kQlooWdJQDgWU6p9hcghBgkkw8EImw9xgFdvsXLayOo7SR74dde1ep4QohhM/mqIRG2HksEsSkFSvdr8hj/6mIi/nwkXcd/Q8MupdRpiBDTQoGgmpnh1QxpPfto2F+PpT6XVFADLyFEMQoE1cz1WTekBXprJ4ToCgWCauZsw7sVBdVdNeXW+9fB9QywvZwQUg8M7+mnJ4ZcIth8LUVqXQNN1WXp4afYJLTfdKXuLkAIqXPUa6haJ1dbfWdBoWiJhe7rg6gEUswToLGlmdK0i2lcASENHpUIqjW3s0LWikC4NLbUd1YMQmYxD603xCCCuo4SYvQoENQQOStA31nQWK6c6SZya4xKlqdSyGB9TBLyy2XTZlRPivdXQrbU9tqOSSCEGB6qGqqhuZ2VvrOgFlXP43abriBrRaDM9oJyPgp5lfBoYo0zz99gfUwSXuWX4W5GESb6Npc5Nz32CTF+VCIwAZIP8yOPshDw0zVEJ+WCX1m1p0wgxJM3pVgTlShOd/Z5jtxzsahrESFGhwKBEv1bOeg7C7Uy+NdbyKgxg2lcWtUo40dZJfIOEVsfk1RX2SKEGBgKBEocea+LvrNQK/cyi/Hb3TSpbaKpNCSnvM5T0p6gbpMAtR0Q0nDprI3g+fPniIuLg5ubG/r2rf8FX0xNKV/1lNTyiIZLMHhbZXQ5OV/t4+mBT4jx0SoQbNmyBfv27UNkZCSsra1x6tQpLFu2DEKhEADQo0cPbNu2DVZWDaPhtSFSd13jW68L4Wr7tkvs2xKB4mMYqX+r9+BnoHgaa0KIYdO4amj//v0IDw8Hi8VCQUEBGIbBunXrYGZmhkWLFmHcuHG4fv06tm/fXhf5rXfBrZvqOwu1Ep2Uh+Vnnok/i9p6Tz19o9UiM9RYTIjx0TgQHDlyBK1atcLp06fh6uqK27dvIzMzE6NGjcKCBQuwdu1a9OrVC3///Xdd5Lfe9fVs2A3GNYmqgW6naTY1tYiiqiGqMSKk4dI4ELx48QLBwcFo3LgxACA6OhosFgvBwcHiNL6+vkhLS1N0igbF2J5vL/PK6uS86lYhEUIMj8aBwMLCQuqt8NKlSzAzM0OvXr3E2woKCmBnZ6ebHBK9eqiimykhpOHTOBC0adMGUVFRKCsrw82bN/HkyRMEBATA1rZq0raUlBScPn0aHA5H55nVCxOs89DmK5vgbSLEaGgcCKZNm4akpCT07dsXs2bNAovFQmhoKABg165dGDt2LEpKSjBv3jydZ1YflPWuMUXUWEyI8dG4++ioUaPAZrOxY8cOAMDkyZMxePBgAEB5eTlatGiBJUuWoHfv3rrNKTEIUtWCEtNjU7wkpOHSahxBSEgIQkJCZLbPnTsX8+fPr3WmDIkpPuCUNfzyqucnKqmoxIQD8fWVJUJIHdLZFBPPnz/HsWPHcPXqVV2d0iDQSFr5KmvUmYlu0/2MIvwuMa1FfEYRriTX78I6hBDNaD2yeO/evTh//rzRjyw2xTBQyNN8+gpRKWLQrtsAgBld3AAAQ6o/y5sSmxBiGLQeWcxms01iZDEVCKQZ0niBA/czkF1Soe9sENLg0chiFeQ99hb18kDbZjb1nhdDVt8B83VhOT76OwGzjj6o3wsTYoRoZLEcByb5Yfs7HRTu/2JgaxyY5Cf+zK7Ro7K3R5O6ypreZZeoXgKzPlRUN1pnFlOJgJDa0riNwBRGFktONCevsZjNYsGjiTWGtGmKcy9yZWbdtLcyvRVADafCiBCiKRpZrMKgNs0AADvGypYQRA+/moOsTKFdoea4MlP4zoQYK41fXadNm4Zly5ahb9++4PF4MiOLIyIiUFZWZjQjiwPc7JG1IhCC6h5RkkQPP8ln4mRfV+QoWfHLVDAMU6ejkGmAMyG6QyOL1cSW8+R5WyJ4uy1iVHtMPmh6A60YMFJjC4QMMP3QPaXHFJYLkFVSAZ86angvLBfAxpINczatyEqIMjSyWE3yXkA7udriQmIuXBtbIqXw7SLxAiOfoGhffDqGc5yktiXllSP411vizy3+F63w+NSCcliZszHpYDweZpVoNMYgt4yv9kpoPhtjMKGjK7aMbq/2+QkxRVq3ajIMg1u3biEhIQFlZWVwdHSEj48Punbtqsv8GQx51Ryf9ffCiLZO2BT7SioQ1Bx1a2w+PvUEH+ZIT0/9MKtY7eP9f7qm9bXbbboCALgxv6da6Q8/zKRAQIgKWgWCe/fuYfny5UhOTgbwtmcNi8VCq1atsH79enTq1El3uTRQ5hqsM8oAACAASURBVGw2/N3sZbZXGnccAAC80bAb6arzz7EqqDVV0xBigDQOBElJSZgzZw5KSkowdOhQBAQEwMXFBYWFhbhx4wZOnz6N999/H4cPH4aHh0dd5Nng1CwsfD7AGx8cf4QsIx71WjPWqYp9W2+mYuvN1HqbaoLmiCJEfRq/nm3evBllZWX4+eefsWnTJsyYMQPDhw/HpEmT8N1332HLli0oKirCzz//XBf5bRD6eDrgwaI+cLNr+HMtKSIz1YQOHrw5pRXoEH4F9zKK1D6mkCfAHw8yan1tQkyZxoEgNjYWQUFBGDBggNz9AwYMQHBwMGJiYmqduYbml3EdpT5vHWO8ddN18cJ9OTkfb0r5iLj2Su1j8ssFWHgyAfczpYMHlQcIUZ/GVUMFBQUqq3w8PDxw6dIlrTNlqC7M7gYbS8Wx05RqI2p+V3W/emYxT3UiNdRsui8XyI7zIISoR+NA0KJFC8TFxSlNExcXBxcXF60zZah8XW01Sm/MyzpWVGr34C2pUD3FtS7iqSkFZUJqS+OqoSFDhiA+Ph4REREy+/h8Pn744QfEx8dj6NChOskgMUx/P30j/fnJGwUppZnVnKFPQm3DZhm/Eg8yq7qxGtJ02YQYOo1LBAsWLMCFCxewZcsWHDt2DAEBAbCzs0NWVhbu3buHzMxMeHl54cMPP9Q4M5mZmQgJCcGiRYswa9YsjY/XF1299wd6OyK/TIC7GjSWGoqzL3LUSqdOiUDSmWdv0L1lEzRtZKEy7eJ/EnDscTYSFveFvZWZePuy00+wKrAN7K1NbzJAQtShcYnA1tYWBw4cwLhx45CTk4O//voLe/fuxblz55Cfn4/x48dj//79Gs8+WlJSgkWLFqG4WP2BSYaiSfUDxtq8dn3kh/k4YahPM11kyWAF/nJLdaJquWV8hB55gBlH7svskxd8r6cWAKgqGUhWDf1+Nx0bYqvGvGSXVEBI9UaESNHqFcnBwQFr167FV199hZcvX6K4uBiNGzdG69atYWFhgbNnzyIjIwMzZsxQ63yvX7/GokWL8PDhQ22yo3erB/mA06wxBrVpKrW9o3Njjc7DMKZboZFRJNuIXFHdAJyUV67RuViQbWcQCBmkFJQj4Kdr+GKgNxb3bqVlTgkxPrV6hbWwsACHw4G/vz+4XC4sLKqK77t378Y333yj1jl27dqF0aNHIyEhQWpNg4bEzsocC3p6yExMZ6vhugRGPjOFQnfTC+H3Yyz23UsHINvQq06bO0viOLmN9EzVqmYAEPkiV+u8/nrnNZaceqL18YQYIr2P9//999/h7u6OPXv24J133tF3dvSKAQMbC73/SOrd89wyAMDFl3ly92cWV6CMX4kFJx4rPAcDidlgIRtMJKuDalPu+uzsM+yJT9f6eEIMkd6fOl999RWOHTsGf39/fWfFIMzr1tLkgoGVmepX/mOPs3D4YabSNMqq/k20sEWIWvT+xOnfvz/MzMxUJzQRlmZsfNLHtOqva1bllPArUVEpVPrwrnkMS2qf7Fs/NRAToliD7E9na2sFc3PtgoeZGRsODnWzEEptWVtbwsHBBlbWqrtKGhMbG0upzxcSczHl0H3sfq+rwjT29o2kPtvZWYvbEuztG6FnxBWp/RaW5rC1tQYAmJuZafw7cCslX9zGAKDOfocM+fezIaL7qZ4GGQiKazFNgYODDfLzS3WYG90pK6tAfn4pypUsddnBuTEeZZco3N8QlZTI/jxjkvJQWFgm/lxaKj2Tq+Q+ACgqKhe/9ecXlCG9Ri+kcp4AxcVVD/LKSqHGvwN9frwq9bmufocM+fezIaL7Kc3ZWX63fpWB4NixYxpf7M0b9UaZEvmU9ZKZ6OuKry4m1l9m6oE6vaXUGbksbw3pt9fQTWMxIcZIZSBYsWKFxnPm1PXC5Q3JhI6uKhs5NTGS66wwEDRrZIEcJaUJQ6Wo/v55zts3OXVHLitCTQSEKKYyEPzrX/+ih3otRIxshx9GcOD53WWp7VfmdUd2CR9j990VbxM9q5Q9tLwcGinc90mfVvj3+ee1ya5eKPq67x6IV3jMwJ03pT4XlAtUPux/ufNaw5wRYhpUBoJFixbVRz6MlhmbBTO2bMN222aN0bYZMKh1U8RnFOFNae3f5JXM52bQtBlIV1xjzqIlp5+orPI59jhb8wsRYgL03n3U1O2f5Id3O7pKbevbygEAsKK/l9xjVga2lru9oRbclA0UU1dBuUD8b3nhQNWtYRgGuXqqVivmCcCj9RSIHlEgqGcjOU7YP7GT3H2iqo3u7k2QtnwA+ng6yE23qJdnXWWvQRPdP23GDIRfe4V2m65IdRGtL603xGDQr+pPxkeIrhlU99Hx48dj/Pjx+s5Gnfp1vK/MNnlvq+ZsbWJ0Ay0S6EApXwhBdR2TNg3Dp59VNUa/LuTB3d4aN1ILMGpPHCJnBcCvuWYz6WrjaQ51cST6QyUCA+BQPY21rZV0W4LmDzTT7hpTUVn1/dUpEeSUVmDG4fvIq64OqlmtdvpZVXfVqJfaT1BHSENBgcAALOzlibWDfTDNr4XUdmWPsz0TfLFuaNu6zVgDpU44/PlmKk4/z8GvNXoSiSeuY6l/LkIaOgoEBsDSjI33u7WUWcaRUfJmO9THCXP83WtsVV015Oui2brLDZE6D29VD3qWCVezEdNDgcCA1XxI7Z0gv5FZ0q7xHRXuWzPIB01tjH8eI3nxs+Ym0YNeVS2SrgeiCYRCfH72GTJrMU0KIbpGgcCA1XwIDVGxjCWLBYRwnDG87dt0XCfpCbdM4T1XXlfMs8+lRyaLSgSi9oSa96U2XXGLKwSoqJTfHfRCYi523nmNT08/VetcPIEQLuui8F1MkvYZIkQFCgT15NFHfXDnQ92vwLZmkI/S/ZLBhMUCPJpY6zwPhuaLyGcy27JKpCetE60mxwBIzCvFzdeFVZ9rRF9GzjZVWv8Qg9F74uTuEzLS/1elhF81cG77rVSN8kCIJigQ1BMnG0u01PAhrG2thLfj22koJM/BMMCawT7Y9k4HLc/cMNxJL1KZpqC8qrcQwwA/XEmW2S9ZIBj0622N8xCnIg8NdfAfMU4UCAyYOt0g5U2r8MXA1lgVJH/0sY2FGca2d6l13gxZpYrX7ZxSPrbdettbSNkzmWEYPMgq1lHOaPI7YpgoEBgwNzsrrY6zNGNjSBvZ9oTGlqaxEpyqQPAi9+1aBkIFM+XSGzsxJRQIDBjHqTGuzOuudvoBrRzF/xYFkQ+6tRS/8Y5p5yzen7UiEKmfDtBJPg1NpQav3QxUlAhqnRvdK+NXos2Gy/jnadUkekKGwZ74NIUN1ISoQoHAwLVt1ljpftEz74Nu7vBp9raHkJ2VObJWBGJmVzc0sqj6Mdd8y7U00+zH/x8F1U2GRpPZTBVNNKdu91JJZfxKvPfHPaVpRFV5tSlwvC7koYhXia+r16U4+igLS049xYarsm0dhKjDoOYaIvL9E9oVL/PK5O6zt6r6ETqos86xgoeaT9NGeJ4r//ySrLVcJ9qQ5Zby0cT67Z9BberwLyXl4XyimlNS1CIS1BwMJ5p5NUcHU5kT00SBoAHo5t4E3dybyN03uVNzlAmECO3SQu5+AEoXFrrzYS80sTZHmw0xauTEECtKak/y7qTWmH1U0Td2WReFC7O7wdqcjd/upuHr4DZ1lj9VqD2D1BYFggbOjM3C3ICaU01IOzylM/bGp8ttLNa0S6ux++TUE0z0ba7Ww/VaSj523nmNF7ll2H8vHeY1pgjZFfcag1s3q7d7bJxhmtQHCgQmIMDNHgFu9rU+jzF2fWSgvMSkbDBZXrkAudXVMYW8Spn9y888g5dDCm7MfzuQUBf3UJRbRsGoaEI0RYGAqM0I4wAYRvpBKprKWp2H63o1pn1Q1RitFQWHajoCmhAR6jVEAADnZwWgkbnyXwejfc7UeLBWVArFQa+2X1l8HoZB7Kt8nQZTmjKb6AqVCAgAoFNzO3RubodrqQUK06haHN5YtFx/SfxvfmXtvrOoK+uhh5lYeDIBIRynWp0PkC1NSH4O3HkT3Vs2wfphnFpfh5gOKhEQMXUfef4t7GDBNo6a6VPP3mD33XSF+8OvvarV+UXVNaLuv6L/q9vTR1l1j8wuBniUXYLf4tI0zicxbRQIiFg7Z/UGr3V3b4KOJrDAjS6ISgS6DJvUXbR+FfMUTytuLCgQELHVg9pA2Yu++AWUBUzrrHjcAnlLkwbc/jtuIK3GOAZ5KA7Ur9YbYjBhf7y+s1GnKBAQMWtzM/TxcAAAWLBZCOvWUmq/VXVjciNzNtqrKD2QKrzqNgZ+ddFAWWB48qYUu2+rv+6AuPsoRYY6p6ztzBhQYzGRwnVqjJhX+TgzMwAt7Czxs8SCKNM7t0B2SQUW9fKEpRk9fdQVn1GETbFVbQ0Jb0oB1O6tXtGxptGUT+oClQiIlC+D2+DY1C7wdbVFMxtLqRlKLc3Y+Ky/N2wszGDOZmNJn1Z6zGnDIW8sgS7e4sXdR2t/KoUyingorhDU4RWIIaBAQKRYmbPRx9NB/FnZDKWm0p20thb/naDT87EkltmUVBcDyvx+jMWo3fKX3STGgwIB0ZrRDjDTsYziCtWJqqlzS0UlgNeFPBx+mFnnA8oeZZcgs5hXR2cnhoACAdGaJvP+E2knn7zBzCMPZLavOvNU/G+v7y9hkYrSxIITj7EmKlEneSrlVyI8NhkCoWxXyU6bYykYGDEKBESl2A96IP5fvWW2q7OmMlHs1LM3SveX8oWIfKF6fYPcsqo6/Pxy2bp8hmHww5UkJOVXDWQ7+SRbYZ3/+pgkrIl+icMPMuXuzypRv2RDGhYKBESlNk1t0ELO+slNbVQvhvPbeF+525s1UmMhHSKXoobmf57KBpbXhTysu5yEqX/cw8OsYsz58yGWnX4q52iguKJqBtUygXEPniKyKBAQrc3v3hLbJ3SS2hbWXXrswQgFc+vIe5hdC+uhs7yRKqL1m3kCIYp4VSWBlALlg9YUlvOoAGi0KBAQrZmz2ZjZzUP8mdPMBh9WBwJ7KzPcnN9T4bE1A0HiJ/3Q2tFGfmIT9PRNicJ9mnQXfTtDqfRRlUIGhx9mSlXvSa3UVlCO9CLDbhMo5VcafB4bCgoEpE40tjRDK4dGCvePbeci9dnWyjTHNh57nCWzbcbh++i346bUtjyJ+n9NJkQVPehf1SgF7Ip7jQUnHmPSwXsyxzAM4P/TNXT+MVZq+38vvYTH+mj1L17H3t1/VyaPdYlnxFVmFAhIrT36qA8AxdVA8lgoGZ9gSj44/khm2+nnOUqPWX5Gfh2/XAqChqjh91JSHlzXRaFjxBXxvs/PPZN7zIXEXPGUGYbgdlpRvV5vddSLer1efaK/RlJrTjaWePRRH6zo7612NbKqHketHRWXJkxZfjkf5xNV9yRaevoJuv10DSV82SU0a1bLMQCyS/i4nVaoo1wap+R81RMCNlQUCIhOONlYwozNQgs7K0zp1By73+2kNL2qnqenZ/rjyrzual/fyoyFlvayPZuMTe+fb6iVbvfddLwqKMf9jGK5++Xd//uZ8tNq69jjrHobe/D73TR8pOMR3DUZc29pCgREp9gsFsJHtoNfczul6SRLBO91ai6z38HaAm2bNcb7Ae5qXffrQT5Y2tdLo7w2RDkK1kBWhC8x6q9SKFqPue4nDCwsF+CD448wWU4bRF1YdvopDtzPqJdrGSPTbKEjeid6Pq0d7IP3Jaa73jqmPVwaW4o/rxnsgx23X6s8H4tF8/TLIzkfVH1WbYi6raYZUa8eY55bi0oERC9Ey8PX7NY4voMr+rVyFH9mazBN5+h2zrrJnJH68UZKvV1LPP+R8T47jQoFAlLv3OysxCUCbZc+/mVcR6nPLLBgZ+RdULVZLlFyPihRdVx9lJxE1zCmt2jj+SayKBCQehe3oBdCqrua9vJootU5OM2kB5+ZwipdLddf0viYLdfflgJEb+fXUgt09lB7kFkMl3VRSMiWPwDOmB+eulIX04drigIBqTfHp3bBNL+qhuEg76bIWhGI9s62es6VcZMcSKarx83K88/x/ZUkAMBfCVUD4mpOoCdqkNbXM66YJxA3jutKXXyXhOwSuH4bjTMqJiCsaxQISJ07O9Mfy/q2Qm9PB2wIaSfTLqALyhbQIbJq81D7+WYqvr2cpDRNXa+RoAzDMGi9IQZLTj0Rb/v5Zgr+d/ll7c5b24zJIRq7IW/CwPpEfz2kznVpYY/l/b3r9BoTOkpPWWEKYwo0lapisrnaqFm9oc/aDtGl90t0J115/gW+u5Ksnwwp8bYtRb8oEJAGYbKvK/58rzOcqqe+lixULOjhAXO29K/yV8FtAFTNeUSqSI4p0FUjrqrCnTr13wXlfIz4/Q4S80prnZ+Siso6C0LKvsvyM08x7LfbGp/TUNq2KBAQg5fx2UCEj2yHvq0c4WCtWc+gQC9HhfsW9vRQuM/YRVzTbVdSmfWTNQg0p57l4HZaIb6Pqf0b+83XBXrpqbQrLg1x6fU795EuUSAgBo/NYmncrjDEpxnGd3DBmsE+CtOsCmpT26yZPFGjcKWQwdcXX+BNadVkdqJHsTpv52w57QkF5XzkaTiKWuTnm6nVedOtuggv4qohPfccMu6O18ToqPvnYm1uhq1jOtRpXkyd5CR1kS9ycTejCKmF5dj2ztsxHur8vEQPQ8lpR9purJoNNWtFoEZ5EggZfHUxUe1ra6JOntXVLzjURkCIFhTNl7N5VDuEdm6h9nnaOzfWVZZMzojf74j/Lahufzj2OBsF5XzxQ7NcIFTZNVLZ6PG6mLSumCfAsxzFC//og76HElAgIEZlkm9zfD+Cq3b6f0L9AQB2VmaYp+YEd0S5thuvSL3dhx55oPCBfiIhC0n5ZQDkT03efet1uce9qj5GG1MO3UPf7TdVJ6xBMnfJ+WUo5gkUplWXgbQVU9UQaVimd26Bry4mwrmxhU7O19jSTFz9kFvGx3Y1JrgjqsWmFEh9rrkuwl8JWbC1NMfcY28X5pH3VlyuYFWwXtveTscdevi+0nPUdCO19usudN96HX6utoic3a3W5wL0XzVEgYA0KAt6eGBBDw+pxuPFvT31mCMCyHaDnPPnQ6nPNUf5vn9MdmU2TQYCCyQSn5FY0a0uewzVbNC9p4P1G94OvNNvKKCqIdKgsOT0IHJspH7poGkjc3g2sUZvOXMc1fxDn9KpOaZ0ao7rYT21y6wJUfUmLnpwpxWWo+sW+esMq/swzK5eZlMeyWmvDaXaRRlRHo88lF27uj5RiYA0WNFzu8HGQvWAsY96eeKnGyngCxl4O9rg1Ax/uelqPobGdXBBkHdTAMCBSZ0w5Y/7sgeZuKfVja4PspS/HYsCQZct1xSmETJVjcOqVkoLk7POs8jyM/LXWxZZH5Mk/jfDMGCxWCgsF+Dggwy42lpiTDsXhcfqu0G3LlGJgDRY7Z1t0cpB9drG/w5sjaNTuwBQf9rrRb08MEBiXYTg1s2QtSIQLo0t8XWw9PgDOyvTHb188omac+So8RBlGGDGkQeYekhxwH2UVYyYV/lq5k6WVCCo/r/Pxhh8EflcbnVVbVUKGRx+mKlwje66mHdLGxQIiEkQVfuo83fXxMocKwPbwExO1HiwqA/m95AekaztJJffDGmr3YFGimEYJKvoDRT4yy31zwcgOa8M/7nwXO7+3++myVQHCoSar/mgzPZbqVhw4jEO3JO/jKbkb5iiQWXFPAF4ChrNdYUCATEJor8xtho1x+Yarpaj7ajQ5raWqhMZiUG7bmPs3jilaRgor35R9FatzPT9cfjpRqrcfcvPPIPrt9FS27ZUp916IwWnaswIKu/qsTVKJ/+58Bwu66Lw9E0JygWVyKxuz3ijxihpRd+u9YYYDNViHiNNUCAgJkGoRolA9JxRp9Tw/XCOzHGqpC0fIPXZwswwqgXqy9UaXUprYhjlpStt1he4rmE1UkYRD9klFVh14QVmHn2gMv3tdOmuqKKg02/HTSw8maDyeMnfNWWB7rGChX90hQIBMSnKRrFq8pgJ7eKGzM8GYlZXNxx5r7PK9I3M2VIzpHrYW6FrC3sNrmj8hGDEi95LepFbinJBJdy1WKFNUwwDDJd4+5bsoSSv5KfsJeCvhGzsiksDoLgHk+T24opKBanqHgUCYhJ6ejTBzK5uCB/ZTmEaG/OqP4eB3opnLJXEYrHwv2EcdHNXf7lN0ToJnw3whqWJlQhUiXyRK3cA2fHHWfD87nK95GHnnddIKXzbBbVjxFXxv+U981W9PJRo8HDfcUt/gxkpEBCTYM5mY/0wDjyaWCtMY2tljuthPbFxhOJgoUj0XOUjTEUPjF4eDuJtTax1MzramAjkVP+sU7EaWn3JKZWt518TlVirc0r2GhJ99wuJuTgnMUiuPlAgIESCt2MjWJlr/mehaO3lLaPbY5KvKw5Nqao+audkAwBws5O/gtrKwW0xv3tLja9P6t7TnNovnKPM9ttV7QtT/riHaYdlu9AeuJeuVYO5OmhAGSF1aEJHV0zo6Cr+vLCXJ3p6OKBny6rqpGl+zbFXomth5xb2uMXTbh5+Uvfupheic3M7nZ1PsnKwiFeJtMK3y4lWChlcfJkr/vzRP09QyQDTNJhdV11UIiBER2rW+FvJaQNgs1jiIAAAP4zg4sb8t1NYWFuwEdy6qdQx3dypUdlQDP3tjky7wPIzT9U6dsKBeGy9Ib0yXM2+C5Ijr3+6mSIzuC6nVPH0GrVBJQJCdITNAiqrnxLPPu4LMzX6obJYLHg5NMKN+T3xW1wahrR1QkGB9KCqhT09ENy6ab01mBLl1l16KfVZ1DNImdXVbQmXkvJkBiQq8jJPdnBdXc1yQYGAEB1hs1ioZBgcntJZ44ZgL4dG+E9QG3Hj4ZdBbdCvlQPSingY5tPMYKYiIMDG2Fe1Ov7fkc9wPbUA52Z1Uz68Uc5TX9tR7KpQ1RAhOvJ/A70BAH09HVSkVG1BTw/4NbfD8LZO4iDw17QuUmkcrc1x7YMeUiOU/VvIr7/WpKcqTX1Rt7bdeo34DNHEeop/MCkS7QUiddVYbBCBQCAQYNeuXQgJCYGfnx8GDRqEH3/8EXw+NZqRhuNfPT2RtSJQ7hxFutDLwwE7x3bA2PbOAID+Xo5o3dQGV+f1wJbR7QFU1TnvGl+1ZvCRKZ3xSR9PcJrZIHpud/ypYuDbs4/7YuMILuYGuCNrRSBOK5illdSPqJd5MtuMukTw9ddf45tvvoGDgwNmzJgBV1dXhIeHY+nSpfrOGiEGZXQ7F0zpVNVrpGn1Ogy2VlVrLABVbQ4hHGe8+KQf+ns54vMBrREzrwc4To3Rt3o2VUXrNDextsBUiR4p/m72+HlMe8z1d8d0FT1Vto5pX+vvZoo0rfFbH5NUJxPQ6b2N4M6dOzh48CCGDRuGTZs2gcVigWEYrFixAseOHcPFixcRFBSk72wSYjCCvB2xYQQX4zq8nTu/Sws7jGjrhM8HVFVP2VnJ/9POWhGIx9nFGLhTvVk8x3VwxbgOVd1f76YXKVx3YHwHV8z/67EmX0OlsO4t8fNN+RPGGQOXdVEaT3AIAK8Ly9G6qY1O86L3QLB3714AwMKFC8V1oSwWC0uWLMHx48dx6NAhCgSESGCxWDJ9yS3N2PjtXV+1jm/vbIv1wzh4nlOKpjYWGOrTDPczilQe9/u7vjj7IgedXG0xcnfVTKJB3o5oU/1QmurXHPvuZcDD3gqbRrZDdFIeNtWiYbWTq/xBesZE3khqleqg5lHvgeDWrVtwdHQEh8OR2u7q6govLy/cvHlTTzkjxHjN7Oom9bmji+qHbssm1pjj7y6eP2eglyMOTn7b7vDfwW2x714G/tXLE/1aOaJfK0epQODc2ALZJW/b/bJWBCKrpALj992VGrXrZmcFrpMNJnZ0xXcxSfhiYGvMU7IqWU2+Lrbo28rBaEsTzja6n75cr4GgoqICGRkZ6NxZfiOWu7s7Xr58idzcXDRt2lRuGkJI/WpsaYZTM/zBbWYjsz1rRaDUtnv/6g02mwWXxlUPr1f5Zei29TqOVjdcuzS2RMy8HuBXCvH73TTM7OomNUvrjfm9AADzjj9CKwdrxH7QA5MP3sPl5Hz8d7APvoh8u+jM9M4tsCc+HZ/288IIjhOW9W2Fa5klCN1/FyM5ThAIGfw6viO233qNq6/y0d3dHu721vjwRFWV1v8N8MZaiTECg1o3RXRSHkZxndDDvQnKK4X4+uLbuYXWD+PgUzUHk+mSomq/2mAx2q6qoQNZWVno378/+vXrh507d8rs//jjj3Hq1CmcPXsWrVq1Em/PzlZdjFXEwcEG+fl1O2eIKaH7qVt0P+XLLePDyoyNxpaaLQvq4GCDxPQCOFqbqzUW46+ELPi62qK1o+I6eH6lEDmlfDS3s8L9zCLwBEKEVFeV/f6uL2YcqVrHwNXWErfm98Lj7GIceZiFn28pLqEEuNnjdlohVgW1xtcXE+HS2BIfdG+JNVGJGM11RlMbCwgqhVg/nCMVKDXl7Cy/e7FeA0FaWhqCgoIQHByMn376SWb/8uXLcfz4cZw4cUKq6qisrALm5tqtE2tmxkZlZd0u+2ZK6H7qFt1P3aqv+8kTVFWXWWn5XKovFhby86fXqiFr66oub4rGC1RUVM2r0aiR9ALlxcU8ecnVQm9cukX3U7fofupWfd9P5Ssu65+iEoFexxHY2tqCzWajuFh+l7SioqoqIDs73c32RwghRJpeA4GlpSXc3NyQmiq/7iw1NRWOjo5wcKj9kH1CCCHy6X1kcUBAALKzs/HypfSMfpmZmUhOTkaXLl0UHEkIIUQX9B4Ixo4dCwDYsGEDhMKqRh2GYfDDDz+AYRhMnjxZn9kjhBCjp/cBZX369EFISAj++ecfTJ48GT179kRcXBxu3bqFYcOGITAwUN9ZJIQQo6b3QAAA//vf/+Dj44M/8lg6YwAAFj9JREFU//wTv/32G9zc3PDRRx9h3rx5NA87IYTUMb2OI9AWDSgzHHQ/dYvup27R/ZRmkAPKCCGE6J/eG4sJIYToFwUCQggxcRQICCHExJlEIKA1keXLzMxEQEAAdu3aJXf/sWPHMHbsWHTp0gUDBgzAN998g5KSErlpo6KiMHnyZHTt2hW9e/fG//3f/yEnJ0du2ri4OMyaNQvdu3dHjx498NFHHyElJUVXX6veZWdnY9WqVRg4cCB8fX3Rt29fLFu2TO53onuqWl5eHtasWYPBgwfDz88PISEh2LFjBwQCgUxaup+6YRKNxatWrcLBgwcREBAAf39/3LlzB7dv38awYcMQHh6u7+zpRUlJCWbPno34+Hh8/vnnmDVrltT+n3/+GT/88AO4XC4GDBiAp0+fIjo6Gl27dsXvv/8OS8u3i2OcPHkSS5cuhYeHB4YOHYr09HScPn0aLVu2xJEjR2Bvby9Oe/PmTcyePRtNmjTByJEjUVRUhJMnT8LGxgZHjhxBy5Yt6+sW6ER2djYmTpyI9PR09O3bF1wuFy9fvkRUVBSaNGmCgwcPwsvLCwDdU3UUFxdj4sSJSExMRFBQELy9vXHnzh3cvXsXQUFB+Omnn8Rdyul+6hBj5G7fvs1wOBxm0aJFjFAoZBiGYYRCIbN8+XKGw+EwFy5c0HMO619qaiozbtw4hsPhMBwOh/n111+l9r9+/Zrp0KEDM3nyZKaiokK8fePGjQyHw2F2794t3lZcXMz06NGDGTRoEFNUVCTefujQIYbD4TDr1q0TbxMKhcywYcOYbt26Menp6eLtV69eZbhcLrNo0aI6+LZ1a+XKlQyHw2F++eUXqe3Hjx9nOBwOExYWxjAM3VN1ff/99wyHw2F+++03qe1LlixhOBwOc/HiRYZh6H7qmtFXDSlbE5nFYuHQoUP6zF6927VrF0aPHo2EhAT06tVLbpqDBw9CIBAgLCwMFhYW4u3z58+Hra2t1D37+++/kZ+fj1mzZsHW9u1yhxMmTIC3tzeOHj2KysqqudqvXr2Kly9fYsKECWjevLk4be/evdG3b19ERkYiLy9P11+5TkVGRqJp06aYOXOm1PYxY8bA09MTMTExEAqFdE/V9Pr1a7Ro0QJTp06V2h4SEgKgqsoGoN9RXTP6QEBrIkv7/fff4e7ujj179uCdd96Rm0Z0T7p37y613crKCl26dEFCQoJ4inBR2p49e8qcp0ePHsjPz8ezZ89Upu3ZsycqKytx+/ZtLb9Z/ausrERYWBgWLlwItpxVoywtLcHn88Hn8+mequn7779HVFQUzM2lJz1ITKxaItLJyQkA/Y7qmlEHAtGayJ6ennL3u7u7o7CwELm5ufWcM/356quvcOzYMfj7+ytM8+rVKzg5OUm9PYm4u7sDgHi2WFEDmoeHh0xaUV2qOmlF501KSlL3q+idmZkZZs6ciWnTpsnse/HiBRITE+Hp6QkrKyu6p1pgGAY5OTnYu3cvIiIi4ObmhjFjxgCg31FdM4i5hupKfn4+AMUL24i2FxUVoWnTpvWWL33q37+/yjT5+fkKG8RE90y0mFBeXh4sLS3Fq81JEv2RitKKfh6SDXM104re4hoyoVCI1atXQygUYtKkSQDonmpj06ZN4iVsnZycsHPnTjRp0gQA3U9dM+oSgai7mWTvAUmi7Tye9ktfGiOBQKD2PdMkrai7rrz0om2i5UkbKoZhsGrVKsTGxsLX11fcdkD3VHPu7u6YM2cOhgwZgtzcXEybNg0PHz4EQPdT14y6RKDtmsimztraWu17pmlaQP7Pwxh+FgKBACtXrsTRo0fh4eGBLVu2iB8edE81N3HiRPG/o6KiMH/+fHz22Wc4ceIE3U8dM+oSAa2JrB17e3uFxd+a98ze3h48Hk/uW5LovkumlTyHsrQNTVlZGRYsWICjR4/Cy8sLv//+O1xdXcX76Z7WTmBgIHr37o1nz57h1atXdD91zKgDAa2JrB0vLy/k5OSgvLxcZt/r16/BZrPRqlUrcVoAcu+xaJu3t7fGaRuSgoICzJw5E9HR0ejQoQP27dsHNzc3qTR0T1UTCAS4evUqrly5Ine/6J7m5eXR/dQxow4EAK2JrI2AgAAIhULcunVLajuPx8Pdu3fh4+MjbjgLCAgAALndcK9fvw47Ozu0adNGZdobN26AzWbDz89Pp9+lrvF4PISFhSE+Ph49evTA7t270axZM5l0dE/VM3/+fCxbtkzcr19SQkICWCwWWrZsSfdTx4w+ENCayJobPXo0zMzMsHnzZqni9NatW1FcXCx1zwYPHozGjRtjx44d4h4XAHD48GEkJSVh4sSJ4j72PXr0gJubGw4ePCj1xhUbG4srV65gyJAhDa731g8//IC4uDh07doV27dvl9udEaB7qg5zc3Nxw/DOnTul9u3btw8PHjxAYGAgnJyc6H7qmEnMNfTJJ5/gn3/+gZ+fn8yayJs2bTLZ5TCPHj2Kzz//XO5cQ9999x22b9+ONm3aICgoCM+fP0dUVBT8/f3x22+/SfWq2L9/P7788ku0aNECI0aMQGZmJk6dOgVPT08cPHhQquotKioKCxYsgJ2dHUaPHo3S0lKcOHECtra2+OOPP+T23zZU2dnZCAoKAp/Px7vvvosWLVrITffBBx/AysqK7qkaMjMzMWnSJGRkZKBfv37gcDh4/PgxYmNj0bJlS+zbt0/c9kL3U3dMIhDw+Xxs27YNf/75JzIzM8UDU+bNm6ewW5kpUBYIGIbBvn37sG/fPrx69QrOzs4YMmQIFi5cKLex7J9//sGOHTvw/PlzNGnSBP369cMnn3wCFxcXmbRXr17F5s2b8ejRI9jY2KBbt25YsmSJuH62oYiMjMS//vUvlelu3rwJe3t7uqdqys7ORnh4OC5evIi8vDy4uLhgyJAh+PDDD+Ho6ChOR/dTd0wiEBBCCFHM6NsICCGEKEeBgBBCTBwFAkIIMXEUCAghxMRRICCEEBNHgYAQQkwcBQJCCDFxFAhMSEREBLhcLkJDQ6Fo+EhhYaE4jb6I8hkZGam3PGhDIBDg22+/Rd++fdGpUyeMHj1aYdrr16+Dy+VixYoVUtuLioqwZ8+eus6qWk6ePClesQuoGoDI5XKxa9cu/WWK1AkKBCboxo0bOHz4sL6zYXQOHz6MX375BXZ2dpg5cybGjx+v8TmGDRsmtfC6vqxfvx5Lly6VmsK9ffv2WLhwIU3UaISMemEaotj69esRFBQkXgyc1N6jR48AAKtWrUKfPn20OkdOTg6cnZ11mS2t81FT+/bt0b59ez3khtQ1KhGYoA4dOqCgoABr1qzRd1aMimgWTMn5cAhpCCgQmKB58+bB29sbp06dwsWLF1WmV1Y3HBoaCi6Xi8LCQgBVi3dwuVxs2bIFZ8+exbhx4+Dn54fg4GD8+uuvAIDbt29j6tSp6NKlC4KDgxERESFeX1pSeXk51q5di969e6NLly4IDQ3F9evX5ebx1KlTmDJlCrp27Qp/f3/MnDkT165dk0ojqpfft28flixZAj8/P/Tr1w+3b99W+v2vXLmC2bNnw9/fH35+fhg3bhz27t0rntZc9J3//PNPAFVTn3O5XIV5lUeUN6Bq3n0ul4uIiAjx/uzsbHz55ZcYMGAAfH19ERwcjPXr18usvhcaGorg4GBER0cjODgYnTt3xuLFi8X7jx07htDQUHTv3h2+vr7o168fli5dKtUWEBwcLPVdgoODASj+Pbh37x4WLFiAnj17olOnTggJCcHWrVtlVgQT5S0jIwNLly5Fz5490blzZ0ybNk3mXgkEAmzevBmjR49G586d0aNHD8ydOxexsbFq31OiPgoEJsjS0hJr1qwBi8XCV199pXApz9o4e/YslixZgjZt2mDy5MkoKSnBunXrsGbNGsyaNQuOjo547733wDAMNm/ejL1798qcY926dTh+/DhCQkIwfPhw3L9/H7Nnz0ZUVJRUuk2bNuHjjz9GVlYWxo0bh3HjxuH58+eYPXs2jh8/LnPeH3/8Effv38f06dPRoUMHdOjQQeH32L17N+bMmYP79+9jyJAhePfdd1FUVISvv/4aS5cuBcMwsLe3x8KFC9GuXTsAwOTJk7Fw4UK4u7urfb/c3d2xcOFCAICTkxMWLlyIHj16AADS0tIwYcIEHDhwAB07dsSsWbPg7e2NHTt2IDQ0FKWlpVLnysvLw8cffwx/f3+MGzcO3bp1AwB8++23+Oyzz1BYWIhx48Zh2rRpcHFxwcmTJxEaGipe7WvGjBlS32XGjBkK8x0ZGYn33nsPly9fRp8+fTBlyhSYmZlhw4YNmD17tkwwKCkpwdSpU5GQkICxY8di8ODBuHPnDubOnYtXr16J061evRoRERFwcHDA9OnTMXz4cMTHx2Pu3LkaBViiJoaYjPDwcIbD4TDnzp1jGIZhVq5cyXA4HGb16tXiNAUFBQyHw2GmT5/+/+3df0hV5x/A8Xel5q79ckv7pRtFHssfXbQuRULXmiZoZcIaouZAcGONFRUl9MsKsx9UVNRq2rCyhCR1i0USOjZvq9aCslmmoKtuaVqGomlY+eyPOOd7j/dm6hS+7D6v/87nPD73uY96Puc8z3N4tFhBQYFQFEXk5OTY1ZmUlCQURREtLS1CCCGsVqtQFEX3OUIIYbFYtPjp06e1uFr+s88+s2unyWQSVqtVi9+5c0cYjUYRHh4uXr9+LYQQory8XPj7+4ukpCTR3t6ulX3+/LmIjIwURqNRNDU1CSGEuHbtmlAURRiNRtHY2Pje/nr48KEICAgQ4eHh4uHDh1r8xYsXIjk5WSiKIoqKirR4WlqaUBRF3L179711q21JS0vTxRVFEUuWLNHFUlNThb+/v/jll1908ZMnTwpFUcTu3bu1mPr72Llzp67skydPxLRp00RiYqLWd7b1K4oiLBZLj9+l+99Ba2urMJlMIjQ0VFRUVGjlXr16JdauXSsURRGHDx+2a9vXX38tOjs7tfjRo0eFoijiwIEDWr1qW23dvn1bKIoivv32WyENLPlE4MTWrVuHl5cXZ86c4datWwNa96RJk4iIiNCOQ0NDATAYDMTHx2txHx8fxo4dy+PHj+3qSE5OxsfHRzsOCAhgyZIl1NXVaVsUnjt3DiEE69ev54MPPtDKenp6kpqaSkdHBxcvXtTVO3PmzF5NyJ4/f57Xr1/zzTff6DYjMRgMbNq0CYCCgoL31vNvNDY2UlZWhtlsZv78+bpzSUlJTJgwgcLCQrufi4qK0h27ubmxZ88eNm7cyLBhw3TnTCYT4HiCuCclJSW0tLSQnJxMYGCgFndxcWHDhg24u7s77J+UlBRcXV21Y7PZDMD9+/cB6OrqQghBXV0d9fX1Wrng4GBKSkrYt29fn9opvZ9cNeTERo4cyebNm1m5ciWbN292eEHpL3XjcJXBYABg/Pjxdhei4cOHa3MMttTkYWvGjBmcPXuWe/fuMXv2bO7cuQO8HYrqPmT05MkTACorK3Xx3g7Z3Lt3D/jfhdKWn58fo0aN0soMlrt37yKEoLm5WTdnoHJ1daW+vp6GhgZt5y6w/46enp4sXryYrq4uqqurqampwWq1UlVVxZUrVwC0OY/e6ql/PvzwQyZPnkxlZSWtra26jWK6b+6ibu+pDiONGjWK6OhoLly4QGRkJCEhIcybN4/58+czderUPrVR6h2ZCJxcVFQUn376KaWlpRw/fpzExMQBqdf27txWX3aEc7QJvIeHB4A2Lt7a2gpAVlbWO+tpaWnRHQ8fPrxXn6/OnTja7QrA29ubBw8e9Kqu/lIT5K1bt3p8amtubtYlAnd3d7syly5dYt++fdqdt8FgICgoiGnTpnHlypV3vmT4Lmr/vGufZm9vbyorK+no6ND1Yfe/AXWrWNvP3717N0FBQRQWFnL9+nWuX7/O3r17CQoKIiMjQy5jHWAyEUikp6fzxx9/8N133xEWFmZ3vqc9nTs6OgatXepF3lZjYyMAo0ePBt5ezIYNG0Z5ebluuGEgqEmnsbHR4YblLS0tur1uB4P6JLVixQrd6p++Ki8vZ9WqVYwfP579+/cTHByMr68vQ4YMISsrS3sq6Avb/nFETWL96SNXV1dSUlJISUmhrq6O33//neLiYi5fvsxXX31FaWnpgP++nZmcI5AYN24ca9asobOzk/T0dLvz6j/cixcvdHEhhG7Z4UD766+/7GLqXXFQUBAA/v7+vHnzxm74B+DmzZvs3btXm0/oK3XljKOff/DgAU+fPsXPz69fdfeWuqS0oqLC4flDhw6RlZVltzqnuwsXLtDV1UV6ejoxMTF8/PHHWoKvra0F9HfkPSV/lXpX7mj5bVtbG5WVlXzyySd93hfcarWyf/9+bWnzxIkTWbZsGT/88ANz5syhoaGBR48e9alOqWcyEUgAJCQkEBISor0da2vKlCkAWCwW3rx5o8Xz8vJobm4etDbl5uby/Plz7fjGjRsUFxfj5+fHjBkzAIiLiwMgMzNTtwy2ra2NrVu3kp2drWtzX8TGxuLi4sKxY8d0Ca+9vZ3t27drZQaSq6srr1690o59fX0xmUyUlZVRXFysK/vjjz9y5MgRLBbLey+26nDYs2fPdPGrV6/y888/A+je5XBxeTtYYNuW7iIiIhg5ciR5eXnaXI1az44dO3j58mW/+sfd3Z3s7GwOHjyoS3CdnZ08ffoUNze3/4u3r/9L5NCQBLy9A8zIyGDp0qV2//wBAQEEBgZy8+ZNEhISMJlMVFdXc/XqVYxGI+Xl5YPSJhcXF2JjY4mOjqapqYni4mLc3d3ZuXOnVmbOnDksX76c3NxcYmJiMJvNuLm5UVJSQn19PfHx8cyePbtfn+/r60taWho7duwgLi6OiIgIDAYDZWVlWK1WYmJiWLp06UB9XeDtuHptbS3p6emYzWYWLFjA9u3bSUxMZNWqVcybNw8/Pz/+/vtvfv31V8aMGePwKa676OhocnJy2LZtG3/++SdeXl5UVVVx+fJlPD09aWpq0iV1db5h165dzJ07V3vHwdaIESPIzMxk9erVxMfHExkZyUcffcS1a9eorq5m1qxZpKam9rkPvLy8+OKLL8jJyWHRokWYzWaGDh2KxWKhpqaGFStWvHNeQuof+UQgaaZOncqXX37p8Nz3339PXFwc9+/f5/Tp07S3t3Py5EmMRuOgtSczM5Pw8HAKCwspLS0lLCyMs2fPEhwcrCu3adMm9uzZw4QJEzh//jxFRUWMHTuWzMzMXl0ke5KcnEx2djaBgYFcunSJoqIixowZQ0ZGxqAsY9yyZQs+Pj4UFBRQWloKvH0iKyws5PPPP6eqqopTp05RVVVFbGws586d69VKmunTp5OVlUVgYCAlJSXk5+fz7NkzVq5cyU8//cTQoUP57bfftPIJCQmEhYVRUVFBbm6u3bCgauHCheTl5REWFobFYiE/Px+A9evXc+LEiT4PC6nWrVvH1q1bGTFiBEVFReTn5+Ph4cGuXbv+1VyJ5NgQ0delApIkSdJ/inwikCRJcnIyEUiSJDk5mQgkSZKcnEwEkiRJTk4mAkmSJCcnE4EkSZKTk4lAkiTJyclEIEmS5ORkIpAkSXJyMhFIkiQ5uX8AEFjDf6AJQXQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(adam_net_accel.loss_history)\n",
    "\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Over Iterations\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7f) Visualize layer weights\n",
    "\n",
    "Run the following code and submit the inline image of the weight visualization of the 1st layer (convolutional layer) of the network.\n",
    "\n",
    "**Note:**\n",
    "- Setting optional parameter to `True` will let you save a .PNG file in your project folder of your weights. I'd suggest setting it to `False` unless look at your weights and they look like they are worth saving. You don't want a training run that produces undesirable weights to overwrite your good looking results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights(wts, saveFig=True, filename='convWts_adam_overfit.png'):\n",
    "    grid_sz = int(np.sqrt(len(wts)))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for x in range(grid_sz):\n",
    "        for y in range(grid_sz):\n",
    "            lin_ind = np.ravel_multi_index((x, y), dims=(grid_sz, grid_sz))\n",
    "            plt.subplot(grid_sz, grid_sz, lin_ind+1)\n",
    "            currImg = wts[lin_ind]\n",
    "            low, high = np.min(currImg), np.max(currImg)\n",
    "            currImg = 255*(currImg - low) / (high - low)\n",
    "            currImg = currImg.astype('uint8')\n",
    "            plt.imshow(currImg)\n",
    "            plt.gca().axis('off')\n",
    "    if saveFig:\n",
    "        plt.savefig('convWts_adam_overfit.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Subsitute your trained network below\n",
    "# netT is my network's name\n",
    "# You shouldn't see RGB noise\n",
    "plot_weights(adam_net_accel.layers[0].wts.transpose(0, 2, 3, 1), saveFig=False, filename='convWts_adam_train_20epoch.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6:** What do the learned filters look like? Does this make sense to you / is this what you expected? In which area of the brain do these filters resemble cell receptive fields?\n",
    "\n",
    "Note: you should not see RGB \"noise\". If you do, and you pass the \"overfit\" test with the Adam optimizer, you probably need to increase the number of training epochs.\n",
    "\n",
    "**Answer:** The filters seem to have some structure to them - there are some vertical, horizontal, and diagonal lines, and some center on/center off filters. Since these are the first layer filters, it makes sense that they are very fundamental/simple features. Cells like these are found in the Primary Visual Cortex (V1) of the primate brain as this is a combination of multiple cells from the LGN which forms complex filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "**General advice:** When making modifications for extensions, make small changes, then check to make sure you pass test code. Also, test out the network runtime on small examples before/after the changes. If you're not careful, the simulation time can become intractable really quickly!\n",
    "\n",
    "**Remember:** One thorough extension usually is worth more than several \"shallow\" extensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Save and load networks\n",
    "\n",
    "For this extension we implemented the ability to save and load any kind of network after it has been trained. This extension followed naturally from a fear of having to rerun the entire notebook with its long runtime in the event our Kernel was interrupted and we lost our network variables.\n",
    "\n",
    "To implement the extension, we wrote the networks hyperparams and weights to a text file, and then parse this text file to recreate the network later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the original network:  0.5175\n",
      "loading  Neural Network Model\n",
      "\n",
      "Accuracy of the new network:  0.5175\n"
     ]
    }
   ],
   "source": [
    "adam_net_accel.save_model(\"adam_net_accel.txt\")\n",
    "print(\"Accuracy of the original network: \",adam_net_accel.accuracy(x_test, y_test))\n",
    "\n",
    "#Create a new network\n",
    "loaded_adam_net_accel = convNet4Accel(input_shape=(3, 32, 32), wt_scale=1e-2, verbose=False)\n",
    "\n",
    "#Load the trained net into the newly created network\n",
    "loaded_adam_net_accel.load_model(\"adam_net_accel.txt\")\n",
    "print(\"Accuracy of the new network: \",loaded_adam_net_accel.accuracy(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. High Accuracy on STL-10\n",
    "\n",
    "We were able to achieve a high accuracy on the STL-10 dataset when we used a mini-batch size of 25, over 20 epochs, a weight-scale of 0.01, and a regularization of 0. The resulting accuracy was 51%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Experiment with different network architectures.\n",
    "\n",
    "The design of the `Network` class is modular. As long as you're careful about shapes, adding/removing network layers (e.g. `Conv2D`, `Dense`, etc.) should be straight forward. Experiment with adding another sequence of `Conv2D` and `MaxPooling2D` layers. Add another `Dense` hidden layer before the output layer. How do the changes affect classification accuracy and loss? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Exploring convolutional kernerls:\n",
    "\n",
    "We decided to toy with the number and size of convolutional kernels in our network. The original network was 32 7x7 kernels; we explore a 64 3x3 network as well as a 32 9x9 network.\n",
    "\n",
    "We find that despite the 64 3x3 network having only about a third as many weights in the convolutional layer, we do not lose out on any performance (it actually increases by 0.5%). This is promising, since we have a much smaller yet capable network. The filters still look like they are encoding some basic information, such as lines in different orientations and spots.\n",
    "\n",
    "For the 32 9x9 network, we see that despite an almost double increase in the number of weights in the model, we see that the accuracy does not improve (infact it decreases by 1.5%). This is in line with our predictions as although we use the same amount of kernels (32) the larger initial Convolution layers result in location specific features and larger features that would be quite image specific. However, the increase in the number of weights allows us more room to improve our model, these come to balance out eachother to result in only a small decrease in the accuracy. We do however, see some interesting filters. These filters encode large amounts of information as predicted, such as spherical looking objects, large gradients in colors, and bigger structures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train...\n",
      "3620 iterations. 181 iter/epoch.\n",
      "iteration: 0 | loss: 2.304380\n",
      "iteration: 1 | loss: 2.305613\n",
      "iteration: 2 | loss: 2.300858\n",
      "iteration: 3 | loss: 2.309360\n",
      "iteration: 4 | loss: 2.300884\n",
      "iteration: 5 | loss: 2.297068\n",
      "iteration: 6 | loss: 2.305005\n",
      "iteration: 7 | loss: 2.296763\n",
      "iteration: 8 | loss: 2.304207\n",
      "iteration: 9 | loss: 2.293069\n",
      "iteration: 10 | loss: 2.272635\n",
      "iteration: 11 | loss: 2.302707\n",
      "iteration: 12 | loss: 2.277796\n",
      "iteration: 13 | loss: 2.262089\n",
      "iteration: 14 | loss: 2.273206\n",
      "iteration: 15 | loss: 2.274984\n",
      "iteration: 16 | loss: 2.294863\n",
      "iteration: 17 | loss: 2.265246\n",
      "iteration: 18 | loss: 2.265383\n",
      "iteration: 19 | loss: 2.240906\n",
      "iteration: 20 | loss: 2.249753\n",
      "iteration: 21 | loss: 2.205706\n",
      "iteration: 22 | loss: 2.227339\n",
      "iteration: 23 | loss: 2.117598\n",
      "iteration: 24 | loss: 2.099524\n",
      "  Train acc: 0.206, Val acc: 0.0\n",
      "iteration: 25 | loss: 2.115364\n",
      "iteration: 26 | loss: 2.208562\n",
      "iteration: 27 | loss: 2.158541\n",
      "iteration: 28 | loss: 2.216174\n",
      "iteration: 29 | loss: 2.144463\n",
      "iteration: 30 | loss: 2.129545\n",
      "iteration: 31 | loss: 2.052372\n",
      "iteration: 32 | loss: 2.048425\n",
      "iteration: 33 | loss: 2.211643\n",
      "iteration: 34 | loss: 2.137767\n",
      "iteration: 35 | loss: 2.281017\n",
      "iteration: 36 | loss: 1.967826\n",
      "iteration: 37 | loss: 1.962637\n",
      "iteration: 38 | loss: 2.080694\n",
      "iteration: 39 | loss: 1.955497\n",
      "iteration: 40 | loss: 1.896440\n",
      "iteration: 41 | loss: 1.837000\n",
      "iteration: 42 | loss: 2.105539\n",
      "iteration: 43 | loss: 1.901738\n",
      "iteration: 44 | loss: 2.145629\n",
      "iteration: 45 | loss: 1.997669\n",
      "iteration: 46 | loss: 1.783573\n",
      "iteration: 47 | loss: 1.743349\n",
      "iteration: 48 | loss: 1.824581\n",
      "iteration: 49 | loss: 2.067987\n",
      "  Train acc: 0.288, Val acc: 0.0\n",
      "iteration: 50 | loss: 1.869539\n",
      "iteration: 51 | loss: 1.966176\n",
      "iteration: 52 | loss: 1.931505\n",
      "iteration: 53 | loss: 1.975427\n",
      "iteration: 54 | loss: 1.899338\n",
      "iteration: 55 | loss: 1.653189\n",
      "iteration: 56 | loss: 1.730199\n",
      "iteration: 57 | loss: 1.637920\n",
      "iteration: 58 | loss: 1.794155\n",
      "iteration: 59 | loss: 1.696678\n",
      "iteration: 60 | loss: 1.594991\n",
      "iteration: 61 | loss: 1.959266\n",
      "iteration: 62 | loss: 2.247469\n",
      "iteration: 63 | loss: 1.881719\n",
      "iteration: 64 | loss: 1.696080\n",
      "iteration: 65 | loss: 2.059605\n",
      "iteration: 66 | loss: 1.819186\n",
      "iteration: 67 | loss: 1.946419\n",
      "iteration: 68 | loss: 1.671806\n",
      "iteration: 69 | loss: 1.883488\n",
      "iteration: 70 | loss: 1.853456\n",
      "iteration: 71 | loss: 1.729848\n",
      "iteration: 72 | loss: 1.733876\n",
      "iteration: 73 | loss: 1.617528\n",
      "iteration: 74 | loss: 1.776993\n",
      "  Train acc: 0.276, Val acc: 0.0\n",
      "iteration: 75 | loss: 1.669489\n",
      "iteration: 76 | loss: 1.703154\n",
      "iteration: 77 | loss: 1.658923\n",
      "iteration: 78 | loss: 1.900643\n",
      "iteration: 79 | loss: 1.765393\n",
      "iteration: 80 | loss: 1.935862\n",
      "iteration: 81 | loss: 1.764442\n",
      "iteration: 82 | loss: 1.858265\n",
      "iteration: 83 | loss: 2.096232\n",
      "iteration: 84 | loss: 2.069942\n",
      "iteration: 85 | loss: 1.799324\n",
      "iteration: 86 | loss: 1.587303\n",
      "iteration: 87 | loss: 1.749045\n",
      "iteration: 88 | loss: 1.926663\n",
      "iteration: 89 | loss: 1.854070\n",
      "iteration: 90 | loss: 1.765629\n",
      "iteration: 91 | loss: 1.722393\n",
      "iteration: 92 | loss: 1.659182\n",
      "iteration: 93 | loss: 1.735659\n",
      "iteration: 94 | loss: 2.192367\n",
      "iteration: 95 | loss: 1.890962\n",
      "iteration: 96 | loss: 1.897319\n",
      "iteration: 97 | loss: 2.078447\n",
      "iteration: 98 | loss: 2.093276\n",
      "iteration: 99 | loss: 1.842737\n",
      "  Train acc: 0.322, Val acc: 0.0\n",
      "iteration: 100 | loss: 1.939742\n",
      "iteration: 101 | loss: 1.950983\n",
      "iteration: 102 | loss: 1.856923\n",
      "iteration: 103 | loss: 1.989326\n",
      "iteration: 104 | loss: 1.855223\n",
      "iteration: 105 | loss: 1.773413\n",
      "iteration: 106 | loss: 2.071388\n",
      "iteration: 107 | loss: 1.536406\n",
      "iteration: 108 | loss: 1.754176\n",
      "iteration: 109 | loss: 1.418539\n",
      "iteration: 110 | loss: 1.790465\n",
      "iteration: 111 | loss: 1.554249\n",
      "iteration: 112 | loss: 1.695793\n",
      "iteration: 113 | loss: 1.855131\n",
      "iteration: 114 | loss: 1.466604\n",
      "iteration: 115 | loss: 1.724547\n",
      "iteration: 116 | loss: 1.766447\n",
      "iteration: 117 | loss: 1.644241\n",
      "iteration: 118 | loss: 1.542087\n",
      "iteration: 119 | loss: 1.954666\n",
      "iteration: 120 | loss: 1.636981\n",
      "iteration: 121 | loss: 1.474420\n",
      "iteration: 122 | loss: 1.758059\n",
      "iteration: 123 | loss: 1.761776\n",
      "iteration: 124 | loss: 2.019705\n",
      "  Train acc: 0.326, Val acc: 0.0\n",
      "iteration: 125 | loss: 1.796774\n",
      "iteration: 126 | loss: 1.386342\n",
      "iteration: 127 | loss: 1.690711\n",
      "iteration: 128 | loss: 1.597993\n",
      "iteration: 129 | loss: 1.688791\n",
      "iteration: 130 | loss: 1.544618\n",
      "iteration: 131 | loss: 1.660444\n",
      "iteration: 132 | loss: 1.983427\n",
      "iteration: 133 | loss: 1.961177\n",
      "iteration: 134 | loss: 1.891784\n",
      "iteration: 135 | loss: 1.414805\n",
      "iteration: 136 | loss: 1.869190\n",
      "iteration: 137 | loss: 1.692877\n",
      "iteration: 138 | loss: 1.612780\n",
      "iteration: 139 | loss: 1.612725\n",
      "iteration: 140 | loss: 1.641281\n",
      "iteration: 141 | loss: 1.632910\n",
      "iteration: 142 | loss: 1.724152\n",
      "iteration: 143 | loss: 1.540583\n",
      "iteration: 144 | loss: 1.810836\n",
      "iteration: 145 | loss: 1.686723\n",
      "iteration: 146 | loss: 1.850810\n",
      "iteration: 147 | loss: 1.534639\n",
      "iteration: 148 | loss: 1.592711\n",
      "iteration: 149 | loss: 1.408769\n",
      "  Train acc: 0.41, Val acc: 0.0\n",
      "iteration: 150 | loss: 1.522412\n",
      "iteration: 151 | loss: 1.534755\n",
      "iteration: 152 | loss: 1.585484\n",
      "iteration: 153 | loss: 1.717411\n",
      "iteration: 154 | loss: 1.825254\n",
      "iteration: 155 | loss: 1.877871\n",
      "iteration: 156 | loss: 1.805316\n",
      "iteration: 157 | loss: 2.054530\n",
      "iteration: 158 | loss: 1.858372\n",
      "iteration: 159 | loss: 1.792868\n",
      "iteration: 160 | loss: 1.576312\n",
      "iteration: 161 | loss: 1.547442\n",
      "iteration: 162 | loss: 1.504304\n",
      "iteration: 163 | loss: 1.629704\n",
      "iteration: 164 | loss: 1.684177\n",
      "iteration: 165 | loss: 1.611722\n",
      "iteration: 166 | loss: 1.689103\n",
      "iteration: 167 | loss: 1.516158\n",
      "iteration: 168 | loss: 1.782165\n",
      "iteration: 169 | loss: 1.750630\n",
      "iteration: 170 | loss: 1.665104\n",
      "iteration: 171 | loss: 1.679023\n",
      "iteration: 172 | loss: 1.661836\n",
      "iteration: 173 | loss: 1.660715\n",
      "iteration: 174 | loss: 1.691006\n",
      "  Train acc: 0.39, Val acc: 0.0\n",
      "iteration: 175 | loss: 1.507718\n",
      "iteration: 176 | loss: 1.559050\n",
      "iteration: 177 | loss: 1.626777\n",
      "iteration: 178 | loss: 1.759509\n",
      "iteration: 179 | loss: 1.499141\n",
      "iteration: 180 | loss: 1.835692\n",
      "iteration: 181 | loss: 1.391783\n",
      "iteration: 182 | loss: 1.651223\n",
      "iteration: 183 | loss: 1.865451\n",
      "iteration: 184 | loss: 1.534183\n",
      "iteration: 185 | loss: 1.614267\n",
      "iteration: 186 | loss: 1.502263\n",
      "iteration: 187 | loss: 1.105441\n",
      "iteration: 188 | loss: 1.708078\n",
      "iteration: 189 | loss: 1.550790\n",
      "iteration: 190 | loss: 1.619898\n",
      "iteration: 191 | loss: 1.540695\n",
      "iteration: 192 | loss: 1.766817\n",
      "iteration: 193 | loss: 1.291273\n",
      "iteration: 194 | loss: 1.468799\n",
      "iteration: 195 | loss: 2.110640\n",
      "iteration: 196 | loss: 1.399979\n",
      "iteration: 197 | loss: 1.493449\n",
      "iteration: 198 | loss: 1.665932\n",
      "iteration: 199 | loss: 1.481018\n",
      "  Train acc: 0.452, Val acc: 0.0\n",
      "iteration: 200 | loss: 1.568621\n",
      "iteration: 201 | loss: 1.257646\n",
      "iteration: 202 | loss: 1.392164\n",
      "iteration: 203 | loss: 1.772632\n",
      "iteration: 204 | loss: 1.401719\n",
      "iteration: 205 | loss: 1.626248\n",
      "iteration: 206 | loss: 1.892527\n",
      "iteration: 207 | loss: 1.857202\n",
      "iteration: 208 | loss: 1.837867\n",
      "iteration: 209 | loss: 1.730014\n",
      "iteration: 210 | loss: 1.594786\n",
      "iteration: 211 | loss: 1.293668\n",
      "iteration: 212 | loss: 1.753135\n",
      "iteration: 213 | loss: 1.595653\n",
      "iteration: 214 | loss: 1.376706\n",
      "iteration: 215 | loss: 1.647082\n",
      "iteration: 216 | loss: 1.457678\n",
      "iteration: 217 | loss: 1.552226\n",
      "iteration: 218 | loss: 1.423012\n",
      "iteration: 219 | loss: 1.224098\n",
      "iteration: 220 | loss: 1.384400\n",
      "iteration: 221 | loss: 1.434161\n",
      "iteration: 222 | loss: 1.434024\n",
      "iteration: 223 | loss: 1.546466\n",
      "iteration: 224 | loss: 1.583205\n",
      "  Train acc: 0.412, Val acc: 0.0\n",
      "iteration: 225 | loss: 1.488218\n",
      "iteration: 226 | loss: 1.809725\n",
      "iteration: 227 | loss: 1.567524\n",
      "iteration: 228 | loss: 1.890504\n",
      "iteration: 229 | loss: 1.527248\n",
      "iteration: 230 | loss: 1.477108\n",
      "iteration: 231 | loss: 1.601485\n",
      "iteration: 232 | loss: 1.472984\n",
      "iteration: 233 | loss: 1.488047\n",
      "iteration: 234 | loss: 1.329605\n",
      "iteration: 235 | loss: 1.445742\n",
      "iteration: 236 | loss: 1.631597\n",
      "iteration: 237 | loss: 1.576464\n",
      "iteration: 238 | loss: 1.489613\n",
      "iteration: 239 | loss: 1.579414\n",
      "iteration: 240 | loss: 1.470157\n",
      "iteration: 241 | loss: 1.490934\n",
      "iteration: 242 | loss: 1.514430\n",
      "iteration: 243 | loss: 1.365837\n",
      "iteration: 244 | loss: 1.486144\n",
      "iteration: 245 | loss: 1.523725\n",
      "iteration: 246 | loss: 1.368530\n",
      "iteration: 247 | loss: 1.633745\n",
      "iteration: 248 | loss: 1.482993\n",
      "iteration: 249 | loss: 1.490443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train acc: 0.468, Val acc: 0.0\n",
      "iteration: 250 | loss: 1.181299\n",
      "iteration: 251 | loss: 1.634419\n",
      "iteration: 252 | loss: 1.570108\n",
      "iteration: 253 | loss: 1.596555\n",
      "iteration: 254 | loss: 1.847137\n",
      "iteration: 255 | loss: 1.384558\n",
      "iteration: 256 | loss: 1.224932\n",
      "iteration: 257 | loss: 1.705106\n",
      "iteration: 258 | loss: 1.496401\n",
      "iteration: 259 | loss: 1.384873\n",
      "iteration: 260 | loss: 1.190441\n",
      "iteration: 261 | loss: 1.441613\n",
      "iteration: 262 | loss: 1.360549\n",
      "iteration: 263 | loss: 1.628536\n",
      "iteration: 264 | loss: 1.566020\n",
      "iteration: 265 | loss: 1.363994\n",
      "iteration: 266 | loss: 1.248847\n",
      "iteration: 267 | loss: 1.334624\n",
      "iteration: 268 | loss: 1.156125\n",
      "iteration: 269 | loss: 1.449277\n",
      "iteration: 270 | loss: 1.398952\n",
      "iteration: 271 | loss: 1.187636\n",
      "iteration: 272 | loss: 1.170562\n",
      "iteration: 273 | loss: 1.416273\n",
      "iteration: 274 | loss: 1.335761\n",
      "  Train acc: 0.428, Val acc: 0.0\n",
      "iteration: 275 | loss: 1.554484\n",
      "iteration: 276 | loss: 1.435991\n",
      "iteration: 277 | loss: 1.422310\n",
      "iteration: 278 | loss: 1.415911\n",
      "iteration: 279 | loss: 1.105824\n",
      "iteration: 280 | loss: 1.307149\n",
      "iteration: 281 | loss: 1.348508\n",
      "iteration: 282 | loss: 1.222782\n",
      "iteration: 283 | loss: 1.274497\n",
      "iteration: 284 | loss: 1.562653\n",
      "iteration: 285 | loss: 1.436806\n",
      "iteration: 286 | loss: 1.316308\n",
      "iteration: 287 | loss: 1.557066\n",
      "iteration: 288 | loss: 1.614894\n",
      "iteration: 289 | loss: 1.502411\n",
      "iteration: 290 | loss: 1.174990\n",
      "iteration: 291 | loss: 1.556922\n",
      "iteration: 292 | loss: 1.409913\n",
      "iteration: 293 | loss: 1.380443\n",
      "iteration: 294 | loss: 1.529780\n",
      "iteration: 295 | loss: 1.385684\n",
      "iteration: 296 | loss: 1.407100\n",
      "iteration: 297 | loss: 1.288759\n",
      "iteration: 298 | loss: 1.317572\n",
      "iteration: 299 | loss: 1.252459\n",
      "  Train acc: 0.472, Val acc: 0.0\n",
      "iteration: 300 | loss: 1.298398\n",
      "iteration: 301 | loss: 1.407477\n",
      "iteration: 302 | loss: 1.277219\n",
      "iteration: 303 | loss: 1.331730\n",
      "iteration: 304 | loss: 1.290611\n",
      "iteration: 305 | loss: 1.623696\n",
      "iteration: 306 | loss: 1.102851\n",
      "iteration: 307 | loss: 1.619117\n",
      "iteration: 308 | loss: 1.499689\n",
      "iteration: 309 | loss: 1.294047\n",
      "iteration: 310 | loss: 1.342825\n",
      "iteration: 311 | loss: 1.356714\n",
      "iteration: 312 | loss: 1.399693\n",
      "iteration: 313 | loss: 1.309052\n",
      "iteration: 314 | loss: 1.346381\n",
      "iteration: 315 | loss: 1.343509\n",
      "iteration: 316 | loss: 1.499566\n",
      "iteration: 317 | loss: 1.464755\n",
      "iteration: 318 | loss: 1.744195\n",
      "iteration: 319 | loss: 1.133418\n",
      "iteration: 320 | loss: 1.536033\n",
      "iteration: 321 | loss: 1.524591\n",
      "iteration: 322 | loss: 1.353585\n",
      "iteration: 323 | loss: 1.180786\n",
      "iteration: 324 | loss: 1.162810\n",
      "  Train acc: 0.446, Val acc: 0.0\n",
      "iteration: 325 | loss: 1.389780\n",
      "iteration: 326 | loss: 1.515181\n",
      "iteration: 327 | loss: 1.304885\n",
      "iteration: 328 | loss: 1.042556\n",
      "iteration: 329 | loss: 1.547204\n",
      "iteration: 330 | loss: 1.324653\n",
      "iteration: 331 | loss: 1.221282\n",
      "iteration: 332 | loss: 1.266148\n",
      "iteration: 333 | loss: 1.508000\n",
      "iteration: 334 | loss: 1.336338\n",
      "iteration: 335 | loss: 1.368848\n",
      "iteration: 336 | loss: 1.697715\n",
      "iteration: 337 | loss: 1.204128\n",
      "iteration: 338 | loss: 1.180871\n",
      "iteration: 339 | loss: 1.558140\n",
      "iteration: 340 | loss: 1.371411\n",
      "iteration: 341 | loss: 1.874315\n",
      "iteration: 342 | loss: 1.213875\n",
      "iteration: 343 | loss: 1.002967\n",
      "iteration: 344 | loss: 1.063539\n",
      "iteration: 345 | loss: 1.015892\n",
      "iteration: 346 | loss: 1.530692\n",
      "iteration: 347 | loss: 1.204387\n",
      "iteration: 348 | loss: 1.553704\n",
      "iteration: 349 | loss: 1.226308\n",
      "  Train acc: 0.492, Val acc: 0.5\n",
      "iteration: 350 | loss: 1.576210\n",
      "iteration: 351 | loss: 1.458467\n",
      "iteration: 352 | loss: 1.225791\n",
      "iteration: 353 | loss: 1.506310\n",
      "iteration: 354 | loss: 1.352196\n",
      "iteration: 355 | loss: 1.301955\n",
      "iteration: 356 | loss: 1.550093\n",
      "iteration: 357 | loss: 1.653891\n",
      "iteration: 358 | loss: 1.286428\n",
      "iteration: 359 | loss: 1.410203\n",
      "iteration: 360 | loss: 1.265252\n",
      "iteration: 361 | loss: 1.464628\n",
      "iteration: 362 | loss: 1.369071\n",
      "iteration: 363 | loss: 1.175873\n",
      "iteration: 364 | loss: 1.257429\n",
      "iteration: 365 | loss: 1.679103\n",
      "iteration: 366 | loss: 1.367561\n",
      "iteration: 367 | loss: 1.410677\n",
      "iteration: 368 | loss: 1.294856\n",
      "iteration: 369 | loss: 1.065735\n",
      "iteration: 370 | loss: 1.129836\n",
      "iteration: 371 | loss: 1.291543\n",
      "iteration: 372 | loss: 1.396795\n",
      "iteration: 373 | loss: 1.350764\n",
      "iteration: 374 | loss: 0.927118\n",
      "  Train acc: 0.484, Val acc: 0.5\n",
      "iteration: 375 | loss: 1.311599\n",
      "iteration: 376 | loss: 1.517858\n",
      "iteration: 377 | loss: 1.031713\n",
      "iteration: 378 | loss: 1.389028\n",
      "iteration: 379 | loss: 1.148481\n",
      "iteration: 380 | loss: 1.223531\n",
      "iteration: 381 | loss: 1.255008\n",
      "iteration: 382 | loss: 1.227327\n",
      "iteration: 383 | loss: 1.165154\n",
      "iteration: 384 | loss: 1.375157\n",
      "iteration: 385 | loss: 1.359867\n",
      "iteration: 386 | loss: 1.418269\n",
      "iteration: 387 | loss: 1.184097\n",
      "iteration: 388 | loss: 1.609358\n",
      "iteration: 389 | loss: 1.367227\n",
      "iteration: 390 | loss: 1.877751\n",
      "iteration: 391 | loss: 1.256738\n",
      "iteration: 392 | loss: 1.367552\n",
      "iteration: 393 | loss: 1.114201\n",
      "iteration: 394 | loss: 0.933327\n",
      "iteration: 395 | loss: 1.202250\n",
      "iteration: 396 | loss: 1.104497\n",
      "iteration: 397 | loss: 1.042135\n",
      "iteration: 398 | loss: 1.518264\n",
      "iteration: 399 | loss: 1.098067\n",
      "  Train acc: 0.528, Val acc: 0.5\n",
      "iteration: 400 | loss: 1.272708\n",
      "iteration: 401 | loss: 1.423292\n",
      "iteration: 402 | loss: 1.350402\n",
      "iteration: 403 | loss: 1.252093\n",
      "iteration: 404 | loss: 1.521208\n",
      "iteration: 405 | loss: 1.221520\n",
      "iteration: 406 | loss: 1.294131\n",
      "iteration: 407 | loss: 1.096980\n",
      "iteration: 408 | loss: 1.340301\n",
      "iteration: 409 | loss: 1.418649\n",
      "iteration: 410 | loss: 1.614765\n",
      "iteration: 411 | loss: 1.326663\n",
      "iteration: 412 | loss: 1.513873\n",
      "iteration: 413 | loss: 0.940320\n",
      "iteration: 414 | loss: 1.326735\n",
      "iteration: 415 | loss: 0.872612\n",
      "iteration: 416 | loss: 1.116546\n",
      "iteration: 417 | loss: 1.342953\n",
      "iteration: 418 | loss: 1.499470\n",
      "iteration: 419 | loss: 1.221883\n",
      "iteration: 420 | loss: 1.325034\n",
      "iteration: 421 | loss: 1.132232\n",
      "iteration: 422 | loss: 1.187756\n",
      "iteration: 423 | loss: 1.297807\n",
      "iteration: 424 | loss: 1.563321\n",
      "  Train acc: 0.482, Val acc: 0.5\n",
      "iteration: 425 | loss: 1.535800\n",
      "iteration: 426 | loss: 1.375313\n",
      "iteration: 427 | loss: 0.993294\n",
      "iteration: 428 | loss: 1.408333\n",
      "iteration: 429 | loss: 1.050545\n",
      "iteration: 430 | loss: 1.282099\n",
      "iteration: 431 | loss: 1.277583\n",
      "iteration: 432 | loss: 1.583090\n",
      "iteration: 433 | loss: 1.299770\n",
      "iteration: 434 | loss: 1.073403\n",
      "iteration: 435 | loss: 1.388542\n",
      "iteration: 436 | loss: 1.172944\n",
      "iteration: 437 | loss: 1.422323\n",
      "iteration: 438 | loss: 1.399466\n",
      "iteration: 439 | loss: 1.400497\n",
      "iteration: 440 | loss: 1.133290\n",
      "iteration: 441 | loss: 1.100339\n",
      "iteration: 442 | loss: 1.509364\n",
      "iteration: 443 | loss: 0.910871\n",
      "iteration: 444 | loss: 1.235506\n",
      "iteration: 445 | loss: 1.210948\n",
      "iteration: 446 | loss: 1.226688\n",
      "iteration: 447 | loss: 1.235797\n",
      "iteration: 448 | loss: 1.267645\n",
      "iteration: 449 | loss: 1.291626\n",
      "  Train acc: 0.532, Val acc: 0.0\n",
      "iteration: 450 | loss: 1.355501\n",
      "iteration: 451 | loss: 1.450538\n",
      "iteration: 452 | loss: 1.271313\n",
      "iteration: 453 | loss: 1.288041\n",
      "iteration: 454 | loss: 1.262210\n",
      "iteration: 455 | loss: 1.303633\n",
      "iteration: 456 | loss: 1.046593\n",
      "iteration: 457 | loss: 1.507633\n",
      "iteration: 458 | loss: 1.305921\n",
      "iteration: 459 | loss: 1.242589\n",
      "iteration: 460 | loss: 1.002375\n",
      "iteration: 461 | loss: 1.297382\n",
      "iteration: 462 | loss: 1.027542\n",
      "iteration: 463 | loss: 1.359009\n",
      "iteration: 464 | loss: 1.146086\n",
      "iteration: 465 | loss: 1.388009\n",
      "iteration: 466 | loss: 1.125097\n",
      "iteration: 467 | loss: 1.026741\n",
      "iteration: 468 | loss: 1.327680\n",
      "iteration: 469 | loss: 1.173305\n",
      "iteration: 470 | loss: 1.046695\n",
      "iteration: 471 | loss: 1.384942\n",
      "iteration: 472 | loss: 1.431153\n",
      "iteration: 473 | loss: 1.053710\n",
      "iteration: 474 | loss: 1.504953\n",
      "  Train acc: 0.538, Val acc: 0.5\n",
      "iteration: 475 | loss: 1.138906\n",
      "iteration: 476 | loss: 1.556439\n",
      "iteration: 477 | loss: 1.217479\n",
      "iteration: 478 | loss: 1.274844\n",
      "iteration: 479 | loss: 1.224713\n",
      "iteration: 480 | loss: 1.191446\n",
      "iteration: 481 | loss: 1.118539\n",
      "iteration: 482 | loss: 1.114749\n",
      "iteration: 483 | loss: 1.011541\n",
      "iteration: 484 | loss: 1.048855\n",
      "iteration: 485 | loss: 1.556262\n",
      "iteration: 486 | loss: 1.307429\n",
      "iteration: 487 | loss: 1.334432\n",
      "iteration: 488 | loss: 1.279372\n",
      "iteration: 489 | loss: 0.793640\n",
      "iteration: 490 | loss: 1.060051\n",
      "iteration: 491 | loss: 1.120318\n",
      "iteration: 492 | loss: 0.914519\n",
      "iteration: 493 | loss: 1.207275\n",
      "iteration: 494 | loss: 0.991335\n",
      "iteration: 495 | loss: 1.278614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 496 | loss: 1.159190\n",
      "iteration: 497 | loss: 1.324320\n",
      "iteration: 498 | loss: 1.520655\n",
      "iteration: 499 | loss: 1.132839\n",
      "  Train acc: 0.552, Val acc: 0.5\n",
      "iteration: 500 | loss: 1.266906\n",
      "iteration: 501 | loss: 1.093410\n",
      "iteration: 502 | loss: 0.943353\n",
      "iteration: 503 | loss: 1.291688\n",
      "iteration: 504 | loss: 1.175563\n",
      "iteration: 505 | loss: 0.945818\n",
      "iteration: 506 | loss: 0.887339\n",
      "iteration: 507 | loss: 1.270420\n",
      "iteration: 508 | loss: 1.123615\n",
      "iteration: 509 | loss: 1.483538\n",
      "iteration: 510 | loss: 1.549443\n",
      "iteration: 511 | loss: 1.073166\n",
      "iteration: 512 | loss: 1.577673\n",
      "iteration: 513 | loss: 1.131713\n",
      "iteration: 514 | loss: 1.401131\n",
      "iteration: 515 | loss: 1.337890\n",
      "iteration: 516 | loss: 1.160479\n",
      "iteration: 517 | loss: 1.173369\n",
      "iteration: 518 | loss: 1.128001\n",
      "iteration: 519 | loss: 1.207886\n",
      "iteration: 520 | loss: 1.373120\n",
      "iteration: 521 | loss: 1.109814\n",
      "iteration: 522 | loss: 1.468781\n",
      "iteration: 523 | loss: 1.065416\n",
      "iteration: 524 | loss: 1.297050\n",
      "  Train acc: 0.578, Val acc: 0.5\n",
      "iteration: 525 | loss: 1.002012\n",
      "iteration: 526 | loss: 1.316615\n",
      "iteration: 527 | loss: 1.112250\n",
      "iteration: 528 | loss: 0.918906\n",
      "iteration: 529 | loss: 1.171497\n",
      "iteration: 530 | loss: 0.941632\n",
      "iteration: 531 | loss: 1.402526\n",
      "iteration: 532 | loss: 1.065685\n",
      "iteration: 533 | loss: 0.983744\n",
      "iteration: 534 | loss: 1.251541\n",
      "iteration: 535 | loss: 0.931475\n",
      "iteration: 536 | loss: 1.156807\n",
      "iteration: 537 | loss: 1.186916\n",
      "iteration: 538 | loss: 1.201871\n",
      "iteration: 539 | loss: 1.075530\n",
      "iteration: 540 | loss: 1.080139\n",
      "iteration: 541 | loss: 1.314949\n",
      "iteration: 542 | loss: 1.184932\n",
      "iteration: 543 | loss: 1.430652\n",
      "iteration: 544 | loss: 1.158139\n",
      "iteration: 545 | loss: 1.419736\n",
      "iteration: 546 | loss: 1.425577\n",
      "iteration: 547 | loss: 1.474022\n",
      "iteration: 548 | loss: 1.238432\n",
      "iteration: 549 | loss: 1.116724\n",
      "  Train acc: 0.578, Val acc: 0.5\n",
      "iteration: 550 | loss: 1.323821\n",
      "iteration: 551 | loss: 1.224027\n",
      "iteration: 552 | loss: 1.033672\n",
      "iteration: 553 | loss: 1.540013\n",
      "iteration: 554 | loss: 1.325200\n",
      "iteration: 555 | loss: 1.197825\n",
      "iteration: 556 | loss: 1.472002\n",
      "iteration: 557 | loss: 1.416436\n",
      "iteration: 558 | loss: 0.827784\n",
      "iteration: 559 | loss: 1.059375\n",
      "iteration: 560 | loss: 1.314120\n",
      "iteration: 561 | loss: 1.232181\n",
      "iteration: 562 | loss: 1.192125\n",
      "iteration: 563 | loss: 1.140568\n",
      "iteration: 564 | loss: 1.509562\n",
      "iteration: 565 | loss: 1.051934\n",
      "iteration: 566 | loss: 1.062245\n",
      "iteration: 567 | loss: 1.157453\n",
      "iteration: 568 | loss: 1.151976\n",
      "iteration: 569 | loss: 1.308798\n",
      "iteration: 570 | loss: 0.790594\n",
      "iteration: 571 | loss: 1.086475\n",
      "iteration: 572 | loss: 1.019201\n",
      "iteration: 573 | loss: 0.925834\n",
      "iteration: 574 | loss: 0.926893\n",
      "  Train acc: 0.586, Val acc: 0.5\n",
      "iteration: 575 | loss: 0.911103\n",
      "iteration: 576 | loss: 1.013292\n",
      "iteration: 577 | loss: 0.904250\n",
      "iteration: 578 | loss: 0.940486\n",
      "iteration: 579 | loss: 1.237610\n",
      "iteration: 580 | loss: 0.924611\n",
      "iteration: 581 | loss: 1.072232\n",
      "iteration: 582 | loss: 1.236634\n",
      "iteration: 583 | loss: 1.206744\n",
      "iteration: 584 | loss: 1.214673\n",
      "iteration: 585 | loss: 0.935632\n",
      "iteration: 586 | loss: 0.806504\n",
      "iteration: 587 | loss: 0.966048\n",
      "iteration: 588 | loss: 1.360218\n",
      "iteration: 589 | loss: 0.970987\n",
      "iteration: 590 | loss: 1.173740\n",
      "iteration: 591 | loss: 1.225834\n",
      "iteration: 592 | loss: 1.231284\n",
      "iteration: 593 | loss: 0.988272\n",
      "iteration: 594 | loss: 0.868223\n",
      "iteration: 595 | loss: 0.832032\n",
      "iteration: 596 | loss: 1.161890\n",
      "iteration: 597 | loss: 0.871282\n",
      "iteration: 598 | loss: 1.297334\n",
      "iteration: 599 | loss: 1.035359\n",
      "  Train acc: 0.526, Val acc: 0.5\n",
      "iteration: 600 | loss: 0.992803\n",
      "iteration: 601 | loss: 1.083143\n",
      "iteration: 602 | loss: 0.910418\n",
      "iteration: 603 | loss: 1.186001\n",
      "iteration: 604 | loss: 1.472200\n",
      "iteration: 605 | loss: 1.640570\n",
      "iteration: 606 | loss: 1.134786\n",
      "iteration: 607 | loss: 1.521137\n",
      "iteration: 608 | loss: 1.064036\n",
      "iteration: 609 | loss: 1.253678\n",
      "iteration: 610 | loss: 1.139258\n",
      "iteration: 611 | loss: 0.805476\n",
      "iteration: 612 | loss: 1.019622\n",
      "iteration: 613 | loss: 1.407560\n",
      "iteration: 614 | loss: 1.139291\n",
      "iteration: 615 | loss: 1.015218\n",
      "iteration: 616 | loss: 0.905584\n",
      "iteration: 617 | loss: 1.145171\n",
      "iteration: 618 | loss: 1.010623\n",
      "iteration: 619 | loss: 1.227204\n",
      "iteration: 620 | loss: 1.092027\n",
      "iteration: 621 | loss: 1.225897\n",
      "iteration: 622 | loss: 0.807584\n",
      "iteration: 623 | loss: 1.117327\n",
      "iteration: 624 | loss: 1.546753\n",
      "  Train acc: 0.602, Val acc: 0.5\n",
      "iteration: 625 | loss: 1.189006\n",
      "iteration: 626 | loss: 1.590720\n",
      "iteration: 627 | loss: 1.117765\n",
      "iteration: 628 | loss: 1.290828\n",
      "iteration: 629 | loss: 0.911417\n",
      "iteration: 630 | loss: 1.145888\n",
      "iteration: 631 | loss: 1.284427\n",
      "iteration: 632 | loss: 0.891298\n",
      "iteration: 633 | loss: 0.908604\n",
      "iteration: 634 | loss: 1.085906\n",
      "iteration: 635 | loss: 1.051065\n",
      "iteration: 636 | loss: 1.101430\n",
      "iteration: 637 | loss: 0.824746\n",
      "iteration: 638 | loss: 1.718921\n",
      "iteration: 639 | loss: 1.119153\n",
      "iteration: 640 | loss: 1.092181\n",
      "iteration: 641 | loss: 1.014625\n",
      "iteration: 642 | loss: 1.052201\n",
      "iteration: 643 | loss: 0.958609\n",
      "iteration: 644 | loss: 0.867373\n",
      "iteration: 645 | loss: 1.066018\n",
      "iteration: 646 | loss: 0.979368\n",
      "iteration: 647 | loss: 1.087710\n",
      "iteration: 648 | loss: 0.916063\n",
      "iteration: 649 | loss: 0.786668\n",
      "  Train acc: 0.584, Val acc: 0.5\n",
      "iteration: 650 | loss: 1.034662\n",
      "iteration: 651 | loss: 1.207309\n",
      "iteration: 652 | loss: 1.286363\n",
      "iteration: 653 | loss: 0.977925\n",
      "iteration: 654 | loss: 0.962135\n",
      "iteration: 655 | loss: 0.782764\n",
      "iteration: 656 | loss: 1.181624\n",
      "iteration: 657 | loss: 1.111984\n",
      "iteration: 658 | loss: 1.059646\n",
      "iteration: 659 | loss: 1.095319\n",
      "iteration: 660 | loss: 1.145649\n",
      "iteration: 661 | loss: 0.990475\n",
      "iteration: 662 | loss: 0.802293\n",
      "iteration: 663 | loss: 0.740081\n",
      "iteration: 664 | loss: 0.733126\n",
      "iteration: 665 | loss: 1.349704\n",
      "iteration: 666 | loss: 0.929155\n",
      "iteration: 667 | loss: 1.172662\n",
      "iteration: 668 | loss: 1.017079\n",
      "iteration: 669 | loss: 1.084116\n",
      "iteration: 670 | loss: 0.925146\n",
      "iteration: 671 | loss: 1.303967\n",
      "iteration: 672 | loss: 0.777904\n",
      "iteration: 673 | loss: 0.992407\n",
      "iteration: 674 | loss: 1.098159\n",
      "  Train acc: 0.624, Val acc: 0.5\n",
      "iteration: 675 | loss: 0.889793\n",
      "iteration: 676 | loss: 1.019962\n",
      "iteration: 677 | loss: 1.162306\n",
      "iteration: 678 | loss: 1.203516\n",
      "iteration: 679 | loss: 1.151821\n",
      "iteration: 680 | loss: 1.149095\n",
      "iteration: 681 | loss: 1.179478\n",
      "iteration: 682 | loss: 0.801298\n",
      "iteration: 683 | loss: 0.903517\n",
      "iteration: 684 | loss: 0.963980\n",
      "iteration: 685 | loss: 1.128507\n",
      "iteration: 686 | loss: 0.695866\n",
      "iteration: 687 | loss: 1.190414\n",
      "iteration: 688 | loss: 0.760985\n",
      "iteration: 689 | loss: 0.911805\n",
      "iteration: 690 | loss: 1.358300\n",
      "iteration: 691 | loss: 1.046206\n",
      "iteration: 692 | loss: 0.956442\n",
      "iteration: 693 | loss: 1.021160\n",
      "iteration: 694 | loss: 0.933676\n",
      "iteration: 695 | loss: 1.167774\n",
      "iteration: 696 | loss: 0.979511\n",
      "iteration: 697 | loss: 1.141260\n",
      "iteration: 698 | loss: 0.876342\n",
      "iteration: 699 | loss: 0.981112\n",
      "  Train acc: 0.64, Val acc: 0.5\n",
      "iteration: 700 | loss: 0.970005\n",
      "iteration: 701 | loss: 0.814114\n",
      "iteration: 702 | loss: 1.390296\n",
      "iteration: 703 | loss: 1.153051\n",
      "iteration: 704 | loss: 0.926320\n",
      "iteration: 705 | loss: 0.807687\n",
      "iteration: 706 | loss: 0.748906\n",
      "iteration: 707 | loss: 1.060783\n",
      "iteration: 708 | loss: 0.681271\n",
      "iteration: 709 | loss: 0.898739\n",
      "iteration: 710 | loss: 0.981762\n",
      "iteration: 711 | loss: 1.047898\n",
      "iteration: 712 | loss: 0.898285\n",
      "iteration: 713 | loss: 0.876441\n",
      "iteration: 714 | loss: 1.045345\n",
      "iteration: 715 | loss: 1.198513\n",
      "iteration: 716 | loss: 0.894498\n",
      "iteration: 717 | loss: 0.999935\n",
      "iteration: 718 | loss: 1.444221\n",
      "iteration: 719 | loss: 1.186866\n",
      "iteration: 720 | loss: 0.883038\n",
      "iteration: 721 | loss: 0.846957\n",
      "iteration: 722 | loss: 0.877781\n",
      "iteration: 723 | loss: 0.832053\n",
      "iteration: 724 | loss: 1.118946\n",
      "  Train acc: 0.666, Val acc: 0.5\n",
      "iteration: 725 | loss: 0.958986\n",
      "iteration: 726 | loss: 1.135519\n",
      "iteration: 727 | loss: 0.985576\n",
      "iteration: 728 | loss: 0.896002\n",
      "iteration: 729 | loss: 0.860849\n",
      "iteration: 730 | loss: 1.079404\n",
      "iteration: 731 | loss: 1.111197\n",
      "iteration: 732 | loss: 0.910722\n",
      "iteration: 733 | loss: 0.788891\n",
      "iteration: 734 | loss: 1.160280\n",
      "iteration: 735 | loss: 0.790331\n",
      "iteration: 736 | loss: 0.826628\n",
      "iteration: 737 | loss: 0.655327\n",
      "iteration: 738 | loss: 0.816628\n",
      "iteration: 739 | loss: 1.207909\n",
      "iteration: 740 | loss: 0.880884\n",
      "iteration: 741 | loss: 1.084190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 742 | loss: 0.693338\n",
      "iteration: 743 | loss: 1.088378\n",
      "iteration: 744 | loss: 1.077348\n",
      "iteration: 745 | loss: 0.933288\n",
      "iteration: 746 | loss: 0.757417\n",
      "iteration: 747 | loss: 1.135377\n",
      "iteration: 748 | loss: 1.192946\n",
      "iteration: 749 | loss: 0.783545\n",
      "  Train acc: 0.668, Val acc: 0.5\n",
      "iteration: 750 | loss: 1.219847\n",
      "iteration: 751 | loss: 1.071125\n",
      "iteration: 752 | loss: 0.993168\n",
      "iteration: 753 | loss: 1.164037\n",
      "iteration: 754 | loss: 0.898825\n",
      "iteration: 755 | loss: 0.947939\n",
      "iteration: 756 | loss: 1.156330\n",
      "iteration: 757 | loss: 1.071362\n",
      "iteration: 758 | loss: 0.875812\n",
      "iteration: 759 | loss: 1.003259\n",
      "iteration: 760 | loss: 0.903034\n",
      "iteration: 761 | loss: 0.790723\n",
      "iteration: 762 | loss: 1.231256\n",
      "iteration: 763 | loss: 0.833267\n",
      "iteration: 764 | loss: 0.854900\n",
      "iteration: 765 | loss: 0.485568\n",
      "iteration: 766 | loss: 0.882214\n",
      "iteration: 767 | loss: 0.977174\n",
      "iteration: 768 | loss: 1.212382\n",
      "iteration: 769 | loss: 0.968512\n",
      "iteration: 770 | loss: 1.168375\n",
      "iteration: 771 | loss: 1.172360\n",
      "iteration: 772 | loss: 0.831159\n",
      "iteration: 773 | loss: 0.478091\n",
      "iteration: 774 | loss: 0.910215\n",
      "  Train acc: 0.632, Val acc: 0.5\n",
      "iteration: 775 | loss: 0.748340\n",
      "iteration: 776 | loss: 0.867399\n",
      "iteration: 777 | loss: 1.236483\n",
      "iteration: 778 | loss: 0.545840\n",
      "iteration: 779 | loss: 1.311151\n",
      "iteration: 780 | loss: 0.538960\n",
      "iteration: 781 | loss: 1.194828\n",
      "iteration: 782 | loss: 0.846745\n",
      "iteration: 783 | loss: 0.807483\n",
      "iteration: 784 | loss: 0.743543\n",
      "iteration: 785 | loss: 1.143854\n",
      "iteration: 786 | loss: 0.913475\n",
      "iteration: 787 | loss: 0.763523\n",
      "iteration: 788 | loss: 1.033803\n",
      "iteration: 789 | loss: 0.737874\n",
      "iteration: 790 | loss: 0.557549\n",
      "iteration: 791 | loss: 1.117298\n",
      "iteration: 792 | loss: 0.890464\n",
      "iteration: 793 | loss: 1.415639\n",
      "iteration: 794 | loss: 0.858519\n",
      "iteration: 795 | loss: 0.920755\n",
      "iteration: 796 | loss: 0.907528\n",
      "iteration: 797 | loss: 0.975656\n",
      "iteration: 798 | loss: 0.792226\n",
      "iteration: 799 | loss: 0.865596\n",
      "  Train acc: 0.63, Val acc: 0.5\n",
      "iteration: 800 | loss: 0.860232\n",
      "iteration: 801 | loss: 0.858201\n",
      "iteration: 802 | loss: 0.904736\n",
      "iteration: 803 | loss: 0.940389\n",
      "iteration: 804 | loss: 0.914300\n",
      "iteration: 805 | loss: 0.823170\n",
      "iteration: 806 | loss: 0.708702\n",
      "iteration: 807 | loss: 0.885093\n",
      "iteration: 808 | loss: 0.803260\n",
      "iteration: 809 | loss: 0.924889\n",
      "iteration: 810 | loss: 0.899128\n",
      "iteration: 811 | loss: 0.612853\n",
      "iteration: 812 | loss: 0.916393\n",
      "iteration: 813 | loss: 0.886979\n",
      "iteration: 814 | loss: 0.840004\n",
      "iteration: 815 | loss: 1.284992\n",
      "iteration: 816 | loss: 0.872265\n",
      "iteration: 817 | loss: 1.127180\n",
      "iteration: 818 | loss: 0.939135\n",
      "iteration: 819 | loss: 1.009882\n",
      "iteration: 820 | loss: 0.992183\n",
      "iteration: 821 | loss: 0.659744\n",
      "iteration: 822 | loss: 1.012207\n",
      "iteration: 823 | loss: 0.895063\n",
      "iteration: 824 | loss: 0.628630\n",
      "  Train acc: 0.686, Val acc: 0.5\n",
      "iteration: 825 | loss: 1.098742\n",
      "iteration: 826 | loss: 0.634111\n",
      "iteration: 827 | loss: 0.817857\n",
      "iteration: 828 | loss: 1.045071\n",
      "iteration: 829 | loss: 0.657312\n",
      "iteration: 830 | loss: 1.000315\n",
      "iteration: 831 | loss: 0.778398\n",
      "iteration: 832 | loss: 0.830917\n",
      "iteration: 833 | loss: 1.150244\n",
      "iteration: 834 | loss: 0.979159\n",
      "iteration: 835 | loss: 1.291567\n",
      "iteration: 836 | loss: 0.927322\n",
      "iteration: 837 | loss: 1.066183\n",
      "iteration: 838 | loss: 0.780349\n",
      "iteration: 839 | loss: 0.907749\n",
      "iteration: 840 | loss: 0.699183\n",
      "iteration: 841 | loss: 0.820657\n",
      "iteration: 842 | loss: 0.777569\n",
      "iteration: 843 | loss: 0.789849\n",
      "iteration: 844 | loss: 0.859627\n",
      "iteration: 845 | loss: 0.608908\n",
      "iteration: 846 | loss: 0.923337\n",
      "iteration: 847 | loss: 1.045609\n",
      "iteration: 848 | loss: 0.903915\n",
      "iteration: 849 | loss: 0.880365\n",
      "  Train acc: 0.658, Val acc: 0.5\n",
      "iteration: 850 | loss: 0.969181\n",
      "iteration: 851 | loss: 0.706662\n",
      "iteration: 852 | loss: 0.542129\n",
      "iteration: 853 | loss: 0.778347\n",
      "iteration: 854 | loss: 0.806833\n",
      "iteration: 855 | loss: 0.467244\n",
      "iteration: 856 | loss: 0.579736\n",
      "iteration: 857 | loss: 0.615791\n",
      "iteration: 858 | loss: 1.091554\n",
      "iteration: 859 | loss: 0.517513\n",
      "iteration: 860 | loss: 0.874698\n",
      "iteration: 861 | loss: 0.932032\n",
      "iteration: 862 | loss: 0.878148\n",
      "iteration: 863 | loss: 1.024936\n",
      "iteration: 864 | loss: 1.233998\n",
      "iteration: 865 | loss: 1.012077\n",
      "iteration: 866 | loss: 0.729308\n",
      "iteration: 867 | loss: 0.713757\n",
      "iteration: 868 | loss: 0.820787\n",
      "iteration: 869 | loss: 0.696945\n",
      "iteration: 870 | loss: 0.805964\n",
      "iteration: 871 | loss: 0.937300\n",
      "iteration: 872 | loss: 1.004258\n",
      "iteration: 873 | loss: 0.935250\n",
      "iteration: 874 | loss: 1.041334\n",
      "  Train acc: 0.726, Val acc: 0.5\n",
      "iteration: 875 | loss: 1.065236\n",
      "iteration: 876 | loss: 0.748758\n",
      "iteration: 877 | loss: 1.041516\n",
      "iteration: 878 | loss: 0.793413\n",
      "iteration: 879 | loss: 0.790869\n",
      "iteration: 880 | loss: 0.810445\n",
      "iteration: 881 | loss: 0.891359\n",
      "iteration: 882 | loss: 1.106597\n",
      "iteration: 883 | loss: 0.937646\n",
      "iteration: 884 | loss: 1.175781\n",
      "iteration: 885 | loss: 0.713934\n",
      "iteration: 886 | loss: 1.009201\n",
      "iteration: 887 | loss: 0.994373\n",
      "iteration: 888 | loss: 0.813189\n",
      "iteration: 889 | loss: 0.977861\n",
      "iteration: 890 | loss: 0.901174\n",
      "iteration: 891 | loss: 0.765597\n",
      "iteration: 892 | loss: 0.696885\n",
      "iteration: 893 | loss: 0.722321\n",
      "iteration: 894 | loss: 0.629075\n",
      "iteration: 895 | loss: 0.524139\n",
      "iteration: 896 | loss: 0.851298\n",
      "iteration: 897 | loss: 0.879468\n",
      "iteration: 898 | loss: 1.081427\n",
      "iteration: 899 | loss: 0.898690\n",
      "  Train acc: 0.67, Val acc: 0.5\n",
      "iteration: 900 | loss: 0.861922\n",
      "iteration: 901 | loss: 0.770439\n",
      "iteration: 902 | loss: 0.968577\n",
      "iteration: 903 | loss: 1.122056\n",
      "iteration: 904 | loss: 0.761127\n",
      "iteration: 905 | loss: 0.702989\n",
      "iteration: 906 | loss: 0.691552\n",
      "iteration: 907 | loss: 0.870801\n",
      "iteration: 908 | loss: 0.770832\n",
      "iteration: 909 | loss: 0.839548\n",
      "iteration: 910 | loss: 0.723292\n",
      "iteration: 911 | loss: 0.973938\n",
      "iteration: 912 | loss: 0.922262\n",
      "iteration: 913 | loss: 1.247643\n",
      "iteration: 914 | loss: 0.754161\n",
      "iteration: 915 | loss: 1.130806\n",
      "iteration: 916 | loss: 0.753203\n",
      "iteration: 917 | loss: 0.857262\n",
      "iteration: 918 | loss: 0.915123\n",
      "iteration: 919 | loss: 0.813158\n",
      "iteration: 920 | loss: 0.786478\n",
      "iteration: 921 | loss: 0.700661\n",
      "iteration: 922 | loss: 0.967759\n",
      "iteration: 923 | loss: 0.861249\n",
      "iteration: 924 | loss: 0.612257\n",
      "  Train acc: 0.686, Val acc: 0.5\n",
      "iteration: 925 | loss: 0.738897\n",
      "iteration: 926 | loss: 0.578721\n",
      "iteration: 927 | loss: 0.822261\n",
      "iteration: 928 | loss: 1.103400\n",
      "iteration: 929 | loss: 0.697323\n",
      "iteration: 930 | loss: 1.102271\n",
      "iteration: 931 | loss: 0.799536\n",
      "iteration: 932 | loss: 1.034616\n",
      "iteration: 933 | loss: 0.923209\n",
      "iteration: 934 | loss: 1.127925\n",
      "iteration: 935 | loss: 0.533682\n",
      "iteration: 936 | loss: 0.778540\n",
      "iteration: 937 | loss: 0.679239\n",
      "iteration: 938 | loss: 0.778143\n",
      "iteration: 939 | loss: 1.180078\n",
      "iteration: 940 | loss: 0.840480\n",
      "iteration: 941 | loss: 0.659424\n",
      "iteration: 942 | loss: 0.668425\n",
      "iteration: 943 | loss: 1.110065\n",
      "iteration: 944 | loss: 1.072007\n",
      "iteration: 945 | loss: 1.002233\n",
      "iteration: 946 | loss: 0.834644\n",
      "iteration: 947 | loss: 0.844674\n",
      "iteration: 948 | loss: 0.760021\n",
      "iteration: 949 | loss: 0.608306\n",
      "  Train acc: 0.688, Val acc: 0.5\n",
      "iteration: 950 | loss: 1.183781\n",
      "iteration: 951 | loss: 0.949234\n",
      "iteration: 952 | loss: 0.596707\n",
      "iteration: 953 | loss: 0.899272\n",
      "iteration: 954 | loss: 0.590384\n",
      "iteration: 955 | loss: 0.543968\n",
      "iteration: 956 | loss: 0.693760\n",
      "iteration: 957 | loss: 1.420194\n",
      "iteration: 958 | loss: 0.913320\n",
      "iteration: 959 | loss: 1.508649\n",
      "iteration: 960 | loss: 0.693148\n",
      "iteration: 961 | loss: 0.832118\n",
      "iteration: 962 | loss: 0.835443\n",
      "iteration: 963 | loss: 0.547751\n",
      "iteration: 964 | loss: 0.788347\n",
      "iteration: 965 | loss: 0.899615\n",
      "iteration: 966 | loss: 0.983937\n",
      "iteration: 967 | loss: 0.620831\n",
      "iteration: 968 | loss: 0.375381\n",
      "iteration: 969 | loss: 1.061440\n",
      "iteration: 970 | loss: 0.703711\n",
      "iteration: 971 | loss: 0.372617\n",
      "iteration: 972 | loss: 0.764007\n",
      "iteration: 973 | loss: 0.640059\n",
      "iteration: 974 | loss: 0.818846\n",
      "  Train acc: 0.762, Val acc: 0.5\n",
      "iteration: 975 | loss: 1.004271\n",
      "iteration: 976 | loss: 0.694048\n",
      "iteration: 977 | loss: 0.817421\n",
      "iteration: 978 | loss: 0.534715\n",
      "iteration: 979 | loss: 0.766531\n",
      "iteration: 980 | loss: 0.651281\n",
      "iteration: 981 | loss: 0.950114\n",
      "iteration: 982 | loss: 1.108570\n",
      "iteration: 983 | loss: 0.659230\n",
      "iteration: 984 | loss: 0.883275\n",
      "iteration: 985 | loss: 0.775303\n",
      "iteration: 986 | loss: 0.682132\n",
      "iteration: 987 | loss: 0.753736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 988 | loss: 0.648049\n",
      "iteration: 989 | loss: 0.842950\n",
      "iteration: 990 | loss: 0.791462\n",
      "iteration: 991 | loss: 0.477963\n",
      "iteration: 992 | loss: 0.607029\n",
      "iteration: 993 | loss: 0.915258\n",
      "iteration: 994 | loss: 0.609588\n",
      "iteration: 995 | loss: 0.771576\n",
      "iteration: 996 | loss: 0.612846\n",
      "iteration: 997 | loss: 0.970601\n",
      "iteration: 998 | loss: 0.619492\n",
      "iteration: 999 | loss: 0.975018\n",
      "  Train acc: 0.728, Val acc: 0.5\n",
      "iteration: 1000 | loss: 0.628166\n",
      "iteration: 1001 | loss: 0.603585\n",
      "iteration: 1002 | loss: 0.748823\n",
      "iteration: 1003 | loss: 1.028960\n",
      "iteration: 1004 | loss: 1.205501\n",
      "iteration: 1005 | loss: 0.829200\n",
      "iteration: 1006 | loss: 0.760235\n",
      "iteration: 1007 | loss: 0.801443\n",
      "iteration: 1008 | loss: 1.005163\n",
      "iteration: 1009 | loss: 0.649290\n",
      "iteration: 1010 | loss: 0.613426\n",
      "iteration: 1011 | loss: 0.737380\n",
      "iteration: 1012 | loss: 1.009991\n",
      "iteration: 1013 | loss: 0.694942\n",
      "iteration: 1014 | loss: 0.653771\n",
      "iteration: 1015 | loss: 0.613667\n",
      "iteration: 1016 | loss: 0.894456\n",
      "iteration: 1017 | loss: 0.874519\n",
      "iteration: 1018 | loss: 0.597234\n",
      "iteration: 1019 | loss: 0.800031\n",
      "iteration: 1020 | loss: 0.597674\n",
      "iteration: 1021 | loss: 0.558771\n",
      "iteration: 1022 | loss: 0.663372\n",
      "iteration: 1023 | loss: 0.844884\n",
      "iteration: 1024 | loss: 0.604698\n",
      "  Train acc: 0.784, Val acc: 0.5\n",
      "iteration: 1025 | loss: 0.679918\n",
      "iteration: 1026 | loss: 0.821277\n",
      "iteration: 1027 | loss: 0.865560\n",
      "iteration: 1028 | loss: 0.881892\n",
      "iteration: 1029 | loss: 0.544532\n",
      "iteration: 1030 | loss: 0.787346\n",
      "iteration: 1031 | loss: 0.781998\n",
      "iteration: 1032 | loss: 0.563871\n",
      "iteration: 1033 | loss: 0.700090\n",
      "iteration: 1034 | loss: 0.743442\n",
      "iteration: 1035 | loss: 0.897233\n",
      "iteration: 1036 | loss: 0.841284\n",
      "iteration: 1037 | loss: 0.811567\n",
      "iteration: 1038 | loss: 1.112308\n",
      "iteration: 1039 | loss: 0.609087\n",
      "iteration: 1040 | loss: 0.614252\n",
      "iteration: 1041 | loss: 0.282823\n",
      "iteration: 1042 | loss: 0.819983\n",
      "iteration: 1043 | loss: 0.997992\n",
      "iteration: 1044 | loss: 0.600291\n",
      "iteration: 1045 | loss: 1.057059\n",
      "iteration: 1046 | loss: 0.473933\n",
      "iteration: 1047 | loss: 0.796345\n",
      "iteration: 1048 | loss: 0.781861\n",
      "iteration: 1049 | loss: 0.720477\n",
      "  Train acc: 0.744, Val acc: 0.5\n",
      "iteration: 1050 | loss: 0.853883\n",
      "iteration: 1051 | loss: 1.099976\n",
      "iteration: 1052 | loss: 1.141547\n",
      "iteration: 1053 | loss: 1.169947\n",
      "iteration: 1054 | loss: 0.955411\n",
      "iteration: 1055 | loss: 0.733495\n",
      "iteration: 1056 | loss: 0.561602\n",
      "iteration: 1057 | loss: 0.701419\n",
      "iteration: 1058 | loss: 0.730653\n",
      "iteration: 1059 | loss: 0.735342\n",
      "iteration: 1060 | loss: 0.629756\n",
      "iteration: 1061 | loss: 0.885639\n",
      "iteration: 1062 | loss: 0.856127\n",
      "iteration: 1063 | loss: 0.548878\n",
      "iteration: 1064 | loss: 0.632235\n",
      "iteration: 1065 | loss: 0.874146\n",
      "iteration: 1066 | loss: 0.695249\n",
      "iteration: 1067 | loss: 1.031370\n",
      "iteration: 1068 | loss: 0.488886\n",
      "iteration: 1069 | loss: 1.417563\n",
      "iteration: 1070 | loss: 1.129912\n",
      "iteration: 1071 | loss: 0.735598\n",
      "iteration: 1072 | loss: 0.600034\n",
      "iteration: 1073 | loss: 0.748452\n",
      "iteration: 1074 | loss: 0.653442\n",
      "  Train acc: 0.788, Val acc: 0.5\n",
      "iteration: 1075 | loss: 0.664151\n",
      "iteration: 1076 | loss: 0.877553\n",
      "iteration: 1077 | loss: 0.626342\n",
      "iteration: 1078 | loss: 0.957990\n",
      "iteration: 1079 | loss: 0.541315\n",
      "iteration: 1080 | loss: 0.620928\n",
      "iteration: 1081 | loss: 0.685310\n",
      "iteration: 1082 | loss: 0.704860\n",
      "iteration: 1083 | loss: 0.747001\n",
      "iteration: 1084 | loss: 0.863999\n",
      "iteration: 1085 | loss: 0.641789\n",
      "iteration: 1086 | loss: 1.027089\n",
      "iteration: 1087 | loss: 0.654608\n",
      "iteration: 1088 | loss: 0.591779\n",
      "iteration: 1089 | loss: 0.464218\n",
      "iteration: 1090 | loss: 0.619716\n",
      "iteration: 1091 | loss: 0.541455\n",
      "iteration: 1092 | loss: 0.388011\n",
      "iteration: 1093 | loss: 0.760456\n",
      "iteration: 1094 | loss: 0.781372\n",
      "iteration: 1095 | loss: 0.858691\n",
      "iteration: 1096 | loss: 0.679346\n",
      "iteration: 1097 | loss: 0.584851\n",
      "iteration: 1098 | loss: 0.879239\n",
      "iteration: 1099 | loss: 0.427422\n",
      "  Train acc: 0.778, Val acc: 0.5\n",
      "iteration: 1100 | loss: 0.652059\n",
      "iteration: 1101 | loss: 0.717251\n",
      "iteration: 1102 | loss: 0.661152\n",
      "iteration: 1103 | loss: 0.749259\n",
      "iteration: 1104 | loss: 0.488547\n",
      "iteration: 1105 | loss: 0.655199\n",
      "iteration: 1106 | loss: 0.534108\n",
      "iteration: 1107 | loss: 0.370388\n",
      "iteration: 1108 | loss: 0.604469\n",
      "iteration: 1109 | loss: 0.400651\n",
      "iteration: 1110 | loss: 0.672124\n",
      "iteration: 1111 | loss: 0.536075\n",
      "iteration: 1112 | loss: 0.671292\n",
      "iteration: 1113 | loss: 0.442839\n",
      "iteration: 1114 | loss: 0.870183\n",
      "iteration: 1115 | loss: 0.825823\n",
      "iteration: 1116 | loss: 0.562477\n",
      "iteration: 1117 | loss: 0.662654\n",
      "iteration: 1118 | loss: 0.519771\n",
      "iteration: 1119 | loss: 0.739095\n",
      "iteration: 1120 | loss: 0.478707\n",
      "iteration: 1121 | loss: 1.222720\n",
      "iteration: 1122 | loss: 0.901054\n",
      "iteration: 1123 | loss: 0.969754\n",
      "iteration: 1124 | loss: 0.687407\n",
      "  Train acc: 0.736, Val acc: 0.5\n",
      "iteration: 1125 | loss: 0.768543\n",
      "iteration: 1126 | loss: 0.717097\n",
      "iteration: 1127 | loss: 0.402317\n",
      "iteration: 1128 | loss: 0.706830\n",
      "iteration: 1129 | loss: 0.454632\n",
      "iteration: 1130 | loss: 0.678909\n",
      "iteration: 1131 | loss: 0.764768\n",
      "iteration: 1132 | loss: 0.674880\n",
      "iteration: 1133 | loss: 0.824035\n",
      "iteration: 1134 | loss: 0.670994\n",
      "iteration: 1135 | loss: 0.676619\n",
      "iteration: 1136 | loss: 0.531208\n",
      "iteration: 1137 | loss: 0.414341\n",
      "iteration: 1138 | loss: 0.624575\n",
      "iteration: 1139 | loss: 1.048091\n",
      "iteration: 1140 | loss: 0.468588\n",
      "iteration: 1141 | loss: 0.631659\n",
      "iteration: 1142 | loss: 0.567342\n",
      "iteration: 1143 | loss: 0.802859\n",
      "iteration: 1144 | loss: 0.745087\n",
      "iteration: 1145 | loss: 0.680555\n",
      "iteration: 1146 | loss: 0.633200\n",
      "iteration: 1147 | loss: 0.897328\n",
      "iteration: 1148 | loss: 0.632902\n",
      "iteration: 1149 | loss: 0.506592\n",
      "  Train acc: 0.786, Val acc: 0.5\n",
      "iteration: 1150 | loss: 0.803017\n",
      "iteration: 1151 | loss: 0.442452\n",
      "iteration: 1152 | loss: 0.757463\n",
      "iteration: 1153 | loss: 0.509224\n",
      "iteration: 1154 | loss: 0.606498\n",
      "iteration: 1155 | loss: 0.654229\n",
      "iteration: 1156 | loss: 0.511989\n",
      "iteration: 1157 | loss: 0.761994\n",
      "iteration: 1158 | loss: 0.490809\n",
      "iteration: 1159 | loss: 0.913667\n",
      "iteration: 1160 | loss: 0.554688\n",
      "iteration: 1161 | loss: 0.501863\n",
      "iteration: 1162 | loss: 0.958403\n",
      "iteration: 1163 | loss: 0.666593\n",
      "iteration: 1164 | loss: 0.480210\n",
      "iteration: 1165 | loss: 0.638328\n",
      "iteration: 1166 | loss: 0.540953\n",
      "iteration: 1167 | loss: 0.455454\n",
      "iteration: 1168 | loss: 0.922501\n",
      "iteration: 1169 | loss: 0.670515\n",
      "iteration: 1170 | loss: 0.738748\n",
      "iteration: 1171 | loss: 0.537425\n",
      "iteration: 1172 | loss: 0.498504\n",
      "iteration: 1173 | loss: 0.596579\n",
      "iteration: 1174 | loss: 0.667727\n",
      "  Train acc: 0.804, Val acc: 0.5\n",
      "iteration: 1175 | loss: 0.529110\n",
      "iteration: 1176 | loss: 0.900657\n",
      "iteration: 1177 | loss: 0.565098\n",
      "iteration: 1178 | loss: 0.659192\n",
      "iteration: 1179 | loss: 0.496608\n",
      "iteration: 1180 | loss: 0.569297\n",
      "iteration: 1181 | loss: 0.730500\n",
      "iteration: 1182 | loss: 0.473528\n",
      "iteration: 1183 | loss: 0.667528\n",
      "iteration: 1184 | loss: 0.353834\n",
      "iteration: 1185 | loss: 0.640266\n",
      "iteration: 1186 | loss: 0.394479\n",
      "iteration: 1187 | loss: 0.551355\n",
      "iteration: 1188 | loss: 0.589955\n",
      "iteration: 1189 | loss: 0.784984\n",
      "iteration: 1190 | loss: 0.839828\n",
      "iteration: 1191 | loss: 0.712775\n",
      "iteration: 1192 | loss: 0.965699\n",
      "iteration: 1193 | loss: 0.460082\n",
      "iteration: 1194 | loss: 0.830222\n",
      "iteration: 1195 | loss: 0.520866\n",
      "iteration: 1196 | loss: 0.751266\n",
      "iteration: 1197 | loss: 1.166958\n",
      "iteration: 1198 | loss: 0.381392\n",
      "iteration: 1199 | loss: 0.493494\n",
      "  Train acc: 0.792, Val acc: 0.5\n",
      "iteration: 1200 | loss: 0.788758\n",
      "iteration: 1201 | loss: 0.515338\n",
      "iteration: 1202 | loss: 0.392008\n",
      "iteration: 1203 | loss: 1.002229\n",
      "iteration: 1204 | loss: 0.452038\n",
      "iteration: 1205 | loss: 0.498780\n",
      "iteration: 1206 | loss: 1.021544\n",
      "iteration: 1207 | loss: 0.689139\n",
      "iteration: 1208 | loss: 0.421376\n",
      "iteration: 1209 | loss: 0.962540\n",
      "iteration: 1210 | loss: 1.404663\n",
      "iteration: 1211 | loss: 0.810090\n",
      "iteration: 1212 | loss: 0.402491\n",
      "iteration: 1213 | loss: 0.402507\n",
      "iteration: 1214 | loss: 0.479862\n",
      "iteration: 1215 | loss: 0.947463\n",
      "iteration: 1216 | loss: 0.545766\n",
      "iteration: 1217 | loss: 0.639338\n",
      "iteration: 1218 | loss: 0.435358\n",
      "iteration: 1219 | loss: 0.541727\n",
      "iteration: 1220 | loss: 0.510454\n",
      "iteration: 1221 | loss: 0.486174\n",
      "iteration: 1222 | loss: 0.435979\n",
      "iteration: 1223 | loss: 0.594965\n",
      "iteration: 1224 | loss: 0.548345\n",
      "  Train acc: 0.832, Val acc: 0.5\n",
      "iteration: 1225 | loss: 0.439693\n",
      "iteration: 1226 | loss: 0.478283\n",
      "iteration: 1227 | loss: 0.615938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1228 | loss: 0.506147\n",
      "iteration: 1229 | loss: 0.688741\n",
      "iteration: 1230 | loss: 0.283644\n",
      "iteration: 1231 | loss: 0.799883\n",
      "iteration: 1232 | loss: 0.403483\n",
      "iteration: 1233 | loss: 0.430889\n",
      "iteration: 1234 | loss: 0.500834\n",
      "iteration: 1235 | loss: 1.066033\n",
      "iteration: 1236 | loss: 0.808256\n",
      "iteration: 1237 | loss: 0.354924\n",
      "iteration: 1238 | loss: 0.839538\n",
      "iteration: 1239 | loss: 0.554329\n",
      "iteration: 1240 | loss: 0.377344\n",
      "iteration: 1241 | loss: 0.492113\n",
      "iteration: 1242 | loss: 0.410478\n",
      "iteration: 1243 | loss: 0.582329\n",
      "iteration: 1244 | loss: 0.387339\n",
      "iteration: 1245 | loss: 0.577232\n",
      "iteration: 1246 | loss: 0.515889\n",
      "iteration: 1247 | loss: 0.420715\n",
      "iteration: 1248 | loss: 0.510551\n",
      "iteration: 1249 | loss: 0.682989\n",
      "  Train acc: 0.8, Val acc: 0.5\n",
      "iteration: 1250 | loss: 0.538883\n",
      "iteration: 1251 | loss: 0.887221\n",
      "iteration: 1252 | loss: 0.633370\n",
      "iteration: 1253 | loss: 0.516606\n",
      "iteration: 1254 | loss: 0.333711\n",
      "iteration: 1255 | loss: 0.612839\n",
      "iteration: 1256 | loss: 0.422851\n",
      "iteration: 1257 | loss: 0.485754\n",
      "iteration: 1258 | loss: 0.859891\n",
      "iteration: 1259 | loss: 0.504610\n",
      "iteration: 1260 | loss: 0.525883\n",
      "iteration: 1261 | loss: 0.423773\n",
      "iteration: 1262 | loss: 0.575925\n",
      "iteration: 1263 | loss: 0.708832\n",
      "iteration: 1264 | loss: 0.401872\n",
      "iteration: 1265 | loss: 0.348910\n",
      "iteration: 1266 | loss: 0.419294\n",
      "iteration: 1267 | loss: 1.248113\n",
      "iteration: 1268 | loss: 0.507349\n",
      "iteration: 1269 | loss: 0.514846\n",
      "iteration: 1270 | loss: 0.339623\n",
      "iteration: 1271 | loss: 0.523357\n",
      "iteration: 1272 | loss: 0.602161\n",
      "iteration: 1273 | loss: 0.377957\n",
      "iteration: 1274 | loss: 0.624317\n",
      "  Train acc: 0.81, Val acc: 0.5\n",
      "iteration: 1275 | loss: 0.417966\n",
      "iteration: 1276 | loss: 0.421157\n",
      "iteration: 1277 | loss: 0.285827\n",
      "iteration: 1278 | loss: 0.413902\n",
      "iteration: 1279 | loss: 0.434574\n",
      "iteration: 1280 | loss: 0.880275\n",
      "iteration: 1281 | loss: 0.723283\n",
      "iteration: 1282 | loss: 0.473850\n",
      "iteration: 1283 | loss: 0.519425\n",
      "iteration: 1284 | loss: 0.365724\n",
      "iteration: 1285 | loss: 0.383123\n",
      "iteration: 1286 | loss: 0.556507\n",
      "iteration: 1287 | loss: 0.868980\n",
      "iteration: 1288 | loss: 0.384352\n",
      "iteration: 1289 | loss: 0.581598\n",
      "iteration: 1290 | loss: 0.539757\n",
      "iteration: 1291 | loss: 0.775227\n",
      "iteration: 1292 | loss: 0.277407\n",
      "iteration: 1293 | loss: 0.837301\n",
      "iteration: 1294 | loss: 0.683031\n",
      "iteration: 1295 | loss: 0.366329\n",
      "iteration: 1296 | loss: 0.704295\n",
      "iteration: 1297 | loss: 1.152583\n",
      "iteration: 1298 | loss: 0.769326\n",
      "iteration: 1299 | loss: 0.571532\n",
      "  Train acc: 0.814, Val acc: 0.5\n",
      "iteration: 1300 | loss: 0.421875\n",
      "iteration: 1301 | loss: 0.395831\n",
      "iteration: 1302 | loss: 0.558731\n",
      "iteration: 1303 | loss: 0.333612\n",
      "iteration: 1304 | loss: 0.792091\n",
      "iteration: 1305 | loss: 0.688407\n",
      "iteration: 1306 | loss: 0.467993\n",
      "iteration: 1307 | loss: 1.072117\n",
      "iteration: 1308 | loss: 0.302038\n",
      "iteration: 1309 | loss: 0.491105\n",
      "iteration: 1310 | loss: 0.745777\n",
      "iteration: 1311 | loss: 0.627244\n",
      "iteration: 1312 | loss: 0.641965\n",
      "iteration: 1313 | loss: 0.639415\n",
      "iteration: 1314 | loss: 0.712269\n",
      "iteration: 1315 | loss: 0.706597\n",
      "iteration: 1316 | loss: 0.373638\n",
      "iteration: 1317 | loss: 0.560667\n",
      "iteration: 1318 | loss: 0.655177\n",
      "iteration: 1319 | loss: 0.480868\n",
      "iteration: 1320 | loss: 0.638242\n",
      "iteration: 1321 | loss: 0.523233\n",
      "iteration: 1322 | loss: 0.479078\n",
      "iteration: 1323 | loss: 0.775572\n",
      "iteration: 1324 | loss: 0.339094\n",
      "  Train acc: 0.844, Val acc: 0.5\n",
      "iteration: 1325 | loss: 0.969329\n",
      "iteration: 1326 | loss: 0.546518\n",
      "iteration: 1327 | loss: 0.501639\n",
      "iteration: 1328 | loss: 0.609481\n",
      "iteration: 1329 | loss: 0.646739\n",
      "iteration: 1330 | loss: 0.413902\n",
      "iteration: 1331 | loss: 0.548524\n",
      "iteration: 1332 | loss: 0.538415\n",
      "iteration: 1333 | loss: 0.363141\n",
      "iteration: 1334 | loss: 0.562099\n",
      "iteration: 1335 | loss: 0.625509\n",
      "iteration: 1336 | loss: 0.456994\n",
      "iteration: 1337 | loss: 0.450291\n",
      "iteration: 1338 | loss: 0.199875\n",
      "iteration: 1339 | loss: 0.514643\n",
      "iteration: 1340 | loss: 0.889685\n",
      "iteration: 1341 | loss: 0.474525\n",
      "iteration: 1342 | loss: 0.404233\n",
      "iteration: 1343 | loss: 0.474926\n",
      "iteration: 1344 | loss: 0.485595\n",
      "iteration: 1345 | loss: 0.433744\n",
      "iteration: 1346 | loss: 0.521862\n",
      "iteration: 1347 | loss: 0.238063\n",
      "iteration: 1348 | loss: 0.568423\n",
      "iteration: 1349 | loss: 0.526021\n",
      "  Train acc: 0.856, Val acc: 0.5\n",
      "iteration: 1350 | loss: 0.330274\n",
      "iteration: 1351 | loss: 0.465695\n",
      "iteration: 1352 | loss: 0.579769\n",
      "iteration: 1353 | loss: 0.448234\n",
      "iteration: 1354 | loss: 0.472455\n",
      "iteration: 1355 | loss: 0.648991\n",
      "iteration: 1356 | loss: 0.839076\n",
      "iteration: 1357 | loss: 0.565683\n",
      "iteration: 1358 | loss: 0.864481\n",
      "iteration: 1359 | loss: 0.616354\n",
      "iteration: 1360 | loss: 0.423624\n",
      "iteration: 1361 | loss: 0.392072\n",
      "iteration: 1362 | loss: 0.686423\n",
      "iteration: 1363 | loss: 0.280396\n",
      "iteration: 1364 | loss: 0.460688\n",
      "iteration: 1365 | loss: 0.736735\n",
      "iteration: 1366 | loss: 0.216884\n",
      "iteration: 1367 | loss: 0.632143\n",
      "iteration: 1368 | loss: 0.408743\n",
      "iteration: 1369 | loss: 0.406830\n",
      "iteration: 1370 | loss: 0.758568\n",
      "iteration: 1371 | loss: 0.327896\n",
      "iteration: 1372 | loss: 0.474369\n",
      "iteration: 1373 | loss: 0.538270\n",
      "iteration: 1374 | loss: 0.382458\n",
      "  Train acc: 0.862, Val acc: 0.5\n",
      "iteration: 1375 | loss: 0.601217\n",
      "iteration: 1376 | loss: 0.325000\n",
      "iteration: 1377 | loss: 0.445900\n",
      "iteration: 1378 | loss: 0.462404\n",
      "iteration: 1379 | loss: 0.507277\n",
      "iteration: 1380 | loss: 0.430904\n",
      "iteration: 1381 | loss: 0.544327\n",
      "iteration: 1382 | loss: 0.357194\n",
      "iteration: 1383 | loss: 0.299147\n",
      "iteration: 1384 | loss: 0.718247\n",
      "iteration: 1385 | loss: 0.386669\n",
      "iteration: 1386 | loss: 0.612298\n",
      "iteration: 1387 | loss: 0.271590\n",
      "iteration: 1388 | loss: 0.423725\n",
      "iteration: 1389 | loss: 0.429435\n",
      "iteration: 1390 | loss: 0.646463\n",
      "iteration: 1391 | loss: 0.600954\n",
      "iteration: 1392 | loss: 0.474950\n",
      "iteration: 1393 | loss: 0.621446\n",
      "iteration: 1394 | loss: 0.412061\n",
      "iteration: 1395 | loss: 0.507510\n",
      "iteration: 1396 | loss: 0.426446\n",
      "iteration: 1397 | loss: 0.629341\n",
      "iteration: 1398 | loss: 0.447014\n",
      "iteration: 1399 | loss: 0.337835\n",
      "  Train acc: 0.88, Val acc: 0.5\n",
      "iteration: 1400 | loss: 0.171704\n",
      "iteration: 1401 | loss: 0.481715\n",
      "iteration: 1402 | loss: 0.502657\n",
      "iteration: 1403 | loss: 0.440736\n",
      "iteration: 1404 | loss: 0.306334\n",
      "iteration: 1405 | loss: 0.440452\n",
      "iteration: 1406 | loss: 0.491845\n",
      "iteration: 1407 | loss: 0.652684\n",
      "iteration: 1408 | loss: 0.492784\n",
      "iteration: 1409 | loss: 0.404263\n",
      "iteration: 1410 | loss: 0.428042\n",
      "iteration: 1411 | loss: 0.496402\n",
      "iteration: 1412 | loss: 0.582396\n",
      "iteration: 1413 | loss: 0.393603\n",
      "iteration: 1414 | loss: 0.349052\n",
      "iteration: 1415 | loss: 0.450981\n",
      "iteration: 1416 | loss: 0.552810\n",
      "iteration: 1417 | loss: 0.573170\n",
      "iteration: 1418 | loss: 0.255364\n",
      "iteration: 1419 | loss: 0.499528\n",
      "iteration: 1420 | loss: 0.602938\n",
      "iteration: 1421 | loss: 0.686322\n",
      "iteration: 1422 | loss: 0.525904\n",
      "iteration: 1423 | loss: 0.625288\n",
      "iteration: 1424 | loss: 0.394488\n",
      "  Train acc: 0.892, Val acc: 0.5\n",
      "iteration: 1425 | loss: 0.649433\n",
      "iteration: 1426 | loss: 0.422355\n",
      "iteration: 1427 | loss: 0.573902\n",
      "iteration: 1428 | loss: 0.413028\n",
      "iteration: 1429 | loss: 0.372326\n",
      "iteration: 1430 | loss: 0.852741\n",
      "iteration: 1431 | loss: 0.317104\n",
      "iteration: 1432 | loss: 0.640044\n",
      "iteration: 1433 | loss: 0.279348\n",
      "iteration: 1434 | loss: 0.505169\n",
      "iteration: 1435 | loss: 0.602348\n",
      "iteration: 1436 | loss: 0.496704\n",
      "iteration: 1437 | loss: 0.570438\n",
      "iteration: 1438 | loss: 0.430827\n",
      "iteration: 1439 | loss: 0.522711\n",
      "iteration: 1440 | loss: 0.819743\n",
      "iteration: 1441 | loss: 0.559362\n",
      "iteration: 1442 | loss: 0.424602\n",
      "iteration: 1443 | loss: 0.168130\n",
      "iteration: 1444 | loss: 0.373695\n",
      "iteration: 1445 | loss: 0.503921\n",
      "iteration: 1446 | loss: 0.392694\n",
      "iteration: 1447 | loss: 0.477160\n",
      "iteration: 1448 | loss: 0.238576\n",
      "iteration: 1449 | loss: 0.397261\n",
      "  Train acc: 0.842, Val acc: 0.5\n",
      "iteration: 1450 | loss: 0.446572\n",
      "iteration: 1451 | loss: 0.580409\n",
      "iteration: 1452 | loss: 0.463429\n",
      "iteration: 1453 | loss: 0.822690\n",
      "iteration: 1454 | loss: 0.524727\n",
      "iteration: 1455 | loss: 0.256207\n",
      "iteration: 1456 | loss: 0.418688\n",
      "iteration: 1457 | loss: 0.612564\n",
      "iteration: 1458 | loss: 0.302623\n",
      "iteration: 1459 | loss: 0.464354\n",
      "iteration: 1460 | loss: 0.240681\n",
      "iteration: 1461 | loss: 0.540671\n",
      "iteration: 1462 | loss: 0.504819\n",
      "iteration: 1463 | loss: 0.434895\n",
      "iteration: 1464 | loss: 0.398338\n",
      "iteration: 1465 | loss: 0.329649\n",
      "iteration: 1466 | loss: 0.500912\n",
      "iteration: 1467 | loss: 0.724452\n",
      "iteration: 1468 | loss: 0.747468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1469 | loss: 0.486550\n",
      "iteration: 1470 | loss: 0.534113\n",
      "iteration: 1471 | loss: 0.430285\n",
      "iteration: 1472 | loss: 0.330938\n",
      "iteration: 1473 | loss: 0.649990\n",
      "iteration: 1474 | loss: 0.604231\n",
      "  Train acc: 0.86, Val acc: 0.5\n",
      "iteration: 1475 | loss: 0.295786\n",
      "iteration: 1476 | loss: 0.374093\n",
      "iteration: 1477 | loss: 0.435936\n",
      "iteration: 1478 | loss: 0.492887\n",
      "iteration: 1479 | loss: 0.382886\n",
      "iteration: 1480 | loss: 0.534680\n",
      "iteration: 1481 | loss: 0.362070\n",
      "iteration: 1482 | loss: 0.377814\n",
      "iteration: 1483 | loss: 0.431285\n",
      "iteration: 1484 | loss: 0.398937\n",
      "iteration: 1485 | loss: 0.339444\n",
      "iteration: 1486 | loss: 0.444395\n",
      "iteration: 1487 | loss: 0.754892\n",
      "iteration: 1488 | loss: 0.352086\n",
      "iteration: 1489 | loss: 0.339000\n",
      "iteration: 1490 | loss: 0.448824\n",
      "iteration: 1491 | loss: 0.420697\n",
      "iteration: 1492 | loss: 0.478979\n",
      "iteration: 1493 | loss: 0.296556\n",
      "iteration: 1494 | loss: 0.410956\n",
      "iteration: 1495 | loss: 0.469769\n",
      "iteration: 1496 | loss: 0.388682\n",
      "iteration: 1497 | loss: 0.406577\n",
      "iteration: 1498 | loss: 0.588308\n",
      "iteration: 1499 | loss: 0.379156\n",
      "  Train acc: 0.842, Val acc: 0.5\n",
      "iteration: 1500 | loss: 0.243634\n",
      "iteration: 1501 | loss: 0.515836\n",
      "iteration: 1502 | loss: 0.360084\n",
      "iteration: 1503 | loss: 0.622917\n",
      "iteration: 1504 | loss: 0.573774\n",
      "iteration: 1505 | loss: 0.358321\n",
      "iteration: 1506 | loss: 0.360896\n",
      "iteration: 1507 | loss: 0.428160\n",
      "iteration: 1508 | loss: 0.198311\n",
      "iteration: 1509 | loss: 0.351681\n",
      "iteration: 1510 | loss: 0.572677\n",
      "iteration: 1511 | loss: 0.314016\n",
      "iteration: 1512 | loss: 0.545503\n",
      "iteration: 1513 | loss: 0.290684\n",
      "iteration: 1514 | loss: 0.279719\n",
      "iteration: 1515 | loss: 0.438782\n",
      "iteration: 1516 | loss: 0.313283\n",
      "iteration: 1517 | loss: 0.244490\n",
      "iteration: 1518 | loss: 0.562382\n",
      "iteration: 1519 | loss: 0.401214\n",
      "iteration: 1520 | loss: 0.156899\n",
      "iteration: 1521 | loss: 0.284025\n",
      "iteration: 1522 | loss: 0.312727\n",
      "iteration: 1523 | loss: 0.372563\n",
      "iteration: 1524 | loss: 0.360247\n",
      "  Train acc: 0.864, Val acc: 0.5\n",
      "iteration: 1525 | loss: 0.361335\n",
      "iteration: 1526 | loss: 0.610055\n",
      "iteration: 1527 | loss: 0.272874\n",
      "iteration: 1528 | loss: 0.349715\n",
      "iteration: 1529 | loss: 0.306622\n",
      "iteration: 1530 | loss: 0.463014\n",
      "iteration: 1531 | loss: 0.444995\n",
      "iteration: 1532 | loss: 0.552587\n",
      "iteration: 1533 | loss: 0.625015\n",
      "iteration: 1534 | loss: 0.546221\n",
      "iteration: 1535 | loss: 0.481282\n",
      "iteration: 1536 | loss: 0.512992\n",
      "iteration: 1537 | loss: 0.654152\n",
      "iteration: 1538 | loss: 0.489767\n",
      "iteration: 1539 | loss: 0.186730\n",
      "iteration: 1540 | loss: 0.395902\n",
      "iteration: 1541 | loss: 0.338397\n",
      "iteration: 1542 | loss: 0.718605\n",
      "iteration: 1543 | loss: 0.224808\n",
      "iteration: 1544 | loss: 0.379157\n",
      "iteration: 1545 | loss: 0.382690\n",
      "iteration: 1546 | loss: 0.565202\n",
      "iteration: 1547 | loss: 0.440692\n",
      "iteration: 1548 | loss: 0.527059\n",
      "iteration: 1549 | loss: 0.254020\n",
      "  Train acc: 0.876, Val acc: 0.5\n",
      "iteration: 1550 | loss: 0.726142\n",
      "iteration: 1551 | loss: 0.438093\n",
      "iteration: 1552 | loss: 0.261766\n",
      "iteration: 1553 | loss: 0.517544\n",
      "iteration: 1554 | loss: 0.270236\n",
      "iteration: 1555 | loss: 0.612025\n",
      "iteration: 1556 | loss: 0.381495\n",
      "iteration: 1557 | loss: 0.277265\n",
      "iteration: 1558 | loss: 0.325348\n",
      "iteration: 1559 | loss: 0.583042\n",
      "iteration: 1560 | loss: 0.342409\n",
      "iteration: 1561 | loss: 0.251448\n",
      "iteration: 1562 | loss: 0.486798\n",
      "iteration: 1563 | loss: 0.342358\n",
      "iteration: 1564 | loss: 0.452922\n",
      "iteration: 1565 | loss: 0.726132\n",
      "iteration: 1566 | loss: 0.325474\n",
      "iteration: 1567 | loss: 0.523389\n",
      "iteration: 1568 | loss: 0.428653\n",
      "iteration: 1569 | loss: 0.357751\n",
      "iteration: 1570 | loss: 0.201114\n",
      "iteration: 1571 | loss: 0.456312\n",
      "iteration: 1572 | loss: 0.633959\n",
      "iteration: 1573 | loss: 0.571095\n",
      "iteration: 1574 | loss: 0.262550\n",
      "  Train acc: 0.88, Val acc: 0.5\n",
      "iteration: 1575 | loss: 0.487239\n",
      "iteration: 1576 | loss: 0.215946\n",
      "iteration: 1577 | loss: 0.496063\n",
      "iteration: 1578 | loss: 0.372708\n",
      "iteration: 1579 | loss: 0.434152\n",
      "iteration: 1580 | loss: 0.311200\n",
      "iteration: 1581 | loss: 0.513363\n",
      "iteration: 1582 | loss: 0.476830\n",
      "iteration: 1583 | loss: 0.088409\n",
      "iteration: 1584 | loss: 0.346979\n",
      "iteration: 1585 | loss: 0.318858\n",
      "iteration: 1586 | loss: 0.573753\n",
      "iteration: 1587 | loss: 0.576823\n",
      "iteration: 1588 | loss: 0.421169\n",
      "iteration: 1589 | loss: 0.334753\n",
      "iteration: 1590 | loss: 0.251149\n",
      "iteration: 1591 | loss: 0.238606\n",
      "iteration: 1592 | loss: 0.199609\n",
      "iteration: 1593 | loss: 0.276279\n",
      "iteration: 1594 | loss: 0.375686\n",
      "iteration: 1595 | loss: 0.317392\n",
      "iteration: 1596 | loss: 0.434059\n",
      "iteration: 1597 | loss: 0.379721\n",
      "iteration: 1598 | loss: 0.432191\n",
      "iteration: 1599 | loss: 0.203064\n",
      "  Train acc: 0.872, Val acc: 0.5\n",
      "iteration: 1600 | loss: 0.207588\n",
      "iteration: 1601 | loss: 0.715155\n",
      "iteration: 1602 | loss: 0.121524\n",
      "iteration: 1603 | loss: 0.523434\n",
      "iteration: 1604 | loss: 0.488445\n",
      "iteration: 1605 | loss: 0.229579\n",
      "iteration: 1606 | loss: 0.254267\n",
      "iteration: 1607 | loss: 0.303016\n",
      "iteration: 1608 | loss: 0.504426\n",
      "iteration: 1609 | loss: 0.298912\n",
      "iteration: 1610 | loss: 0.415484\n",
      "iteration: 1611 | loss: 0.264428\n",
      "iteration: 1612 | loss: 0.209847\n",
      "iteration: 1613 | loss: 0.341591\n",
      "iteration: 1614 | loss: 0.674525\n",
      "iteration: 1615 | loss: 0.724395\n",
      "iteration: 1616 | loss: 0.263541\n",
      "iteration: 1617 | loss: 0.434533\n",
      "iteration: 1618 | loss: 0.470277\n",
      "iteration: 1619 | loss: 0.399289\n",
      "iteration: 1620 | loss: 0.348480\n",
      "iteration: 1621 | loss: 0.333576\n",
      "iteration: 1622 | loss: 0.219443\n",
      "iteration: 1623 | loss: 0.282444\n",
      "iteration: 1624 | loss: 0.393446\n",
      "  Train acc: 0.888, Val acc: 0.5\n",
      "iteration: 1625 | loss: 0.489913\n",
      "iteration: 1626 | loss: 0.375249\n",
      "iteration: 1627 | loss: 0.462573\n",
      "iteration: 1628 | loss: 0.300853\n",
      "iteration: 1629 | loss: 0.128904\n",
      "iteration: 1630 | loss: 0.234184\n",
      "iteration: 1631 | loss: 0.245181\n",
      "iteration: 1632 | loss: 0.445460\n",
      "iteration: 1633 | loss: 0.282154\n",
      "iteration: 1634 | loss: 0.319355\n",
      "iteration: 1635 | loss: 0.536425\n",
      "iteration: 1636 | loss: 0.354376\n",
      "iteration: 1637 | loss: 0.246788\n",
      "iteration: 1638 | loss: 0.209777\n",
      "iteration: 1639 | loss: 0.232063\n",
      "iteration: 1640 | loss: 0.414447\n",
      "iteration: 1641 | loss: 0.151486\n",
      "iteration: 1642 | loss: 0.405614\n",
      "iteration: 1643 | loss: 0.417449\n",
      "iteration: 1644 | loss: 0.223332\n",
      "iteration: 1645 | loss: 0.495428\n",
      "iteration: 1646 | loss: 0.232582\n",
      "iteration: 1647 | loss: 0.272150\n",
      "iteration: 1648 | loss: 0.386084\n",
      "iteration: 1649 | loss: 0.358049\n",
      "  Train acc: 0.896, Val acc: 0.5\n",
      "iteration: 1650 | loss: 0.312012\n",
      "iteration: 1651 | loss: 0.344590\n",
      "iteration: 1652 | loss: 0.313747\n",
      "iteration: 1653 | loss: 0.206332\n",
      "iteration: 1654 | loss: 0.523130\n",
      "iteration: 1655 | loss: 0.131475\n",
      "iteration: 1656 | loss: 0.340457\n",
      "iteration: 1657 | loss: 0.237743\n",
      "iteration: 1658 | loss: 0.299586\n",
      "iteration: 1659 | loss: 0.378983\n",
      "iteration: 1660 | loss: 0.511805\n",
      "iteration: 1661 | loss: 0.305551\n",
      "iteration: 1662 | loss: 0.294214\n",
      "iteration: 1663 | loss: 0.218356\n",
      "iteration: 1664 | loss: 0.265099\n",
      "iteration: 1665 | loss: 0.559404\n",
      "iteration: 1666 | loss: 0.340979\n",
      "iteration: 1667 | loss: 0.343805\n",
      "iteration: 1668 | loss: 0.359085\n",
      "iteration: 1669 | loss: 0.316667\n",
      "iteration: 1670 | loss: 0.220167\n",
      "iteration: 1671 | loss: 0.434294\n",
      "iteration: 1672 | loss: 0.285640\n",
      "iteration: 1673 | loss: 0.433678\n",
      "iteration: 1674 | loss: 0.325839\n",
      "  Train acc: 0.884, Val acc: 0.5\n",
      "iteration: 1675 | loss: 0.365383\n",
      "iteration: 1676 | loss: 0.690894\n",
      "iteration: 1677 | loss: 0.572836\n",
      "iteration: 1678 | loss: 0.194949\n",
      "iteration: 1679 | loss: 0.406257\n",
      "iteration: 1680 | loss: 0.367486\n",
      "iteration: 1681 | loss: 0.310172\n",
      "iteration: 1682 | loss: 0.579931\n",
      "iteration: 1683 | loss: 0.413117\n",
      "iteration: 1684 | loss: 0.234878\n",
      "iteration: 1685 | loss: 0.366039\n",
      "iteration: 1686 | loss: 0.127991\n",
      "iteration: 1687 | loss: 0.724306\n",
      "iteration: 1688 | loss: 0.177628\n",
      "iteration: 1689 | loss: 0.226943\n",
      "iteration: 1690 | loss: 0.140797\n",
      "iteration: 1691 | loss: 0.275421\n",
      "iteration: 1692 | loss: 0.312797\n",
      "iteration: 1693 | loss: 0.235435\n",
      "iteration: 1694 | loss: 0.375732\n",
      "iteration: 1695 | loss: 0.353596\n",
      "iteration: 1696 | loss: 0.450957\n",
      "iteration: 1697 | loss: 0.194399\n",
      "iteration: 1698 | loss: 0.413289\n",
      "iteration: 1699 | loss: 0.235490\n",
      "  Train acc: 0.902, Val acc: 0.5\n",
      "iteration: 1700 | loss: 0.262848\n",
      "iteration: 1701 | loss: 0.291237\n",
      "iteration: 1702 | loss: 0.386375\n",
      "iteration: 1703 | loss: 0.272021\n",
      "iteration: 1704 | loss: 0.474723\n",
      "iteration: 1705 | loss: 0.344770\n",
      "iteration: 1706 | loss: 0.279311\n",
      "iteration: 1707 | loss: 0.271552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1708 | loss: 0.133003\n",
      "iteration: 1709 | loss: 0.262235\n",
      "iteration: 1710 | loss: 0.294978\n",
      "iteration: 1711 | loss: 0.595842\n",
      "iteration: 1712 | loss: 0.202514\n",
      "iteration: 1713 | loss: 0.233203\n",
      "iteration: 1714 | loss: 0.461085\n",
      "iteration: 1715 | loss: 0.242346\n",
      "iteration: 1716 | loss: 0.206081\n",
      "iteration: 1717 | loss: 0.162305\n",
      "iteration: 1718 | loss: 0.271250\n",
      "iteration: 1719 | loss: 0.224584\n",
      "iteration: 1720 | loss: 0.148753\n",
      "iteration: 1721 | loss: 0.297243\n",
      "iteration: 1722 | loss: 0.365555\n",
      "iteration: 1723 | loss: 0.417812\n",
      "iteration: 1724 | loss: 0.324878\n",
      "  Train acc: 0.926, Val acc: 0.5\n",
      "iteration: 1725 | loss: 0.358477\n",
      "iteration: 1726 | loss: 0.229844\n",
      "iteration: 1727 | loss: 0.316898\n",
      "iteration: 1728 | loss: 0.356732\n",
      "iteration: 1729 | loss: 0.325121\n",
      "iteration: 1730 | loss: 0.215593\n",
      "iteration: 1731 | loss: 0.689432\n",
      "iteration: 1732 | loss: 0.261646\n",
      "iteration: 1733 | loss: 0.465976\n",
      "iteration: 1734 | loss: 0.375253\n",
      "iteration: 1735 | loss: 0.256123\n",
      "iteration: 1736 | loss: 0.421903\n",
      "iteration: 1737 | loss: 0.186307\n",
      "iteration: 1738 | loss: 0.271565\n",
      "iteration: 1739 | loss: 0.303734\n",
      "iteration: 1740 | loss: 0.252359\n",
      "iteration: 1741 | loss: 0.416306\n",
      "iteration: 1742 | loss: 0.424053\n",
      "iteration: 1743 | loss: 0.201493\n",
      "iteration: 1744 | loss: 0.435766\n",
      "iteration: 1745 | loss: 0.178008\n",
      "iteration: 1746 | loss: 0.237174\n",
      "iteration: 1747 | loss: 0.409039\n",
      "iteration: 1748 | loss: 0.509140\n",
      "iteration: 1749 | loss: 0.227093\n",
      "  Train acc: 0.916, Val acc: 0.5\n",
      "iteration: 1750 | loss: 0.216461\n",
      "iteration: 1751 | loss: 0.149076\n",
      "iteration: 1752 | loss: 0.188918\n",
      "iteration: 1753 | loss: 0.331407\n",
      "iteration: 1754 | loss: 0.445584\n",
      "iteration: 1755 | loss: 0.445737\n",
      "iteration: 1756 | loss: 0.248006\n",
      "iteration: 1757 | loss: 0.333592\n",
      "iteration: 1758 | loss: 0.245625\n",
      "iteration: 1759 | loss: 0.177449\n",
      "iteration: 1760 | loss: 0.320319\n",
      "iteration: 1761 | loss: 0.354637\n",
      "iteration: 1762 | loss: 0.283582\n",
      "iteration: 1763 | loss: 0.259661\n",
      "iteration: 1764 | loss: 0.309936\n",
      "iteration: 1765 | loss: 0.242721\n",
      "iteration: 1766 | loss: 0.279799\n",
      "iteration: 1767 | loss: 0.488187\n",
      "iteration: 1768 | loss: 0.301437\n",
      "iteration: 1769 | loss: 0.269293\n",
      "iteration: 1770 | loss: 0.552018\n",
      "iteration: 1771 | loss: 0.110975\n",
      "iteration: 1772 | loss: 0.437119\n",
      "iteration: 1773 | loss: 0.290708\n",
      "iteration: 1774 | loss: 0.364923\n",
      "  Train acc: 0.904, Val acc: 0.5\n",
      "iteration: 1775 | loss: 0.349024\n",
      "iteration: 1776 | loss: 0.504312\n",
      "iteration: 1777 | loss: 0.161702\n",
      "iteration: 1778 | loss: 0.340497\n",
      "iteration: 1779 | loss: 0.316272\n",
      "iteration: 1780 | loss: 0.564850\n",
      "iteration: 1781 | loss: 0.343686\n",
      "iteration: 1782 | loss: 0.419486\n",
      "iteration: 1783 | loss: 0.234581\n",
      "iteration: 1784 | loss: 0.164531\n",
      "iteration: 1785 | loss: 0.254455\n",
      "iteration: 1786 | loss: 0.186348\n",
      "iteration: 1787 | loss: 0.346805\n",
      "iteration: 1788 | loss: 0.179038\n",
      "iteration: 1789 | loss: 0.273876\n",
      "iteration: 1790 | loss: 0.286837\n",
      "iteration: 1791 | loss: 0.355998\n",
      "iteration: 1792 | loss: 0.457081\n",
      "iteration: 1793 | loss: 0.239179\n",
      "iteration: 1794 | loss: 0.470465\n",
      "iteration: 1795 | loss: 0.286945\n",
      "iteration: 1796 | loss: 0.325722\n",
      "iteration: 1797 | loss: 0.182700\n",
      "iteration: 1798 | loss: 0.351808\n",
      "iteration: 1799 | loss: 0.290869\n",
      "  Train acc: 0.93, Val acc: 0.5\n",
      "iteration: 1800 | loss: 0.219279\n",
      "iteration: 1801 | loss: 0.248401\n",
      "iteration: 1802 | loss: 0.391889\n",
      "iteration: 1803 | loss: 0.193105\n",
      "iteration: 1804 | loss: 0.468373\n",
      "iteration: 1805 | loss: 0.298293\n",
      "iteration: 1806 | loss: 0.251052\n",
      "iteration: 1807 | loss: 0.587713\n",
      "iteration: 1808 | loss: 0.147192\n",
      "iteration: 1809 | loss: 0.233693\n",
      "iteration: 1810 | loss: 0.320717\n",
      "iteration: 1811 | loss: 0.252870\n",
      "iteration: 1812 | loss: 0.210921\n",
      "iteration: 1813 | loss: 0.278046\n",
      "iteration: 1814 | loss: 0.179751\n",
      "iteration: 1815 | loss: 0.152731\n",
      "iteration: 1816 | loss: 0.312887\n",
      "iteration: 1817 | loss: 0.154519\n",
      "iteration: 1818 | loss: 0.209142\n",
      "iteration: 1819 | loss: 0.455359\n",
      "iteration: 1820 | loss: 0.356999\n",
      "iteration: 1821 | loss: 0.184572\n",
      "iteration: 1822 | loss: 0.353849\n",
      "iteration: 1823 | loss: 0.256780\n",
      "iteration: 1824 | loss: 0.228369\n",
      "  Train acc: 0.944, Val acc: 0.5\n",
      "iteration: 1825 | loss: 0.204427\n",
      "iteration: 1826 | loss: 0.153327\n",
      "iteration: 1827 | loss: 0.185170\n",
      "iteration: 1828 | loss: 0.240122\n",
      "iteration: 1829 | loss: 0.243950\n",
      "iteration: 1830 | loss: 0.425694\n",
      "iteration: 1831 | loss: 0.259379\n",
      "iteration: 1832 | loss: 0.140071\n",
      "iteration: 1833 | loss: 0.116143\n",
      "iteration: 1834 | loss: 0.081703\n",
      "iteration: 1835 | loss: 0.198291\n",
      "iteration: 1836 | loss: 0.403870\n",
      "iteration: 1837 | loss: 0.217123\n",
      "iteration: 1838 | loss: 0.254295\n",
      "iteration: 1839 | loss: 0.181106\n",
      "iteration: 1840 | loss: 0.434930\n",
      "iteration: 1841 | loss: 0.222426\n",
      "iteration: 1842 | loss: 0.128595\n",
      "iteration: 1843 | loss: 0.283056\n",
      "iteration: 1844 | loss: 0.345118\n",
      "iteration: 1845 | loss: 0.532093\n",
      "iteration: 1846 | loss: 0.153120\n",
      "iteration: 1847 | loss: 0.223250\n",
      "iteration: 1848 | loss: 0.174237\n",
      "iteration: 1849 | loss: 0.461456\n",
      "  Train acc: 0.944, Val acc: 0.5\n",
      "iteration: 1850 | loss: 0.249813\n",
      "iteration: 1851 | loss: 0.460953\n",
      "iteration: 1852 | loss: 0.081102\n",
      "iteration: 1853 | loss: 0.120664\n",
      "iteration: 1854 | loss: 0.365560\n",
      "iteration: 1855 | loss: 0.184195\n",
      "iteration: 1856 | loss: 0.302774\n",
      "iteration: 1857 | loss: 0.342858\n",
      "iteration: 1858 | loss: 0.066106\n",
      "iteration: 1859 | loss: 0.237029\n",
      "iteration: 1860 | loss: 0.195492\n",
      "iteration: 1861 | loss: 0.264340\n",
      "iteration: 1862 | loss: 0.277056\n",
      "iteration: 1863 | loss: 0.304862\n",
      "iteration: 1864 | loss: 0.208825\n",
      "iteration: 1865 | loss: 0.124307\n",
      "iteration: 1866 | loss: 0.182942\n",
      "iteration: 1867 | loss: 0.420046\n",
      "iteration: 1868 | loss: 0.248532\n",
      "iteration: 1869 | loss: 0.076980\n",
      "iteration: 1870 | loss: 0.304391\n",
      "iteration: 1871 | loss: 0.387928\n",
      "iteration: 1872 | loss: 0.234996\n",
      "iteration: 1873 | loss: 0.284603\n",
      "iteration: 1874 | loss: 0.370432\n",
      "  Train acc: 0.932, Val acc: 0.5\n",
      "iteration: 1875 | loss: 0.301978\n",
      "iteration: 1876 | loss: 0.347621\n",
      "iteration: 1877 | loss: 0.214816\n",
      "iteration: 1878 | loss: 0.220177\n",
      "iteration: 1879 | loss: 0.558619\n",
      "iteration: 1880 | loss: 0.079983\n",
      "iteration: 1881 | loss: 0.145353\n",
      "iteration: 1882 | loss: 0.212868\n",
      "iteration: 1883 | loss: 0.301640\n",
      "iteration: 1884 | loss: 0.078832\n",
      "iteration: 1885 | loss: 0.179589\n",
      "iteration: 1886 | loss: 0.104637\n",
      "iteration: 1887 | loss: 0.224287\n",
      "iteration: 1888 | loss: 0.359571\n",
      "iteration: 1889 | loss: 0.125873\n",
      "iteration: 1890 | loss: 0.275077\n",
      "iteration: 1891 | loss: 0.145498\n",
      "iteration: 1892 | loss: 0.489830\n",
      "iteration: 1893 | loss: 0.157306\n",
      "iteration: 1894 | loss: 0.171656\n",
      "iteration: 1895 | loss: 0.199945\n",
      "iteration: 1896 | loss: 0.138639\n",
      "iteration: 1897 | loss: 0.251918\n",
      "iteration: 1898 | loss: 0.240189\n",
      "iteration: 1899 | loss: 0.193742\n",
      "  Train acc: 0.93, Val acc: 0.5\n",
      "iteration: 1900 | loss: 0.182378\n",
      "iteration: 1901 | loss: 0.155801\n",
      "iteration: 1902 | loss: 0.341413\n",
      "iteration: 1903 | loss: 0.147117\n",
      "iteration: 1904 | loss: 0.115562\n",
      "iteration: 1905 | loss: 0.222984\n",
      "iteration: 1906 | loss: 0.124548\n",
      "iteration: 1907 | loss: 0.131647\n",
      "iteration: 1908 | loss: 0.152580\n",
      "iteration: 1909 | loss: 0.115931\n",
      "iteration: 1910 | loss: 0.385209\n",
      "iteration: 1911 | loss: 0.300984\n",
      "iteration: 1912 | loss: 0.174989\n",
      "iteration: 1913 | loss: 0.222015\n",
      "iteration: 1914 | loss: 0.296813\n",
      "iteration: 1915 | loss: 0.267161\n",
      "iteration: 1916 | loss: 0.187780\n",
      "iteration: 1917 | loss: 0.164862\n",
      "iteration: 1918 | loss: 0.165974\n",
      "iteration: 1919 | loss: 0.225396\n",
      "iteration: 1920 | loss: 0.162318\n",
      "iteration: 1921 | loss: 0.259537\n",
      "iteration: 1922 | loss: 0.087017\n",
      "iteration: 1923 | loss: 0.537785\n",
      "iteration: 1924 | loss: 0.171280\n",
      "  Train acc: 0.958, Val acc: 0.5\n",
      "iteration: 1925 | loss: 0.421592\n",
      "iteration: 1926 | loss: 0.084454\n",
      "iteration: 1927 | loss: 0.127945\n",
      "iteration: 1928 | loss: 0.247682\n",
      "iteration: 1929 | loss: 0.034371\n",
      "iteration: 1930 | loss: 0.227789\n",
      "iteration: 1931 | loss: 0.170436\n",
      "iteration: 1932 | loss: 0.274794\n",
      "iteration: 1933 | loss: 0.061801\n",
      "iteration: 1934 | loss: 0.311310\n",
      "iteration: 1935 | loss: 0.211606\n",
      "iteration: 1936 | loss: 0.138860\n",
      "iteration: 1937 | loss: 0.273024\n",
      "iteration: 1938 | loss: 0.207438\n",
      "iteration: 1939 | loss: 0.390675\n",
      "iteration: 1940 | loss: 0.422221\n",
      "iteration: 1941 | loss: 0.238611\n",
      "iteration: 1942 | loss: 0.439502\n",
      "iteration: 1943 | loss: 0.245653\n",
      "iteration: 1944 | loss: 0.163735\n",
      "iteration: 1945 | loss: 0.217643\n",
      "iteration: 1946 | loss: 0.343587\n",
      "iteration: 1947 | loss: 0.150435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1948 | loss: 0.166496\n",
      "iteration: 1949 | loss: 0.153686\n",
      "  Train acc: 0.948, Val acc: 0.5\n",
      "iteration: 1950 | loss: 0.118145\n",
      "iteration: 1951 | loss: 0.108230\n",
      "iteration: 1952 | loss: 0.358989\n",
      "iteration: 1953 | loss: 0.296174\n",
      "iteration: 1954 | loss: 0.207882\n",
      "iteration: 1955 | loss: 0.181074\n",
      "iteration: 1956 | loss: 0.086795\n",
      "iteration: 1957 | loss: 0.146543\n",
      "iteration: 1958 | loss: 0.177333\n",
      "iteration: 1959 | loss: 0.080835\n",
      "iteration: 1960 | loss: 0.146865\n",
      "iteration: 1961 | loss: 0.104653\n",
      "iteration: 1962 | loss: 0.314349\n",
      "iteration: 1963 | loss: 0.106372\n",
      "iteration: 1964 | loss: 0.167976\n",
      "iteration: 1965 | loss: 0.133289\n",
      "iteration: 1966 | loss: 0.346134\n",
      "iteration: 1967 | loss: 0.157226\n",
      "iteration: 1968 | loss: 0.176684\n",
      "iteration: 1969 | loss: 0.110736\n",
      "iteration: 1970 | loss: 0.202991\n",
      "iteration: 1971 | loss: 0.382016\n",
      "iteration: 1972 | loss: 0.241255\n",
      "iteration: 1973 | loss: 0.104887\n",
      "iteration: 1974 | loss: 0.203662\n",
      "  Train acc: 0.934, Val acc: 0.5\n",
      "iteration: 1975 | loss: 0.352536\n",
      "iteration: 1976 | loss: 0.145100\n",
      "iteration: 1977 | loss: 0.306297\n",
      "iteration: 1978 | loss: 0.162665\n",
      "iteration: 1979 | loss: 0.204272\n",
      "iteration: 1980 | loss: 0.412097\n",
      "iteration: 1981 | loss: 0.225569\n",
      "iteration: 1982 | loss: 0.225916\n",
      "iteration: 1983 | loss: 0.313256\n",
      "iteration: 1984 | loss: 0.265581\n",
      "iteration: 1985 | loss: 0.491738\n",
      "iteration: 1986 | loss: 0.257221\n",
      "iteration: 1987 | loss: 0.440673\n",
      "iteration: 1988 | loss: 0.378793\n",
      "iteration: 1989 | loss: 0.191549\n",
      "iteration: 1990 | loss: 0.256021\n",
      "iteration: 1991 | loss: 0.268551\n",
      "iteration: 1992 | loss: 0.160286\n",
      "iteration: 1993 | loss: 0.340844\n",
      "iteration: 1994 | loss: 0.160859\n",
      "iteration: 1995 | loss: 0.287189\n",
      "iteration: 1996 | loss: 0.228139\n",
      "iteration: 1997 | loss: 0.286075\n",
      "iteration: 1998 | loss: 0.105690\n",
      "iteration: 1999 | loss: 0.201885\n",
      "  Train acc: 0.948, Val acc: 0.5\n",
      "iteration: 2000 | loss: 0.328069\n",
      "iteration: 2001 | loss: 0.111312\n",
      "iteration: 2002 | loss: 0.113633\n",
      "iteration: 2003 | loss: 0.168042\n",
      "iteration: 2004 | loss: 0.235549\n",
      "iteration: 2005 | loss: 0.102085\n",
      "iteration: 2006 | loss: 0.230517\n",
      "iteration: 2007 | loss: 0.226578\n",
      "iteration: 2008 | loss: 0.045193\n",
      "iteration: 2009 | loss: 0.071016\n",
      "iteration: 2010 | loss: 0.102893\n",
      "iteration: 2011 | loss: 0.213894\n",
      "iteration: 2012 | loss: 0.212222\n",
      "iteration: 2013 | loss: 0.129207\n",
      "iteration: 2014 | loss: 0.075333\n",
      "iteration: 2015 | loss: 0.183786\n",
      "iteration: 2016 | loss: 0.145884\n",
      "iteration: 2017 | loss: 0.184889\n",
      "iteration: 2018 | loss: 0.128846\n",
      "iteration: 2019 | loss: 0.114395\n",
      "iteration: 2020 | loss: 0.047778\n",
      "iteration: 2021 | loss: 0.133183\n",
      "iteration: 2022 | loss: 0.361058\n",
      "iteration: 2023 | loss: 0.359387\n",
      "iteration: 2024 | loss: 0.143992\n",
      "  Train acc: 0.94, Val acc: 0.5\n",
      "iteration: 2025 | loss: 0.418749\n",
      "iteration: 2026 | loss: 0.302176\n",
      "iteration: 2027 | loss: 0.185991\n",
      "iteration: 2028 | loss: 0.249414\n",
      "iteration: 2029 | loss: 0.231012\n",
      "iteration: 2030 | loss: 0.162513\n",
      "iteration: 2031 | loss: 0.258722\n",
      "iteration: 2032 | loss: 0.167687\n",
      "iteration: 2033 | loss: 0.169319\n",
      "iteration: 2034 | loss: 0.275993\n",
      "iteration: 2035 | loss: 0.252418\n",
      "iteration: 2036 | loss: 0.226223\n",
      "iteration: 2037 | loss: 0.180906\n",
      "iteration: 2038 | loss: 0.109631\n",
      "iteration: 2039 | loss: 0.081088\n",
      "iteration: 2040 | loss: 0.185349\n",
      "iteration: 2041 | loss: 0.172251\n",
      "iteration: 2042 | loss: 0.165241\n",
      "iteration: 2043 | loss: 0.308511\n",
      "iteration: 2044 | loss: 0.217832\n",
      "iteration: 2045 | loss: 0.107490\n",
      "iteration: 2046 | loss: 0.243447\n",
      "iteration: 2047 | loss: 0.080935\n",
      "iteration: 2048 | loss: 0.162645\n",
      "iteration: 2049 | loss: 0.148682\n",
      "  Train acc: 0.956, Val acc: 0.5\n",
      "iteration: 2050 | loss: 0.038365\n",
      "iteration: 2051 | loss: 0.127328\n",
      "iteration: 2052 | loss: 0.158163\n",
      "iteration: 2053 | loss: 0.351462\n",
      "iteration: 2054 | loss: 0.097262\n",
      "iteration: 2055 | loss: 0.202884\n",
      "iteration: 2056 | loss: 0.366318\n",
      "iteration: 2057 | loss: 0.161130\n",
      "iteration: 2058 | loss: 0.077287\n",
      "iteration: 2059 | loss: 0.341004\n",
      "iteration: 2060 | loss: 0.377150\n",
      "iteration: 2061 | loss: 0.126330\n",
      "iteration: 2062 | loss: 0.085465\n",
      "iteration: 2063 | loss: 0.261406\n",
      "iteration: 2064 | loss: 0.198011\n",
      "iteration: 2065 | loss: 0.183333\n",
      "iteration: 2066 | loss: 0.154600\n",
      "iteration: 2067 | loss: 0.121027\n",
      "iteration: 2068 | loss: 0.224829\n",
      "iteration: 2069 | loss: 0.289426\n",
      "iteration: 2070 | loss: 0.131685\n",
      "iteration: 2071 | loss: 0.241662\n",
      "iteration: 2072 | loss: 0.325463\n",
      "iteration: 2073 | loss: 0.130689\n",
      "iteration: 2074 | loss: 0.051020\n",
      "  Train acc: 0.968, Val acc: 0.5\n",
      "iteration: 2075 | loss: 0.090270\n",
      "iteration: 2076 | loss: 0.170592\n",
      "iteration: 2077 | loss: 0.115138\n",
      "iteration: 2078 | loss: 0.113916\n",
      "iteration: 2079 | loss: 0.252126\n",
      "iteration: 2080 | loss: 0.143574\n",
      "iteration: 2081 | loss: 0.140689\n",
      "iteration: 2082 | loss: 0.184126\n",
      "iteration: 2083 | loss: 0.146060\n",
      "iteration: 2084 | loss: 0.085259\n",
      "iteration: 2085 | loss: 0.116979\n",
      "iteration: 2086 | loss: 0.141263\n",
      "iteration: 2087 | loss: 0.128888\n",
      "iteration: 2088 | loss: 0.110065\n",
      "iteration: 2089 | loss: 0.191876\n",
      "iteration: 2090 | loss: 0.187431\n",
      "iteration: 2091 | loss: 0.265711\n",
      "iteration: 2092 | loss: 0.073290\n",
      "iteration: 2093 | loss: 0.229661\n",
      "iteration: 2094 | loss: 0.185458\n",
      "iteration: 2095 | loss: 0.137893\n",
      "iteration: 2096 | loss: 0.096306\n",
      "iteration: 2097 | loss: 0.076836\n",
      "iteration: 2098 | loss: 0.160657\n",
      "iteration: 2099 | loss: 0.103040\n",
      "  Train acc: 0.964, Val acc: 0.5\n",
      "iteration: 2100 | loss: 0.181840\n",
      "iteration: 2101 | loss: 0.060559\n",
      "iteration: 2102 | loss: 0.077574\n",
      "iteration: 2103 | loss: 0.122575\n",
      "iteration: 2104 | loss: 0.221631\n",
      "iteration: 2105 | loss: 0.138811\n",
      "iteration: 2106 | loss: 0.190365\n",
      "iteration: 2107 | loss: 0.183862\n",
      "iteration: 2108 | loss: 0.137661\n",
      "iteration: 2109 | loss: 0.119832\n",
      "iteration: 2110 | loss: 0.244765\n",
      "iteration: 2111 | loss: 0.141800\n",
      "iteration: 2112 | loss: 0.141997\n",
      "iteration: 2113 | loss: 0.114947\n",
      "iteration: 2114 | loss: 0.150339\n",
      "iteration: 2115 | loss: 0.203585\n",
      "iteration: 2116 | loss: 0.344670\n",
      "iteration: 2117 | loss: 0.137469\n",
      "iteration: 2118 | loss: 0.100148\n",
      "iteration: 2119 | loss: 0.175880\n",
      "iteration: 2120 | loss: 0.097185\n",
      "iteration: 2121 | loss: 0.220533\n",
      "iteration: 2122 | loss: 0.109318\n",
      "iteration: 2123 | loss: 0.151636\n",
      "iteration: 2124 | loss: 0.144869\n",
      "  Train acc: 0.964, Val acc: 0.5\n",
      "iteration: 2125 | loss: 0.070348\n",
      "iteration: 2126 | loss: 0.330621\n",
      "iteration: 2127 | loss: 0.094680\n",
      "iteration: 2128 | loss: 0.355633\n",
      "iteration: 2129 | loss: 0.284358\n",
      "iteration: 2130 | loss: 0.220264\n",
      "iteration: 2131 | loss: 0.117651\n",
      "iteration: 2132 | loss: 0.158379\n",
      "iteration: 2133 | loss: 0.073258\n",
      "iteration: 2134 | loss: 0.173820\n",
      "iteration: 2135 | loss: 0.180896\n",
      "iteration: 2136 | loss: 0.171255\n",
      "iteration: 2137 | loss: 0.083796\n",
      "iteration: 2138 | loss: 0.066462\n",
      "iteration: 2139 | loss: 0.315124\n",
      "iteration: 2140 | loss: 0.091646\n",
      "iteration: 2141 | loss: 0.109022\n",
      "iteration: 2142 | loss: 0.271576\n",
      "iteration: 2143 | loss: 0.065487\n",
      "iteration: 2144 | loss: 0.272449\n",
      "iteration: 2145 | loss: 0.210992\n",
      "iteration: 2146 | loss: 0.154350\n",
      "iteration: 2147 | loss: 0.145803\n",
      "iteration: 2148 | loss: 0.199466\n",
      "iteration: 2149 | loss: 0.108157\n",
      "  Train acc: 0.952, Val acc: 0.5\n",
      "iteration: 2150 | loss: 0.116258\n",
      "iteration: 2151 | loss: 0.108106\n",
      "iteration: 2152 | loss: 0.243819\n",
      "iteration: 2153 | loss: 0.191499\n",
      "iteration: 2154 | loss: 0.303567\n",
      "iteration: 2155 | loss: 0.275428\n",
      "iteration: 2156 | loss: 0.484886\n",
      "iteration: 2157 | loss: 0.176426\n",
      "iteration: 2158 | loss: 0.169451\n",
      "iteration: 2159 | loss: 0.091025\n",
      "iteration: 2160 | loss: 0.108993\n",
      "iteration: 2161 | loss: 0.073923\n",
      "iteration: 2162 | loss: 0.148243\n",
      "iteration: 2163 | loss: 0.345668\n",
      "iteration: 2164 | loss: 0.205028\n",
      "iteration: 2165 | loss: 0.164390\n",
      "iteration: 2166 | loss: 0.184719\n",
      "iteration: 2167 | loss: 0.120569\n",
      "iteration: 2168 | loss: 0.382333\n",
      "iteration: 2169 | loss: 0.082452\n",
      "iteration: 2170 | loss: 0.113764\n",
      "iteration: 2171 | loss: 0.059813\n",
      "iteration: 2172 | loss: 0.138112\n",
      "iteration: 2173 | loss: 0.272021\n",
      "iteration: 2174 | loss: 0.137332\n",
      "  Train acc: 0.958, Val acc: 0.5\n",
      "iteration: 2175 | loss: 0.052241\n",
      "iteration: 2176 | loss: 0.132178\n",
      "iteration: 2177 | loss: 0.123498\n",
      "iteration: 2178 | loss: 0.139180\n",
      "iteration: 2179 | loss: 0.261052\n",
      "iteration: 2180 | loss: 0.208497\n",
      "iteration: 2181 | loss: 0.125419\n",
      "iteration: 2182 | loss: 0.238680\n",
      "iteration: 2183 | loss: 0.151807\n",
      "iteration: 2184 | loss: 0.132018\n",
      "iteration: 2185 | loss: 0.083167\n",
      "iteration: 2186 | loss: 0.157083\n",
      "iteration: 2187 | loss: 0.217570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2188 | loss: 0.239083\n",
      "iteration: 2189 | loss: 0.246958\n",
      "iteration: 2190 | loss: 0.095236\n",
      "iteration: 2191 | loss: 0.062118\n",
      "iteration: 2192 | loss: 0.269188\n",
      "iteration: 2193 | loss: 0.196523\n",
      "iteration: 2194 | loss: 0.109569\n",
      "iteration: 2195 | loss: 0.098970\n",
      "iteration: 2196 | loss: 0.120655\n",
      "iteration: 2197 | loss: 0.104608\n",
      "iteration: 2198 | loss: 0.050953\n",
      "iteration: 2199 | loss: 0.039670\n",
      "  Train acc: 0.98, Val acc: 0.5\n",
      "iteration: 2200 | loss: 0.184344\n",
      "iteration: 2201 | loss: 0.058789\n",
      "iteration: 2202 | loss: 0.110582\n",
      "iteration: 2203 | loss: 0.253569\n",
      "iteration: 2204 | loss: 0.085410\n",
      "iteration: 2205 | loss: 0.045424\n",
      "iteration: 2206 | loss: 0.066769\n",
      "iteration: 2207 | loss: 0.157833\n",
      "iteration: 2208 | loss: 0.045489\n",
      "iteration: 2209 | loss: 0.076619\n",
      "iteration: 2210 | loss: 0.072630\n",
      "iteration: 2211 | loss: 0.175373\n",
      "iteration: 2212 | loss: 0.211680\n",
      "iteration: 2213 | loss: 0.091534\n",
      "iteration: 2214 | loss: 0.032069\n",
      "iteration: 2215 | loss: 0.115112\n",
      "iteration: 2216 | loss: 0.115909\n",
      "iteration: 2217 | loss: 0.066402\n",
      "iteration: 2218 | loss: 0.141959\n",
      "iteration: 2219 | loss: 0.235302\n",
      "iteration: 2220 | loss: 0.073330\n",
      "iteration: 2221 | loss: 0.158212\n",
      "iteration: 2222 | loss: 0.082658\n",
      "iteration: 2223 | loss: 0.129357\n",
      "iteration: 2224 | loss: 0.113982\n",
      "  Train acc: 0.988, Val acc: 0.5\n",
      "iteration: 2225 | loss: 0.077807\n",
      "iteration: 2226 | loss: 0.203430\n",
      "iteration: 2227 | loss: 0.172192\n",
      "iteration: 2228 | loss: 0.066911\n",
      "iteration: 2229 | loss: 0.079213\n",
      "iteration: 2230 | loss: 0.090435\n",
      "iteration: 2231 | loss: 0.105205\n",
      "iteration: 2232 | loss: 0.053269\n",
      "iteration: 2233 | loss: 0.095933\n",
      "iteration: 2234 | loss: 0.063891\n",
      "iteration: 2235 | loss: 0.129191\n",
      "iteration: 2236 | loss: 0.061320\n",
      "iteration: 2237 | loss: 0.190807\n",
      "iteration: 2238 | loss: 0.110884\n",
      "iteration: 2239 | loss: 0.114514\n",
      "iteration: 2240 | loss: 0.051392\n",
      "iteration: 2241 | loss: 0.167560\n",
      "iteration: 2242 | loss: 0.144877\n",
      "iteration: 2243 | loss: 0.092798\n",
      "iteration: 2244 | loss: 0.154130\n",
      "iteration: 2245 | loss: 0.145477\n",
      "iteration: 2246 | loss: 0.131902\n",
      "iteration: 2247 | loss: 0.173605\n",
      "iteration: 2248 | loss: 0.130694\n",
      "iteration: 2249 | loss: 0.185814\n",
      "  Train acc: 0.974, Val acc: 0.5\n",
      "iteration: 2250 | loss: 0.075927\n",
      "iteration: 2251 | loss: 0.036764\n",
      "iteration: 2252 | loss: 0.063508\n",
      "iteration: 2253 | loss: 0.083511\n",
      "iteration: 2254 | loss: 0.202054\n",
      "iteration: 2255 | loss: 0.092745\n",
      "iteration: 2256 | loss: 0.090017\n",
      "iteration: 2257 | loss: 0.124957\n",
      "iteration: 2258 | loss: 0.056872\n",
      "iteration: 2259 | loss: 0.146148\n",
      "iteration: 2260 | loss: 0.195671\n",
      "iteration: 2261 | loss: 0.056006\n",
      "iteration: 2262 | loss: 0.065661\n",
      "iteration: 2263 | loss: 0.095186\n",
      "iteration: 2264 | loss: 0.099203\n",
      "iteration: 2265 | loss: 0.092529\n",
      "iteration: 2266 | loss: 0.087790\n",
      "iteration: 2267 | loss: 0.051305\n",
      "iteration: 2268 | loss: 0.081439\n",
      "iteration: 2269 | loss: 0.135837\n",
      "iteration: 2270 | loss: 0.047271\n",
      "iteration: 2271 | loss: 0.084375\n",
      "iteration: 2272 | loss: 0.138965\n",
      "iteration: 2273 | loss: 0.289840\n",
      "iteration: 2274 | loss: 0.048463\n",
      "  Train acc: 0.968, Val acc: 0.5\n",
      "iteration: 2275 | loss: 0.083766\n",
      "iteration: 2276 | loss: 0.034812\n",
      "iteration: 2277 | loss: 0.122115\n",
      "iteration: 2278 | loss: 0.165029\n",
      "iteration: 2279 | loss: 0.178724\n",
      "iteration: 2280 | loss: 0.093535\n",
      "iteration: 2281 | loss: 0.177658\n",
      "iteration: 2282 | loss: 0.408293\n",
      "iteration: 2283 | loss: 0.059075\n",
      "iteration: 2284 | loss: 0.050645\n",
      "iteration: 2285 | loss: 0.130322\n",
      "iteration: 2286 | loss: 0.106508\n",
      "iteration: 2287 | loss: 0.113148\n",
      "iteration: 2288 | loss: 0.065453\n",
      "iteration: 2289 | loss: 0.108732\n",
      "iteration: 2290 | loss: 0.165737\n",
      "iteration: 2291 | loss: 0.085438\n",
      "iteration: 2292 | loss: 0.089997\n",
      "iteration: 2293 | loss: 0.139081\n",
      "iteration: 2294 | loss: 0.089795\n",
      "iteration: 2295 | loss: 0.144177\n",
      "iteration: 2296 | loss: 0.097736\n",
      "iteration: 2297 | loss: 0.080556\n",
      "iteration: 2298 | loss: 0.456982\n",
      "iteration: 2299 | loss: 0.098457\n",
      "  Train acc: 0.97, Val acc: 0.5\n",
      "iteration: 2300 | loss: 0.086811\n",
      "iteration: 2301 | loss: 0.107439\n",
      "iteration: 2302 | loss: 0.083887\n",
      "iteration: 2303 | loss: 0.385862\n",
      "iteration: 2304 | loss: 0.046203\n",
      "iteration: 2305 | loss: 0.051639\n",
      "iteration: 2306 | loss: 0.170943\n",
      "iteration: 2307 | loss: 0.151156\n",
      "iteration: 2308 | loss: 0.133346\n",
      "iteration: 2309 | loss: 0.105649\n",
      "iteration: 2310 | loss: 0.078652\n",
      "iteration: 2311 | loss: 0.050359\n",
      "iteration: 2312 | loss: 0.102089\n",
      "iteration: 2313 | loss: 0.189836\n",
      "iteration: 2314 | loss: 0.143904\n",
      "iteration: 2315 | loss: 0.066111\n",
      "iteration: 2316 | loss: 0.110665\n",
      "iteration: 2317 | loss: 0.080785\n",
      "iteration: 2318 | loss: 0.070006\n",
      "iteration: 2319 | loss: 0.100193\n",
      "iteration: 2320 | loss: 0.109221\n",
      "iteration: 2321 | loss: 0.236584\n",
      "iteration: 2322 | loss: 0.043026\n",
      "iteration: 2323 | loss: 0.255066\n",
      "iteration: 2324 | loss: 0.137229\n",
      "  Train acc: 0.976, Val acc: 0.5\n",
      "iteration: 2325 | loss: 0.196643\n",
      "iteration: 2326 | loss: 0.086452\n",
      "iteration: 2327 | loss: 0.117888\n",
      "iteration: 2328 | loss: 0.022959\n",
      "iteration: 2329 | loss: 0.097940\n",
      "iteration: 2330 | loss: 0.139019\n",
      "iteration: 2331 | loss: 0.053920\n",
      "iteration: 2332 | loss: 0.259829\n",
      "iteration: 2333 | loss: 0.142951\n",
      "iteration: 2334 | loss: 0.210036\n",
      "iteration: 2335 | loss: 0.082831\n",
      "iteration: 2336 | loss: 0.060573\n",
      "iteration: 2337 | loss: 0.089064\n",
      "iteration: 2338 | loss: 0.213971\n",
      "iteration: 2339 | loss: 0.154405\n",
      "iteration: 2340 | loss: 0.075588\n",
      "iteration: 2341 | loss: 0.150062\n",
      "iteration: 2342 | loss: 0.152418\n",
      "iteration: 2343 | loss: 0.144322\n",
      "iteration: 2344 | loss: 0.091063\n",
      "iteration: 2345 | loss: 0.034184\n",
      "iteration: 2346 | loss: 0.109490\n",
      "iteration: 2347 | loss: 0.121404\n",
      "iteration: 2348 | loss: 0.107246\n",
      "iteration: 2349 | loss: 0.070655\n",
      "  Train acc: 0.978, Val acc: 0.5\n",
      "iteration: 2350 | loss: 0.191022\n",
      "iteration: 2351 | loss: 0.137014\n",
      "iteration: 2352 | loss: 0.135815\n",
      "iteration: 2353 | loss: 0.044445\n",
      "iteration: 2354 | loss: 0.072593\n",
      "iteration: 2355 | loss: 0.054161\n",
      "iteration: 2356 | loss: 0.126881\n",
      "iteration: 2357 | loss: 0.051849\n",
      "iteration: 2358 | loss: 0.065319\n",
      "iteration: 2359 | loss: 0.125376\n",
      "iteration: 2360 | loss: 0.060103\n",
      "iteration: 2361 | loss: 0.111780\n",
      "iteration: 2362 | loss: 0.051098\n",
      "iteration: 2363 | loss: 0.083135\n",
      "iteration: 2364 | loss: 0.086970\n",
      "iteration: 2365 | loss: 0.141783\n",
      "iteration: 2366 | loss: 0.069501\n",
      "iteration: 2367 | loss: 0.114678\n",
      "iteration: 2368 | loss: 0.068684\n",
      "iteration: 2369 | loss: 0.046896\n",
      "iteration: 2370 | loss: 0.074100\n",
      "iteration: 2371 | loss: 0.050850\n",
      "iteration: 2372 | loss: 0.092567\n",
      "iteration: 2373 | loss: 0.145977\n",
      "iteration: 2374 | loss: 0.034129\n",
      "  Train acc: 0.982, Val acc: 0.5\n",
      "iteration: 2375 | loss: 0.070988\n",
      "iteration: 2376 | loss: 0.062836\n",
      "iteration: 2377 | loss: 0.040377\n",
      "iteration: 2378 | loss: 0.038539\n",
      "iteration: 2379 | loss: 0.255917\n",
      "iteration: 2380 | loss: 0.084972\n",
      "iteration: 2381 | loss: 0.054587\n",
      "iteration: 2382 | loss: 0.089068\n",
      "iteration: 2383 | loss: 0.055986\n",
      "iteration: 2384 | loss: 0.255149\n",
      "iteration: 2385 | loss: 0.160789\n",
      "iteration: 2386 | loss: 0.067842\n",
      "iteration: 2387 | loss: 0.125083\n",
      "iteration: 2388 | loss: 0.080034\n",
      "iteration: 2389 | loss: 0.119697\n",
      "iteration: 2390 | loss: 0.083361\n",
      "iteration: 2391 | loss: 0.078790\n",
      "iteration: 2392 | loss: 0.063890\n",
      "iteration: 2393 | loss: 0.239418\n",
      "iteration: 2394 | loss: 0.066543\n",
      "iteration: 2395 | loss: 0.073772\n",
      "iteration: 2396 | loss: 0.092513\n",
      "iteration: 2397 | loss: 0.293253\n",
      "iteration: 2398 | loss: 0.077320\n",
      "iteration: 2399 | loss: 0.226138\n",
      "  Train acc: 0.978, Val acc: 0.5\n",
      "iteration: 2400 | loss: 0.046669\n",
      "iteration: 2401 | loss: 0.063841\n",
      "iteration: 2402 | loss: 0.097944\n",
      "iteration: 2403 | loss: 0.027514\n",
      "iteration: 2404 | loss: 0.091208\n",
      "iteration: 2405 | loss: 0.045832\n",
      "iteration: 2406 | loss: 0.174874\n",
      "iteration: 2407 | loss: 0.055085\n",
      "iteration: 2408 | loss: 0.090022\n",
      "iteration: 2409 | loss: 0.082591\n",
      "iteration: 2410 | loss: 0.089075\n",
      "iteration: 2411 | loss: 0.085292\n",
      "iteration: 2412 | loss: 0.039518\n",
      "iteration: 2413 | loss: 0.177198\n",
      "iteration: 2414 | loss: 0.172410\n",
      "iteration: 2415 | loss: 0.063781\n",
      "iteration: 2416 | loss: 0.045224\n",
      "iteration: 2417 | loss: 0.077705\n",
      "iteration: 2418 | loss: 0.057807\n",
      "iteration: 2419 | loss: 0.080726\n",
      "iteration: 2420 | loss: 0.115871\n",
      "iteration: 2421 | loss: 0.021459\n",
      "iteration: 2422 | loss: 0.154760\n",
      "iteration: 2423 | loss: 0.112100\n",
      "iteration: 2424 | loss: 0.083302\n",
      "  Train acc: 0.974, Val acc: 0.5\n",
      "iteration: 2425 | loss: 0.051467\n",
      "iteration: 2426 | loss: 0.092484\n",
      "iteration: 2427 | loss: 0.171991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2428 | loss: 0.034036\n",
      "iteration: 2429 | loss: 0.050836\n",
      "iteration: 2430 | loss: 0.174650\n",
      "iteration: 2431 | loss: 0.298857\n",
      "iteration: 2432 | loss: 0.027843\n",
      "iteration: 2433 | loss: 0.114575\n",
      "iteration: 2434 | loss: 0.027163\n",
      "iteration: 2435 | loss: 0.188574\n",
      "iteration: 2436 | loss: 0.061507\n",
      "iteration: 2437 | loss: 0.059911\n",
      "iteration: 2438 | loss: 0.085225\n",
      "iteration: 2439 | loss: 0.055017\n",
      "iteration: 2440 | loss: 0.098974\n",
      "iteration: 2441 | loss: 0.047091\n",
      "iteration: 2442 | loss: 0.143088\n",
      "iteration: 2443 | loss: 0.098214\n",
      "iteration: 2444 | loss: 0.178607\n",
      "iteration: 2445 | loss: 0.036681\n",
      "iteration: 2446 | loss: 0.047501\n",
      "iteration: 2447 | loss: 0.102759\n",
      "iteration: 2448 | loss: 0.058695\n",
      "iteration: 2449 | loss: 0.048137\n",
      "  Train acc: 0.998, Val acc: 0.5\n",
      "iteration: 2450 | loss: 0.067077\n",
      "iteration: 2451 | loss: 0.042602\n",
      "iteration: 2452 | loss: 0.044809\n",
      "iteration: 2453 | loss: 0.189136\n",
      "iteration: 2454 | loss: 0.062516\n",
      "iteration: 2455 | loss: 0.052112\n",
      "iteration: 2456 | loss: 0.036113\n",
      "iteration: 2457 | loss: 0.092371\n",
      "iteration: 2458 | loss: 0.172886\n",
      "iteration: 2459 | loss: 0.075283\n",
      "iteration: 2460 | loss: 0.035649\n",
      "iteration: 2461 | loss: 0.024676\n",
      "iteration: 2462 | loss: 0.048058\n",
      "iteration: 2463 | loss: 0.067839\n",
      "iteration: 2464 | loss: 0.030676\n",
      "iteration: 2465 | loss: 0.116152\n",
      "iteration: 2466 | loss: 0.050524\n",
      "iteration: 2467 | loss: 0.154370\n",
      "iteration: 2468 | loss: 0.072518\n",
      "iteration: 2469 | loss: 0.083737\n",
      "iteration: 2470 | loss: 0.069337\n",
      "iteration: 2471 | loss: 0.074216\n",
      "iteration: 2472 | loss: 0.067169\n",
      "iteration: 2473 | loss: 0.052277\n",
      "iteration: 2474 | loss: 0.366508\n",
      "  Train acc: 0.986, Val acc: 0.5\n",
      "iteration: 2475 | loss: 0.048489\n",
      "iteration: 2476 | loss: 0.104743\n",
      "iteration: 2477 | loss: 0.042700\n",
      "iteration: 2478 | loss: 0.029540\n",
      "iteration: 2479 | loss: 0.187047\n",
      "iteration: 2480 | loss: 0.039939\n",
      "iteration: 2481 | loss: 0.036515\n",
      "iteration: 2482 | loss: 0.031338\n",
      "iteration: 2483 | loss: 0.067211\n",
      "iteration: 2484 | loss: 0.107607\n",
      "iteration: 2485 | loss: 0.053342\n",
      "iteration: 2486 | loss: 0.126500\n",
      "iteration: 2487 | loss: 0.040696\n",
      "iteration: 2488 | loss: 0.193319\n",
      "iteration: 2489 | loss: 0.135982\n",
      "iteration: 2490 | loss: 0.032690\n",
      "iteration: 2491 | loss: 0.093153\n",
      "iteration: 2492 | loss: 0.084168\n",
      "iteration: 2493 | loss: 0.055612\n",
      "iteration: 2494 | loss: 0.020920\n",
      "iteration: 2495 | loss: 0.059386\n",
      "iteration: 2496 | loss: 0.053638\n",
      "iteration: 2497 | loss: 0.061738\n",
      "iteration: 2498 | loss: 0.086120\n",
      "iteration: 2499 | loss: 0.031288\n",
      "  Train acc: 0.986, Val acc: 0.5\n",
      "iteration: 2500 | loss: 0.022744\n",
      "iteration: 2501 | loss: 0.045773\n",
      "iteration: 2502 | loss: 0.103847\n",
      "iteration: 2503 | loss: 0.163867\n",
      "iteration: 2504 | loss: 0.039425\n",
      "iteration: 2505 | loss: 0.031864\n",
      "iteration: 2506 | loss: 0.045484\n",
      "iteration: 2507 | loss: 0.089244\n",
      "iteration: 2508 | loss: 0.127296\n",
      "iteration: 2509 | loss: 0.132426\n",
      "iteration: 2510 | loss: 0.060419\n",
      "iteration: 2511 | loss: 0.208941\n",
      "iteration: 2512 | loss: 0.040623\n",
      "iteration: 2513 | loss: 0.031285\n",
      "iteration: 2514 | loss: 0.034555\n",
      "iteration: 2515 | loss: 0.184641\n",
      "iteration: 2516 | loss: 0.171765\n",
      "iteration: 2517 | loss: 0.043717\n",
      "iteration: 2518 | loss: 0.075751\n",
      "iteration: 2519 | loss: 0.030794\n",
      "iteration: 2520 | loss: 0.077667\n",
      "iteration: 2521 | loss: 0.188860\n",
      "iteration: 2522 | loss: 0.028759\n",
      "iteration: 2523 | loss: 0.086241\n",
      "iteration: 2524 | loss: 0.145891\n",
      "  Train acc: 0.978, Val acc: 0.5\n",
      "iteration: 2525 | loss: 0.073760\n",
      "iteration: 2526 | loss: 0.030064\n",
      "iteration: 2527 | loss: 0.065512\n",
      "iteration: 2528 | loss: 0.078735\n",
      "iteration: 2529 | loss: 0.171052\n",
      "iteration: 2530 | loss: 0.120175\n",
      "iteration: 2531 | loss: 0.043186\n",
      "iteration: 2532 | loss: 0.016625\n",
      "iteration: 2533 | loss: 0.083199\n",
      "iteration: 2534 | loss: 0.028571\n",
      "iteration: 2535 | loss: 0.064769\n",
      "iteration: 2536 | loss: 0.084896\n",
      "iteration: 2537 | loss: 0.113401\n",
      "iteration: 2538 | loss: 0.058127\n",
      "iteration: 2539 | loss: 0.033228\n",
      "iteration: 2540 | loss: 0.097431\n",
      "iteration: 2541 | loss: 0.307204\n",
      "iteration: 2542 | loss: 0.048503\n",
      "iteration: 2543 | loss: 0.050342\n",
      "iteration: 2544 | loss: 0.025650\n",
      "iteration: 2545 | loss: 0.107896\n",
      "iteration: 2546 | loss: 0.080292\n",
      "iteration: 2547 | loss: 0.046104\n",
      "iteration: 2548 | loss: 0.091984\n",
      "iteration: 2549 | loss: 0.082454\n",
      "  Train acc: 0.99, Val acc: 0.5\n",
      "iteration: 2550 | loss: 0.039101\n",
      "iteration: 2551 | loss: 0.066197\n",
      "iteration: 2552 | loss: 0.091943\n",
      "iteration: 2553 | loss: 0.045042\n",
      "iteration: 2554 | loss: 0.034322\n",
      "iteration: 2555 | loss: 0.044278\n",
      "iteration: 2556 | loss: 0.065516\n",
      "iteration: 2557 | loss: 0.051300\n",
      "iteration: 2558 | loss: 0.029399\n",
      "iteration: 2559 | loss: 0.089678\n",
      "iteration: 2560 | loss: 0.047112\n",
      "iteration: 2561 | loss: 0.071073\n",
      "iteration: 2562 | loss: 0.034293\n",
      "iteration: 2563 | loss: 0.052047\n",
      "iteration: 2564 | loss: 0.087363\n",
      "iteration: 2565 | loss: 0.065031\n",
      "iteration: 2566 | loss: 0.136982\n",
      "iteration: 2567 | loss: 0.074126\n",
      "iteration: 2568 | loss: 0.127769\n",
      "iteration: 2569 | loss: 0.032838\n",
      "iteration: 2570 | loss: 0.174899\n",
      "iteration: 2571 | loss: 0.044907\n",
      "iteration: 2572 | loss: 0.029371\n",
      "iteration: 2573 | loss: 0.028593\n",
      "iteration: 2574 | loss: 0.065178\n",
      "  Train acc: 0.978, Val acc: 0.5\n",
      "iteration: 2575 | loss: 0.040222\n",
      "iteration: 2576 | loss: 0.161442\n",
      "iteration: 2577 | loss: 0.108032\n",
      "iteration: 2578 | loss: 0.051690\n",
      "iteration: 2579 | loss: 0.036694\n",
      "iteration: 2580 | loss: 0.053907\n",
      "iteration: 2581 | loss: 0.064969\n",
      "iteration: 2582 | loss: 0.092252\n",
      "iteration: 2583 | loss: 0.087449\n",
      "iteration: 2584 | loss: 0.091920\n",
      "iteration: 2585 | loss: 0.080173\n",
      "iteration: 2586 | loss: 0.060682\n",
      "iteration: 2587 | loss: 0.081320\n",
      "iteration: 2588 | loss: 0.068503\n",
      "iteration: 2589 | loss: 0.102892\n",
      "iteration: 2590 | loss: 0.024007\n",
      "iteration: 2591 | loss: 0.073181\n",
      "iteration: 2592 | loss: 0.100874\n",
      "iteration: 2593 | loss: 0.032906\n",
      "iteration: 2594 | loss: 0.092413\n",
      "iteration: 2595 | loss: 0.030054\n",
      "iteration: 2596 | loss: 0.131488\n",
      "iteration: 2597 | loss: 0.022216\n",
      "iteration: 2598 | loss: 0.123421\n",
      "iteration: 2599 | loss: 0.036994\n",
      "  Train acc: 0.972, Val acc: 0.5\n",
      "iteration: 2600 | loss: 0.055329\n",
      "iteration: 2601 | loss: 0.114960\n",
      "iteration: 2602 | loss: 0.021018\n",
      "iteration: 2603 | loss: 0.188209\n",
      "iteration: 2604 | loss: 0.046561\n",
      "iteration: 2605 | loss: 0.140677\n",
      "iteration: 2606 | loss: 0.027812\n",
      "iteration: 2607 | loss: 0.023525\n",
      "iteration: 2608 | loss: 0.061686\n",
      "iteration: 2609 | loss: 0.059324\n",
      "iteration: 2610 | loss: 0.069984\n",
      "iteration: 2611 | loss: 0.065636\n",
      "iteration: 2612 | loss: 0.054292\n",
      "iteration: 2613 | loss: 0.056159\n",
      "iteration: 2614 | loss: 0.034757\n",
      "iteration: 2615 | loss: 0.068106\n",
      "iteration: 2616 | loss: 0.182513\n",
      "iteration: 2617 | loss: 0.066678\n",
      "iteration: 2618 | loss: 0.089083\n",
      "iteration: 2619 | loss: 0.055768\n",
      "iteration: 2620 | loss: 0.021761\n",
      "iteration: 2621 | loss: 0.049444\n",
      "iteration: 2622 | loss: 0.055254\n",
      "iteration: 2623 | loss: 0.035041\n",
      "iteration: 2624 | loss: 0.032693\n",
      "  Train acc: 0.992, Val acc: 0.5\n",
      "iteration: 2625 | loss: 0.039111\n",
      "iteration: 2626 | loss: 0.027073\n",
      "iteration: 2627 | loss: 0.128553\n",
      "iteration: 2628 | loss: 0.152417\n",
      "iteration: 2629 | loss: 0.013669\n",
      "iteration: 2630 | loss: 0.021158\n",
      "iteration: 2631 | loss: 0.097546\n",
      "iteration: 2632 | loss: 0.065156\n",
      "iteration: 2633 | loss: 0.047855\n",
      "iteration: 2634 | loss: 0.060862\n",
      "iteration: 2635 | loss: 0.053296\n",
      "iteration: 2636 | loss: 0.023243\n",
      "iteration: 2637 | loss: 0.082936\n",
      "iteration: 2638 | loss: 0.022377\n",
      "iteration: 2639 | loss: 0.062133\n",
      "iteration: 2640 | loss: 0.022581\n",
      "iteration: 2641 | loss: 0.085690\n",
      "iteration: 2642 | loss: 0.041450\n",
      "iteration: 2643 | loss: 0.119410\n",
      "iteration: 2644 | loss: 0.025491\n",
      "iteration: 2645 | loss: 0.091909\n",
      "iteration: 2646 | loss: 0.017736\n",
      "iteration: 2647 | loss: 0.012773\n",
      "iteration: 2648 | loss: 0.014188\n",
      "iteration: 2649 | loss: 0.080037\n",
      "  Train acc: 0.99, Val acc: 0.5\n",
      "iteration: 2650 | loss: 0.028375\n",
      "iteration: 2651 | loss: 0.042172\n",
      "iteration: 2652 | loss: 0.204132\n",
      "iteration: 2653 | loss: 0.014083\n",
      "iteration: 2654 | loss: 0.015877\n",
      "iteration: 2655 | loss: 0.028361\n",
      "iteration: 2656 | loss: 0.095665\n",
      "iteration: 2657 | loss: 0.076323\n",
      "iteration: 2658 | loss: 0.025299\n",
      "iteration: 2659 | loss: 0.045053\n",
      "iteration: 2660 | loss: 0.047060\n",
      "iteration: 2661 | loss: 0.033065\n",
      "iteration: 2662 | loss: 0.026833\n",
      "iteration: 2663 | loss: 0.042985\n",
      "iteration: 2664 | loss: 0.108463\n",
      "iteration: 2665 | loss: 0.042312\n",
      "iteration: 2666 | loss: 0.087289\n",
      "iteration: 2667 | loss: 0.021220\n",
      "iteration: 2668 | loss: 0.116428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2669 | loss: 0.023780\n",
      "iteration: 2670 | loss: 0.078785\n",
      "iteration: 2671 | loss: 0.032173\n",
      "iteration: 2672 | loss: 0.081755\n",
      "iteration: 2673 | loss: 0.021692\n",
      "iteration: 2674 | loss: 0.221062\n",
      "  Train acc: 0.982, Val acc: 0.5\n",
      "iteration: 2675 | loss: 0.025956\n",
      "iteration: 2676 | loss: 0.088322\n",
      "iteration: 2677 | loss: 0.042036\n",
      "iteration: 2678 | loss: 0.107292\n",
      "iteration: 2679 | loss: 0.014822\n",
      "iteration: 2680 | loss: 0.045541\n",
      "iteration: 2681 | loss: 0.061992\n",
      "iteration: 2682 | loss: 0.032504\n",
      "iteration: 2683 | loss: 0.086412\n",
      "iteration: 2684 | loss: 0.046233\n",
      "iteration: 2685 | loss: 0.135206\n",
      "iteration: 2686 | loss: 0.015839\n",
      "iteration: 2687 | loss: 0.027760\n",
      "iteration: 2688 | loss: 0.017445\n",
      "iteration: 2689 | loss: 0.021509\n",
      "iteration: 2690 | loss: 0.075485\n",
      "iteration: 2691 | loss: 0.039920\n",
      "iteration: 2692 | loss: 0.060794\n",
      "iteration: 2693 | loss: 0.033746\n",
      "iteration: 2694 | loss: 0.028641\n",
      "iteration: 2695 | loss: 0.073550\n",
      "iteration: 2696 | loss: 0.024678\n",
      "iteration: 2697 | loss: 0.037373\n",
      "iteration: 2698 | loss: 0.025540\n",
      "iteration: 2699 | loss: 0.027972\n",
      "  Train acc: 0.99, Val acc: 0.5\n",
      "iteration: 2700 | loss: 0.073211\n",
      "iteration: 2701 | loss: 0.029144\n",
      "iteration: 2702 | loss: 0.017767\n",
      "iteration: 2703 | loss: 0.026489\n",
      "iteration: 2704 | loss: 0.034887\n",
      "iteration: 2705 | loss: 0.222682\n",
      "iteration: 2706 | loss: 0.027869\n",
      "iteration: 2707 | loss: 0.062917\n",
      "iteration: 2708 | loss: 0.030107\n",
      "iteration: 2709 | loss: 0.027211\n",
      "iteration: 2710 | loss: 0.031382\n",
      "iteration: 2711 | loss: 0.040617\n",
      "iteration: 2712 | loss: 0.068345\n",
      "iteration: 2713 | loss: 0.025443\n",
      "iteration: 2714 | loss: 0.056136\n",
      "iteration: 2715 | loss: 0.030711\n",
      "iteration: 2716 | loss: 0.056347\n",
      "iteration: 2717 | loss: 0.043554\n",
      "iteration: 2718 | loss: 0.029992\n",
      "iteration: 2719 | loss: 0.033776\n",
      "iteration: 2720 | loss: 0.022453\n",
      "iteration: 2721 | loss: 0.044674\n",
      "iteration: 2722 | loss: 0.015428\n",
      "iteration: 2723 | loss: 0.053358\n",
      "iteration: 2724 | loss: 0.100734\n",
      "  Train acc: 0.998, Val acc: 0.5\n",
      "iteration: 2725 | loss: 0.023886\n",
      "iteration: 2726 | loss: 0.014728\n",
      "iteration: 2727 | loss: 0.035108\n",
      "iteration: 2728 | loss: 0.008066\n",
      "iteration: 2729 | loss: 0.012498\n",
      "iteration: 2730 | loss: 0.031467\n",
      "iteration: 2731 | loss: 0.059655\n",
      "iteration: 2732 | loss: 0.040416\n",
      "iteration: 2733 | loss: 0.041546\n",
      "iteration: 2734 | loss: 0.030253\n",
      "iteration: 2735 | loss: 0.016295\n",
      "iteration: 2736 | loss: 0.023923\n",
      "iteration: 2737 | loss: 0.013668\n",
      "iteration: 2738 | loss: 0.019436\n",
      "iteration: 2739 | loss: 0.099156\n",
      "iteration: 2740 | loss: 0.020852\n",
      "iteration: 2741 | loss: 0.042616\n",
      "iteration: 2742 | loss: 0.042038\n",
      "iteration: 2743 | loss: 0.019716\n",
      "iteration: 2744 | loss: 0.111726\n",
      "iteration: 2745 | loss: 0.010609\n",
      "iteration: 2746 | loss: 0.042411\n",
      "iteration: 2747 | loss: 0.053022\n",
      "iteration: 2748 | loss: 0.057049\n",
      "iteration: 2749 | loss: 0.048312\n",
      "  Train acc: 0.996, Val acc: 0.5\n",
      "iteration: 2750 | loss: 0.022060\n",
      "iteration: 2751 | loss: 0.025190\n",
      "iteration: 2752 | loss: 0.009924\n",
      "iteration: 2753 | loss: 0.032569\n",
      "iteration: 2754 | loss: 0.032529\n",
      "iteration: 2755 | loss: 0.026982\n",
      "iteration: 2756 | loss: 0.032675\n",
      "iteration: 2757 | loss: 0.024050\n",
      "iteration: 2758 | loss: 0.034931\n",
      "iteration: 2759 | loss: 0.011351\n",
      "iteration: 2760 | loss: 0.053486\n",
      "iteration: 2761 | loss: 0.024215\n",
      "iteration: 2762 | loss: 0.050634\n",
      "iteration: 2763 | loss: 0.059006\n",
      "iteration: 2764 | loss: 0.061305\n",
      "iteration: 2765 | loss: 0.036841\n",
      "iteration: 2766 | loss: 0.022223\n",
      "iteration: 2767 | loss: 0.019538\n",
      "iteration: 2768 | loss: 0.018697\n",
      "iteration: 2769 | loss: 0.008844\n",
      "iteration: 2770 | loss: 0.034361\n",
      "iteration: 2771 | loss: 0.159513\n",
      "iteration: 2772 | loss: 0.031087\n",
      "iteration: 2773 | loss: 0.020105\n",
      "iteration: 2774 | loss: 0.020252\n",
      "  Train acc: 0.996, Val acc: 0.5\n",
      "iteration: 2775 | loss: 0.020968\n",
      "iteration: 2776 | loss: 0.307252\n",
      "iteration: 2777 | loss: 0.023072\n",
      "iteration: 2778 | loss: 0.174727\n",
      "iteration: 2779 | loss: 0.041675\n",
      "iteration: 2780 | loss: 0.036400\n",
      "iteration: 2781 | loss: 0.041893\n",
      "iteration: 2782 | loss: 0.029393\n",
      "iteration: 2783 | loss: 0.022498\n",
      "iteration: 2784 | loss: 0.025028\n",
      "iteration: 2785 | loss: 0.012883\n",
      "iteration: 2786 | loss: 0.048333\n",
      "iteration: 2787 | loss: 0.046893\n",
      "iteration: 2788 | loss: 0.009109\n",
      "iteration: 2789 | loss: 0.047394\n",
      "iteration: 2790 | loss: 0.036355\n",
      "iteration: 2791 | loss: 0.037393\n",
      "iteration: 2792 | loss: 0.023745\n",
      "iteration: 2793 | loss: 0.022863\n",
      "iteration: 2794 | loss: 0.027655\n",
      "iteration: 2795 | loss: 0.009676\n",
      "iteration: 2796 | loss: 0.058668\n",
      "iteration: 2797 | loss: 0.060601\n",
      "iteration: 2798 | loss: 0.032432\n",
      "iteration: 2799 | loss: 0.037023\n",
      "  Train acc: 0.992, Val acc: 0.5\n",
      "iteration: 2800 | loss: 0.013497\n",
      "iteration: 2801 | loss: 0.014792\n",
      "iteration: 2802 | loss: 0.024103\n",
      "iteration: 2803 | loss: 0.188167\n",
      "iteration: 2804 | loss: 0.055265\n",
      "iteration: 2805 | loss: 0.053515\n",
      "iteration: 2806 | loss: 0.078348\n",
      "iteration: 2807 | loss: 0.018866\n",
      "iteration: 2808 | loss: 0.038090\n",
      "iteration: 2809 | loss: 0.032569\n",
      "iteration: 2810 | loss: 0.050598\n",
      "iteration: 2811 | loss: 0.021899\n",
      "iteration: 2812 | loss: 0.234103\n",
      "iteration: 2813 | loss: 0.051199\n",
      "iteration: 2814 | loss: 0.190938\n",
      "iteration: 2815 | loss: 0.029571\n",
      "iteration: 2816 | loss: 0.019361\n",
      "iteration: 2817 | loss: 0.068181\n",
      "iteration: 2818 | loss: 0.035739\n",
      "iteration: 2819 | loss: 0.011656\n",
      "iteration: 2820 | loss: 0.043549\n",
      "iteration: 2821 | loss: 0.121839\n",
      "iteration: 2822 | loss: 0.026264\n",
      "iteration: 2823 | loss: 0.128066\n",
      "iteration: 2824 | loss: 0.035899\n",
      "  Train acc: 0.994, Val acc: 0.5\n",
      "iteration: 2825 | loss: 0.056731\n",
      "iteration: 2826 | loss: 0.017548\n",
      "iteration: 2827 | loss: 0.038231\n",
      "iteration: 2828 | loss: 0.029877\n",
      "iteration: 2829 | loss: 0.032850\n",
      "iteration: 2830 | loss: 0.128717\n",
      "iteration: 2831 | loss: 0.039284\n",
      "iteration: 2832 | loss: 0.080172\n",
      "iteration: 2833 | loss: 0.045802\n",
      "iteration: 2834 | loss: 0.057571\n",
      "iteration: 2835 | loss: 0.021413\n",
      "iteration: 2836 | loss: 0.136011\n",
      "iteration: 2837 | loss: 0.088144\n",
      "iteration: 2838 | loss: 0.026777\n",
      "iteration: 2839 | loss: 0.082924\n",
      "iteration: 2840 | loss: 0.059087\n",
      "iteration: 2841 | loss: 0.034484\n",
      "iteration: 2842 | loss: 0.016038\n",
      "iteration: 2843 | loss: 0.038263\n",
      "iteration: 2844 | loss: 0.084076\n",
      "iteration: 2845 | loss: 0.047459\n",
      "iteration: 2846 | loss: 0.083677\n",
      "iteration: 2847 | loss: 0.035261\n",
      "iteration: 2848 | loss: 0.026377\n",
      "iteration: 2849 | loss: 0.050395\n",
      "  Train acc: 0.982, Val acc: 0.5\n",
      "iteration: 2850 | loss: 0.057925\n",
      "iteration: 2851 | loss: 0.034561\n",
      "iteration: 2852 | loss: 0.052721\n",
      "iteration: 2853 | loss: 0.057465\n",
      "iteration: 2854 | loss: 0.031366\n",
      "iteration: 2855 | loss: 0.032008\n",
      "iteration: 2856 | loss: 0.041501\n",
      "iteration: 2857 | loss: 0.022142\n",
      "iteration: 2858 | loss: 0.037512\n",
      "iteration: 2859 | loss: 0.025680\n",
      "iteration: 2860 | loss: 0.027880\n",
      "iteration: 2861 | loss: 0.054777\n",
      "iteration: 2862 | loss: 0.025956\n",
      "iteration: 2863 | loss: 0.020774\n",
      "iteration: 2864 | loss: 0.040329\n",
      "iteration: 2865 | loss: 0.200955\n",
      "iteration: 2866 | loss: 0.026557\n",
      "iteration: 2867 | loss: 0.030101\n",
      "iteration: 2868 | loss: 0.031493\n",
      "iteration: 2869 | loss: 0.032244\n",
      "iteration: 2870 | loss: 0.038083\n",
      "iteration: 2871 | loss: 0.032903\n",
      "iteration: 2872 | loss: 0.025838\n",
      "iteration: 2873 | loss: 0.012839\n",
      "iteration: 2874 | loss: 0.021264\n",
      "  Train acc: 0.978, Val acc: 0.5\n",
      "iteration: 2875 | loss: 0.159525\n",
      "iteration: 2876 | loss: 0.039206\n",
      "iteration: 2877 | loss: 0.038817\n",
      "iteration: 2878 | loss: 0.097321\n",
      "iteration: 2879 | loss: 0.016235\n",
      "iteration: 2880 | loss: 0.053715\n",
      "iteration: 2881 | loss: 0.022944\n",
      "iteration: 2882 | loss: 0.018342\n",
      "iteration: 2883 | loss: 0.058164\n",
      "iteration: 2884 | loss: 0.015820\n",
      "iteration: 2885 | loss: 0.071317\n",
      "iteration: 2886 | loss: 0.040212\n",
      "iteration: 2887 | loss: 0.036066\n",
      "iteration: 2888 | loss: 0.008639\n",
      "iteration: 2889 | loss: 0.017977\n",
      "iteration: 2890 | loss: 0.026759\n",
      "iteration: 2891 | loss: 0.027326\n",
      "iteration: 2892 | loss: 0.006012\n",
      "iteration: 2893 | loss: 0.031205\n",
      "iteration: 2894 | loss: 0.008032\n",
      "iteration: 2895 | loss: 0.012980\n",
      "iteration: 2896 | loss: 0.035888\n",
      "iteration: 2897 | loss: 0.026635\n",
      "iteration: 2898 | loss: 0.034597\n",
      "iteration: 2899 | loss: 0.044380\n",
      "  Train acc: 0.998, Val acc: 0.5\n",
      "iteration: 2900 | loss: 0.060534\n",
      "iteration: 2901 | loss: 0.043407\n",
      "iteration: 2902 | loss: 0.034226\n",
      "iteration: 2903 | loss: 0.029932\n",
      "iteration: 2904 | loss: 0.023125\n",
      "iteration: 2905 | loss: 0.016574\n",
      "iteration: 2906 | loss: 0.016501\n",
      "iteration: 2907 | loss: 0.015693\n",
      "iteration: 2908 | loss: 0.023826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2909 | loss: 0.028263\n",
      "iteration: 2910 | loss: 0.015668\n",
      "iteration: 2911 | loss: 0.042186\n",
      "iteration: 2912 | loss: 0.011971\n",
      "iteration: 2913 | loss: 0.014519\n",
      "iteration: 2914 | loss: 0.005887\n",
      "iteration: 2915 | loss: 0.022033\n",
      "iteration: 2916 | loss: 0.010556\n",
      "iteration: 2917 | loss: 0.036794\n",
      "iteration: 2918 | loss: 0.022980\n",
      "iteration: 2919 | loss: 0.019357\n",
      "iteration: 2920 | loss: 0.023331\n",
      "iteration: 2921 | loss: 0.013523\n",
      "iteration: 2922 | loss: 0.011289\n",
      "iteration: 2923 | loss: 0.078323\n",
      "iteration: 2924 | loss: 0.031708\n",
      "  Train acc: 0.99, Val acc: 0.5\n",
      "iteration: 2925 | loss: 0.060720\n",
      "iteration: 2926 | loss: 0.028376\n",
      "iteration: 2927 | loss: 0.080250\n",
      "iteration: 2928 | loss: 0.189830\n",
      "iteration: 2929 | loss: 0.005471\n",
      "iteration: 2930 | loss: 0.047945\n",
      "iteration: 2931 | loss: 0.014442\n",
      "iteration: 2932 | loss: 0.015410\n",
      "iteration: 2933 | loss: 0.023667\n",
      "iteration: 2934 | loss: 0.043557\n",
      "iteration: 2935 | loss: 0.067697\n",
      "iteration: 2936 | loss: 0.122060\n",
      "iteration: 2937 | loss: 0.019574\n",
      "iteration: 2938 | loss: 0.030590\n",
      "iteration: 2939 | loss: 0.053066\n",
      "iteration: 2940 | loss: 0.009116\n",
      "iteration: 2941 | loss: 0.042909\n",
      "iteration: 2942 | loss: 0.013935\n",
      "iteration: 2943 | loss: 0.048619\n",
      "iteration: 2944 | loss: 0.088457\n",
      "iteration: 2945 | loss: 0.087898\n",
      "iteration: 2946 | loss: 0.030416\n",
      "iteration: 2947 | loss: 0.047812\n",
      "iteration: 2948 | loss: 0.057213\n",
      "iteration: 2949 | loss: 0.038713\n",
      "  Train acc: 0.994, Val acc: 0.5\n",
      "iteration: 2950 | loss: 0.019055\n",
      "iteration: 2951 | loss: 0.100326\n",
      "iteration: 2952 | loss: 0.095166\n",
      "iteration: 2953 | loss: 0.069416\n",
      "iteration: 2954 | loss: 0.026393\n",
      "iteration: 2955 | loss: 0.013937\n",
      "iteration: 2956 | loss: 0.032491\n",
      "iteration: 2957 | loss: 0.041808\n",
      "iteration: 2958 | loss: 0.022002\n",
      "iteration: 2959 | loss: 0.050418\n",
      "iteration: 2960 | loss: 0.016137\n",
      "iteration: 2961 | loss: 0.033626\n",
      "iteration: 2962 | loss: 0.051682\n",
      "iteration: 2963 | loss: 0.032643\n",
      "iteration: 2964 | loss: 0.021897\n",
      "iteration: 2965 | loss: 0.017063\n",
      "iteration: 2966 | loss: 0.027061\n",
      "iteration: 2967 | loss: 0.015779\n",
      "iteration: 2968 | loss: 0.055374\n",
      "iteration: 2969 | loss: 0.012506\n",
      "iteration: 2970 | loss: 0.013614\n",
      "iteration: 2971 | loss: 0.016392\n",
      "iteration: 2972 | loss: 0.013797\n",
      "iteration: 2973 | loss: 0.049906\n",
      "iteration: 2974 | loss: 0.033855\n",
      "  Train acc: 0.994, Val acc: 0.5\n",
      "iteration: 2975 | loss: 0.146434\n",
      "iteration: 2976 | loss: 0.038587\n",
      "iteration: 2977 | loss: 0.036039\n",
      "iteration: 2978 | loss: 0.023344\n",
      "iteration: 2979 | loss: 0.010787\n",
      "iteration: 2980 | loss: 0.011437\n",
      "iteration: 2981 | loss: 0.117789\n",
      "iteration: 2982 | loss: 0.040190\n",
      "iteration: 2983 | loss: 0.021678\n",
      "iteration: 2984 | loss: 0.024373\n",
      "iteration: 2985 | loss: 0.013594\n",
      "iteration: 2986 | loss: 0.051260\n",
      "iteration: 2987 | loss: 0.029800\n",
      "iteration: 2988 | loss: 0.059063\n",
      "iteration: 2989 | loss: 0.027608\n",
      "iteration: 2990 | loss: 0.072597\n",
      "iteration: 2991 | loss: 0.030261\n",
      "iteration: 2992 | loss: 0.036983\n",
      "iteration: 2993 | loss: 0.031492\n",
      "iteration: 2994 | loss: 0.011208\n",
      "iteration: 2995 | loss: 0.032164\n",
      "iteration: 2996 | loss: 0.033048\n",
      "iteration: 2997 | loss: 0.070385\n",
      "iteration: 2998 | loss: 0.021104\n",
      "iteration: 2999 | loss: 0.027002\n",
      "  Train acc: 0.99, Val acc: 0.5\n",
      "iteration: 3000 | loss: 0.048836\n",
      "iteration: 3001 | loss: 0.018628\n",
      "iteration: 3002 | loss: 0.012293\n",
      "iteration: 3003 | loss: 0.080924\n",
      "iteration: 3004 | loss: 0.031822\n",
      "iteration: 3005 | loss: 0.012649\n",
      "iteration: 3006 | loss: 0.022787\n",
      "iteration: 3007 | loss: 0.022835\n",
      "iteration: 3008 | loss: 0.011410\n",
      "iteration: 3009 | loss: 0.045060\n",
      "iteration: 3010 | loss: 0.060917\n",
      "iteration: 3011 | loss: 0.017790\n",
      "iteration: 3012 | loss: 0.012841\n",
      "iteration: 3013 | loss: 0.018406\n",
      "iteration: 3014 | loss: 0.021307\n",
      "iteration: 3015 | loss: 0.053227\n",
      "iteration: 3016 | loss: 0.084290\n",
      "iteration: 3017 | loss: 0.024597\n",
      "iteration: 3018 | loss: 0.008178\n",
      "iteration: 3019 | loss: 0.023871\n",
      "iteration: 3020 | loss: 0.019783\n",
      "iteration: 3021 | loss: 0.012110\n",
      "iteration: 3022 | loss: 0.014817\n",
      "iteration: 3023 | loss: 0.015059\n",
      "iteration: 3024 | loss: 0.073407\n",
      "  Train acc: 0.996, Val acc: 0.5\n",
      "iteration: 3025 | loss: 0.040860\n",
      "iteration: 3026 | loss: 0.019062\n",
      "iteration: 3027 | loss: 0.007586\n",
      "iteration: 3028 | loss: 0.024262\n",
      "iteration: 3029 | loss: 0.017193\n",
      "iteration: 3030 | loss: 0.024026\n",
      "iteration: 3031 | loss: 0.030320\n",
      "iteration: 3032 | loss: 0.006169\n",
      "iteration: 3033 | loss: 0.009281\n",
      "iteration: 3034 | loss: 0.035184\n",
      "iteration: 3035 | loss: 0.012473\n",
      "iteration: 3036 | loss: 0.026436\n",
      "iteration: 3037 | loss: 0.005910\n",
      "iteration: 3038 | loss: 0.010427\n",
      "iteration: 3039 | loss: 0.016227\n",
      "iteration: 3040 | loss: 0.011681\n",
      "iteration: 3041 | loss: 0.018731\n",
      "iteration: 3042 | loss: 0.004103\n",
      "iteration: 3043 | loss: 0.015375\n",
      "iteration: 3044 | loss: 0.012447\n",
      "iteration: 3045 | loss: 0.013651\n",
      "iteration: 3046 | loss: 0.011709\n",
      "iteration: 3047 | loss: 0.022954\n",
      "iteration: 3048 | loss: 0.016010\n",
      "iteration: 3049 | loss: 0.026143\n",
      "  Train acc: 1.0, Val acc: 0.5\n",
      "iteration: 3050 | loss: 0.047242\n",
      "iteration: 3051 | loss: 0.025281\n",
      "iteration: 3052 | loss: 0.013837\n",
      "iteration: 3053 | loss: 0.116600\n",
      "iteration: 3054 | loss: 0.015088\n",
      "iteration: 3055 | loss: 0.042592\n",
      "iteration: 3056 | loss: 0.010466\n",
      "iteration: 3057 | loss: 0.040975\n",
      "iteration: 3058 | loss: 0.026308\n",
      "iteration: 3059 | loss: 0.017142\n",
      "iteration: 3060 | loss: 0.025876\n",
      "iteration: 3061 | loss: 0.025032\n",
      "iteration: 3062 | loss: 0.027193\n",
      "iteration: 3063 | loss: 0.004106\n",
      "iteration: 3064 | loss: 0.014481\n",
      "iteration: 3065 | loss: 0.038665\n",
      "iteration: 3066 | loss: 0.031846\n",
      "iteration: 3067 | loss: 0.036134\n",
      "iteration: 3068 | loss: 0.029939\n",
      "iteration: 3069 | loss: 0.012826\n",
      "iteration: 3070 | loss: 0.098716\n",
      "iteration: 3071 | loss: 0.024017\n",
      "iteration: 3072 | loss: 0.031140\n",
      "iteration: 3073 | loss: 0.023839\n",
      "iteration: 3074 | loss: 0.166825\n",
      "  Train acc: 0.996, Val acc: 0.5\n",
      "iteration: 3075 | loss: 0.024056\n",
      "iteration: 3076 | loss: 0.031543\n",
      "iteration: 3077 | loss: 0.017270\n",
      "iteration: 3078 | loss: 0.026703\n",
      "iteration: 3079 | loss: 0.012536\n",
      "iteration: 3080 | loss: 0.042403\n",
      "iteration: 3081 | loss: 0.032148\n",
      "iteration: 3082 | loss: 0.040524\n",
      "iteration: 3083 | loss: 0.031585\n",
      "iteration: 3084 | loss: 0.028936\n",
      "iteration: 3085 | loss: 0.015374\n",
      "iteration: 3086 | loss: 0.007716\n",
      "iteration: 3087 | loss: 0.020348\n",
      "iteration: 3088 | loss: 0.012025\n",
      "iteration: 3089 | loss: 0.157911\n",
      "iteration: 3090 | loss: 0.016802\n",
      "iteration: 3091 | loss: 0.003556\n",
      "iteration: 3092 | loss: 0.027678\n",
      "iteration: 3093 | loss: 0.017828\n",
      "iteration: 3094 | loss: 0.019468\n",
      "iteration: 3095 | loss: 0.029103\n",
      "iteration: 3096 | loss: 0.038768\n",
      "iteration: 3097 | loss: 0.042414\n",
      "iteration: 3098 | loss: 0.009610\n",
      "iteration: 3099 | loss: 0.036172\n",
      "  Train acc: 0.998, Val acc: 0.5\n",
      "iteration: 3100 | loss: 0.037152\n",
      "iteration: 3101 | loss: 0.018104\n",
      "iteration: 3102 | loss: 0.018977\n",
      "iteration: 3103 | loss: 0.019861\n",
      "iteration: 3104 | loss: 0.028813\n",
      "iteration: 3105 | loss: 0.010884\n",
      "iteration: 3106 | loss: 0.159063\n",
      "iteration: 3107 | loss: 0.013585\n",
      "iteration: 3108 | loss: 0.007804\n",
      "iteration: 3109 | loss: 0.015433\n",
      "iteration: 3110 | loss: 0.016819\n",
      "iteration: 3111 | loss: 0.064283\n",
      "iteration: 3112 | loss: 0.005762\n",
      "iteration: 3113 | loss: 0.017320\n",
      "iteration: 3114 | loss: 0.016275\n",
      "iteration: 3115 | loss: 0.007559\n",
      "iteration: 3116 | loss: 0.019414\n",
      "iteration: 3117 | loss: 0.008711\n",
      "iteration: 3118 | loss: 0.014382\n",
      "iteration: 3119 | loss: 0.051579\n",
      "iteration: 3120 | loss: 0.020259\n",
      "iteration: 3121 | loss: 0.013236\n",
      "iteration: 3122 | loss: 0.018168\n",
      "iteration: 3123 | loss: 0.030034\n",
      "iteration: 3124 | loss: 0.025538\n",
      "  Train acc: 0.99, Val acc: 0.5\n",
      "iteration: 3125 | loss: 0.006891\n",
      "iteration: 3126 | loss: 0.061694\n",
      "iteration: 3127 | loss: 0.026931\n",
      "iteration: 3128 | loss: 0.013163\n",
      "iteration: 3129 | loss: 0.019177\n",
      "iteration: 3130 | loss: 0.017320\n",
      "iteration: 3131 | loss: 0.036554\n",
      "iteration: 3132 | loss: 0.019391\n",
      "iteration: 3133 | loss: 0.012502\n",
      "iteration: 3134 | loss: 0.031482\n",
      "iteration: 3135 | loss: 0.025207\n",
      "iteration: 3136 | loss: 0.014998\n",
      "iteration: 3137 | loss: 0.017780\n",
      "iteration: 3138 | loss: 0.020179\n",
      "iteration: 3139 | loss: 0.009782\n",
      "iteration: 3140 | loss: 0.014397\n",
      "iteration: 3141 | loss: 0.163073\n",
      "iteration: 3142 | loss: 0.021616\n",
      "iteration: 3143 | loss: 0.016575\n",
      "iteration: 3144 | loss: 0.187191\n",
      "iteration: 3145 | loss: 0.046153\n",
      "iteration: 3146 | loss: 0.061205\n",
      "iteration: 3147 | loss: 0.049164\n",
      "iteration: 3148 | loss: 0.040227\n",
      "iteration: 3149 | loss: 0.093533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train acc: 0.994, Val acc: 0.5\n",
      "iteration: 3150 | loss: 0.023479\n",
      "iteration: 3151 | loss: 0.069524\n",
      "iteration: 3152 | loss: 0.029440\n",
      "iteration: 3153 | loss: 0.123378\n",
      "iteration: 3154 | loss: 0.055888\n",
      "iteration: 3155 | loss: 0.005603\n",
      "iteration: 3156 | loss: 0.052133\n",
      "iteration: 3157 | loss: 0.020465\n",
      "iteration: 3158 | loss: 0.075270\n",
      "iteration: 3159 | loss: 0.019140\n",
      "iteration: 3160 | loss: 0.032913\n",
      "iteration: 3161 | loss: 0.173138\n",
      "iteration: 3162 | loss: 0.042473\n",
      "iteration: 3163 | loss: 0.016148\n",
      "iteration: 3164 | loss: 0.028367\n",
      "iteration: 3165 | loss: 0.012071\n",
      "iteration: 3166 | loss: 0.018618\n",
      "iteration: 3167 | loss: 0.098119\n",
      "iteration: 3168 | loss: 0.052035\n",
      "iteration: 3169 | loss: 0.055076\n",
      "iteration: 3170 | loss: 0.063293\n",
      "iteration: 3171 | loss: 0.019880\n",
      "iteration: 3172 | loss: 0.025623\n",
      "iteration: 3173 | loss: 0.017138\n",
      "iteration: 3174 | loss: 0.016662\n",
      "  Train acc: 0.996, Val acc: 0.5\n",
      "iteration: 3175 | loss: 0.055883\n",
      "iteration: 3176 | loss: 0.031172\n",
      "iteration: 3177 | loss: 0.028519\n",
      "iteration: 3178 | loss: 0.070251\n",
      "iteration: 3179 | loss: 0.054968\n",
      "iteration: 3180 | loss: 0.021738\n",
      "iteration: 3181 | loss: 0.021441\n",
      "iteration: 3182 | loss: 0.007821\n",
      "iteration: 3183 | loss: 0.051711\n",
      "iteration: 3184 | loss: 0.012241\n",
      "iteration: 3185 | loss: 0.021033\n",
      "iteration: 3186 | loss: 0.009241\n",
      "iteration: 3187 | loss: 0.049377\n",
      "iteration: 3188 | loss: 0.056009\n",
      "iteration: 3189 | loss: 0.057533\n",
      "iteration: 3190 | loss: 0.019400\n",
      "iteration: 3191 | loss: 0.015028\n",
      "iteration: 3192 | loss: 0.039580\n",
      "iteration: 3193 | loss: 0.052800\n",
      "iteration: 3194 | loss: 0.035972\n",
      "iteration: 3195 | loss: 0.100138\n",
      "iteration: 3196 | loss: 0.005565\n",
      "iteration: 3197 | loss: 0.036603\n",
      "iteration: 3198 | loss: 0.011406\n",
      "iteration: 3199 | loss: 0.034427\n",
      "  Train acc: 0.994, Val acc: 0.5\n",
      "iteration: 3200 | loss: 0.039025\n",
      "iteration: 3201 | loss: 0.023308\n",
      "iteration: 3202 | loss: 0.020724\n",
      "iteration: 3203 | loss: 0.014656\n",
      "iteration: 3204 | loss: 0.023430\n",
      "iteration: 3205 | loss: 0.013386\n",
      "iteration: 3206 | loss: 0.008645\n",
      "iteration: 3207 | loss: 0.036836\n",
      "iteration: 3208 | loss: 0.056437\n",
      "iteration: 3209 | loss: 0.027626\n",
      "iteration: 3210 | loss: 0.017356\n",
      "iteration: 3211 | loss: 0.005774\n",
      "iteration: 3212 | loss: 0.033338\n",
      "iteration: 3213 | loss: 0.112822\n",
      "iteration: 3214 | loss: 0.019009\n",
      "iteration: 3215 | loss: 0.022963\n",
      "iteration: 3216 | loss: 0.017744\n",
      "iteration: 3217 | loss: 0.012134\n",
      "iteration: 3218 | loss: 0.030329\n",
      "iteration: 3219 | loss: 0.017639\n",
      "iteration: 3220 | loss: 0.021619\n",
      "iteration: 3221 | loss: 0.010889\n",
      "iteration: 3222 | loss: 0.055290\n",
      "iteration: 3223 | loss: 0.018291\n",
      "iteration: 3224 | loss: 0.036665\n",
      "  Train acc: 0.99, Val acc: 0.5\n",
      "iteration: 3225 | loss: 0.037532\n",
      "iteration: 3226 | loss: 0.053415\n",
      "iteration: 3227 | loss: 0.024150\n",
      "iteration: 3228 | loss: 0.008581\n",
      "iteration: 3229 | loss: 0.014998\n",
      "iteration: 3230 | loss: 0.037065\n",
      "iteration: 3231 | loss: 0.024858\n",
      "iteration: 3232 | loss: 0.015436\n",
      "iteration: 3233 | loss: 0.030515\n",
      "iteration: 3234 | loss: 0.009820\n",
      "iteration: 3235 | loss: 0.022999\n",
      "iteration: 3236 | loss: 0.053909\n",
      "iteration: 3237 | loss: 0.088459\n",
      "iteration: 3238 | loss: 0.012096\n",
      "iteration: 3239 | loss: 0.032689\n",
      "iteration: 3240 | loss: 0.022706\n",
      "iteration: 3241 | loss: 0.017864\n",
      "iteration: 3242 | loss: 0.009207\n",
      "iteration: 3243 | loss: 0.026811\n",
      "iteration: 3244 | loss: 0.013391\n",
      "iteration: 3245 | loss: 0.040191\n",
      "iteration: 3246 | loss: 0.031506\n",
      "iteration: 3247 | loss: 0.009874\n",
      "iteration: 3248 | loss: 0.036174\n",
      "iteration: 3249 | loss: 0.022884\n",
      "  Train acc: 1.0, Val acc: 0.5\n",
      "iteration: 3250 | loss: 0.010885\n",
      "iteration: 3251 | loss: 0.027356\n",
      "iteration: 3252 | loss: 0.062622\n",
      "iteration: 3253 | loss: 0.006901\n",
      "iteration: 3254 | loss: 0.037169\n",
      "iteration: 3255 | loss: 0.008844\n",
      "iteration: 3256 | loss: 0.020308\n",
      "iteration: 3257 | loss: 0.023544\n",
      "iteration: 3258 | loss: 0.042597\n",
      "iteration: 3259 | loss: 0.022354\n",
      "iteration: 3260 | loss: 0.009497\n",
      "iteration: 3261 | loss: 0.011272\n",
      "iteration: 3262 | loss: 0.116042\n",
      "iteration: 3263 | loss: 0.068562\n",
      "iteration: 3264 | loss: 0.032268\n",
      "iteration: 3265 | loss: 0.033813\n",
      "iteration: 3266 | loss: 0.011274\n",
      "iteration: 3267 | loss: 0.293413\n",
      "iteration: 3268 | loss: 0.051199\n",
      "iteration: 3269 | loss: 0.017501\n",
      "iteration: 3270 | loss: 0.036876\n",
      "iteration: 3271 | loss: 0.058424\n",
      "iteration: 3272 | loss: 0.024941\n",
      "iteration: 3273 | loss: 0.047586\n",
      "iteration: 3274 | loss: 0.014413\n",
      "  Train acc: 0.994, Val acc: 0.5\n",
      "iteration: 3275 | loss: 0.024551\n",
      "iteration: 3276 | loss: 0.037084\n",
      "iteration: 3277 | loss: 0.014858\n",
      "iteration: 3278 | loss: 0.239815\n",
      "iteration: 3279 | loss: 0.058048\n",
      "iteration: 3280 | loss: 0.043956\n",
      "iteration: 3281 | loss: 0.010681\n",
      "iteration: 3282 | loss: 0.011963\n",
      "iteration: 3283 | loss: 0.025579\n",
      "iteration: 3284 | loss: 0.018629\n",
      "iteration: 3285 | loss: 0.024176\n",
      "iteration: 3286 | loss: 0.096999\n",
      "iteration: 3287 | loss: 0.014653\n",
      "iteration: 3288 | loss: 0.020727\n",
      "iteration: 3289 | loss: 0.032295\n",
      "iteration: 3290 | loss: 0.072255\n",
      "iteration: 3291 | loss: 0.160813\n",
      "iteration: 3292 | loss: 0.053590\n",
      "iteration: 3293 | loss: 0.085014\n",
      "iteration: 3294 | loss: 0.011297\n",
      "iteration: 3295 | loss: 0.049575\n",
      "iteration: 3296 | loss: 0.019956\n",
      "iteration: 3297 | loss: 0.028485\n",
      "iteration: 3298 | loss: 0.070513\n",
      "iteration: 3299 | loss: 0.010732\n",
      "  Train acc: 0.996, Val acc: 0.5\n",
      "iteration: 3300 | loss: 0.023383\n",
      "iteration: 3301 | loss: 0.024040\n",
      "iteration: 3302 | loss: 0.021459\n",
      "iteration: 3303 | loss: 0.042251\n",
      "iteration: 3304 | loss: 0.010633\n",
      "iteration: 3305 | loss: 0.023956\n",
      "iteration: 3306 | loss: 0.045187\n",
      "iteration: 3307 | loss: 0.004560\n",
      "iteration: 3308 | loss: 0.024970\n",
      "iteration: 3309 | loss: 0.024882\n",
      "iteration: 3310 | loss: 0.121536\n",
      "iteration: 3311 | loss: 0.017375\n",
      "iteration: 3312 | loss: 0.023656\n",
      "iteration: 3313 | loss: 0.156202\n",
      "iteration: 3314 | loss: 0.006807\n",
      "iteration: 3315 | loss: 0.010703\n",
      "iteration: 3316 | loss: 0.014675\n",
      "iteration: 3317 | loss: 0.116470\n",
      "iteration: 3318 | loss: 0.159931\n",
      "iteration: 3319 | loss: 0.026410\n",
      "iteration: 3320 | loss: 0.009239\n",
      "iteration: 3321 | loss: 0.027026\n",
      "iteration: 3322 | loss: 0.243521\n",
      "iteration: 3323 | loss: 0.201635\n",
      "iteration: 3324 | loss: 0.018279\n",
      "  Train acc: 0.994, Val acc: 0.5\n",
      "iteration: 3325 | loss: 0.006381\n",
      "iteration: 3326 | loss: 0.020622\n",
      "iteration: 3327 | loss: 0.032852\n",
      "iteration: 3328 | loss: 0.119229\n",
      "iteration: 3329 | loss: 0.015376\n",
      "iteration: 3330 | loss: 0.039409\n",
      "iteration: 3331 | loss: 0.012476\n",
      "iteration: 3332 | loss: 0.025224\n",
      "iteration: 3333 | loss: 0.052842\n",
      "iteration: 3334 | loss: 0.050374\n",
      "iteration: 3335 | loss: 0.012115\n",
      "iteration: 3336 | loss: 0.021667\n",
      "iteration: 3337 | loss: 0.022748\n",
      "iteration: 3338 | loss: 0.012094\n",
      "iteration: 3339 | loss: 0.018386\n",
      "iteration: 3340 | loss: 0.021991\n",
      "iteration: 3341 | loss: 0.080769\n",
      "iteration: 3342 | loss: 0.008801\n",
      "iteration: 3343 | loss: 0.005852\n",
      "iteration: 3344 | loss: 0.008158\n",
      "iteration: 3345 | loss: 0.067435\n",
      "iteration: 3346 | loss: 0.027003\n",
      "iteration: 3347 | loss: 0.004500\n",
      "iteration: 3348 | loss: 0.015850\n",
      "iteration: 3349 | loss: 0.076416\n",
      "  Train acc: 0.996, Val acc: 0.5\n",
      "iteration: 3350 | loss: 0.027786\n",
      "iteration: 3351 | loss: 0.024035\n",
      "iteration: 3352 | loss: 0.017093\n",
      "iteration: 3353 | loss: 0.037721\n",
      "iteration: 3354 | loss: 0.005577\n",
      "iteration: 3355 | loss: 0.013363\n",
      "iteration: 3356 | loss: 0.044927\n",
      "iteration: 3357 | loss: 0.078528\n",
      "iteration: 3358 | loss: 0.018388\n",
      "iteration: 3359 | loss: 0.025674\n",
      "iteration: 3360 | loss: 0.009899\n",
      "iteration: 3361 | loss: 0.003638\n",
      "iteration: 3362 | loss: 0.047339\n",
      "iteration: 3363 | loss: 0.024328\n",
      "iteration: 3364 | loss: 0.021070\n",
      "iteration: 3365 | loss: 0.154569\n",
      "iteration: 3366 | loss: 0.026933\n",
      "iteration: 3367 | loss: 0.012882\n",
      "iteration: 3368 | loss: 0.029428\n",
      "iteration: 3369 | loss: 0.009655\n",
      "iteration: 3370 | loss: 0.017407\n",
      "iteration: 3371 | loss: 0.016707\n",
      "iteration: 3372 | loss: 0.057242\n",
      "iteration: 3373 | loss: 0.179775\n",
      "iteration: 3374 | loss: 0.044659\n",
      "  Train acc: 0.994, Val acc: 0.5\n",
      "iteration: 3375 | loss: 0.012863\n",
      "iteration: 3376 | loss: 0.015367\n",
      "iteration: 3377 | loss: 0.036530\n",
      "iteration: 3378 | loss: 0.016473\n",
      "iteration: 3379 | loss: 0.009307\n",
      "iteration: 3380 | loss: 0.017867\n",
      "iteration: 3381 | loss: 0.019652\n",
      "iteration: 3382 | loss: 0.036353\n",
      "iteration: 3383 | loss: 0.040362\n",
      "iteration: 3384 | loss: 0.017107\n",
      "iteration: 3385 | loss: 0.037307\n",
      "iteration: 3386 | loss: 0.012383\n",
      "iteration: 3387 | loss: 0.053337\n",
      "iteration: 3388 | loss: 0.031005\n",
      "iteration: 3389 | loss: 0.008964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3390 | loss: 0.011754\n",
      "iteration: 3391 | loss: 0.037407\n",
      "iteration: 3392 | loss: 0.061760\n",
      "iteration: 3393 | loss: 0.008141\n",
      "iteration: 3394 | loss: 0.013453\n",
      "iteration: 3395 | loss: 0.010439\n",
      "iteration: 3396 | loss: 0.054587\n",
      "iteration: 3397 | loss: 0.010505\n",
      "iteration: 3398 | loss: 0.014799\n",
      "iteration: 3399 | loss: 0.007614\n",
      "  Train acc: 0.998, Val acc: 0.5\n",
      "iteration: 3400 | loss: 0.018732\n",
      "iteration: 3401 | loss: 0.009611\n",
      "iteration: 3402 | loss: 0.023866\n",
      "iteration: 3403 | loss: 0.021620\n",
      "iteration: 3404 | loss: 0.022144\n",
      "iteration: 3405 | loss: 0.018487\n",
      "iteration: 3406 | loss: 0.009590\n",
      "iteration: 3407 | loss: 0.008787\n",
      "iteration: 3408 | loss: 0.032493\n",
      "iteration: 3409 | loss: 0.004323\n",
      "iteration: 3410 | loss: 0.018045\n",
      "iteration: 3411 | loss: 0.047220\n",
      "iteration: 3412 | loss: 0.047591\n",
      "iteration: 3413 | loss: 0.012352\n",
      "iteration: 3414 | loss: 0.031091\n",
      "iteration: 3415 | loss: 0.008559\n",
      "iteration: 3416 | loss: 0.014181\n",
      "iteration: 3417 | loss: 0.021750\n",
      "iteration: 3418 | loss: 0.019031\n",
      "iteration: 3419 | loss: 0.010523\n",
      "iteration: 3420 | loss: 0.025078\n",
      "iteration: 3421 | loss: 0.008898\n",
      "iteration: 3422 | loss: 0.007933\n",
      "iteration: 3423 | loss: 0.010012\n",
      "iteration: 3424 | loss: 0.038730\n",
      "  Train acc: 0.998, Val acc: 0.5\n",
      "iteration: 3425 | loss: 0.005620\n",
      "iteration: 3426 | loss: 0.005115\n",
      "iteration: 3427 | loss: 0.043496\n",
      "iteration: 3428 | loss: 0.022498\n",
      "iteration: 3429 | loss: 0.028266\n",
      "iteration: 3430 | loss: 0.011026\n",
      "iteration: 3431 | loss: 0.011039\n",
      "iteration: 3432 | loss: 0.013888\n",
      "iteration: 3433 | loss: 0.013085\n",
      "iteration: 3434 | loss: 0.024658\n",
      "iteration: 3435 | loss: 0.023872\n",
      "iteration: 3436 | loss: 0.009110\n",
      "iteration: 3437 | loss: 0.018819\n",
      "iteration: 3438 | loss: 0.012524\n",
      "iteration: 3439 | loss: 0.018804\n",
      "iteration: 3440 | loss: 0.007869\n",
      "iteration: 3441 | loss: 0.013176\n",
      "iteration: 3442 | loss: 0.015987\n",
      "iteration: 3443 | loss: 0.010802\n",
      "iteration: 3444 | loss: 0.014368\n",
      "iteration: 3445 | loss: 0.011067\n",
      "iteration: 3446 | loss: 0.008765\n",
      "iteration: 3447 | loss: 0.012052\n",
      "iteration: 3448 | loss: 0.029399\n",
      "iteration: 3449 | loss: 0.013016\n",
      "  Train acc: 0.996, Val acc: 0.5\n",
      "iteration: 3450 | loss: 0.016313\n",
      "iteration: 3451 | loss: 0.004726\n",
      "iteration: 3452 | loss: 0.046090\n",
      "iteration: 3453 | loss: 0.009118\n",
      "iteration: 3454 | loss: 0.012606\n",
      "iteration: 3455 | loss: 0.005697\n",
      "iteration: 3456 | loss: 0.010942\n",
      "iteration: 3457 | loss: 0.007537\n",
      "iteration: 3458 | loss: 0.010981\n",
      "iteration: 3459 | loss: 0.012345\n",
      "iteration: 3460 | loss: 0.014530\n",
      "iteration: 3461 | loss: 0.012456\n",
      "iteration: 3462 | loss: 0.007177\n",
      "iteration: 3463 | loss: 0.017620\n",
      "iteration: 3464 | loss: 0.005387\n",
      "iteration: 3465 | loss: 0.008194\n",
      "iteration: 3466 | loss: 0.013664\n",
      "iteration: 3467 | loss: 0.005434\n",
      "iteration: 3468 | loss: 0.029032\n",
      "iteration: 3469 | loss: 0.006417\n",
      "iteration: 3470 | loss: 0.012525\n",
      "iteration: 3471 | loss: 0.018593\n",
      "iteration: 3472 | loss: 0.006017\n",
      "iteration: 3473 | loss: 0.009865\n",
      "iteration: 3474 | loss: 0.006284\n",
      "  Train acc: 1.0, Val acc: 0.5\n",
      "iteration: 3475 | loss: 0.006967\n",
      "iteration: 3476 | loss: 0.027158\n",
      "iteration: 3477 | loss: 0.029287\n",
      "iteration: 3478 | loss: 0.003716\n",
      "iteration: 3479 | loss: 0.007702\n",
      "iteration: 3480 | loss: 0.008111\n",
      "iteration: 3481 | loss: 0.008582\n",
      "iteration: 3482 | loss: 0.011862\n",
      "iteration: 3483 | loss: 0.010229\n",
      "iteration: 3484 | loss: 0.012652\n",
      "iteration: 3485 | loss: 0.022372\n",
      "iteration: 3486 | loss: 0.073014\n",
      "iteration: 3487 | loss: 0.005883\n",
      "iteration: 3488 | loss: 0.013576\n",
      "iteration: 3489 | loss: 0.019188\n",
      "iteration: 3490 | loss: 0.061893\n",
      "iteration: 3491 | loss: 0.005342\n",
      "iteration: 3492 | loss: 0.005109\n",
      "iteration: 3493 | loss: 0.005956\n",
      "iteration: 3494 | loss: 0.009625\n",
      "iteration: 3495 | loss: 0.006940\n",
      "iteration: 3496 | loss: 0.078003\n",
      "iteration: 3497 | loss: 0.006904\n",
      "iteration: 3498 | loss: 0.009390\n",
      "iteration: 3499 | loss: 0.006349\n",
      "  Train acc: 1.0, Val acc: 0.5\n",
      "iteration: 3500 | loss: 0.006524\n",
      "iteration: 3501 | loss: 0.019203\n",
      "iteration: 3502 | loss: 0.009767\n",
      "iteration: 3503 | loss: 0.010792\n",
      "iteration: 3504 | loss: 0.006868\n",
      "iteration: 3505 | loss: 0.020366\n",
      "iteration: 3506 | loss: 0.013921\n",
      "iteration: 3507 | loss: 0.010028\n",
      "iteration: 3508 | loss: 0.013492\n",
      "iteration: 3509 | loss: 0.011284\n",
      "iteration: 3510 | loss: 0.054493\n",
      "iteration: 3511 | loss: 0.007208\n",
      "iteration: 3512 | loss: 0.011612\n",
      "iteration: 3513 | loss: 0.027216\n",
      "iteration: 3514 | loss: 0.005971\n",
      "iteration: 3515 | loss: 0.005180\n",
      "iteration: 3516 | loss: 0.009034\n",
      "iteration: 3517 | loss: 0.084141\n",
      "iteration: 3518 | loss: 0.031496\n",
      "iteration: 3519 | loss: 0.011533\n",
      "iteration: 3520 | loss: 0.003258\n",
      "iteration: 3521 | loss: 0.018240\n",
      "iteration: 3522 | loss: 0.015595\n",
      "iteration: 3523 | loss: 0.004648\n",
      "iteration: 3524 | loss: 0.008842\n",
      "  Train acc: 1.0, Val acc: 0.5\n",
      "iteration: 3525 | loss: 0.005899\n",
      "iteration: 3526 | loss: 0.008555\n",
      "iteration: 3527 | loss: 0.008424\n",
      "iteration: 3528 | loss: 0.103576\n",
      "iteration: 3529 | loss: 0.007828\n",
      "iteration: 3530 | loss: 0.022222\n",
      "iteration: 3531 | loss: 0.006229\n",
      "iteration: 3532 | loss: 0.006861\n",
      "iteration: 3533 | loss: 0.006420\n",
      "iteration: 3534 | loss: 0.038413\n",
      "iteration: 3535 | loss: 0.012210\n",
      "iteration: 3536 | loss: 0.031103\n",
      "iteration: 3537 | loss: 0.015689\n",
      "iteration: 3538 | loss: 0.005747\n",
      "iteration: 3539 | loss: 0.019825\n",
      "iteration: 3540 | loss: 0.019296\n",
      "iteration: 3541 | loss: 0.007709\n",
      "iteration: 3542 | loss: 0.082973\n",
      "iteration: 3543 | loss: 0.003992\n",
      "iteration: 3544 | loss: 0.016530\n",
      "iteration: 3545 | loss: 0.014524\n",
      "iteration: 3546 | loss: 0.009844\n",
      "iteration: 3547 | loss: 0.009094\n",
      "iteration: 3548 | loss: 0.015175\n",
      "iteration: 3549 | loss: 0.011087\n",
      "  Train acc: 0.994, Val acc: 0.5\n",
      "iteration: 3550 | loss: 0.007521\n",
      "iteration: 3551 | loss: 0.005160\n",
      "iteration: 3552 | loss: 0.015843\n",
      "iteration: 3553 | loss: 0.012429\n",
      "iteration: 3554 | loss: 0.006222\n",
      "iteration: 3555 | loss: 0.007131\n",
      "iteration: 3556 | loss: 0.003802\n",
      "iteration: 3557 | loss: 0.008435\n",
      "iteration: 3558 | loss: 0.007897\n",
      "iteration: 3559 | loss: 0.013992\n",
      "iteration: 3560 | loss: 0.007433\n",
      "iteration: 3561 | loss: 0.010800\n",
      "iteration: 3562 | loss: 0.011088\n",
      "iteration: 3563 | loss: 0.011747\n",
      "iteration: 3564 | loss: 0.008944\n",
      "iteration: 3565 | loss: 0.010741\n",
      "iteration: 3566 | loss: 0.020397\n",
      "iteration: 3567 | loss: 0.016582\n",
      "iteration: 3568 | loss: 0.008511\n",
      "iteration: 3569 | loss: 0.013402\n",
      "iteration: 3570 | loss: 0.010688\n",
      "iteration: 3571 | loss: 0.019659\n",
      "iteration: 3572 | loss: 0.010953\n",
      "iteration: 3573 | loss: 0.004189\n",
      "iteration: 3574 | loss: 0.008378\n",
      "  Train acc: 1.0, Val acc: 0.5\n",
      "iteration: 3575 | loss: 0.005216\n",
      "iteration: 3576 | loss: 0.005103\n",
      "iteration: 3577 | loss: 0.006592\n",
      "iteration: 3578 | loss: 0.007252\n",
      "iteration: 3579 | loss: 0.009028\n",
      "iteration: 3580 | loss: 0.010892\n",
      "iteration: 3581 | loss: 0.003307\n",
      "iteration: 3582 | loss: 0.005307\n",
      "iteration: 3583 | loss: 0.012320\n",
      "iteration: 3584 | loss: 0.030464\n",
      "iteration: 3585 | loss: 0.006726\n",
      "iteration: 3586 | loss: 0.008656\n",
      "iteration: 3587 | loss: 0.030218\n",
      "iteration: 3588 | loss: 0.024200\n",
      "iteration: 3589 | loss: 0.008670\n",
      "iteration: 3590 | loss: 0.009361\n",
      "iteration: 3591 | loss: 0.012958\n",
      "iteration: 3592 | loss: 0.010903\n",
      "iteration: 3593 | loss: 0.013946\n",
      "iteration: 3594 | loss: 0.005927\n",
      "iteration: 3595 | loss: 0.003147\n",
      "iteration: 3596 | loss: 0.010242\n",
      "iteration: 3597 | loss: 0.011721\n",
      "iteration: 3598 | loss: 0.012250\n",
      "iteration: 3599 | loss: 0.012897\n",
      "  Train acc: 1.0, Val acc: 0.5\n",
      "iteration: 3600 | loss: 0.007119\n",
      "iteration: 3601 | loss: 0.005445\n",
      "iteration: 3602 | loss: 0.021048\n",
      "iteration: 3603 | loss: 0.002318\n",
      "iteration: 3604 | loss: 0.006160\n",
      "iteration: 3605 | loss: 0.006055\n",
      "iteration: 3606 | loss: 0.012683\n",
      "iteration: 3607 | loss: 0.006150\n",
      "iteration: 3608 | loss: 0.008440\n",
      "iteration: 3609 | loss: 0.006625\n",
      "iteration: 3610 | loss: 0.006039\n",
      "iteration: 3611 | loss: 0.007480\n",
      "iteration: 3612 | loss: 0.003223\n",
      "iteration: 3613 | loss: 0.009517\n",
      "iteration: 3614 | loss: 0.008363\n",
      "iteration: 3615 | loss: 0.004660\n",
      "iteration: 3616 | loss: 0.009171\n",
      "iteration: 3617 | loss: 0.006739\n",
      "iteration: 3618 | loss: 0.026475\n",
      "iteration: 3619 | loss: 0.006037\n"
     ]
    }
   ],
   "source": [
    "from network import convNet4AccelSmallKernels\n",
    "adam_small_ker_accel = convNet4AccelSmallKernels(input_shape=(3, 32, 32), wt_scale=1e-2, verbose=False)\n",
    "adam_small_ker_accel.compile(\"Adam\")\n",
    "adam_small_ker_accel.fit(x_train, y_train, x_val, y_val, mini_batch_sz=25, n_epochs=20, acc_freq=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.525"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam_small_ker_accel.accuracy(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_weights(adam_small_ker_accel.layers[0].wts.transpose(0, 2, 3, 1), saveFig=False, filename='convWts_adam_train_20epoch.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train...\n",
      "3620 iterations. 181 iter/epoch.\n",
      "iteration: 0 | loss: 2.302447\n",
      "iteration: 1 | loss: 2.303018\n",
      "iteration: 2 | loss: 2.289785\n",
      "iteration: 3 | loss: 2.290967\n",
      "iteration: 4 | loss: 2.278074\n",
      "iteration: 5 | loss: 2.275007\n",
      "iteration: 6 | loss: 2.371063\n",
      "iteration: 7 | loss: 2.313193\n",
      "iteration: 8 | loss: 2.264168\n",
      "iteration: 9 | loss: 2.251530\n",
      "iteration: 10 | loss: 2.278035\n",
      "iteration: 11 | loss: 2.256010\n",
      "iteration: 12 | loss: 2.166868\n",
      "iteration: 13 | loss: 2.224917\n",
      "iteration: 14 | loss: 2.200451\n",
      "iteration: 15 | loss: 2.242534\n",
      "iteration: 16 | loss: 2.213744\n",
      "iteration: 17 | loss: 2.110305\n",
      "iteration: 18 | loss: 2.166846\n",
      "iteration: 19 | loss: 1.966621\n",
      "iteration: 20 | loss: 2.046005\n",
      "iteration: 21 | loss: 2.152372\n",
      "iteration: 22 | loss: 1.987536\n",
      "iteration: 23 | loss: 2.045974\n",
      "iteration: 24 | loss: 1.982274\n",
      "  Train acc: 0.31, Val acc: 0.0\n",
      "iteration: 25 | loss: 1.985258\n",
      "iteration: 26 | loss: 1.848829\n",
      "iteration: 27 | loss: 1.906644\n",
      "iteration: 28 | loss: 1.866015\n",
      "iteration: 29 | loss: 1.882048\n",
      "iteration: 30 | loss: 1.861909\n",
      "iteration: 31 | loss: 1.755582\n",
      "iteration: 32 | loss: 2.056178\n",
      "iteration: 33 | loss: 2.044965\n",
      "iteration: 34 | loss: 1.991373\n",
      "iteration: 35 | loss: 2.081912\n",
      "iteration: 36 | loss: 1.815726\n",
      "iteration: 37 | loss: 2.091257\n",
      "iteration: 38 | loss: 1.768525\n",
      "iteration: 39 | loss: 1.996687\n",
      "iteration: 40 | loss: 2.057747\n",
      "iteration: 41 | loss: 2.037578\n",
      "iteration: 42 | loss: 1.651070\n",
      "iteration: 43 | loss: 1.680886\n",
      "iteration: 44 | loss: 1.956879\n",
      "iteration: 45 | loss: 2.008092\n",
      "iteration: 46 | loss: 1.840240\n",
      "iteration: 47 | loss: 1.901369\n",
      "iteration: 48 | loss: 2.020709\n",
      "iteration: 49 | loss: 2.056294\n",
      "  Train acc: 0.31, Val acc: 0.0\n",
      "iteration: 50 | loss: 1.982733\n",
      "iteration: 51 | loss: 1.903431\n",
      "iteration: 52 | loss: 1.862770\n",
      "iteration: 53 | loss: 1.662306\n",
      "iteration: 54 | loss: 1.800564\n",
      "iteration: 55 | loss: 2.010434\n",
      "iteration: 56 | loss: 2.222018\n",
      "iteration: 57 | loss: 2.033751\n",
      "iteration: 58 | loss: 1.842274\n",
      "iteration: 59 | loss: 1.908358\n",
      "iteration: 60 | loss: 1.900945\n",
      "iteration: 61 | loss: 1.797802\n",
      "iteration: 62 | loss: 1.587979\n",
      "iteration: 63 | loss: 1.700463\n",
      "iteration: 64 | loss: 1.660820\n",
      "iteration: 65 | loss: 1.902791\n",
      "iteration: 66 | loss: 1.943182\n",
      "iteration: 67 | loss: 1.789487\n",
      "iteration: 68 | loss: 1.951685\n",
      "iteration: 69 | loss: 1.805574\n",
      "iteration: 70 | loss: 1.736556\n",
      "iteration: 71 | loss: 2.063528\n",
      "iteration: 72 | loss: 1.744816\n",
      "iteration: 73 | loss: 1.761705\n",
      "iteration: 74 | loss: 1.666397\n",
      "  Train acc: 0.334, Val acc: 0.0\n",
      "iteration: 75 | loss: 1.957992\n",
      "iteration: 76 | loss: 2.001721\n",
      "iteration: 77 | loss: 1.952865\n",
      "iteration: 78 | loss: 2.106337\n",
      "iteration: 79 | loss: 1.848019\n",
      "iteration: 80 | loss: 1.561006\n",
      "iteration: 81 | loss: 1.810181\n",
      "iteration: 82 | loss: 1.892920\n",
      "iteration: 83 | loss: 1.675556\n",
      "iteration: 84 | loss: 1.730121\n",
      "iteration: 85 | loss: 1.694335\n",
      "iteration: 86 | loss: 1.755636\n",
      "iteration: 87 | loss: 1.928990\n",
      "iteration: 88 | loss: 1.925781\n",
      "iteration: 89 | loss: 1.811683\n",
      "iteration: 90 | loss: 1.860958\n",
      "iteration: 91 | loss: 1.942034\n",
      "iteration: 92 | loss: 1.490215\n",
      "iteration: 93 | loss: 1.811712\n",
      "iteration: 94 | loss: 2.119080\n",
      "iteration: 95 | loss: 1.872687\n",
      "iteration: 96 | loss: 1.611860\n",
      "iteration: 97 | loss: 1.990815\n",
      "iteration: 98 | loss: 1.466640\n",
      "iteration: 99 | loss: 1.777606\n",
      "  Train acc: 0.414, Val acc: 0.0\n",
      "iteration: 100 | loss: 1.609265\n",
      "iteration: 101 | loss: 1.972666\n",
      "iteration: 102 | loss: 1.632721\n",
      "iteration: 103 | loss: 1.735387\n",
      "iteration: 104 | loss: 1.939993\n",
      "iteration: 105 | loss: 1.578693\n",
      "iteration: 106 | loss: 1.387495\n",
      "iteration: 107 | loss: 1.681257\n",
      "iteration: 108 | loss: 1.685484\n",
      "iteration: 109 | loss: 1.837886\n",
      "iteration: 110 | loss: 1.970110\n",
      "iteration: 111 | loss: 1.558896\n",
      "iteration: 112 | loss: 1.711679\n",
      "iteration: 113 | loss: 1.624881\n",
      "iteration: 114 | loss: 1.731451\n",
      "iteration: 115 | loss: 1.661171\n",
      "iteration: 116 | loss: 1.755852\n",
      "iteration: 117 | loss: 1.868322\n",
      "iteration: 118 | loss: 1.552201\n",
      "iteration: 119 | loss: 1.384261\n",
      "iteration: 120 | loss: 1.885925\n",
      "iteration: 121 | loss: 1.604988\n",
      "iteration: 122 | loss: 1.423145\n",
      "iteration: 123 | loss: 1.934038\n",
      "iteration: 124 | loss: 1.804225\n",
      "  Train acc: 0.35, Val acc: 0.0\n",
      "iteration: 125 | loss: 1.519946\n",
      "iteration: 126 | loss: 1.478730\n",
      "iteration: 127 | loss: 1.349102\n",
      "iteration: 128 | loss: 1.534281\n",
      "iteration: 129 | loss: 1.389092\n",
      "iteration: 130 | loss: 1.522611\n",
      "iteration: 131 | loss: 1.693739\n",
      "iteration: 132 | loss: 1.656740\n",
      "iteration: 133 | loss: 1.697874\n",
      "iteration: 134 | loss: 1.825450\n",
      "iteration: 135 | loss: 1.733836\n",
      "iteration: 136 | loss: 1.796771\n",
      "iteration: 137 | loss: 1.862931\n",
      "iteration: 138 | loss: 1.391514\n",
      "iteration: 139 | loss: 1.969271\n",
      "iteration: 140 | loss: 1.583683\n",
      "iteration: 141 | loss: 1.649935\n",
      "iteration: 142 | loss: 1.673860\n",
      "iteration: 143 | loss: 1.757481\n",
      "iteration: 144 | loss: 1.796134\n",
      "iteration: 145 | loss: 1.770895\n",
      "iteration: 146 | loss: 1.534142\n",
      "iteration: 147 | loss: 1.785333\n",
      "iteration: 148 | loss: 2.001162\n",
      "iteration: 149 | loss: 1.489559\n",
      "  Train acc: 0.336, Val acc: 0.0\n",
      "iteration: 150 | loss: 1.652030\n",
      "iteration: 151 | loss: 1.728772\n",
      "iteration: 152 | loss: 1.492352\n",
      "iteration: 153 | loss: 1.547357\n",
      "iteration: 154 | loss: 1.601913\n",
      "iteration: 155 | loss: 1.480869\n",
      "iteration: 156 | loss: 1.590662\n",
      "iteration: 157 | loss: 1.842168\n",
      "iteration: 158 | loss: 1.859737\n",
      "iteration: 159 | loss: 1.519885\n",
      "iteration: 160 | loss: 1.731214\n",
      "iteration: 161 | loss: 1.824738\n",
      "iteration: 162 | loss: 2.089042\n",
      "iteration: 163 | loss: 1.240122\n",
      "iteration: 164 | loss: 1.661207\n",
      "iteration: 165 | loss: 1.825735\n",
      "iteration: 166 | loss: 1.515342\n",
      "iteration: 167 | loss: 1.404522\n",
      "iteration: 168 | loss: 1.614694\n",
      "iteration: 169 | loss: 1.451943\n",
      "iteration: 170 | loss: 1.864333\n",
      "iteration: 171 | loss: 1.536689\n",
      "iteration: 172 | loss: 1.373407\n",
      "iteration: 173 | loss: 1.725681\n",
      "iteration: 174 | loss: 1.703753\n",
      "  Train acc: 0.41, Val acc: 0.0\n",
      "iteration: 175 | loss: 1.643393\n",
      "iteration: 176 | loss: 1.563086\n",
      "iteration: 177 | loss: 1.750984\n",
      "iteration: 178 | loss: 1.550288\n",
      "iteration: 179 | loss: 1.376658\n",
      "iteration: 180 | loss: 1.669508\n",
      "iteration: 181 | loss: 1.503646\n",
      "iteration: 182 | loss: 1.610728\n",
      "iteration: 183 | loss: 1.786225\n",
      "iteration: 184 | loss: 1.663909\n",
      "iteration: 185 | loss: 1.501661\n",
      "iteration: 186 | loss: 1.438952\n",
      "iteration: 187 | loss: 1.767539\n",
      "iteration: 188 | loss: 1.976414\n",
      "iteration: 189 | loss: 1.434987\n",
      "iteration: 190 | loss: 1.506735\n",
      "iteration: 191 | loss: 1.785702\n",
      "iteration: 192 | loss: 1.477943\n",
      "iteration: 193 | loss: 1.796436\n",
      "iteration: 194 | loss: 1.512179\n",
      "iteration: 195 | loss: 1.434228\n",
      "iteration: 196 | loss: 1.451662\n",
      "iteration: 197 | loss: 1.388359\n",
      "iteration: 198 | loss: 1.587290\n",
      "iteration: 199 | loss: 1.817835\n",
      "  Train acc: 0.416, Val acc: 0.0\n",
      "iteration: 200 | loss: 1.646216\n",
      "iteration: 201 | loss: 1.460234\n",
      "iteration: 202 | loss: 1.870370\n",
      "iteration: 203 | loss: 1.848163\n",
      "iteration: 204 | loss: 1.870400\n",
      "iteration: 205 | loss: 1.900810\n",
      "iteration: 206 | loss: 1.492649\n",
      "iteration: 207 | loss: 1.859277\n",
      "iteration: 208 | loss: 1.500899\n",
      "iteration: 209 | loss: 1.507445\n",
      "iteration: 210 | loss: 1.521637\n",
      "iteration: 211 | loss: 1.758304\n",
      "iteration: 212 | loss: 1.583113\n",
      "iteration: 213 | loss: 1.498798\n",
      "iteration: 214 | loss: 1.497955\n",
      "iteration: 215 | loss: 1.647130\n",
      "iteration: 216 | loss: 1.468450\n",
      "iteration: 217 | loss: 1.643002\n",
      "iteration: 218 | loss: 1.546718\n",
      "iteration: 219 | loss: 1.823206\n",
      "iteration: 220 | loss: 1.543378\n",
      "iteration: 221 | loss: 1.727338\n",
      "iteration: 222 | loss: 1.406950\n",
      "iteration: 223 | loss: 2.250256\n",
      "iteration: 224 | loss: 1.590613\n",
      "  Train acc: 0.498, Val acc: 0.0\n",
      "iteration: 225 | loss: 1.693462\n",
      "iteration: 226 | loss: 1.343266\n",
      "iteration: 227 | loss: 1.555542\n",
      "iteration: 228 | loss: 1.064698\n",
      "iteration: 229 | loss: 1.565471\n",
      "iteration: 230 | loss: 1.461545\n",
      "iteration: 231 | loss: 1.661120\n",
      "iteration: 232 | loss: 1.497129\n",
      "iteration: 233 | loss: 1.618451\n",
      "iteration: 234 | loss: 1.666741\n",
      "iteration: 235 | loss: 1.407944\n",
      "iteration: 236 | loss: 1.580605\n",
      "iteration: 237 | loss: 1.620188\n",
      "iteration: 238 | loss: 1.500736\n",
      "iteration: 239 | loss: 1.528560\n",
      "iteration: 240 | loss: 1.580124\n",
      "iteration: 241 | loss: 1.389018\n",
      "iteration: 242 | loss: 1.277818\n",
      "iteration: 243 | loss: 1.601257\n",
      "iteration: 244 | loss: 1.566916\n",
      "iteration: 245 | loss: 1.667194\n",
      "iteration: 246 | loss: 1.619235\n",
      "iteration: 247 | loss: 0.952477\n",
      "iteration: 248 | loss: 1.641074\n",
      "iteration: 249 | loss: 1.355115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train acc: 0.448, Val acc: 0.0\n",
      "iteration: 250 | loss: 1.645616\n",
      "iteration: 251 | loss: 1.241349\n",
      "iteration: 252 | loss: 1.420743\n",
      "iteration: 253 | loss: 1.146753\n",
      "iteration: 254 | loss: 1.682948\n",
      "iteration: 255 | loss: 2.036678\n",
      "iteration: 256 | loss: 1.299533\n",
      "iteration: 257 | loss: 1.678522\n",
      "iteration: 258 | loss: 1.625533\n",
      "iteration: 259 | loss: 1.731495\n",
      "iteration: 260 | loss: 1.558547\n",
      "iteration: 261 | loss: 1.470961\n",
      "iteration: 262 | loss: 1.597250\n",
      "iteration: 263 | loss: 1.584206\n",
      "iteration: 264 | loss: 1.378216\n",
      "iteration: 265 | loss: 1.430854\n",
      "iteration: 266 | loss: 1.412296\n",
      "iteration: 267 | loss: 1.244141\n",
      "iteration: 268 | loss: 1.381669\n",
      "iteration: 269 | loss: 1.609090\n",
      "iteration: 270 | loss: 1.576639\n",
      "iteration: 271 | loss: 1.277531\n",
      "iteration: 272 | loss: 1.498808\n",
      "iteration: 273 | loss: 1.205967\n",
      "iteration: 274 | loss: 1.480644\n",
      "  Train acc: 0.37, Val acc: 0.0\n",
      "iteration: 275 | loss: 1.428660\n",
      "iteration: 276 | loss: 1.895276\n",
      "iteration: 277 | loss: 1.286907\n",
      "iteration: 278 | loss: 1.110847\n",
      "iteration: 279 | loss: 1.729450\n",
      "iteration: 280 | loss: 1.600967\n",
      "iteration: 281 | loss: 2.055264\n",
      "iteration: 282 | loss: 1.521035\n",
      "iteration: 283 | loss: 1.352777\n",
      "iteration: 284 | loss: 1.277659\n",
      "iteration: 285 | loss: 1.421985\n",
      "iteration: 286 | loss: 1.184043\n",
      "iteration: 287 | loss: 1.401037\n",
      "iteration: 288 | loss: 1.372744\n",
      "iteration: 289 | loss: 1.316337\n",
      "iteration: 290 | loss: 1.640160\n",
      "iteration: 291 | loss: 1.379850\n",
      "iteration: 292 | loss: 1.431768\n",
      "iteration: 293 | loss: 1.456849\n",
      "iteration: 294 | loss: 1.494605\n",
      "iteration: 295 | loss: 1.372392\n",
      "iteration: 296 | loss: 1.508157\n",
      "iteration: 297 | loss: 1.190409\n",
      "iteration: 298 | loss: 1.222512\n",
      "iteration: 299 | loss: 1.149489\n",
      "  Train acc: 0.456, Val acc: 0.0\n",
      "iteration: 300 | loss: 1.327139\n",
      "iteration: 301 | loss: 1.443772\n",
      "iteration: 302 | loss: 1.417916\n",
      "iteration: 303 | loss: 1.819504\n",
      "iteration: 304 | loss: 1.910638\n",
      "iteration: 305 | loss: 1.103529\n",
      "iteration: 306 | loss: 1.466568\n",
      "iteration: 307 | loss: 1.501086\n",
      "iteration: 308 | loss: 1.383851\n",
      "iteration: 309 | loss: 1.519093\n",
      "iteration: 310 | loss: 1.293634\n",
      "iteration: 311 | loss: 1.528964\n",
      "iteration: 312 | loss: 1.220350\n",
      "iteration: 313 | loss: 1.414160\n",
      "iteration: 314 | loss: 1.535679\n",
      "iteration: 315 | loss: 1.668581\n",
      "iteration: 316 | loss: 1.607324\n",
      "iteration: 317 | loss: 1.278750\n",
      "iteration: 318 | loss: 1.716215\n",
      "iteration: 319 | loss: 1.224991\n",
      "iteration: 320 | loss: 1.665330\n",
      "iteration: 321 | loss: 1.270876\n",
      "iteration: 322 | loss: 1.741502\n",
      "iteration: 323 | loss: 1.504520\n",
      "iteration: 324 | loss: 1.600837\n",
      "  Train acc: 0.466, Val acc: 0.0\n",
      "iteration: 325 | loss: 1.020652\n",
      "iteration: 326 | loss: 1.454402\n",
      "iteration: 327 | loss: 1.262289\n",
      "iteration: 328 | loss: 1.127833\n",
      "iteration: 329 | loss: 1.628760\n",
      "iteration: 330 | loss: 1.425622\n",
      "iteration: 331 | loss: 1.369230\n",
      "iteration: 332 | loss: 1.223921\n",
      "iteration: 333 | loss: 1.108261\n",
      "iteration: 334 | loss: 1.522111\n",
      "iteration: 335 | loss: 1.719184\n",
      "iteration: 336 | loss: 1.392397\n",
      "iteration: 337 | loss: 1.201903\n",
      "iteration: 338 | loss: 1.192319\n",
      "iteration: 339 | loss: 1.559931\n",
      "iteration: 340 | loss: 1.391825\n",
      "iteration: 341 | loss: 1.593587\n",
      "iteration: 342 | loss: 1.397045\n",
      "iteration: 343 | loss: 1.412300\n",
      "iteration: 344 | loss: 1.205592\n",
      "iteration: 345 | loss: 1.417584\n",
      "iteration: 346 | loss: 1.425052\n",
      "iteration: 347 | loss: 1.623434\n",
      "iteration: 348 | loss: 1.392120\n",
      "iteration: 349 | loss: 1.399857\n",
      "  Train acc: 0.422, Val acc: 0.0\n",
      "iteration: 350 | loss: 1.409135\n",
      "iteration: 351 | loss: 1.282456\n",
      "iteration: 352 | loss: 1.247991\n",
      "iteration: 353 | loss: 1.416913\n",
      "iteration: 354 | loss: 1.392953\n",
      "iteration: 355 | loss: 1.284030\n",
      "iteration: 356 | loss: 1.614330\n",
      "iteration: 357 | loss: 1.323227\n",
      "iteration: 358 | loss: 1.504853\n",
      "iteration: 359 | loss: 0.930809\n",
      "iteration: 360 | loss: 1.195581\n",
      "iteration: 361 | loss: 1.333935\n",
      "iteration: 362 | loss: 1.624411\n",
      "iteration: 363 | loss: 1.179775\n",
      "iteration: 364 | loss: 1.270652\n",
      "iteration: 365 | loss: 1.458543\n",
      "iteration: 366 | loss: 1.490711\n",
      "iteration: 367 | loss: 1.503218\n",
      "iteration: 368 | loss: 1.824830\n",
      "iteration: 369 | loss: 1.345934\n",
      "iteration: 370 | loss: 1.243256\n",
      "iteration: 371 | loss: 1.165664\n",
      "iteration: 372 | loss: 1.185256\n",
      "iteration: 373 | loss: 1.402127\n",
      "iteration: 374 | loss: 1.714211\n",
      "  Train acc: 0.526, Val acc: 0.0\n",
      "iteration: 375 | loss: 1.597239\n",
      "iteration: 376 | loss: 1.526717\n",
      "iteration: 377 | loss: 1.625284\n",
      "iteration: 378 | loss: 1.285445\n",
      "iteration: 379 | loss: 1.427727\n",
      "iteration: 380 | loss: 1.535800\n",
      "iteration: 381 | loss: 1.669273\n",
      "iteration: 382 | loss: 1.488113\n",
      "iteration: 383 | loss: 1.227405\n",
      "iteration: 384 | loss: 1.224858\n",
      "iteration: 385 | loss: 1.303785\n",
      "iteration: 386 | loss: 1.527460\n",
      "iteration: 387 | loss: 1.357404\n",
      "iteration: 388 | loss: 1.037977\n",
      "iteration: 389 | loss: 1.419693\n",
      "iteration: 390 | loss: 1.390607\n",
      "iteration: 391 | loss: 1.137127\n",
      "iteration: 392 | loss: 1.562666\n",
      "iteration: 393 | loss: 1.334566\n",
      "iteration: 394 | loss: 1.628968\n",
      "iteration: 395 | loss: 1.448798\n",
      "iteration: 396 | loss: 1.232316\n",
      "iteration: 397 | loss: 1.479438\n",
      "iteration: 398 | loss: 1.416515\n",
      "iteration: 399 | loss: 1.389504\n",
      "  Train acc: 0.492, Val acc: 0.0\n",
      "iteration: 400 | loss: 1.377955\n",
      "iteration: 401 | loss: 1.340476\n",
      "iteration: 402 | loss: 1.336197\n",
      "iteration: 403 | loss: 1.304605\n",
      "iteration: 404 | loss: 1.280158\n",
      "iteration: 405 | loss: 1.447542\n",
      "iteration: 406 | loss: 1.075151\n",
      "iteration: 407 | loss: 1.139166\n",
      "iteration: 408 | loss: 1.216618\n",
      "iteration: 409 | loss: 1.268087\n",
      "iteration: 410 | loss: 1.430909\n",
      "iteration: 411 | loss: 1.502860\n",
      "iteration: 412 | loss: 1.324637\n",
      "iteration: 413 | loss: 1.252424\n",
      "iteration: 414 | loss: 1.334559\n",
      "iteration: 415 | loss: 1.601229\n",
      "iteration: 416 | loss: 1.364410\n",
      "iteration: 417 | loss: 1.115884\n",
      "iteration: 418 | loss: 1.534345\n",
      "iteration: 419 | loss: 1.504701\n",
      "iteration: 420 | loss: 1.334064\n",
      "iteration: 421 | loss: 1.215134\n",
      "iteration: 422 | loss: 1.502786\n",
      "iteration: 423 | loss: 1.300092\n",
      "iteration: 424 | loss: 1.486135\n",
      "  Train acc: 0.514, Val acc: 0.0\n",
      "iteration: 425 | loss: 1.205150\n",
      "iteration: 426 | loss: 1.277849\n",
      "iteration: 427 | loss: 1.603886\n",
      "iteration: 428 | loss: 1.662602\n",
      "iteration: 429 | loss: 1.198871\n",
      "iteration: 430 | loss: 1.610197\n",
      "iteration: 431 | loss: 1.211651\n",
      "iteration: 432 | loss: 1.238020\n",
      "iteration: 433 | loss: 1.210670\n",
      "iteration: 434 | loss: 1.063445\n",
      "iteration: 435 | loss: 0.999013\n",
      "iteration: 436 | loss: 1.281079\n",
      "iteration: 437 | loss: 1.416370\n",
      "iteration: 438 | loss: 1.259449\n",
      "iteration: 439 | loss: 1.495084\n",
      "iteration: 440 | loss: 1.437240\n",
      "iteration: 441 | loss: 1.572911\n",
      "iteration: 442 | loss: 1.260278\n",
      "iteration: 443 | loss: 1.370334\n",
      "iteration: 444 | loss: 1.411442\n",
      "iteration: 445 | loss: 1.201283\n",
      "iteration: 446 | loss: 1.097176\n",
      "iteration: 447 | loss: 1.372448\n",
      "iteration: 448 | loss: 1.405399\n",
      "iteration: 449 | loss: 1.250740\n",
      "  Train acc: 0.448, Val acc: 0.0\n",
      "iteration: 450 | loss: 1.211688\n",
      "iteration: 451 | loss: 1.120664\n",
      "iteration: 452 | loss: 1.027821\n",
      "iteration: 453 | loss: 1.314161\n",
      "iteration: 454 | loss: 1.121385\n",
      "iteration: 455 | loss: 1.215233\n",
      "iteration: 456 | loss: 1.436217\n",
      "iteration: 457 | loss: 1.460088\n",
      "iteration: 458 | loss: 1.177704\n",
      "iteration: 459 | loss: 1.446687\n",
      "iteration: 460 | loss: 1.338899\n",
      "iteration: 461 | loss: 1.200198\n",
      "iteration: 462 | loss: 1.385321\n",
      "iteration: 463 | loss: 1.491431\n",
      "iteration: 464 | loss: 1.412761\n",
      "iteration: 465 | loss: 1.506555\n",
      "iteration: 466 | loss: 1.518873\n",
      "iteration: 467 | loss: 1.308002\n",
      "iteration: 468 | loss: 1.595668\n",
      "iteration: 469 | loss: 1.403373\n",
      "iteration: 470 | loss: 1.646384\n",
      "iteration: 471 | loss: 1.446688\n",
      "iteration: 472 | loss: 1.094263\n",
      "iteration: 473 | loss: 1.703110\n",
      "iteration: 474 | loss: 1.240461\n",
      "  Train acc: 0.566, Val acc: 0.0\n",
      "iteration: 475 | loss: 1.461304\n",
      "iteration: 476 | loss: 1.289457\n",
      "iteration: 477 | loss: 1.497716\n",
      "iteration: 478 | loss: 1.483852\n",
      "iteration: 479 | loss: 1.135329\n",
      "iteration: 480 | loss: 1.457623\n",
      "iteration: 481 | loss: 1.498169\n",
      "iteration: 482 | loss: 1.324399\n",
      "iteration: 483 | loss: 1.642945\n",
      "iteration: 484 | loss: 1.340082\n",
      "iteration: 485 | loss: 1.809591\n",
      "iteration: 486 | loss: 1.235686\n",
      "iteration: 487 | loss: 1.517046\n",
      "iteration: 488 | loss: 1.186132\n",
      "iteration: 489 | loss: 1.256555\n",
      "iteration: 490 | loss: 1.220046\n",
      "iteration: 491 | loss: 1.283781\n",
      "iteration: 492 | loss: 1.496789\n",
      "iteration: 493 | loss: 1.331750\n",
      "iteration: 494 | loss: 1.342361\n",
      "iteration: 495 | loss: 1.426219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 496 | loss: 1.415816\n",
      "iteration: 497 | loss: 1.383948\n",
      "iteration: 498 | loss: 1.223904\n",
      "iteration: 499 | loss: 1.181841\n",
      "  Train acc: 0.518, Val acc: 0.0\n",
      "iteration: 500 | loss: 1.072090\n",
      "iteration: 501 | loss: 1.179704\n",
      "iteration: 502 | loss: 1.086606\n",
      "iteration: 503 | loss: 1.336985\n",
      "iteration: 504 | loss: 1.334282\n",
      "iteration: 505 | loss: 1.450412\n",
      "iteration: 506 | loss: 1.156871\n",
      "iteration: 507 | loss: 1.134926\n",
      "iteration: 508 | loss: 1.228993\n",
      "iteration: 509 | loss: 1.359856\n",
      "iteration: 510 | loss: 1.218083\n",
      "iteration: 511 | loss: 1.312823\n",
      "iteration: 512 | loss: 1.151178\n",
      "iteration: 513 | loss: 1.412983\n",
      "iteration: 514 | loss: 1.185369\n",
      "iteration: 515 | loss: 1.178417\n",
      "iteration: 516 | loss: 1.629110\n",
      "iteration: 517 | loss: 1.054567\n",
      "iteration: 518 | loss: 1.570115\n",
      "iteration: 519 | loss: 1.006452\n",
      "iteration: 520 | loss: 1.276861\n",
      "iteration: 521 | loss: 1.196264\n",
      "iteration: 522 | loss: 1.394707\n",
      "iteration: 523 | loss: 1.099913\n",
      "iteration: 524 | loss: 1.442989\n",
      "  Train acc: 0.594, Val acc: 0.0\n",
      "iteration: 525 | loss: 1.246907\n",
      "iteration: 526 | loss: 1.404421\n",
      "iteration: 527 | loss: 1.352414\n",
      "iteration: 528 | loss: 1.297387\n",
      "iteration: 529 | loss: 1.157528\n",
      "iteration: 530 | loss: 1.067021\n",
      "iteration: 531 | loss: 1.340301\n",
      "iteration: 532 | loss: 1.287828\n",
      "iteration: 533 | loss: 1.430296\n",
      "iteration: 534 | loss: 1.215150\n",
      "iteration: 535 | loss: 1.581128\n",
      "iteration: 536 | loss: 1.205533\n",
      "iteration: 537 | loss: 1.343919\n",
      "iteration: 538 | loss: 1.590352\n",
      "iteration: 539 | loss: 1.463104\n",
      "iteration: 540 | loss: 1.047553\n",
      "iteration: 541 | loss: 1.394361\n",
      "iteration: 542 | loss: 0.976961\n",
      "iteration: 543 | loss: 0.828367\n",
      "iteration: 544 | loss: 1.137871\n",
      "iteration: 545 | loss: 1.050586\n",
      "iteration: 546 | loss: 1.733748\n",
      "iteration: 547 | loss: 1.404298\n",
      "iteration: 548 | loss: 1.107631\n",
      "iteration: 549 | loss: 1.310355\n",
      "  Train acc: 0.574, Val acc: 0.5\n",
      "iteration: 550 | loss: 1.388389\n",
      "iteration: 551 | loss: 1.123397\n",
      "iteration: 552 | loss: 1.158778\n",
      "iteration: 553 | loss: 1.314167\n",
      "iteration: 554 | loss: 1.356819\n",
      "iteration: 555 | loss: 1.280506\n",
      "iteration: 556 | loss: 1.216719\n",
      "iteration: 557 | loss: 1.015800\n",
      "iteration: 558 | loss: 1.295210\n",
      "iteration: 559 | loss: 1.256012\n",
      "iteration: 560 | loss: 1.527835\n",
      "iteration: 561 | loss: 1.423455\n",
      "iteration: 562 | loss: 1.150275\n",
      "iteration: 563 | loss: 1.494670\n",
      "iteration: 564 | loss: 1.127967\n",
      "iteration: 565 | loss: 1.366883\n",
      "iteration: 566 | loss: 1.303402\n",
      "iteration: 567 | loss: 1.370029\n",
      "iteration: 568 | loss: 1.124531\n",
      "iteration: 569 | loss: 1.149012\n",
      "iteration: 570 | loss: 1.184276\n",
      "iteration: 571 | loss: 1.303365\n",
      "iteration: 572 | loss: 1.340834\n",
      "iteration: 573 | loss: 1.488521\n",
      "iteration: 574 | loss: 1.673322\n",
      "  Train acc: 0.588, Val acc: 0.0\n",
      "iteration: 575 | loss: 1.158924\n",
      "iteration: 576 | loss: 0.997009\n",
      "iteration: 577 | loss: 1.171445\n",
      "iteration: 578 | loss: 1.167642\n",
      "iteration: 579 | loss: 1.541855\n",
      "iteration: 580 | loss: 1.345415\n",
      "iteration: 581 | loss: 1.295944\n",
      "iteration: 582 | loss: 1.403221\n",
      "iteration: 583 | loss: 1.457738\n",
      "iteration: 584 | loss: 1.421612\n",
      "iteration: 585 | loss: 1.121253\n",
      "iteration: 586 | loss: 1.242458\n",
      "iteration: 587 | loss: 1.299731\n",
      "iteration: 588 | loss: 1.382627\n",
      "iteration: 589 | loss: 1.337993\n",
      "iteration: 590 | loss: 0.853342\n",
      "iteration: 591 | loss: 1.349109\n",
      "iteration: 592 | loss: 0.974962\n",
      "iteration: 593 | loss: 1.455253\n",
      "iteration: 594 | loss: 0.908057\n",
      "iteration: 595 | loss: 1.085196\n",
      "iteration: 596 | loss: 1.032358\n",
      "iteration: 597 | loss: 1.167786\n",
      "iteration: 598 | loss: 0.976427\n",
      "iteration: 599 | loss: 1.064941\n",
      "  Train acc: 0.552, Val acc: 0.0\n",
      "iteration: 600 | loss: 1.346091\n",
      "iteration: 601 | loss: 1.460704\n",
      "iteration: 602 | loss: 1.450163\n",
      "iteration: 603 | loss: 1.185415\n",
      "iteration: 604 | loss: 1.406867\n",
      "iteration: 605 | loss: 1.123991\n",
      "iteration: 606 | loss: 1.122416\n",
      "iteration: 607 | loss: 1.238959\n",
      "iteration: 608 | loss: 1.603371\n",
      "iteration: 609 | loss: 1.533964\n",
      "iteration: 610 | loss: 1.287751\n",
      "iteration: 611 | loss: 1.582041\n",
      "iteration: 612 | loss: 1.027110\n",
      "iteration: 613 | loss: 1.169300\n",
      "iteration: 614 | loss: 1.642895\n",
      "iteration: 615 | loss: 0.901801\n",
      "iteration: 616 | loss: 1.123388\n",
      "iteration: 617 | loss: 1.288311\n",
      "iteration: 618 | loss: 1.295854\n",
      "iteration: 619 | loss: 1.388547\n",
      "iteration: 620 | loss: 1.446331\n",
      "iteration: 621 | loss: 0.944548\n",
      "iteration: 622 | loss: 0.960274\n",
      "iteration: 623 | loss: 0.883345\n",
      "iteration: 624 | loss: 1.034998\n",
      "  Train acc: 0.614, Val acc: 0.0\n",
      "iteration: 625 | loss: 1.145247\n",
      "iteration: 626 | loss: 1.118937\n",
      "iteration: 627 | loss: 1.155727\n",
      "iteration: 628 | loss: 1.238334\n",
      "iteration: 629 | loss: 1.015017\n",
      "iteration: 630 | loss: 1.241172\n",
      "iteration: 631 | loss: 1.090268\n",
      "iteration: 632 | loss: 1.527608\n",
      "iteration: 633 | loss: 0.829393\n",
      "iteration: 634 | loss: 1.310196\n",
      "iteration: 635 | loss: 1.075310\n",
      "iteration: 636 | loss: 1.344796\n",
      "iteration: 637 | loss: 1.252948\n",
      "iteration: 638 | loss: 1.118221\n",
      "iteration: 639 | loss: 1.037782\n",
      "iteration: 640 | loss: 1.498014\n",
      "iteration: 641 | loss: 0.987467\n",
      "iteration: 642 | loss: 1.014007\n",
      "iteration: 643 | loss: 1.096395\n",
      "iteration: 644 | loss: 1.281600\n",
      "iteration: 645 | loss: 0.924104\n",
      "iteration: 646 | loss: 1.108724\n",
      "iteration: 647 | loss: 1.052818\n",
      "iteration: 648 | loss: 0.923535\n",
      "iteration: 649 | loss: 1.028672\n",
      "  Train acc: 0.61, Val acc: 0.5\n",
      "iteration: 650 | loss: 0.972416\n",
      "iteration: 651 | loss: 1.159710\n",
      "iteration: 652 | loss: 1.160617\n",
      "iteration: 653 | loss: 0.971828\n",
      "iteration: 654 | loss: 1.404958\n",
      "iteration: 655 | loss: 1.172763\n",
      "iteration: 656 | loss: 1.037806\n",
      "iteration: 657 | loss: 1.346613\n",
      "iteration: 658 | loss: 1.522439\n",
      "iteration: 659 | loss: 1.147618\n",
      "iteration: 660 | loss: 1.140859\n",
      "iteration: 661 | loss: 0.853285\n",
      "iteration: 662 | loss: 1.019468\n",
      "iteration: 663 | loss: 1.037935\n",
      "iteration: 664 | loss: 1.172860\n",
      "iteration: 665 | loss: 0.968403\n",
      "iteration: 666 | loss: 1.113412\n",
      "iteration: 667 | loss: 0.705454\n",
      "iteration: 668 | loss: 1.401920\n",
      "iteration: 669 | loss: 1.367409\n",
      "iteration: 670 | loss: 1.301303\n",
      "iteration: 671 | loss: 0.691632\n",
      "iteration: 672 | loss: 1.443656\n",
      "iteration: 673 | loss: 1.436248\n",
      "iteration: 674 | loss: 1.329517\n",
      "  Train acc: 0.624, Val acc: 0.5\n",
      "iteration: 675 | loss: 1.107797\n",
      "iteration: 676 | loss: 0.879511\n",
      "iteration: 677 | loss: 1.108306\n",
      "iteration: 678 | loss: 1.207869\n",
      "iteration: 679 | loss: 1.002016\n",
      "iteration: 680 | loss: 1.128694\n",
      "iteration: 681 | loss: 1.331027\n",
      "iteration: 682 | loss: 1.052868\n",
      "iteration: 683 | loss: 0.973560\n",
      "iteration: 684 | loss: 1.450552\n",
      "iteration: 685 | loss: 1.105647\n",
      "iteration: 686 | loss: 1.183598\n",
      "iteration: 687 | loss: 0.864961\n",
      "iteration: 688 | loss: 0.810083\n",
      "iteration: 689 | loss: 1.104176\n",
      "iteration: 690 | loss: 1.433386\n",
      "iteration: 691 | loss: 0.713223\n",
      "iteration: 692 | loss: 1.206982\n",
      "iteration: 693 | loss: 1.147993\n",
      "iteration: 694 | loss: 0.959133\n",
      "iteration: 695 | loss: 0.995712\n",
      "iteration: 696 | loss: 1.401700\n",
      "iteration: 697 | loss: 0.968744\n",
      "iteration: 698 | loss: 1.382008\n",
      "iteration: 699 | loss: 1.187276\n",
      "  Train acc: 0.592, Val acc: 0.5\n",
      "iteration: 700 | loss: 1.134641\n",
      "iteration: 701 | loss: 1.157123\n",
      "iteration: 702 | loss: 1.167618\n",
      "iteration: 703 | loss: 1.198262\n",
      "iteration: 704 | loss: 1.164387\n",
      "iteration: 705 | loss: 0.976812\n",
      "iteration: 706 | loss: 0.826979\n",
      "iteration: 707 | loss: 0.989718\n",
      "iteration: 708 | loss: 0.956209\n",
      "iteration: 709 | loss: 1.366169\n",
      "iteration: 710 | loss: 1.087117\n",
      "iteration: 711 | loss: 0.964300\n",
      "iteration: 712 | loss: 1.128727\n",
      "iteration: 713 | loss: 0.963921\n",
      "iteration: 714 | loss: 0.960824\n",
      "iteration: 715 | loss: 1.212919\n",
      "iteration: 716 | loss: 1.239896\n",
      "iteration: 717 | loss: 1.010851\n",
      "iteration: 718 | loss: 0.974642\n",
      "iteration: 719 | loss: 0.689104\n",
      "iteration: 720 | loss: 0.933088\n",
      "iteration: 721 | loss: 0.950228\n",
      "iteration: 722 | loss: 0.925309\n",
      "iteration: 723 | loss: 1.114387\n",
      "iteration: 724 | loss: 0.859492\n",
      "  Train acc: 0.624, Val acc: 0.5\n",
      "iteration: 725 | loss: 1.219860\n",
      "iteration: 726 | loss: 1.072223\n",
      "iteration: 727 | loss: 1.037435\n",
      "iteration: 728 | loss: 1.166991\n",
      "iteration: 729 | loss: 1.206912\n",
      "iteration: 730 | loss: 1.124473\n",
      "iteration: 731 | loss: 1.008022\n",
      "iteration: 732 | loss: 0.865675\n",
      "iteration: 733 | loss: 1.266269\n",
      "iteration: 734 | loss: 1.306321\n",
      "iteration: 735 | loss: 1.211966\n",
      "iteration: 736 | loss: 1.236435\n",
      "iteration: 737 | loss: 1.177801\n",
      "iteration: 738 | loss: 0.915861\n",
      "iteration: 739 | loss: 1.006785\n",
      "iteration: 740 | loss: 1.002461\n",
      "iteration: 741 | loss: 1.087873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 742 | loss: 0.974234\n",
      "iteration: 743 | loss: 1.488879\n",
      "iteration: 744 | loss: 0.936485\n",
      "iteration: 745 | loss: 0.978814\n",
      "iteration: 746 | loss: 0.612789\n",
      "iteration: 747 | loss: 0.911261\n",
      "iteration: 748 | loss: 0.813591\n",
      "iteration: 749 | loss: 1.045676\n",
      "  Train acc: 0.618, Val acc: 0.0\n",
      "iteration: 750 | loss: 1.098820\n",
      "iteration: 751 | loss: 0.953575\n",
      "iteration: 752 | loss: 0.979799\n",
      "iteration: 753 | loss: 0.945272\n",
      "iteration: 754 | loss: 0.989617\n",
      "iteration: 755 | loss: 1.522893\n",
      "iteration: 756 | loss: 1.408029\n",
      "iteration: 757 | loss: 0.861258\n",
      "iteration: 758 | loss: 0.898212\n",
      "iteration: 759 | loss: 1.056830\n",
      "iteration: 760 | loss: 1.044037\n",
      "iteration: 761 | loss: 1.045521\n",
      "iteration: 762 | loss: 1.493870\n",
      "iteration: 763 | loss: 1.101319\n",
      "iteration: 764 | loss: 0.829571\n",
      "iteration: 765 | loss: 1.237495\n",
      "iteration: 766 | loss: 1.168051\n",
      "iteration: 767 | loss: 0.780781\n",
      "iteration: 768 | loss: 0.707591\n",
      "iteration: 769 | loss: 1.199627\n",
      "iteration: 770 | loss: 1.124228\n",
      "iteration: 771 | loss: 1.374408\n",
      "iteration: 772 | loss: 0.979131\n",
      "iteration: 773 | loss: 1.387159\n",
      "iteration: 774 | loss: 0.885817\n",
      "  Train acc: 0.622, Val acc: 0.0\n",
      "iteration: 775 | loss: 1.106516\n",
      "iteration: 776 | loss: 0.970772\n",
      "iteration: 777 | loss: 1.030026\n",
      "iteration: 778 | loss: 1.174835\n",
      "iteration: 779 | loss: 1.190217\n",
      "iteration: 780 | loss: 1.238519\n",
      "iteration: 781 | loss: 1.097647\n",
      "iteration: 782 | loss: 0.858366\n",
      "iteration: 783 | loss: 0.778496\n",
      "iteration: 784 | loss: 1.001254\n",
      "iteration: 785 | loss: 1.149787\n",
      "iteration: 786 | loss: 1.073248\n",
      "iteration: 787 | loss: 1.690317\n",
      "iteration: 788 | loss: 0.951601\n",
      "iteration: 789 | loss: 0.687397\n",
      "iteration: 790 | loss: 1.223943\n",
      "iteration: 791 | loss: 0.800007\n",
      "iteration: 792 | loss: 1.285569\n",
      "iteration: 793 | loss: 1.202728\n",
      "iteration: 794 | loss: 0.870618\n",
      "iteration: 795 | loss: 0.621047\n",
      "iteration: 796 | loss: 1.206396\n",
      "iteration: 797 | loss: 1.154489\n",
      "iteration: 798 | loss: 0.895838\n",
      "iteration: 799 | loss: 0.727856\n",
      "  Train acc: 0.644, Val acc: 0.5\n",
      "iteration: 800 | loss: 0.830639\n",
      "iteration: 801 | loss: 0.874753\n",
      "iteration: 802 | loss: 0.987344\n",
      "iteration: 803 | loss: 0.887357\n",
      "iteration: 804 | loss: 1.026738\n",
      "iteration: 805 | loss: 0.639201\n",
      "iteration: 806 | loss: 1.040385\n",
      "iteration: 807 | loss: 0.588912\n",
      "iteration: 808 | loss: 1.241466\n",
      "iteration: 809 | loss: 0.873971\n",
      "iteration: 810 | loss: 1.222097\n",
      "iteration: 811 | loss: 1.415343\n",
      "iteration: 812 | loss: 0.787922\n",
      "iteration: 813 | loss: 0.584940\n",
      "iteration: 814 | loss: 0.951446\n",
      "iteration: 815 | loss: 1.010280\n",
      "iteration: 816 | loss: 0.880455\n",
      "iteration: 817 | loss: 0.952206\n",
      "iteration: 818 | loss: 1.105084\n",
      "iteration: 819 | loss: 0.774168\n",
      "iteration: 820 | loss: 0.925310\n",
      "iteration: 821 | loss: 0.800231\n",
      "iteration: 822 | loss: 0.842557\n",
      "iteration: 823 | loss: 0.769507\n",
      "iteration: 824 | loss: 1.010199\n",
      "  Train acc: 0.652, Val acc: 0.0\n",
      "iteration: 825 | loss: 0.780443\n",
      "iteration: 826 | loss: 1.368056\n",
      "iteration: 827 | loss: 0.755264\n",
      "iteration: 828 | loss: 0.624256\n",
      "iteration: 829 | loss: 1.091101\n",
      "iteration: 830 | loss: 0.875768\n",
      "iteration: 831 | loss: 0.816184\n",
      "iteration: 832 | loss: 0.881473\n",
      "iteration: 833 | loss: 1.126227\n",
      "iteration: 834 | loss: 0.907568\n",
      "iteration: 835 | loss: 0.776884\n",
      "iteration: 836 | loss: 1.173522\n",
      "iteration: 837 | loss: 1.064699\n",
      "iteration: 838 | loss: 1.409134\n",
      "iteration: 839 | loss: 1.345485\n",
      "iteration: 840 | loss: 1.057119\n",
      "iteration: 841 | loss: 0.621842\n",
      "iteration: 842 | loss: 1.347617\n",
      "iteration: 843 | loss: 1.038738\n",
      "iteration: 844 | loss: 0.948259\n",
      "iteration: 845 | loss: 1.343030\n",
      "iteration: 846 | loss: 0.862026\n",
      "iteration: 847 | loss: 1.543615\n",
      "iteration: 848 | loss: 1.087771\n",
      "iteration: 849 | loss: 0.960545\n",
      "  Train acc: 0.628, Val acc: 0.0\n",
      "iteration: 850 | loss: 1.061911\n",
      "iteration: 851 | loss: 0.903269\n",
      "iteration: 852 | loss: 0.843300\n",
      "iteration: 853 | loss: 1.045093\n",
      "iteration: 854 | loss: 1.060500\n",
      "iteration: 855 | loss: 0.876482\n",
      "iteration: 856 | loss: 1.020570\n",
      "iteration: 857 | loss: 0.900777\n",
      "iteration: 858 | loss: 1.311194\n",
      "iteration: 859 | loss: 0.724693\n",
      "iteration: 860 | loss: 1.008909\n",
      "iteration: 861 | loss: 1.337597\n",
      "iteration: 862 | loss: 0.910917\n",
      "iteration: 863 | loss: 1.024939\n",
      "iteration: 864 | loss: 1.231721\n",
      "iteration: 865 | loss: 0.442069\n",
      "iteration: 866 | loss: 1.256994\n",
      "iteration: 867 | loss: 0.768208\n",
      "iteration: 868 | loss: 1.039005\n",
      "iteration: 869 | loss: 1.340317\n",
      "iteration: 870 | loss: 0.928686\n",
      "iteration: 871 | loss: 0.750590\n",
      "iteration: 872 | loss: 0.766331\n",
      "iteration: 873 | loss: 1.027551\n",
      "iteration: 874 | loss: 1.272837\n",
      "  Train acc: 0.656, Val acc: 0.0\n",
      "iteration: 875 | loss: 0.966852\n",
      "iteration: 876 | loss: 1.160707\n",
      "iteration: 877 | loss: 0.599984\n",
      "iteration: 878 | loss: 1.080648\n",
      "iteration: 879 | loss: 0.952246\n",
      "iteration: 880 | loss: 1.162627\n",
      "iteration: 881 | loss: 1.402057\n",
      "iteration: 882 | loss: 0.839528\n",
      "iteration: 883 | loss: 0.542178\n",
      "iteration: 884 | loss: 0.846650\n",
      "iteration: 885 | loss: 0.579863\n",
      "iteration: 886 | loss: 0.978245\n",
      "iteration: 887 | loss: 1.141606\n",
      "iteration: 888 | loss: 1.123136\n",
      "iteration: 889 | loss: 1.172600\n",
      "iteration: 890 | loss: 1.335158\n",
      "iteration: 891 | loss: 0.889019\n",
      "iteration: 892 | loss: 1.041740\n",
      "iteration: 893 | loss: 1.053730\n",
      "iteration: 894 | loss: 1.331251\n",
      "iteration: 895 | loss: 0.922464\n",
      "iteration: 896 | loss: 0.955791\n",
      "iteration: 897 | loss: 1.128522\n",
      "iteration: 898 | loss: 0.781413\n",
      "iteration: 899 | loss: 0.820179\n",
      "  Train acc: 0.642, Val acc: 0.5\n",
      "iteration: 900 | loss: 0.889672\n",
      "iteration: 901 | loss: 0.970929\n",
      "iteration: 902 | loss: 1.297722\n",
      "iteration: 903 | loss: 1.002997\n",
      "iteration: 904 | loss: 0.833225\n",
      "iteration: 905 | loss: 0.575565\n",
      "iteration: 906 | loss: 0.863888\n",
      "iteration: 907 | loss: 0.671838\n",
      "iteration: 908 | loss: 0.693691\n",
      "iteration: 909 | loss: 0.770489\n",
      "iteration: 910 | loss: 1.183248\n",
      "iteration: 911 | loss: 0.906553\n",
      "iteration: 912 | loss: 0.757483\n",
      "iteration: 913 | loss: 1.108760\n",
      "iteration: 914 | loss: 0.864041\n",
      "iteration: 915 | loss: 1.438211\n",
      "iteration: 916 | loss: 1.082302\n",
      "iteration: 917 | loss: 0.830103\n",
      "iteration: 918 | loss: 0.985230\n",
      "iteration: 919 | loss: 0.651051\n",
      "iteration: 920 | loss: 1.075326\n",
      "iteration: 921 | loss: 0.962689\n",
      "iteration: 922 | loss: 0.924268\n",
      "iteration: 923 | loss: 0.789365\n",
      "iteration: 924 | loss: 0.885010\n",
      "  Train acc: 0.652, Val acc: 0.5\n",
      "iteration: 925 | loss: 1.030130\n",
      "iteration: 926 | loss: 1.135223\n",
      "iteration: 927 | loss: 0.968047\n",
      "iteration: 928 | loss: 1.069491\n",
      "iteration: 929 | loss: 0.872273\n",
      "iteration: 930 | loss: 0.934278\n",
      "iteration: 931 | loss: 1.258114\n",
      "iteration: 932 | loss: 0.749848\n",
      "iteration: 933 | loss: 0.635579\n",
      "iteration: 934 | loss: 1.194621\n",
      "iteration: 935 | loss: 1.009412\n",
      "iteration: 936 | loss: 0.905245\n",
      "iteration: 937 | loss: 0.843798\n",
      "iteration: 938 | loss: 1.046864\n",
      "iteration: 939 | loss: 0.959731\n",
      "iteration: 940 | loss: 0.506716\n",
      "iteration: 941 | loss: 1.059469\n",
      "iteration: 942 | loss: 1.286935\n",
      "iteration: 943 | loss: 1.046672\n",
      "iteration: 944 | loss: 0.892057\n",
      "iteration: 945 | loss: 1.149209\n",
      "iteration: 946 | loss: 0.741772\n",
      "iteration: 947 | loss: 1.503705\n",
      "iteration: 948 | loss: 0.881700\n",
      "iteration: 949 | loss: 1.132985\n",
      "  Train acc: 0.704, Val acc: 0.5\n",
      "iteration: 950 | loss: 0.778690\n",
      "iteration: 951 | loss: 0.870894\n",
      "iteration: 952 | loss: 0.758677\n",
      "iteration: 953 | loss: 1.200711\n",
      "iteration: 954 | loss: 1.171436\n",
      "iteration: 955 | loss: 0.921482\n",
      "iteration: 956 | loss: 0.764192\n",
      "iteration: 957 | loss: 0.888531\n",
      "iteration: 958 | loss: 0.832293\n",
      "iteration: 959 | loss: 0.985007\n",
      "iteration: 960 | loss: 0.913117\n",
      "iteration: 961 | loss: 1.332298\n",
      "iteration: 962 | loss: 0.834931\n",
      "iteration: 963 | loss: 1.059363\n",
      "iteration: 964 | loss: 0.927633\n",
      "iteration: 965 | loss: 0.853465\n",
      "iteration: 966 | loss: 0.773283\n",
      "iteration: 967 | loss: 0.721797\n",
      "iteration: 968 | loss: 0.975563\n",
      "iteration: 969 | loss: 1.269246\n",
      "iteration: 970 | loss: 1.123085\n",
      "iteration: 971 | loss: 0.935863\n",
      "iteration: 972 | loss: 1.012445\n",
      "iteration: 973 | loss: 1.228700\n",
      "iteration: 974 | loss: 1.208541\n",
      "  Train acc: 0.658, Val acc: 0.5\n",
      "iteration: 975 | loss: 0.592563\n",
      "iteration: 976 | loss: 1.205368\n",
      "iteration: 977 | loss: 1.003319\n",
      "iteration: 978 | loss: 0.707203\n",
      "iteration: 979 | loss: 1.002476\n",
      "iteration: 980 | loss: 1.109126\n",
      "iteration: 981 | loss: 0.803172\n",
      "iteration: 982 | loss: 0.620484\n",
      "iteration: 983 | loss: 0.984549\n",
      "iteration: 984 | loss: 0.883393\n",
      "iteration: 985 | loss: 0.510379\n",
      "iteration: 986 | loss: 0.947039\n",
      "iteration: 987 | loss: 0.879146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 988 | loss: 0.936944\n",
      "iteration: 989 | loss: 0.942437\n",
      "iteration: 990 | loss: 1.077495\n",
      "iteration: 991 | loss: 1.260037\n",
      "iteration: 992 | loss: 0.853808\n",
      "iteration: 993 | loss: 0.931240\n",
      "iteration: 994 | loss: 1.167646\n",
      "iteration: 995 | loss: 0.742802\n",
      "iteration: 996 | loss: 0.885945\n",
      "iteration: 997 | loss: 0.806535\n",
      "iteration: 998 | loss: 0.997101\n",
      "iteration: 999 | loss: 0.778178\n",
      "  Train acc: 0.726, Val acc: 0.5\n",
      "iteration: 1000 | loss: 1.007281\n",
      "iteration: 1001 | loss: 0.827744\n",
      "iteration: 1002 | loss: 0.711082\n",
      "iteration: 1003 | loss: 0.898480\n",
      "iteration: 1004 | loss: 0.959194\n",
      "iteration: 1005 | loss: 0.786676\n",
      "iteration: 1006 | loss: 0.844513\n",
      "iteration: 1007 | loss: 0.959847\n",
      "iteration: 1008 | loss: 0.970967\n",
      "iteration: 1009 | loss: 0.842137\n",
      "iteration: 1010 | loss: 0.773806\n",
      "iteration: 1011 | loss: 0.469796\n",
      "iteration: 1012 | loss: 0.768641\n",
      "iteration: 1013 | loss: 1.050184\n",
      "iteration: 1014 | loss: 0.715098\n",
      "iteration: 1015 | loss: 0.762993\n",
      "iteration: 1016 | loss: 1.048460\n",
      "iteration: 1017 | loss: 0.942704\n",
      "iteration: 1018 | loss: 0.681373\n",
      "iteration: 1019 | loss: 1.109359\n",
      "iteration: 1020 | loss: 0.582940\n",
      "iteration: 1021 | loss: 0.574180\n",
      "iteration: 1022 | loss: 0.684277\n",
      "iteration: 1023 | loss: 1.120871\n",
      "iteration: 1024 | loss: 0.697935\n",
      "  Train acc: 0.676, Val acc: 0.5\n",
      "iteration: 1025 | loss: 0.866477\n",
      "iteration: 1026 | loss: 0.661881\n",
      "iteration: 1027 | loss: 0.610045\n",
      "iteration: 1028 | loss: 0.792187\n",
      "iteration: 1029 | loss: 1.063670\n",
      "iteration: 1030 | loss: 0.929750\n",
      "iteration: 1031 | loss: 0.980826\n",
      "iteration: 1032 | loss: 0.590605\n",
      "iteration: 1033 | loss: 0.990463\n",
      "iteration: 1034 | loss: 1.117492\n",
      "iteration: 1035 | loss: 0.681466\n",
      "iteration: 1036 | loss: 1.242393\n",
      "iteration: 1037 | loss: 0.917156\n",
      "iteration: 1038 | loss: 1.171207\n",
      "iteration: 1039 | loss: 1.090811\n",
      "iteration: 1040 | loss: 1.270965\n",
      "iteration: 1041 | loss: 0.891357\n",
      "iteration: 1042 | loss: 0.948519\n",
      "iteration: 1043 | loss: 0.556588\n",
      "iteration: 1044 | loss: 0.655212\n",
      "iteration: 1045 | loss: 0.690935\n",
      "iteration: 1046 | loss: 1.254969\n",
      "iteration: 1047 | loss: 0.761657\n",
      "iteration: 1048 | loss: 0.589276\n",
      "iteration: 1049 | loss: 1.175793\n",
      "  Train acc: 0.696, Val acc: 0.5\n",
      "iteration: 1050 | loss: 0.597698\n",
      "iteration: 1051 | loss: 0.678129\n",
      "iteration: 1052 | loss: 0.573514\n",
      "iteration: 1053 | loss: 0.675322\n",
      "iteration: 1054 | loss: 0.833646\n",
      "iteration: 1055 | loss: 0.609958\n",
      "iteration: 1056 | loss: 0.865231\n",
      "iteration: 1057 | loss: 0.673225\n",
      "iteration: 1058 | loss: 1.130548\n",
      "iteration: 1059 | loss: 0.785193\n",
      "iteration: 1060 | loss: 0.686496\n",
      "iteration: 1061 | loss: 0.567832\n",
      "iteration: 1062 | loss: 0.531207\n",
      "iteration: 1063 | loss: 0.656347\n",
      "iteration: 1064 | loss: 0.879282\n",
      "iteration: 1065 | loss: 0.702723\n",
      "iteration: 1066 | loss: 0.808620\n",
      "iteration: 1067 | loss: 0.688107\n",
      "iteration: 1068 | loss: 0.834835\n",
      "iteration: 1069 | loss: 0.742858\n",
      "iteration: 1070 | loss: 0.672205\n",
      "iteration: 1071 | loss: 0.960145\n",
      "iteration: 1072 | loss: 1.331205\n",
      "iteration: 1073 | loss: 0.815120\n",
      "iteration: 1074 | loss: 0.944645\n",
      "  Train acc: 0.7, Val acc: 0.5\n",
      "iteration: 1075 | loss: 1.142816\n",
      "iteration: 1076 | loss: 0.907911\n",
      "iteration: 1077 | loss: 1.137338\n",
      "iteration: 1078 | loss: 0.782290\n",
      "iteration: 1079 | loss: 0.677656\n",
      "iteration: 1080 | loss: 0.913911\n",
      "iteration: 1081 | loss: 1.108700\n",
      "iteration: 1082 | loss: 0.773217\n",
      "iteration: 1083 | loss: 0.732343\n",
      "iteration: 1084 | loss: 0.968266\n",
      "iteration: 1085 | loss: 0.955666\n",
      "iteration: 1086 | loss: 0.863977\n",
      "iteration: 1087 | loss: 0.536739\n",
      "iteration: 1088 | loss: 0.710747\n",
      "iteration: 1089 | loss: 0.939773\n",
      "iteration: 1090 | loss: 0.634877\n",
      "iteration: 1091 | loss: 0.631378\n",
      "iteration: 1092 | loss: 0.850314\n",
      "iteration: 1093 | loss: 1.140239\n",
      "iteration: 1094 | loss: 0.499924\n",
      "iteration: 1095 | loss: 0.704832\n",
      "iteration: 1096 | loss: 1.088138\n",
      "iteration: 1097 | loss: 0.758682\n",
      "iteration: 1098 | loss: 0.691994\n",
      "iteration: 1099 | loss: 0.536697\n",
      "  Train acc: 0.754, Val acc: 0.5\n",
      "iteration: 1100 | loss: 0.852540\n",
      "iteration: 1101 | loss: 0.623262\n",
      "iteration: 1102 | loss: 0.878833\n",
      "iteration: 1103 | loss: 0.830481\n",
      "iteration: 1104 | loss: 0.806937\n",
      "iteration: 1105 | loss: 0.697744\n",
      "iteration: 1106 | loss: 0.884592\n",
      "iteration: 1107 | loss: 1.064119\n",
      "iteration: 1108 | loss: 0.895936\n",
      "iteration: 1109 | loss: 0.758778\n",
      "iteration: 1110 | loss: 0.925946\n",
      "iteration: 1111 | loss: 0.529374\n",
      "iteration: 1112 | loss: 0.653230\n",
      "iteration: 1113 | loss: 0.925982\n",
      "iteration: 1114 | loss: 0.862412\n",
      "iteration: 1115 | loss: 0.820885\n",
      "iteration: 1116 | loss: 0.576438\n",
      "iteration: 1117 | loss: 1.543845\n",
      "iteration: 1118 | loss: 0.628584\n",
      "iteration: 1119 | loss: 0.897758\n",
      "iteration: 1120 | loss: 0.722698\n",
      "iteration: 1121 | loss: 0.655988\n",
      "iteration: 1122 | loss: 0.560519\n",
      "iteration: 1123 | loss: 0.909822\n",
      "iteration: 1124 | loss: 0.809572\n",
      "  Train acc: 0.744, Val acc: 0.5\n",
      "iteration: 1125 | loss: 1.038660\n",
      "iteration: 1126 | loss: 0.921788\n",
      "iteration: 1127 | loss: 0.789126\n",
      "iteration: 1128 | loss: 0.566774\n",
      "iteration: 1129 | loss: 0.693527\n",
      "iteration: 1130 | loss: 0.688769\n",
      "iteration: 1131 | loss: 0.656744\n",
      "iteration: 1132 | loss: 0.815644\n",
      "iteration: 1133 | loss: 0.809027\n",
      "iteration: 1134 | loss: 0.399343\n",
      "iteration: 1135 | loss: 0.891819\n",
      "iteration: 1136 | loss: 0.696695\n",
      "iteration: 1137 | loss: 0.745922\n",
      "iteration: 1138 | loss: 0.468485\n",
      "iteration: 1139 | loss: 0.436630\n",
      "iteration: 1140 | loss: 0.880256\n",
      "iteration: 1141 | loss: 0.885538\n",
      "iteration: 1142 | loss: 0.656683\n",
      "iteration: 1143 | loss: 0.602457\n",
      "iteration: 1144 | loss: 0.750494\n",
      "iteration: 1145 | loss: 0.786082\n",
      "iteration: 1146 | loss: 0.491442\n",
      "iteration: 1147 | loss: 0.606845\n",
      "iteration: 1148 | loss: 0.689815\n",
      "iteration: 1149 | loss: 1.130831\n",
      "  Train acc: 0.72, Val acc: 0.5\n",
      "iteration: 1150 | loss: 0.905332\n",
      "iteration: 1151 | loss: 1.277731\n",
      "iteration: 1152 | loss: 0.710580\n",
      "iteration: 1153 | loss: 0.720433\n",
      "iteration: 1154 | loss: 0.450300\n",
      "iteration: 1155 | loss: 0.899996\n",
      "iteration: 1156 | loss: 0.729860\n",
      "iteration: 1157 | loss: 0.581488\n",
      "iteration: 1158 | loss: 0.997514\n",
      "iteration: 1159 | loss: 0.999694\n",
      "iteration: 1160 | loss: 0.828025\n",
      "iteration: 1161 | loss: 0.725966\n",
      "iteration: 1162 | loss: 0.949051\n",
      "iteration: 1163 | loss: 0.777878\n",
      "iteration: 1164 | loss: 0.837758\n",
      "iteration: 1165 | loss: 0.879080\n",
      "iteration: 1166 | loss: 0.911719\n",
      "iteration: 1167 | loss: 0.730606\n",
      "iteration: 1168 | loss: 0.618274\n",
      "iteration: 1169 | loss: 1.047969\n",
      "iteration: 1170 | loss: 0.929004\n",
      "iteration: 1171 | loss: 0.868189\n",
      "iteration: 1172 | loss: 0.930676\n",
      "iteration: 1173 | loss: 0.568449\n",
      "iteration: 1174 | loss: 0.686937\n",
      "  Train acc: 0.752, Val acc: 0.5\n",
      "iteration: 1175 | loss: 0.605723\n",
      "iteration: 1176 | loss: 0.758774\n",
      "iteration: 1177 | loss: 0.705676\n",
      "iteration: 1178 | loss: 0.602049\n",
      "iteration: 1179 | loss: 0.506225\n",
      "iteration: 1180 | loss: 0.866411\n",
      "iteration: 1181 | loss: 0.857526\n",
      "iteration: 1182 | loss: 0.728350\n",
      "iteration: 1183 | loss: 0.650438\n",
      "iteration: 1184 | loss: 0.883693\n",
      "iteration: 1185 | loss: 0.741047\n",
      "iteration: 1186 | loss: 0.809087\n",
      "iteration: 1187 | loss: 0.717365\n",
      "iteration: 1188 | loss: 0.878147\n",
      "iteration: 1189 | loss: 0.692014\n",
      "iteration: 1190 | loss: 0.578134\n",
      "iteration: 1191 | loss: 0.864047\n",
      "iteration: 1192 | loss: 0.577570\n",
      "iteration: 1193 | loss: 0.774304\n",
      "iteration: 1194 | loss: 0.841007\n",
      "iteration: 1195 | loss: 0.542351\n",
      "iteration: 1196 | loss: 0.385548\n",
      "iteration: 1197 | loss: 0.393944\n",
      "iteration: 1198 | loss: 0.728708\n",
      "iteration: 1199 | loss: 0.623604\n",
      "  Train acc: 0.782, Val acc: 0.5\n",
      "iteration: 1200 | loss: 0.795171\n",
      "iteration: 1201 | loss: 0.554851\n",
      "iteration: 1202 | loss: 0.981965\n",
      "iteration: 1203 | loss: 0.713008\n",
      "iteration: 1204 | loss: 0.553702\n",
      "iteration: 1205 | loss: 0.832280\n",
      "iteration: 1206 | loss: 0.779471\n",
      "iteration: 1207 | loss: 1.041203\n",
      "iteration: 1208 | loss: 0.286051\n",
      "iteration: 1209 | loss: 0.719379\n",
      "iteration: 1210 | loss: 1.309620\n",
      "iteration: 1211 | loss: 1.050327\n",
      "iteration: 1212 | loss: 1.118271\n",
      "iteration: 1213 | loss: 0.808334\n",
      "iteration: 1214 | loss: 0.659693\n",
      "iteration: 1215 | loss: 1.004591\n",
      "iteration: 1216 | loss: 0.708532\n",
      "iteration: 1217 | loss: 0.576177\n",
      "iteration: 1218 | loss: 0.574950\n",
      "iteration: 1219 | loss: 0.485526\n",
      "iteration: 1220 | loss: 1.069853\n",
      "iteration: 1221 | loss: 0.902945\n",
      "iteration: 1222 | loss: 0.678603\n",
      "iteration: 1223 | loss: 0.624349\n",
      "iteration: 1224 | loss: 0.802501\n",
      "  Train acc: 0.76, Val acc: 0.5\n",
      "iteration: 1225 | loss: 1.021407\n",
      "iteration: 1226 | loss: 0.503817\n",
      "iteration: 1227 | loss: 0.763422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1228 | loss: 0.988935\n",
      "iteration: 1229 | loss: 0.628421\n",
      "iteration: 1230 | loss: 0.691932\n",
      "iteration: 1231 | loss: 0.836234\n",
      "iteration: 1232 | loss: 0.965088\n",
      "iteration: 1233 | loss: 0.727063\n",
      "iteration: 1234 | loss: 0.644635\n",
      "iteration: 1235 | loss: 1.210183\n",
      "iteration: 1236 | loss: 0.718809\n",
      "iteration: 1237 | loss: 0.428774\n",
      "iteration: 1238 | loss: 0.690483\n",
      "iteration: 1239 | loss: 0.527302\n",
      "iteration: 1240 | loss: 0.547538\n",
      "iteration: 1241 | loss: 0.552907\n",
      "iteration: 1242 | loss: 0.544127\n",
      "iteration: 1243 | loss: 0.781303\n",
      "iteration: 1244 | loss: 0.688110\n",
      "iteration: 1245 | loss: 0.642501\n",
      "iteration: 1246 | loss: 0.646476\n",
      "iteration: 1247 | loss: 1.134673\n",
      "iteration: 1248 | loss: 0.742243\n",
      "iteration: 1249 | loss: 0.508318\n",
      "  Train acc: 0.728, Val acc: 0.5\n",
      "iteration: 1250 | loss: 0.587232\n",
      "iteration: 1251 | loss: 1.050467\n",
      "iteration: 1252 | loss: 0.778600\n",
      "iteration: 1253 | loss: 0.713468\n",
      "iteration: 1254 | loss: 0.954471\n",
      "iteration: 1255 | loss: 0.516102\n",
      "iteration: 1256 | loss: 0.571109\n",
      "iteration: 1257 | loss: 1.025377\n",
      "iteration: 1258 | loss: 0.447446\n",
      "iteration: 1259 | loss: 0.912287\n",
      "iteration: 1260 | loss: 0.908201\n",
      "iteration: 1261 | loss: 0.523853\n",
      "iteration: 1262 | loss: 0.405189\n",
      "iteration: 1263 | loss: 0.700060\n",
      "iteration: 1264 | loss: 0.598008\n",
      "iteration: 1265 | loss: 0.522622\n",
      "iteration: 1266 | loss: 0.753239\n",
      "iteration: 1267 | loss: 1.007423\n",
      "iteration: 1268 | loss: 0.768599\n",
      "iteration: 1269 | loss: 0.704157\n",
      "iteration: 1270 | loss: 0.850071\n",
      "iteration: 1271 | loss: 1.260873\n",
      "iteration: 1272 | loss: 0.642988\n",
      "iteration: 1273 | loss: 0.681296\n",
      "iteration: 1274 | loss: 0.743464\n",
      "  Train acc: 0.724, Val acc: 0.5\n",
      "iteration: 1275 | loss: 0.436645\n",
      "iteration: 1276 | loss: 0.321798\n",
      "iteration: 1277 | loss: 0.957352\n",
      "iteration: 1278 | loss: 1.013793\n",
      "iteration: 1279 | loss: 0.581882\n",
      "iteration: 1280 | loss: 0.823694\n",
      "iteration: 1281 | loss: 0.630990\n",
      "iteration: 1282 | loss: 0.818237\n",
      "iteration: 1283 | loss: 1.075200\n",
      "iteration: 1284 | loss: 0.628217\n",
      "iteration: 1285 | loss: 0.543746\n",
      "iteration: 1286 | loss: 0.680057\n",
      "iteration: 1287 | loss: 0.703864\n",
      "iteration: 1288 | loss: 0.678018\n",
      "iteration: 1289 | loss: 0.794522\n",
      "iteration: 1290 | loss: 0.822840\n",
      "iteration: 1291 | loss: 0.695130\n",
      "iteration: 1292 | loss: 0.395427\n",
      "iteration: 1293 | loss: 0.694133\n",
      "iteration: 1294 | loss: 0.680801\n",
      "iteration: 1295 | loss: 0.564139\n",
      "iteration: 1296 | loss: 0.630344\n",
      "iteration: 1297 | loss: 0.436079\n",
      "iteration: 1298 | loss: 0.792091\n",
      "iteration: 1299 | loss: 0.907494\n",
      "  Train acc: 0.748, Val acc: 0.5\n",
      "iteration: 1300 | loss: 0.492378\n",
      "iteration: 1301 | loss: 0.780262\n",
      "iteration: 1302 | loss: 0.736595\n",
      "iteration: 1303 | loss: 0.435521\n",
      "iteration: 1304 | loss: 0.640004\n",
      "iteration: 1305 | loss: 0.510199\n",
      "iteration: 1306 | loss: 0.448841\n",
      "iteration: 1307 | loss: 0.516828\n",
      "iteration: 1308 | loss: 0.859015\n",
      "iteration: 1309 | loss: 0.945910\n",
      "iteration: 1310 | loss: 1.063861\n",
      "iteration: 1311 | loss: 0.675454\n",
      "iteration: 1312 | loss: 0.782907\n",
      "iteration: 1313 | loss: 0.746899\n",
      "iteration: 1314 | loss: 0.858028\n",
      "iteration: 1315 | loss: 0.860466\n",
      "iteration: 1316 | loss: 0.575103\n",
      "iteration: 1317 | loss: 0.621671\n",
      "iteration: 1318 | loss: 0.567782\n",
      "iteration: 1319 | loss: 0.562814\n",
      "iteration: 1320 | loss: 0.550318\n",
      "iteration: 1321 | loss: 0.496550\n",
      "iteration: 1322 | loss: 0.622374\n",
      "iteration: 1323 | loss: 0.597186\n",
      "iteration: 1324 | loss: 0.523849\n",
      "  Train acc: 0.778, Val acc: 0.5\n",
      "iteration: 1325 | loss: 0.493559\n",
      "iteration: 1326 | loss: 0.695737\n",
      "iteration: 1327 | loss: 0.576702\n",
      "iteration: 1328 | loss: 0.976704\n",
      "iteration: 1329 | loss: 0.481283\n",
      "iteration: 1330 | loss: 0.629877\n",
      "iteration: 1331 | loss: 0.571331\n",
      "iteration: 1332 | loss: 0.674342\n",
      "iteration: 1333 | loss: 0.913971\n",
      "iteration: 1334 | loss: 0.504233\n",
      "iteration: 1335 | loss: 0.856004\n",
      "iteration: 1336 | loss: 0.896576\n",
      "iteration: 1337 | loss: 0.465383\n",
      "iteration: 1338 | loss: 0.405848\n",
      "iteration: 1339 | loss: 0.592909\n",
      "iteration: 1340 | loss: 0.693292\n",
      "iteration: 1341 | loss: 0.884911\n",
      "iteration: 1342 | loss: 0.859509\n",
      "iteration: 1343 | loss: 0.462923\n",
      "iteration: 1344 | loss: 0.551646\n",
      "iteration: 1345 | loss: 1.056699\n",
      "iteration: 1346 | loss: 0.544834\n",
      "iteration: 1347 | loss: 0.389641\n",
      "iteration: 1348 | loss: 0.631299\n",
      "iteration: 1349 | loss: 0.840420\n",
      "  Train acc: 0.744, Val acc: 0.5\n",
      "iteration: 1350 | loss: 0.646958\n",
      "iteration: 1351 | loss: 0.682966\n",
      "iteration: 1352 | loss: 0.486831\n",
      "iteration: 1353 | loss: 0.934534\n",
      "iteration: 1354 | loss: 0.841162\n",
      "iteration: 1355 | loss: 0.840748\n",
      "iteration: 1356 | loss: 0.728231\n",
      "iteration: 1357 | loss: 0.343616\n",
      "iteration: 1358 | loss: 0.764077\n",
      "iteration: 1359 | loss: 0.671090\n",
      "iteration: 1360 | loss: 0.638987\n",
      "iteration: 1361 | loss: 0.398315\n",
      "iteration: 1362 | loss: 0.512844\n",
      "iteration: 1363 | loss: 0.422265\n",
      "iteration: 1364 | loss: 1.038162\n",
      "iteration: 1365 | loss: 0.564641\n",
      "iteration: 1366 | loss: 0.595222\n",
      "iteration: 1367 | loss: 0.657840\n",
      "iteration: 1368 | loss: 0.648061\n",
      "iteration: 1369 | loss: 0.741112\n",
      "iteration: 1370 | loss: 0.402696\n",
      "iteration: 1371 | loss: 0.479322\n",
      "iteration: 1372 | loss: 0.757115\n",
      "iteration: 1373 | loss: 0.662977\n",
      "iteration: 1374 | loss: 0.534220\n",
      "  Train acc: 0.782, Val acc: 0.5\n",
      "iteration: 1375 | loss: 0.446128\n",
      "iteration: 1376 | loss: 0.691380\n",
      "iteration: 1377 | loss: 0.947132\n",
      "iteration: 1378 | loss: 0.509005\n",
      "iteration: 1379 | loss: 0.663105\n",
      "iteration: 1380 | loss: 0.508816\n",
      "iteration: 1381 | loss: 0.751982\n",
      "iteration: 1382 | loss: 0.937459\n",
      "iteration: 1383 | loss: 0.674046\n",
      "iteration: 1384 | loss: 0.995458\n",
      "iteration: 1385 | loss: 0.667529\n",
      "iteration: 1386 | loss: 0.713309\n",
      "iteration: 1387 | loss: 0.600975\n",
      "iteration: 1388 | loss: 0.709555\n",
      "iteration: 1389 | loss: 0.449020\n",
      "iteration: 1390 | loss: 0.493897\n",
      "iteration: 1391 | loss: 0.726501\n",
      "iteration: 1392 | loss: 0.619842\n",
      "iteration: 1393 | loss: 0.675908\n",
      "iteration: 1394 | loss: 0.474190\n",
      "iteration: 1395 | loss: 1.023464\n",
      "iteration: 1396 | loss: 0.596488\n",
      "iteration: 1397 | loss: 0.705335\n",
      "iteration: 1398 | loss: 0.626086\n",
      "iteration: 1399 | loss: 0.476971\n",
      "  Train acc: 0.814, Val acc: 0.5\n",
      "iteration: 1400 | loss: 0.463792\n",
      "iteration: 1401 | loss: 0.473525\n",
      "iteration: 1402 | loss: 0.700836\n",
      "iteration: 1403 | loss: 0.357772\n",
      "iteration: 1404 | loss: 0.460258\n",
      "iteration: 1405 | loss: 0.708801\n",
      "iteration: 1406 | loss: 0.386963\n",
      "iteration: 1407 | loss: 0.568642\n",
      "iteration: 1408 | loss: 0.943798\n",
      "iteration: 1409 | loss: 0.343588\n",
      "iteration: 1410 | loss: 0.814343\n",
      "iteration: 1411 | loss: 0.581836\n",
      "iteration: 1412 | loss: 0.346815\n",
      "iteration: 1413 | loss: 0.623315\n",
      "iteration: 1414 | loss: 0.402616\n",
      "iteration: 1415 | loss: 0.933199\n",
      "iteration: 1416 | loss: 0.499215\n",
      "iteration: 1417 | loss: 0.500648\n",
      "iteration: 1418 | loss: 0.375829\n",
      "iteration: 1419 | loss: 0.309931\n",
      "iteration: 1420 | loss: 0.775632\n",
      "iteration: 1421 | loss: 0.309769\n",
      "iteration: 1422 | loss: 0.665846\n",
      "iteration: 1423 | loss: 0.623893\n",
      "iteration: 1424 | loss: 0.678880\n",
      "  Train acc: 0.762, Val acc: 0.5\n",
      "iteration: 1425 | loss: 0.396577\n",
      "iteration: 1426 | loss: 0.700952\n",
      "iteration: 1427 | loss: 0.507940\n",
      "iteration: 1428 | loss: 0.399590\n",
      "iteration: 1429 | loss: 0.580407\n",
      "iteration: 1430 | loss: 0.606239\n",
      "iteration: 1431 | loss: 0.649875\n",
      "iteration: 1432 | loss: 0.707572\n",
      "iteration: 1433 | loss: 0.792357\n",
      "iteration: 1434 | loss: 0.438991\n",
      "iteration: 1435 | loss: 0.474644\n",
      "iteration: 1436 | loss: 0.665684\n",
      "iteration: 1437 | loss: 0.878547\n",
      "iteration: 1438 | loss: 0.754536\n",
      "iteration: 1439 | loss: 0.457371\n",
      "iteration: 1440 | loss: 0.269151\n",
      "iteration: 1441 | loss: 0.795218\n",
      "iteration: 1442 | loss: 0.938004\n",
      "iteration: 1443 | loss: 0.820829\n",
      "iteration: 1444 | loss: 0.464221\n",
      "iteration: 1445 | loss: 0.425444\n",
      "iteration: 1446 | loss: 0.463480\n",
      "iteration: 1447 | loss: 0.454480\n",
      "iteration: 1448 | loss: 0.631036\n",
      "iteration: 1449 | loss: 0.476626\n",
      "  Train acc: 0.742, Val acc: 0.5\n",
      "iteration: 1450 | loss: 0.571393\n",
      "iteration: 1451 | loss: 0.784147\n",
      "iteration: 1452 | loss: 0.818541\n",
      "iteration: 1453 | loss: 0.586746\n",
      "iteration: 1454 | loss: 0.900165\n",
      "iteration: 1455 | loss: 0.609651\n",
      "iteration: 1456 | loss: 0.915103\n",
      "iteration: 1457 | loss: 0.620439\n",
      "iteration: 1458 | loss: 0.567570\n",
      "iteration: 1459 | loss: 0.671865\n",
      "iteration: 1460 | loss: 0.316903\n",
      "iteration: 1461 | loss: 0.669191\n",
      "iteration: 1462 | loss: 0.541416\n",
      "iteration: 1463 | loss: 0.774697\n",
      "iteration: 1464 | loss: 0.830383\n",
      "iteration: 1465 | loss: 0.947954\n",
      "iteration: 1466 | loss: 0.583442\n",
      "iteration: 1467 | loss: 0.816254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1468 | loss: 0.346263\n",
      "iteration: 1469 | loss: 0.341340\n",
      "iteration: 1470 | loss: 0.479399\n",
      "iteration: 1471 | loss: 0.663805\n",
      "iteration: 1472 | loss: 0.726460\n",
      "iteration: 1473 | loss: 0.708867\n",
      "iteration: 1474 | loss: 0.365203\n",
      "  Train acc: 0.802, Val acc: 0.5\n",
      "iteration: 1475 | loss: 0.514421\n",
      "iteration: 1476 | loss: 0.492211\n",
      "iteration: 1477 | loss: 0.728714\n",
      "iteration: 1478 | loss: 0.509018\n",
      "iteration: 1479 | loss: 0.903979\n",
      "iteration: 1480 | loss: 0.487441\n",
      "iteration: 1481 | loss: 0.660285\n",
      "iteration: 1482 | loss: 0.774852\n",
      "iteration: 1483 | loss: 0.389592\n",
      "iteration: 1484 | loss: 0.601450\n",
      "iteration: 1485 | loss: 0.477996\n",
      "iteration: 1486 | loss: 0.557218\n",
      "iteration: 1487 | loss: 0.686689\n",
      "iteration: 1488 | loss: 0.404810\n",
      "iteration: 1489 | loss: 0.620555\n",
      "iteration: 1490 | loss: 0.779211\n",
      "iteration: 1491 | loss: 0.611229\n",
      "iteration: 1492 | loss: 0.554641\n",
      "iteration: 1493 | loss: 0.823750\n",
      "iteration: 1494 | loss: 0.568021\n",
      "iteration: 1495 | loss: 0.620931\n",
      "iteration: 1496 | loss: 0.346586\n",
      "iteration: 1497 | loss: 0.761524\n",
      "iteration: 1498 | loss: 0.564842\n",
      "iteration: 1499 | loss: 0.511736\n",
      "  Train acc: 0.828, Val acc: 0.5\n",
      "iteration: 1500 | loss: 0.826056\n",
      "iteration: 1501 | loss: 0.446745\n",
      "iteration: 1502 | loss: 0.515966\n",
      "iteration: 1503 | loss: 0.532579\n",
      "iteration: 1504 | loss: 0.301512\n",
      "iteration: 1505 | loss: 0.369085\n",
      "iteration: 1506 | loss: 0.492150\n",
      "iteration: 1507 | loss: 0.498390\n",
      "iteration: 1508 | loss: 0.697927\n",
      "iteration: 1509 | loss: 0.317200\n",
      "iteration: 1510 | loss: 0.486293\n",
      "iteration: 1511 | loss: 0.579735\n",
      "iteration: 1512 | loss: 0.798656\n",
      "iteration: 1513 | loss: 0.657258\n",
      "iteration: 1514 | loss: 0.338127\n",
      "iteration: 1515 | loss: 0.344110\n",
      "iteration: 1516 | loss: 0.400614\n",
      "iteration: 1517 | loss: 0.403053\n",
      "iteration: 1518 | loss: 0.247650\n",
      "iteration: 1519 | loss: 0.845396\n",
      "iteration: 1520 | loss: 0.808833\n",
      "iteration: 1521 | loss: 0.491461\n",
      "iteration: 1522 | loss: 0.452491\n",
      "iteration: 1523 | loss: 0.700919\n",
      "iteration: 1524 | loss: 0.522094\n",
      "  Train acc: 0.816, Val acc: 0.5\n",
      "iteration: 1525 | loss: 0.240945\n",
      "iteration: 1526 | loss: 0.769455\n",
      "iteration: 1527 | loss: 0.679911\n",
      "iteration: 1528 | loss: 0.498180\n",
      "iteration: 1529 | loss: 0.476145\n",
      "iteration: 1530 | loss: 0.772508\n",
      "iteration: 1531 | loss: 0.970793\n",
      "iteration: 1532 | loss: 0.774241\n",
      "iteration: 1533 | loss: 0.473513\n",
      "iteration: 1534 | loss: 0.683766\n",
      "iteration: 1535 | loss: 0.551863\n",
      "iteration: 1536 | loss: 0.546709\n",
      "iteration: 1537 | loss: 0.494899\n",
      "iteration: 1538 | loss: 0.419475\n",
      "iteration: 1539 | loss: 0.528086\n",
      "iteration: 1540 | loss: 0.389507\n",
      "iteration: 1541 | loss: 0.565777\n",
      "iteration: 1542 | loss: 0.711851\n",
      "iteration: 1543 | loss: 0.551060\n",
      "iteration: 1544 | loss: 0.405941\n",
      "iteration: 1545 | loss: 0.348372\n",
      "iteration: 1546 | loss: 0.340921\n",
      "iteration: 1547 | loss: 0.518596\n",
      "iteration: 1548 | loss: 0.646895\n",
      "iteration: 1549 | loss: 0.416637\n",
      "  Train acc: 0.798, Val acc: 0.5\n",
      "iteration: 1550 | loss: 0.828300\n",
      "iteration: 1551 | loss: 0.541747\n",
      "iteration: 1552 | loss: 0.268715\n",
      "iteration: 1553 | loss: 0.290736\n",
      "iteration: 1554 | loss: 0.557119\n",
      "iteration: 1555 | loss: 0.649935\n",
      "iteration: 1556 | loss: 0.483463\n",
      "iteration: 1557 | loss: 0.513343\n",
      "iteration: 1558 | loss: 0.350761\n",
      "iteration: 1559 | loss: 0.545120\n",
      "iteration: 1560 | loss: 0.329958\n",
      "iteration: 1561 | loss: 0.361792\n",
      "iteration: 1562 | loss: 0.334702\n",
      "iteration: 1563 | loss: 0.559508\n",
      "iteration: 1564 | loss: 0.337754\n",
      "iteration: 1565 | loss: 0.459569\n",
      "iteration: 1566 | loss: 0.363896\n",
      "iteration: 1567 | loss: 0.352674\n",
      "iteration: 1568 | loss: 0.916738\n",
      "iteration: 1569 | loss: 0.504754\n",
      "iteration: 1570 | loss: 0.639037\n",
      "iteration: 1571 | loss: 0.557672\n",
      "iteration: 1572 | loss: 0.412628\n",
      "iteration: 1573 | loss: 0.530410\n",
      "iteration: 1574 | loss: 0.566509\n",
      "  Train acc: 0.828, Val acc: 0.5\n",
      "iteration: 1575 | loss: 0.571996\n",
      "iteration: 1576 | loss: 0.325168\n",
      "iteration: 1577 | loss: 0.199325\n",
      "iteration: 1578 | loss: 0.293001\n",
      "iteration: 1579 | loss: 0.326617\n",
      "iteration: 1580 | loss: 0.345220\n",
      "iteration: 1581 | loss: 0.507448\n",
      "iteration: 1582 | loss: 0.832830\n",
      "iteration: 1583 | loss: 0.315094\n",
      "iteration: 1584 | loss: 0.558648\n",
      "iteration: 1585 | loss: 0.749111\n",
      "iteration: 1586 | loss: 0.667116\n",
      "iteration: 1587 | loss: 0.560953\n",
      "iteration: 1588 | loss: 0.743073\n",
      "iteration: 1589 | loss: 0.587413\n",
      "iteration: 1590 | loss: 0.665177\n",
      "iteration: 1591 | loss: 0.779624\n",
      "iteration: 1592 | loss: 0.237937\n",
      "iteration: 1593 | loss: 0.345008\n",
      "iteration: 1594 | loss: 0.412227\n",
      "iteration: 1595 | loss: 0.507829\n",
      "iteration: 1596 | loss: 0.536578\n",
      "iteration: 1597 | loss: 0.247443\n",
      "iteration: 1598 | loss: 0.723351\n",
      "iteration: 1599 | loss: 0.417379\n",
      "  Train acc: 0.852, Val acc: 0.5\n",
      "iteration: 1600 | loss: 0.278971\n",
      "iteration: 1601 | loss: 0.551746\n",
      "iteration: 1602 | loss: 0.474525\n",
      "iteration: 1603 | loss: 0.244527\n",
      "iteration: 1604 | loss: 0.545361\n",
      "iteration: 1605 | loss: 0.499141\n",
      "iteration: 1606 | loss: 0.694533\n",
      "iteration: 1607 | loss: 0.686405\n",
      "iteration: 1608 | loss: 0.425024\n",
      "iteration: 1609 | loss: 0.401017\n",
      "iteration: 1610 | loss: 0.203579\n",
      "iteration: 1611 | loss: 0.463637\n",
      "iteration: 1612 | loss: 0.401050\n",
      "iteration: 1613 | loss: 0.910052\n",
      "iteration: 1614 | loss: 0.572312\n",
      "iteration: 1615 | loss: 0.346684\n",
      "iteration: 1616 | loss: 0.635102\n",
      "iteration: 1617 | loss: 0.335355\n",
      "iteration: 1618 | loss: 0.733730\n",
      "iteration: 1619 | loss: 0.182915\n",
      "iteration: 1620 | loss: 0.729861\n",
      "iteration: 1621 | loss: 0.414018\n",
      "iteration: 1622 | loss: 0.524520\n",
      "iteration: 1623 | loss: 0.276104\n",
      "iteration: 1624 | loss: 0.740952\n",
      "  Train acc: 0.816, Val acc: 0.5\n",
      "iteration: 1625 | loss: 0.267233\n",
      "iteration: 1626 | loss: 0.609375\n",
      "iteration: 1627 | loss: 0.287195\n",
      "iteration: 1628 | loss: 0.309761\n",
      "iteration: 1629 | loss: 0.690366\n",
      "iteration: 1630 | loss: 0.211352\n",
      "iteration: 1631 | loss: 0.287553\n",
      "iteration: 1632 | loss: 0.426237\n",
      "iteration: 1633 | loss: 0.316450\n",
      "iteration: 1634 | loss: 0.570800\n",
      "iteration: 1635 | loss: 0.454745\n",
      "iteration: 1636 | loss: 0.373256\n",
      "iteration: 1637 | loss: 0.628835\n",
      "iteration: 1638 | loss: 0.819656\n",
      "iteration: 1639 | loss: 0.397450\n",
      "iteration: 1640 | loss: 0.239035\n",
      "iteration: 1641 | loss: 0.331871\n",
      "iteration: 1642 | loss: 0.389231\n",
      "iteration: 1643 | loss: 0.229334\n",
      "iteration: 1644 | loss: 0.551267\n",
      "iteration: 1645 | loss: 0.764558\n",
      "iteration: 1646 | loss: 0.438596\n",
      "iteration: 1647 | loss: 0.350594\n",
      "iteration: 1648 | loss: 0.543481\n",
      "iteration: 1649 | loss: 0.326907\n",
      "  Train acc: 0.874, Val acc: 0.5\n",
      "iteration: 1650 | loss: 0.412002\n",
      "iteration: 1651 | loss: 0.320559\n",
      "iteration: 1652 | loss: 0.445827\n",
      "iteration: 1653 | loss: 0.315125\n",
      "iteration: 1654 | loss: 0.636892\n",
      "iteration: 1655 | loss: 0.375798\n",
      "iteration: 1656 | loss: 0.412447\n",
      "iteration: 1657 | loss: 0.539784\n",
      "iteration: 1658 | loss: 0.479877\n",
      "iteration: 1659 | loss: 0.325302\n",
      "iteration: 1660 | loss: 0.494092\n",
      "iteration: 1661 | loss: 0.574052\n",
      "iteration: 1662 | loss: 0.289833\n",
      "iteration: 1663 | loss: 0.699066\n",
      "iteration: 1664 | loss: 0.801868\n",
      "iteration: 1665 | loss: 0.334131\n",
      "iteration: 1666 | loss: 0.387946\n",
      "iteration: 1667 | loss: 0.516782\n",
      "iteration: 1668 | loss: 0.480904\n",
      "iteration: 1669 | loss: 0.594724\n",
      "iteration: 1670 | loss: 0.401707\n",
      "iteration: 1671 | loss: 0.715832\n",
      "iteration: 1672 | loss: 0.432777\n",
      "iteration: 1673 | loss: 0.393223\n",
      "iteration: 1674 | loss: 0.316496\n",
      "  Train acc: 0.882, Val acc: 0.5\n",
      "iteration: 1675 | loss: 0.368265\n",
      "iteration: 1676 | loss: 0.701482\n",
      "iteration: 1677 | loss: 0.205426\n",
      "iteration: 1678 | loss: 0.460210\n",
      "iteration: 1679 | loss: 0.491149\n",
      "iteration: 1680 | loss: 0.205422\n",
      "iteration: 1681 | loss: 0.233960\n",
      "iteration: 1682 | loss: 0.301906\n",
      "iteration: 1683 | loss: 0.421403\n",
      "iteration: 1684 | loss: 0.289865\n",
      "iteration: 1685 | loss: 0.659378\n",
      "iteration: 1686 | loss: 0.336748\n",
      "iteration: 1687 | loss: 0.405831\n",
      "iteration: 1688 | loss: 0.098707\n",
      "iteration: 1689 | loss: 0.227872\n",
      "iteration: 1690 | loss: 0.155990\n",
      "iteration: 1691 | loss: 0.407156\n",
      "iteration: 1692 | loss: 0.328919\n",
      "iteration: 1693 | loss: 0.545645\n",
      "iteration: 1694 | loss: 0.526509\n",
      "iteration: 1695 | loss: 0.295999\n",
      "iteration: 1696 | loss: 0.535000\n",
      "iteration: 1697 | loss: 0.489937\n",
      "iteration: 1698 | loss: 0.300921\n",
      "iteration: 1699 | loss: 0.481221\n",
      "  Train acc: 0.81, Val acc: 0.5\n",
      "iteration: 1700 | loss: 0.470380\n",
      "iteration: 1701 | loss: 0.260871\n",
      "iteration: 1702 | loss: 0.528413\n",
      "iteration: 1703 | loss: 0.785893\n",
      "iteration: 1704 | loss: 0.525102\n",
      "iteration: 1705 | loss: 0.442753\n",
      "iteration: 1706 | loss: 0.517946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1707 | loss: 0.312239\n",
      "iteration: 1708 | loss: 0.294601\n",
      "iteration: 1709 | loss: 0.325740\n",
      "iteration: 1710 | loss: 0.623870\n",
      "iteration: 1711 | loss: 0.475960\n",
      "iteration: 1712 | loss: 0.458220\n",
      "iteration: 1713 | loss: 0.565421\n",
      "iteration: 1714 | loss: 0.395328\n",
      "iteration: 1715 | loss: 0.400206\n",
      "iteration: 1716 | loss: 0.339073\n",
      "iteration: 1717 | loss: 0.407317\n",
      "iteration: 1718 | loss: 0.637007\n",
      "iteration: 1719 | loss: 0.282689\n",
      "iteration: 1720 | loss: 0.571335\n",
      "iteration: 1721 | loss: 0.441300\n",
      "iteration: 1722 | loss: 0.689165\n",
      "iteration: 1723 | loss: 0.374055\n",
      "iteration: 1724 | loss: 0.307231\n",
      "  Train acc: 0.866, Val acc: 0.5\n",
      "iteration: 1725 | loss: 0.368528\n",
      "iteration: 1726 | loss: 0.476842\n",
      "iteration: 1727 | loss: 0.409403\n",
      "iteration: 1728 | loss: 0.486051\n",
      "iteration: 1729 | loss: 0.441822\n",
      "iteration: 1730 | loss: 0.526453\n",
      "iteration: 1731 | loss: 0.263835\n",
      "iteration: 1732 | loss: 0.260692\n",
      "iteration: 1733 | loss: 0.635963\n",
      "iteration: 1734 | loss: 0.563459\n",
      "iteration: 1735 | loss: 0.329101\n",
      "iteration: 1736 | loss: 0.601809\n",
      "iteration: 1737 | loss: 0.527351\n",
      "iteration: 1738 | loss: 0.333939\n",
      "iteration: 1739 | loss: 0.364709\n",
      "iteration: 1740 | loss: 0.402823\n",
      "iteration: 1741 | loss: 0.408939\n",
      "iteration: 1742 | loss: 0.329421\n",
      "iteration: 1743 | loss: 0.394075\n",
      "iteration: 1744 | loss: 0.263652\n",
      "iteration: 1745 | loss: 0.365695\n",
      "iteration: 1746 | loss: 0.368781\n",
      "iteration: 1747 | loss: 0.557543\n",
      "iteration: 1748 | loss: 0.380411\n",
      "iteration: 1749 | loss: 0.438624\n",
      "  Train acc: 0.872, Val acc: 0.5\n",
      "iteration: 1750 | loss: 0.242249\n",
      "iteration: 1751 | loss: 0.503190\n",
      "iteration: 1752 | loss: 0.451490\n",
      "iteration: 1753 | loss: 0.399530\n",
      "iteration: 1754 | loss: 0.253715\n",
      "iteration: 1755 | loss: 0.434843\n",
      "iteration: 1756 | loss: 0.378563\n",
      "iteration: 1757 | loss: 0.490413\n",
      "iteration: 1758 | loss: 0.631058\n",
      "iteration: 1759 | loss: 0.563620\n",
      "iteration: 1760 | loss: 0.448026\n",
      "iteration: 1761 | loss: 0.348885\n",
      "iteration: 1762 | loss: 0.257994\n",
      "iteration: 1763 | loss: 0.511065\n",
      "iteration: 1764 | loss: 0.417071\n",
      "iteration: 1765 | loss: 0.418286\n",
      "iteration: 1766 | loss: 0.291725\n",
      "iteration: 1767 | loss: 0.136687\n",
      "iteration: 1768 | loss: 0.283073\n",
      "iteration: 1769 | loss: 0.422762\n",
      "iteration: 1770 | loss: 0.492704\n",
      "iteration: 1771 | loss: 0.165851\n",
      "iteration: 1772 | loss: 0.357119\n",
      "iteration: 1773 | loss: 0.151367\n",
      "iteration: 1774 | loss: 0.552428\n",
      "  Train acc: 0.87, Val acc: 0.5\n",
      "iteration: 1775 | loss: 0.429029\n",
      "iteration: 1776 | loss: 0.284276\n",
      "iteration: 1777 | loss: 0.263285\n",
      "iteration: 1778 | loss: 0.419185\n",
      "iteration: 1779 | loss: 0.491938\n",
      "iteration: 1780 | loss: 0.356568\n",
      "iteration: 1781 | loss: 0.430105\n",
      "iteration: 1782 | loss: 0.256212\n",
      "iteration: 1783 | loss: 0.174618\n",
      "iteration: 1784 | loss: 0.250070\n",
      "iteration: 1785 | loss: 0.209138\n",
      "iteration: 1786 | loss: 0.595554\n",
      "iteration: 1787 | loss: 0.579113\n",
      "iteration: 1788 | loss: 0.345765\n",
      "iteration: 1789 | loss: 0.525350\n",
      "iteration: 1790 | loss: 0.311754\n",
      "iteration: 1791 | loss: 0.259462\n",
      "iteration: 1792 | loss: 0.596939\n",
      "iteration: 1793 | loss: 0.757972\n",
      "iteration: 1794 | loss: 0.445485\n",
      "iteration: 1795 | loss: 0.517379\n",
      "iteration: 1796 | loss: 0.386838\n",
      "iteration: 1797 | loss: 0.475685\n",
      "iteration: 1798 | loss: 0.442519\n",
      "iteration: 1799 | loss: 0.216516\n",
      "  Train acc: 0.864, Val acc: 0.5\n",
      "iteration: 1800 | loss: 0.304826\n",
      "iteration: 1801 | loss: 0.524630\n",
      "iteration: 1802 | loss: 0.426083\n",
      "iteration: 1803 | loss: 0.706986\n",
      "iteration: 1804 | loss: 0.470767\n",
      "iteration: 1805 | loss: 0.285436\n",
      "iteration: 1806 | loss: 0.246764\n",
      "iteration: 1807 | loss: 0.337445\n",
      "iteration: 1808 | loss: 0.263558\n",
      "iteration: 1809 | loss: 0.338331\n",
      "iteration: 1810 | loss: 0.475688\n",
      "iteration: 1811 | loss: 0.532577\n",
      "iteration: 1812 | loss: 0.372405\n",
      "iteration: 1813 | loss: 0.170396\n",
      "iteration: 1814 | loss: 0.446790\n",
      "iteration: 1815 | loss: 0.378567\n",
      "iteration: 1816 | loss: 0.493362\n",
      "iteration: 1817 | loss: 0.430132\n",
      "iteration: 1818 | loss: 0.420896\n",
      "iteration: 1819 | loss: 0.429167\n",
      "iteration: 1820 | loss: 0.293054\n",
      "iteration: 1821 | loss: 0.116924\n",
      "iteration: 1822 | loss: 0.310786\n",
      "iteration: 1823 | loss: 0.363748\n",
      "iteration: 1824 | loss: 0.584290\n",
      "  Train acc: 0.874, Val acc: 0.5\n",
      "iteration: 1825 | loss: 0.412959\n",
      "iteration: 1826 | loss: 0.650416\n",
      "iteration: 1827 | loss: 0.312744\n",
      "iteration: 1828 | loss: 0.501830\n",
      "iteration: 1829 | loss: 0.629484\n",
      "iteration: 1830 | loss: 1.018864\n",
      "iteration: 1831 | loss: 0.413644\n",
      "iteration: 1832 | loss: 0.552262\n",
      "iteration: 1833 | loss: 0.312331\n",
      "iteration: 1834 | loss: 0.345286\n",
      "iteration: 1835 | loss: 0.164685\n",
      "iteration: 1836 | loss: 0.417332\n",
      "iteration: 1837 | loss: 0.337470\n",
      "iteration: 1838 | loss: 0.425738\n",
      "iteration: 1839 | loss: 0.562443\n",
      "iteration: 1840 | loss: 0.529521\n",
      "iteration: 1841 | loss: 0.543061\n",
      "iteration: 1842 | loss: 0.098550\n",
      "iteration: 1843 | loss: 0.373263\n",
      "iteration: 1844 | loss: 0.341291\n",
      "iteration: 1845 | loss: 0.363895\n",
      "iteration: 1846 | loss: 0.583789\n",
      "iteration: 1847 | loss: 0.147140\n",
      "iteration: 1848 | loss: 0.364381\n",
      "iteration: 1849 | loss: 0.231664\n",
      "  Train acc: 0.844, Val acc: 0.5\n",
      "iteration: 1850 | loss: 0.619920\n",
      "iteration: 1851 | loss: 0.166148\n",
      "iteration: 1852 | loss: 0.342887\n",
      "iteration: 1853 | loss: 0.214465\n",
      "iteration: 1854 | loss: 0.338185\n",
      "iteration: 1855 | loss: 0.358066\n",
      "iteration: 1856 | loss: 0.388453\n",
      "iteration: 1857 | loss: 0.167781\n",
      "iteration: 1858 | loss: 0.457291\n",
      "iteration: 1859 | loss: 0.314310\n",
      "iteration: 1860 | loss: 0.447342\n",
      "iteration: 1861 | loss: 0.247863\n",
      "iteration: 1862 | loss: 0.539933\n",
      "iteration: 1863 | loss: 0.412361\n",
      "iteration: 1864 | loss: 0.329282\n",
      "iteration: 1865 | loss: 0.395773\n",
      "iteration: 1866 | loss: 0.455842\n",
      "iteration: 1867 | loss: 0.383639\n",
      "iteration: 1868 | loss: 0.247319\n",
      "iteration: 1869 | loss: 0.290956\n",
      "iteration: 1870 | loss: 0.746006\n",
      "iteration: 1871 | loss: 0.426315\n",
      "iteration: 1872 | loss: 0.226437\n",
      "iteration: 1873 | loss: 0.786133\n",
      "iteration: 1874 | loss: 0.363009\n",
      "  Train acc: 0.84, Val acc: 0.5\n",
      "iteration: 1875 | loss: 0.455402\n",
      "iteration: 1876 | loss: 0.193937\n",
      "iteration: 1877 | loss: 0.223044\n",
      "iteration: 1878 | loss: 0.409808\n",
      "iteration: 1879 | loss: 0.245959\n",
      "iteration: 1880 | loss: 0.399577\n",
      "iteration: 1881 | loss: 0.636691\n",
      "iteration: 1882 | loss: 0.403106\n",
      "iteration: 1883 | loss: 0.213528\n",
      "iteration: 1884 | loss: 0.429866\n",
      "iteration: 1885 | loss: 0.489375\n",
      "iteration: 1886 | loss: 0.243679\n",
      "iteration: 1887 | loss: 0.550384\n",
      "iteration: 1888 | loss: 0.405224\n",
      "iteration: 1889 | loss: 0.313175\n",
      "iteration: 1890 | loss: 0.265540\n",
      "iteration: 1891 | loss: 0.333041\n",
      "iteration: 1892 | loss: 0.246377\n",
      "iteration: 1893 | loss: 0.297068\n",
      "iteration: 1894 | loss: 0.406596\n",
      "iteration: 1895 | loss: 0.491347\n",
      "iteration: 1896 | loss: 0.337226\n",
      "iteration: 1897 | loss: 0.433153\n",
      "iteration: 1898 | loss: 0.150350\n",
      "iteration: 1899 | loss: 0.342800\n",
      "  Train acc: 0.9, Val acc: 0.5\n",
      "iteration: 1900 | loss: 0.320969\n",
      "iteration: 1901 | loss: 0.308371\n",
      "iteration: 1902 | loss: 0.318423\n",
      "iteration: 1903 | loss: 0.328596\n",
      "iteration: 1904 | loss: 0.488713\n",
      "iteration: 1905 | loss: 0.232198\n",
      "iteration: 1906 | loss: 0.716504\n",
      "iteration: 1907 | loss: 0.281280\n",
      "iteration: 1908 | loss: 0.278951\n",
      "iteration: 1909 | loss: 0.379428\n",
      "iteration: 1910 | loss: 0.776064\n",
      "iteration: 1911 | loss: 0.252683\n",
      "iteration: 1912 | loss: 0.360353\n",
      "iteration: 1913 | loss: 0.421324\n",
      "iteration: 1914 | loss: 0.586428\n",
      "iteration: 1915 | loss: 0.506477\n",
      "iteration: 1916 | loss: 0.297214\n",
      "iteration: 1917 | loss: 0.655948\n",
      "iteration: 1918 | loss: 0.345749\n",
      "iteration: 1919 | loss: 0.638046\n",
      "iteration: 1920 | loss: 0.382722\n",
      "iteration: 1921 | loss: 0.265741\n",
      "iteration: 1922 | loss: 0.581428\n",
      "iteration: 1923 | loss: 0.454559\n",
      "iteration: 1924 | loss: 0.425971\n",
      "  Train acc: 0.87, Val acc: 0.5\n",
      "iteration: 1925 | loss: 0.491252\n",
      "iteration: 1926 | loss: 0.357740\n",
      "iteration: 1927 | loss: 0.374333\n",
      "iteration: 1928 | loss: 0.299138\n",
      "iteration: 1929 | loss: 0.289687\n",
      "iteration: 1930 | loss: 0.346913\n",
      "iteration: 1931 | loss: 0.321720\n",
      "iteration: 1932 | loss: 0.384349\n",
      "iteration: 1933 | loss: 0.313320\n",
      "iteration: 1934 | loss: 0.504135\n",
      "iteration: 1935 | loss: 0.142751\n",
      "iteration: 1936 | loss: 0.256175\n",
      "iteration: 1937 | loss: 0.465147\n",
      "iteration: 1938 | loss: 0.409796\n",
      "iteration: 1939 | loss: 0.265919\n",
      "iteration: 1940 | loss: 0.462155\n",
      "iteration: 1941 | loss: 0.335440\n",
      "iteration: 1942 | loss: 0.232802\n",
      "iteration: 1943 | loss: 0.433413\n",
      "iteration: 1944 | loss: 0.296118\n",
      "iteration: 1945 | loss: 0.224177\n",
      "iteration: 1946 | loss: 0.303731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1947 | loss: 0.323548\n",
      "iteration: 1948 | loss: 0.433263\n",
      "iteration: 1949 | loss: 0.108287\n",
      "  Train acc: 0.908, Val acc: 0.5\n",
      "iteration: 1950 | loss: 0.148719\n",
      "iteration: 1951 | loss: 0.210092\n",
      "iteration: 1952 | loss: 0.221243\n",
      "iteration: 1953 | loss: 0.164756\n",
      "iteration: 1954 | loss: 0.244708\n",
      "iteration: 1955 | loss: 0.360536\n",
      "iteration: 1956 | loss: 0.302200\n",
      "iteration: 1957 | loss: 0.404830\n",
      "iteration: 1958 | loss: 0.297624\n",
      "iteration: 1959 | loss: 0.115623\n",
      "iteration: 1960 | loss: 0.367798\n",
      "iteration: 1961 | loss: 0.459806\n",
      "iteration: 1962 | loss: 0.094863\n",
      "iteration: 1963 | loss: 0.166910\n",
      "iteration: 1964 | loss: 0.315123\n",
      "iteration: 1965 | loss: 0.120570\n",
      "iteration: 1966 | loss: 0.340246\n",
      "iteration: 1967 | loss: 0.438210\n",
      "iteration: 1968 | loss: 0.266313\n",
      "iteration: 1969 | loss: 0.147412\n",
      "iteration: 1970 | loss: 0.183960\n",
      "iteration: 1971 | loss: 0.571177\n",
      "iteration: 1972 | loss: 0.679569\n",
      "iteration: 1973 | loss: 0.248948\n",
      "iteration: 1974 | loss: 0.431715\n",
      "  Train acc: 0.826, Val acc: 0.5\n",
      "iteration: 1975 | loss: 0.508117\n",
      "iteration: 1976 | loss: 0.191390\n",
      "iteration: 1977 | loss: 0.136653\n",
      "iteration: 1978 | loss: 0.202356\n",
      "iteration: 1979 | loss: 0.301029\n",
      "iteration: 1980 | loss: 0.408544\n",
      "iteration: 1981 | loss: 0.071518\n",
      "iteration: 1982 | loss: 0.367258\n",
      "iteration: 1983 | loss: 0.245061\n",
      "iteration: 1984 | loss: 0.186717\n",
      "iteration: 1985 | loss: 0.382860\n",
      "iteration: 1986 | loss: 0.235410\n",
      "iteration: 1987 | loss: 0.103258\n",
      "iteration: 1988 | loss: 0.193275\n",
      "iteration: 1989 | loss: 0.404939\n",
      "iteration: 1990 | loss: 0.266359\n",
      "iteration: 1991 | loss: 0.365764\n",
      "iteration: 1992 | loss: 0.249596\n",
      "iteration: 1993 | loss: 0.397055\n",
      "iteration: 1994 | loss: 0.311394\n",
      "iteration: 1995 | loss: 0.571828\n",
      "iteration: 1996 | loss: 0.390535\n",
      "iteration: 1997 | loss: 0.227858\n",
      "iteration: 1998 | loss: 0.462512\n",
      "iteration: 1999 | loss: 0.639081\n",
      "  Train acc: 0.922, Val acc: 0.5\n",
      "iteration: 2000 | loss: 0.504065\n",
      "iteration: 2001 | loss: 0.365670\n",
      "iteration: 2002 | loss: 0.345349\n",
      "iteration: 2003 | loss: 0.200580\n",
      "iteration: 2004 | loss: 0.177840\n",
      "iteration: 2005 | loss: 0.197433\n",
      "iteration: 2006 | loss: 0.242308\n",
      "iteration: 2007 | loss: 0.253193\n",
      "iteration: 2008 | loss: 0.449551\n",
      "iteration: 2009 | loss: 0.395130\n",
      "iteration: 2010 | loss: 0.284950\n",
      "iteration: 2011 | loss: 0.401899\n",
      "iteration: 2012 | loss: 0.354812\n",
      "iteration: 2013 | loss: 0.243660\n",
      "iteration: 2014 | loss: 0.326399\n",
      "iteration: 2015 | loss: 0.311973\n",
      "iteration: 2016 | loss: 0.353179\n",
      "iteration: 2017 | loss: 0.473759\n",
      "iteration: 2018 | loss: 0.229178\n",
      "iteration: 2019 | loss: 0.250981\n",
      "iteration: 2020 | loss: 0.342501\n",
      "iteration: 2021 | loss: 0.176962\n",
      "iteration: 2022 | loss: 0.266295\n",
      "iteration: 2023 | loss: 0.201609\n",
      "iteration: 2024 | loss: 0.145136\n",
      "  Train acc: 0.918, Val acc: 0.5\n",
      "iteration: 2025 | loss: 0.261478\n",
      "iteration: 2026 | loss: 0.188486\n",
      "iteration: 2027 | loss: 0.173169\n",
      "iteration: 2028 | loss: 0.119573\n",
      "iteration: 2029 | loss: 0.301159\n",
      "iteration: 2030 | loss: 0.482031\n",
      "iteration: 2031 | loss: 0.271367\n",
      "iteration: 2032 | loss: 0.632134\n",
      "iteration: 2033 | loss: 0.246183\n",
      "iteration: 2034 | loss: 0.498722\n",
      "iteration: 2035 | loss: 0.226439\n",
      "iteration: 2036 | loss: 0.353083\n",
      "iteration: 2037 | loss: 0.229366\n",
      "iteration: 2038 | loss: 0.320358\n",
      "iteration: 2039 | loss: 0.583035\n",
      "iteration: 2040 | loss: 0.471906\n",
      "iteration: 2041 | loss: 0.213350\n",
      "iteration: 2042 | loss: 0.405075\n",
      "iteration: 2043 | loss: 0.229164\n",
      "iteration: 2044 | loss: 0.326906\n",
      "iteration: 2045 | loss: 0.326977\n",
      "iteration: 2046 | loss: 0.323055\n",
      "iteration: 2047 | loss: 0.435796\n",
      "iteration: 2048 | loss: 0.139243\n",
      "iteration: 2049 | loss: 0.194928\n",
      "  Train acc: 0.92, Val acc: 0.5\n",
      "iteration: 2050 | loss: 0.381233\n",
      "iteration: 2051 | loss: 0.213049\n",
      "iteration: 2052 | loss: 0.251138\n",
      "iteration: 2053 | loss: 0.490380\n",
      "iteration: 2054 | loss: 0.236276\n",
      "iteration: 2055 | loss: 0.325700\n",
      "iteration: 2056 | loss: 0.428166\n",
      "iteration: 2057 | loss: 0.368753\n",
      "iteration: 2058 | loss: 0.198366\n",
      "iteration: 2059 | loss: 0.257525\n",
      "iteration: 2060 | loss: 0.119374\n",
      "iteration: 2061 | loss: 0.245244\n",
      "iteration: 2062 | loss: 0.143416\n",
      "iteration: 2063 | loss: 0.273463\n",
      "iteration: 2064 | loss: 0.291472\n",
      "iteration: 2065 | loss: 0.397377\n",
      "iteration: 2066 | loss: 0.175511\n",
      "iteration: 2067 | loss: 0.226989\n",
      "iteration: 2068 | loss: 0.257972\n",
      "iteration: 2069 | loss: 0.242893\n",
      "iteration: 2070 | loss: 0.434774\n",
      "iteration: 2071 | loss: 0.234423\n",
      "iteration: 2072 | loss: 0.357464\n",
      "iteration: 2073 | loss: 0.219789\n",
      "iteration: 2074 | loss: 0.154994\n",
      "  Train acc: 0.93, Val acc: 0.5\n",
      "iteration: 2075 | loss: 0.249199\n",
      "iteration: 2076 | loss: 0.085913\n",
      "iteration: 2077 | loss: 0.254544\n",
      "iteration: 2078 | loss: 0.100605\n",
      "iteration: 2079 | loss: 0.101951\n",
      "iteration: 2080 | loss: 0.277354\n",
      "iteration: 2081 | loss: 0.782379\n",
      "iteration: 2082 | loss: 0.278015\n",
      "iteration: 2083 | loss: 0.302183\n",
      "iteration: 2084 | loss: 0.134207\n",
      "iteration: 2085 | loss: 0.152083\n",
      "iteration: 2086 | loss: 0.241102\n",
      "iteration: 2087 | loss: 0.254480\n",
      "iteration: 2088 | loss: 0.322572\n",
      "iteration: 2089 | loss: 0.249171\n",
      "iteration: 2090 | loss: 0.362622\n",
      "iteration: 2091 | loss: 0.367571\n",
      "iteration: 2092 | loss: 0.565814\n",
      "iteration: 2093 | loss: 0.200404\n",
      "iteration: 2094 | loss: 0.199965\n",
      "iteration: 2095 | loss: 0.118852\n",
      "iteration: 2096 | loss: 0.160065\n",
      "iteration: 2097 | loss: 0.120147\n",
      "iteration: 2098 | loss: 0.469997\n",
      "iteration: 2099 | loss: 0.089421\n",
      "  Train acc: 0.914, Val acc: 0.5\n",
      "iteration: 2100 | loss: 0.110617\n",
      "iteration: 2101 | loss: 0.166422\n",
      "iteration: 2102 | loss: 0.294991\n",
      "iteration: 2103 | loss: 0.207933\n",
      "iteration: 2104 | loss: 0.236717\n",
      "iteration: 2105 | loss: 0.274865\n",
      "iteration: 2106 | loss: 0.037125\n",
      "iteration: 2107 | loss: 0.362588\n",
      "iteration: 2108 | loss: 0.183374\n",
      "iteration: 2109 | loss: 0.199609\n",
      "iteration: 2110 | loss: 0.090256\n",
      "iteration: 2111 | loss: 0.282702\n",
      "iteration: 2112 | loss: 0.099894\n",
      "iteration: 2113 | loss: 0.326155\n",
      "iteration: 2114 | loss: 0.735980\n",
      "iteration: 2115 | loss: 0.188343\n",
      "iteration: 2116 | loss: 0.441700\n",
      "iteration: 2117 | loss: 0.160642\n",
      "iteration: 2118 | loss: 0.287400\n",
      "iteration: 2119 | loss: 0.171824\n",
      "iteration: 2120 | loss: 0.248409\n",
      "iteration: 2121 | loss: 0.220850\n",
      "iteration: 2122 | loss: 0.250260\n",
      "iteration: 2123 | loss: 0.350621\n",
      "iteration: 2124 | loss: 0.171823\n",
      "  Train acc: 0.932, Val acc: 0.5\n",
      "iteration: 2125 | loss: 0.141974\n",
      "iteration: 2126 | loss: 0.048248\n",
      "iteration: 2127 | loss: 0.278023\n",
      "iteration: 2128 | loss: 0.096974\n",
      "iteration: 2129 | loss: 0.129905\n",
      "iteration: 2130 | loss: 0.379875\n",
      "iteration: 2131 | loss: 0.066088\n",
      "iteration: 2132 | loss: 0.240989\n",
      "iteration: 2133 | loss: 0.158944\n",
      "iteration: 2134 | loss: 0.269837\n",
      "iteration: 2135 | loss: 0.419588\n",
      "iteration: 2136 | loss: 0.303153\n",
      "iteration: 2137 | loss: 0.157669\n",
      "iteration: 2138 | loss: 0.427219\n",
      "iteration: 2139 | loss: 0.252304\n",
      "iteration: 2140 | loss: 0.218335\n",
      "iteration: 2141 | loss: 0.687574\n",
      "iteration: 2142 | loss: 0.321427\n",
      "iteration: 2143 | loss: 0.327013\n",
      "iteration: 2144 | loss: 0.586604\n",
      "iteration: 2145 | loss: 0.201061\n",
      "iteration: 2146 | loss: 0.241426\n",
      "iteration: 2147 | loss: 0.417708\n",
      "iteration: 2148 | loss: 0.195969\n",
      "iteration: 2149 | loss: 0.286105\n",
      "  Train acc: 0.92, Val acc: 0.5\n",
      "iteration: 2150 | loss: 0.262194\n",
      "iteration: 2151 | loss: 0.238102\n",
      "iteration: 2152 | loss: 0.365252\n",
      "iteration: 2153 | loss: 0.251932\n",
      "iteration: 2154 | loss: 0.069254\n",
      "iteration: 2155 | loss: 0.307668\n",
      "iteration: 2156 | loss: 0.144619\n",
      "iteration: 2157 | loss: 0.266099\n",
      "iteration: 2158 | loss: 0.368120\n",
      "iteration: 2159 | loss: 0.259675\n",
      "iteration: 2160 | loss: 0.237414\n",
      "iteration: 2161 | loss: 0.124385\n",
      "iteration: 2162 | loss: 0.381973\n",
      "iteration: 2163 | loss: 0.226288\n",
      "iteration: 2164 | loss: 0.220032\n",
      "iteration: 2165 | loss: 0.434849\n",
      "iteration: 2166 | loss: 0.101286\n",
      "iteration: 2167 | loss: 0.278684\n",
      "iteration: 2168 | loss: 0.187759\n",
      "iteration: 2169 | loss: 0.458688\n",
      "iteration: 2170 | loss: 0.239825\n",
      "iteration: 2171 | loss: 0.861998\n",
      "iteration: 2172 | loss: 0.137125\n",
      "iteration: 2173 | loss: 0.262522\n",
      "iteration: 2174 | loss: 0.361834\n",
      "  Train acc: 0.924, Val acc: 0.5\n",
      "iteration: 2175 | loss: 0.143453\n",
      "iteration: 2176 | loss: 0.212978\n",
      "iteration: 2177 | loss: 0.081246\n",
      "iteration: 2178 | loss: 0.172158\n",
      "iteration: 2179 | loss: 0.174980\n",
      "iteration: 2180 | loss: 0.350724\n",
      "iteration: 2181 | loss: 0.195846\n",
      "iteration: 2182 | loss: 0.151657\n",
      "iteration: 2183 | loss: 0.244299\n",
      "iteration: 2184 | loss: 0.202800\n",
      "iteration: 2185 | loss: 0.096650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2186 | loss: 0.126196\n",
      "iteration: 2187 | loss: 0.155384\n",
      "iteration: 2188 | loss: 0.130650\n",
      "iteration: 2189 | loss: 0.336474\n",
      "iteration: 2190 | loss: 0.276937\n",
      "iteration: 2191 | loss: 0.109873\n",
      "iteration: 2192 | loss: 0.167040\n",
      "iteration: 2193 | loss: 0.306675\n",
      "iteration: 2194 | loss: 0.053688\n",
      "iteration: 2195 | loss: 0.130931\n",
      "iteration: 2196 | loss: 0.200009\n",
      "iteration: 2197 | loss: 0.175994\n",
      "iteration: 2198 | loss: 0.256214\n",
      "iteration: 2199 | loss: 0.061344\n",
      "  Train acc: 0.904, Val acc: 0.5\n",
      "iteration: 2200 | loss: 0.414397\n",
      "iteration: 2201 | loss: 0.211846\n",
      "iteration: 2202 | loss: 0.248873\n",
      "iteration: 2203 | loss: 0.649372\n",
      "iteration: 2204 | loss: 0.112317\n",
      "iteration: 2205 | loss: 0.534642\n",
      "iteration: 2206 | loss: 0.169594\n",
      "iteration: 2207 | loss: 0.105058\n",
      "iteration: 2208 | loss: 0.252010\n",
      "iteration: 2209 | loss: 0.190785\n",
      "iteration: 2210 | loss: 0.165694\n",
      "iteration: 2211 | loss: 0.320472\n",
      "iteration: 2212 | loss: 0.288621\n",
      "iteration: 2213 | loss: 0.336010\n",
      "iteration: 2214 | loss: 0.371932\n",
      "iteration: 2215 | loss: 0.227836\n",
      "iteration: 2216 | loss: 0.347045\n",
      "iteration: 2217 | loss: 0.335393\n",
      "iteration: 2218 | loss: 0.190580\n",
      "iteration: 2219 | loss: 0.104820\n",
      "iteration: 2220 | loss: 0.154378\n",
      "iteration: 2221 | loss: 0.450974\n",
      "iteration: 2222 | loss: 0.366434\n",
      "iteration: 2223 | loss: 0.249169\n",
      "iteration: 2224 | loss: 0.129107\n",
      "  Train acc: 0.928, Val acc: 0.5\n",
      "iteration: 2225 | loss: 0.510462\n",
      "iteration: 2226 | loss: 0.388734\n",
      "iteration: 2227 | loss: 0.307206\n",
      "iteration: 2228 | loss: 0.174822\n",
      "iteration: 2229 | loss: 0.069170\n",
      "iteration: 2230 | loss: 0.182228\n",
      "iteration: 2231 | loss: 0.305791\n",
      "iteration: 2232 | loss: 0.194213\n",
      "iteration: 2233 | loss: 0.179171\n",
      "iteration: 2234 | loss: 0.546023\n",
      "iteration: 2235 | loss: 0.192642\n",
      "iteration: 2236 | loss: 0.126969\n",
      "iteration: 2237 | loss: 0.323146\n",
      "iteration: 2238 | loss: 0.383518\n",
      "iteration: 2239 | loss: 0.348200\n",
      "iteration: 2240 | loss: 0.234177\n",
      "iteration: 2241 | loss: 0.161430\n",
      "iteration: 2242 | loss: 0.537192\n",
      "iteration: 2243 | loss: 0.324252\n",
      "iteration: 2244 | loss: 0.193148\n",
      "iteration: 2245 | loss: 0.319000\n",
      "iteration: 2246 | loss: 0.362300\n",
      "iteration: 2247 | loss: 0.283391\n",
      "iteration: 2248 | loss: 0.168217\n",
      "iteration: 2249 | loss: 0.285777\n",
      "  Train acc: 0.898, Val acc: 0.5\n",
      "iteration: 2250 | loss: 0.426088\n",
      "iteration: 2251 | loss: 0.533908\n",
      "iteration: 2252 | loss: 0.406225\n",
      "iteration: 2253 | loss: 0.223580\n",
      "iteration: 2254 | loss: 0.503128\n",
      "iteration: 2255 | loss: 0.749039\n",
      "iteration: 2256 | loss: 0.198289\n",
      "iteration: 2257 | loss: 0.422543\n",
      "iteration: 2258 | loss: 0.188903\n",
      "iteration: 2259 | loss: 0.066753\n",
      "iteration: 2260 | loss: 0.226335\n",
      "iteration: 2261 | loss: 0.414706\n",
      "iteration: 2262 | loss: 0.067849\n",
      "iteration: 2263 | loss: 0.225697\n",
      "iteration: 2264 | loss: 0.589772\n",
      "iteration: 2265 | loss: 0.393458\n",
      "iteration: 2266 | loss: 0.252796\n",
      "iteration: 2267 | loss: 0.321478\n",
      "iteration: 2268 | loss: 0.225451\n",
      "iteration: 2269 | loss: 0.216444\n",
      "iteration: 2270 | loss: 0.146970\n",
      "iteration: 2271 | loss: 0.312709\n",
      "iteration: 2272 | loss: 0.098082\n",
      "iteration: 2273 | loss: 0.327961\n",
      "iteration: 2274 | loss: 0.135671\n",
      "  Train acc: 0.868, Val acc: 0.5\n",
      "iteration: 2275 | loss: 0.285905\n",
      "iteration: 2276 | loss: 0.204456\n",
      "iteration: 2277 | loss: 0.481564\n",
      "iteration: 2278 | loss: 0.156250\n",
      "iteration: 2279 | loss: 0.548813\n",
      "iteration: 2280 | loss: 0.213783\n",
      "iteration: 2281 | loss: 0.288371\n",
      "iteration: 2282 | loss: 0.597143\n",
      "iteration: 2283 | loss: 0.309004\n",
      "iteration: 2284 | loss: 0.167873\n",
      "iteration: 2285 | loss: 0.314285\n",
      "iteration: 2286 | loss: 0.271555\n",
      "iteration: 2287 | loss: 0.163002\n",
      "iteration: 2288 | loss: 0.319298\n",
      "iteration: 2289 | loss: 0.729102\n",
      "iteration: 2290 | loss: 0.185425\n",
      "iteration: 2291 | loss: 0.421650\n",
      "iteration: 2292 | loss: 0.391724\n",
      "iteration: 2293 | loss: 0.421237\n",
      "iteration: 2294 | loss: 0.350937\n",
      "iteration: 2295 | loss: 0.313268\n",
      "iteration: 2296 | loss: 0.218706\n",
      "iteration: 2297 | loss: 0.591416\n",
      "iteration: 2298 | loss: 0.309079\n",
      "iteration: 2299 | loss: 0.437663\n",
      "  Train acc: 0.924, Val acc: 0.5\n",
      "iteration: 2300 | loss: 0.230110\n",
      "iteration: 2301 | loss: 0.116413\n",
      "iteration: 2302 | loss: 0.277010\n",
      "iteration: 2303 | loss: 0.245124\n",
      "iteration: 2304 | loss: 0.437768\n",
      "iteration: 2305 | loss: 0.251721\n",
      "iteration: 2306 | loss: 0.258574\n",
      "iteration: 2307 | loss: 0.097815\n",
      "iteration: 2308 | loss: 0.285966\n",
      "iteration: 2309 | loss: 0.203568\n",
      "iteration: 2310 | loss: 0.244588\n",
      "iteration: 2311 | loss: 0.139562\n",
      "iteration: 2312 | loss: 0.192646\n",
      "iteration: 2313 | loss: 0.352341\n",
      "iteration: 2314 | loss: 0.160705\n",
      "iteration: 2315 | loss: 0.409909\n",
      "iteration: 2316 | loss: 0.193059\n",
      "iteration: 2317 | loss: 0.289969\n",
      "iteration: 2318 | loss: 0.325358\n",
      "iteration: 2319 | loss: 0.185190\n",
      "iteration: 2320 | loss: 0.181323\n",
      "iteration: 2321 | loss: 0.156092\n",
      "iteration: 2322 | loss: 0.164564\n",
      "iteration: 2323 | loss: 0.133133\n",
      "iteration: 2324 | loss: 0.122901\n",
      "  Train acc: 0.912, Val acc: 0.5\n",
      "iteration: 2325 | loss: 0.288873\n",
      "iteration: 2326 | loss: 0.226234\n",
      "iteration: 2327 | loss: 0.403680\n",
      "iteration: 2328 | loss: 0.140601\n",
      "iteration: 2329 | loss: 0.221888\n",
      "iteration: 2330 | loss: 0.109822\n",
      "iteration: 2331 | loss: 0.135872\n",
      "iteration: 2332 | loss: 0.106875\n",
      "iteration: 2333 | loss: 0.121694\n",
      "iteration: 2334 | loss: 0.199633\n",
      "iteration: 2335 | loss: 0.132984\n",
      "iteration: 2336 | loss: 0.272167\n",
      "iteration: 2337 | loss: 0.118871\n",
      "iteration: 2338 | loss: 0.195742\n",
      "iteration: 2339 | loss: 0.215754\n",
      "iteration: 2340 | loss: 0.149520\n",
      "iteration: 2341 | loss: 0.159516\n",
      "iteration: 2342 | loss: 0.327715\n",
      "iteration: 2343 | loss: 0.205087\n",
      "iteration: 2344 | loss: 0.210207\n",
      "iteration: 2345 | loss: 0.191299\n",
      "iteration: 2346 | loss: 0.392916\n",
      "iteration: 2347 | loss: 0.267419\n",
      "iteration: 2348 | loss: 0.255468\n",
      "iteration: 2349 | loss: 0.251311\n",
      "  Train acc: 0.944, Val acc: 0.5\n",
      "iteration: 2350 | loss: 0.220502\n",
      "iteration: 2351 | loss: 0.098183\n",
      "iteration: 2352 | loss: 0.094331\n",
      "iteration: 2353 | loss: 0.143931\n",
      "iteration: 2354 | loss: 0.364633\n",
      "iteration: 2355 | loss: 0.148515\n",
      "iteration: 2356 | loss: 0.242778\n",
      "iteration: 2357 | loss: 0.298025\n",
      "iteration: 2358 | loss: 0.139921\n",
      "iteration: 2359 | loss: 0.146180\n",
      "iteration: 2360 | loss: 0.150868\n",
      "iteration: 2361 | loss: 0.163376\n",
      "iteration: 2362 | loss: 0.221068\n",
      "iteration: 2363 | loss: 0.169259\n",
      "iteration: 2364 | loss: 0.136823\n",
      "iteration: 2365 | loss: 0.175859\n",
      "iteration: 2366 | loss: 0.131310\n",
      "iteration: 2367 | loss: 0.163094\n",
      "iteration: 2368 | loss: 0.116030\n",
      "iteration: 2369 | loss: 0.218797\n",
      "iteration: 2370 | loss: 0.204680\n",
      "iteration: 2371 | loss: 0.105480\n",
      "iteration: 2372 | loss: 0.086116\n",
      "iteration: 2373 | loss: 0.283061\n",
      "iteration: 2374 | loss: 0.124127\n",
      "  Train acc: 0.928, Val acc: 0.5\n",
      "iteration: 2375 | loss: 0.141354\n",
      "iteration: 2376 | loss: 0.164863\n",
      "iteration: 2377 | loss: 0.078206\n",
      "iteration: 2378 | loss: 0.216897\n",
      "iteration: 2379 | loss: 0.194788\n",
      "iteration: 2380 | loss: 0.104995\n",
      "iteration: 2381 | loss: 0.245464\n",
      "iteration: 2382 | loss: 0.051683\n",
      "iteration: 2383 | loss: 0.144443\n",
      "iteration: 2384 | loss: 0.098535\n",
      "iteration: 2385 | loss: 0.265786\n",
      "iteration: 2386 | loss: 0.384193\n",
      "iteration: 2387 | loss: 0.238691\n",
      "iteration: 2388 | loss: 0.317971\n",
      "iteration: 2389 | loss: 0.213293\n",
      "iteration: 2390 | loss: 0.138656\n",
      "iteration: 2391 | loss: 0.178029\n",
      "iteration: 2392 | loss: 0.321986\n",
      "iteration: 2393 | loss: 0.235090\n",
      "iteration: 2394 | loss: 0.180778\n",
      "iteration: 2395 | loss: 0.692652\n",
      "iteration: 2396 | loss: 0.183953\n",
      "iteration: 2397 | loss: 0.219314\n",
      "iteration: 2398 | loss: 0.242617\n",
      "iteration: 2399 | loss: 0.185192\n",
      "  Train acc: 0.936, Val acc: 0.5\n",
      "iteration: 2400 | loss: 0.355104\n",
      "iteration: 2401 | loss: 0.093280\n",
      "iteration: 2402 | loss: 0.198522\n",
      "iteration: 2403 | loss: 0.353034\n",
      "iteration: 2404 | loss: 0.202196\n",
      "iteration: 2405 | loss: 0.050646\n",
      "iteration: 2406 | loss: 0.173065\n",
      "iteration: 2407 | loss: 0.094562\n",
      "iteration: 2408 | loss: 0.371542\n",
      "iteration: 2409 | loss: 0.071141\n",
      "iteration: 2410 | loss: 0.151068\n",
      "iteration: 2411 | loss: 0.131308\n",
      "iteration: 2412 | loss: 0.412272\n",
      "iteration: 2413 | loss: 0.248986\n",
      "iteration: 2414 | loss: 0.177090\n",
      "iteration: 2415 | loss: 0.240718\n",
      "iteration: 2416 | loss: 0.119529\n",
      "iteration: 2417 | loss: 0.213288\n",
      "iteration: 2418 | loss: 0.114022\n",
      "iteration: 2419 | loss: 0.136286\n",
      "iteration: 2420 | loss: 0.118895\n",
      "iteration: 2421 | loss: 0.239259\n",
      "iteration: 2422 | loss: 0.073030\n",
      "iteration: 2423 | loss: 0.253115\n",
      "iteration: 2424 | loss: 0.236791\n",
      "  Train acc: 0.938, Val acc: 0.5\n",
      "iteration: 2425 | loss: 0.224442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2426 | loss: 0.164214\n",
      "iteration: 2427 | loss: 0.350847\n",
      "iteration: 2428 | loss: 0.332026\n",
      "iteration: 2429 | loss: 0.238699\n",
      "iteration: 2430 | loss: 0.097304\n",
      "iteration: 2431 | loss: 0.161666\n",
      "iteration: 2432 | loss: 0.209733\n",
      "iteration: 2433 | loss: 0.111598\n",
      "iteration: 2434 | loss: 0.372337\n",
      "iteration: 2435 | loss: 0.205960\n",
      "iteration: 2436 | loss: 0.079879\n",
      "iteration: 2437 | loss: 0.077783\n",
      "iteration: 2438 | loss: 0.216435\n",
      "iteration: 2439 | loss: 0.249509\n",
      "iteration: 2440 | loss: 0.066552\n",
      "iteration: 2441 | loss: 0.427704\n",
      "iteration: 2442 | loss: 0.138922\n",
      "iteration: 2443 | loss: 0.122777\n",
      "iteration: 2444 | loss: 0.079364\n",
      "iteration: 2445 | loss: 0.111305\n",
      "iteration: 2446 | loss: 0.237396\n",
      "iteration: 2447 | loss: 0.188291\n",
      "iteration: 2448 | loss: 0.204331\n",
      "iteration: 2449 | loss: 0.096823\n",
      "  Train acc: 0.954, Val acc: 0.5\n",
      "iteration: 2450 | loss: 0.082665\n",
      "iteration: 2451 | loss: 0.168967\n",
      "iteration: 2452 | loss: 0.277385\n",
      "iteration: 2453 | loss: 0.123094\n",
      "iteration: 2454 | loss: 0.127811\n",
      "iteration: 2455 | loss: 0.140056\n",
      "iteration: 2456 | loss: 0.106885\n",
      "iteration: 2457 | loss: 0.141374\n",
      "iteration: 2458 | loss: 0.291585\n",
      "iteration: 2459 | loss: 0.214557\n",
      "iteration: 2460 | loss: 0.147381\n",
      "iteration: 2461 | loss: 0.277169\n",
      "iteration: 2462 | loss: 0.145959\n",
      "iteration: 2463 | loss: 0.442458\n",
      "iteration: 2464 | loss: 0.172206\n",
      "iteration: 2465 | loss: 0.387617\n",
      "iteration: 2466 | loss: 0.159309\n",
      "iteration: 2467 | loss: 0.088206\n",
      "iteration: 2468 | loss: 0.192610\n",
      "iteration: 2469 | loss: 0.094760\n",
      "iteration: 2470 | loss: 0.227987\n",
      "iteration: 2471 | loss: 0.193814\n",
      "iteration: 2472 | loss: 0.647961\n",
      "iteration: 2473 | loss: 0.121228\n",
      "iteration: 2474 | loss: 0.259808\n",
      "  Train acc: 0.952, Val acc: 0.5\n",
      "iteration: 2475 | loss: 0.068858\n",
      "iteration: 2476 | loss: 0.192546\n",
      "iteration: 2477 | loss: 0.184101\n",
      "iteration: 2478 | loss: 0.076275\n",
      "iteration: 2479 | loss: 0.145469\n",
      "iteration: 2480 | loss: 0.160809\n",
      "iteration: 2481 | loss: 0.270510\n",
      "iteration: 2482 | loss: 0.300539\n",
      "iteration: 2483 | loss: 0.060184\n",
      "iteration: 2484 | loss: 0.082211\n",
      "iteration: 2485 | loss: 0.176771\n",
      "iteration: 2486 | loss: 0.219988\n",
      "iteration: 2487 | loss: 0.181835\n",
      "iteration: 2488 | loss: 0.174042\n",
      "iteration: 2489 | loss: 0.302442\n",
      "iteration: 2490 | loss: 0.121300\n",
      "iteration: 2491 | loss: 0.136606\n",
      "iteration: 2492 | loss: 0.331649\n",
      "iteration: 2493 | loss: 0.096289\n",
      "iteration: 2494 | loss: 0.157273\n",
      "iteration: 2495 | loss: 0.189248\n",
      "iteration: 2496 | loss: 0.121480\n",
      "iteration: 2497 | loss: 0.062076\n",
      "iteration: 2498 | loss: 0.084881\n",
      "iteration: 2499 | loss: 0.117356\n",
      "  Train acc: 0.93, Val acc: 0.5\n",
      "iteration: 2500 | loss: 0.231534\n",
      "iteration: 2501 | loss: 0.196153\n",
      "iteration: 2502 | loss: 0.127152\n",
      "iteration: 2503 | loss: 0.142923\n",
      "iteration: 2504 | loss: 0.263157\n",
      "iteration: 2505 | loss: 0.231001\n",
      "iteration: 2506 | loss: 0.271736\n",
      "iteration: 2507 | loss: 0.427949\n",
      "iteration: 2508 | loss: 0.066551\n",
      "iteration: 2509 | loss: 0.150677\n",
      "iteration: 2510 | loss: 0.033789\n",
      "iteration: 2511 | loss: 0.073686\n",
      "iteration: 2512 | loss: 0.149613\n",
      "iteration: 2513 | loss: 0.316033\n",
      "iteration: 2514 | loss: 0.184795\n",
      "iteration: 2515 | loss: 0.086091\n",
      "iteration: 2516 | loss: 0.190560\n",
      "iteration: 2517 | loss: 0.131829\n",
      "iteration: 2518 | loss: 0.105158\n",
      "iteration: 2519 | loss: 0.046035\n",
      "iteration: 2520 | loss: 0.157831\n",
      "iteration: 2521 | loss: 0.073434\n",
      "iteration: 2522 | loss: 0.094665\n",
      "iteration: 2523 | loss: 0.053483\n",
      "iteration: 2524 | loss: 0.174152\n",
      "  Train acc: 0.926, Val acc: 0.5\n",
      "iteration: 2525 | loss: 0.176317\n",
      "iteration: 2526 | loss: 0.172500\n",
      "iteration: 2527 | loss: 0.133722\n",
      "iteration: 2528 | loss: 0.081639\n",
      "iteration: 2529 | loss: 0.096547\n",
      "iteration: 2530 | loss: 0.283055\n",
      "iteration: 2531 | loss: 0.219783\n",
      "iteration: 2532 | loss: 0.108962\n",
      "iteration: 2533 | loss: 0.056395\n",
      "iteration: 2534 | loss: 0.042521\n",
      "iteration: 2535 | loss: 0.087497\n",
      "iteration: 2536 | loss: 0.239278\n",
      "iteration: 2537 | loss: 0.185055\n",
      "iteration: 2538 | loss: 0.227146\n",
      "iteration: 2539 | loss: 0.109561\n",
      "iteration: 2540 | loss: 0.169269\n",
      "iteration: 2541 | loss: 0.119121\n",
      "iteration: 2542 | loss: 0.119024\n",
      "iteration: 2543 | loss: 0.205461\n",
      "iteration: 2544 | loss: 0.139187\n",
      "iteration: 2545 | loss: 0.192560\n",
      "iteration: 2546 | loss: 0.169132\n",
      "iteration: 2547 | loss: 0.266502\n",
      "iteration: 2548 | loss: 0.155073\n",
      "iteration: 2549 | loss: 0.206262\n",
      "  Train acc: 0.976, Val acc: 0.5\n",
      "iteration: 2550 | loss: 0.127802\n",
      "iteration: 2551 | loss: 0.191967\n",
      "iteration: 2552 | loss: 0.082550\n",
      "iteration: 2553 | loss: 0.105271\n",
      "iteration: 2554 | loss: 0.368936\n",
      "iteration: 2555 | loss: 0.144231\n",
      "iteration: 2556 | loss: 0.162339\n",
      "iteration: 2557 | loss: 0.091525\n",
      "iteration: 2558 | loss: 0.078794\n",
      "iteration: 2559 | loss: 0.070284\n",
      "iteration: 2560 | loss: 0.253859\n",
      "iteration: 2561 | loss: 0.062594\n",
      "iteration: 2562 | loss: 0.065504\n",
      "iteration: 2563 | loss: 0.175523\n",
      "iteration: 2564 | loss: 0.083393\n",
      "iteration: 2565 | loss: 0.125103\n",
      "iteration: 2566 | loss: 0.078632\n",
      "iteration: 2567 | loss: 0.095470\n",
      "iteration: 2568 | loss: 0.140413\n",
      "iteration: 2569 | loss: 0.241381\n",
      "iteration: 2570 | loss: 0.180208\n",
      "iteration: 2571 | loss: 0.084675\n",
      "iteration: 2572 | loss: 0.225548\n",
      "iteration: 2573 | loss: 0.112878\n",
      "iteration: 2574 | loss: 0.223352\n",
      "  Train acc: 0.964, Val acc: 0.5\n",
      "iteration: 2575 | loss: 0.235915\n",
      "iteration: 2576 | loss: 0.100869\n",
      "iteration: 2577 | loss: 0.237803\n",
      "iteration: 2578 | loss: 0.084701\n",
      "iteration: 2579 | loss: 0.023105\n",
      "iteration: 2580 | loss: 0.385709\n",
      "iteration: 2581 | loss: 0.084339\n",
      "iteration: 2582 | loss: 0.232943\n",
      "iteration: 2583 | loss: 0.164267\n",
      "iteration: 2584 | loss: 0.136585\n",
      "iteration: 2585 | loss: 0.137663\n",
      "iteration: 2586 | loss: 0.165073\n",
      "iteration: 2587 | loss: 0.103442\n",
      "iteration: 2588 | loss: 0.142636\n",
      "iteration: 2589 | loss: 0.071863\n",
      "iteration: 2590 | loss: 0.026635\n",
      "iteration: 2591 | loss: 0.424530\n",
      "iteration: 2592 | loss: 0.251009\n",
      "iteration: 2593 | loss: 0.145964\n",
      "iteration: 2594 | loss: 0.069853\n",
      "iteration: 2595 | loss: 0.189676\n",
      "iteration: 2596 | loss: 0.099456\n",
      "iteration: 2597 | loss: 0.141211\n",
      "iteration: 2598 | loss: 0.049811\n",
      "iteration: 2599 | loss: 0.178833\n",
      "  Train acc: 0.94, Val acc: 0.5\n",
      "iteration: 2600 | loss: 0.099035\n",
      "iteration: 2601 | loss: 0.103983\n",
      "iteration: 2602 | loss: 0.182260\n",
      "iteration: 2603 | loss: 0.363358\n",
      "iteration: 2604 | loss: 0.111730\n",
      "iteration: 2605 | loss: 0.092015\n",
      "iteration: 2606 | loss: 0.149260\n",
      "iteration: 2607 | loss: 0.081586\n",
      "iteration: 2608 | loss: 0.118192\n",
      "iteration: 2609 | loss: 0.041506\n",
      "iteration: 2610 | loss: 0.124395\n",
      "iteration: 2611 | loss: 0.285352\n",
      "iteration: 2612 | loss: 0.153449\n",
      "iteration: 2613 | loss: 0.223264\n",
      "iteration: 2614 | loss: 0.386833\n",
      "iteration: 2615 | loss: 0.268976\n",
      "iteration: 2616 | loss: 0.197117\n",
      "iteration: 2617 | loss: 0.149233\n",
      "iteration: 2618 | loss: 0.139949\n",
      "iteration: 2619 | loss: 0.071646\n",
      "iteration: 2620 | loss: 0.066587\n",
      "iteration: 2621 | loss: 0.137889\n",
      "iteration: 2622 | loss: 0.108452\n",
      "iteration: 2623 | loss: 0.089464\n",
      "iteration: 2624 | loss: 0.082849\n",
      "  Train acc: 0.956, Val acc: 0.5\n",
      "iteration: 2625 | loss: 0.084913\n",
      "iteration: 2626 | loss: 0.216672\n",
      "iteration: 2627 | loss: 0.203471\n",
      "iteration: 2628 | loss: 0.523226\n",
      "iteration: 2629 | loss: 0.197036\n",
      "iteration: 2630 | loss: 0.059192\n",
      "iteration: 2631 | loss: 0.140178\n",
      "iteration: 2632 | loss: 0.100854\n",
      "iteration: 2633 | loss: 0.145004\n",
      "iteration: 2634 | loss: 0.235124\n",
      "iteration: 2635 | loss: 0.094965\n",
      "iteration: 2636 | loss: 0.358089\n",
      "iteration: 2637 | loss: 0.217547\n",
      "iteration: 2638 | loss: 0.234939\n",
      "iteration: 2639 | loss: 0.090677\n",
      "iteration: 2640 | loss: 0.153406\n",
      "iteration: 2641 | loss: 0.057851\n",
      "iteration: 2642 | loss: 0.183311\n",
      "iteration: 2643 | loss: 0.161046\n",
      "iteration: 2644 | loss: 0.077868\n",
      "iteration: 2645 | loss: 0.143905\n",
      "iteration: 2646 | loss: 0.027778\n",
      "iteration: 2647 | loss: 0.150237\n",
      "iteration: 2648 | loss: 0.169653\n",
      "iteration: 2649 | loss: 0.086318\n",
      "  Train acc: 0.958, Val acc: 0.5\n",
      "iteration: 2650 | loss: 0.040647\n",
      "iteration: 2651 | loss: 0.083278\n",
      "iteration: 2652 | loss: 0.046826\n",
      "iteration: 2653 | loss: 0.139927\n",
      "iteration: 2654 | loss: 0.294835\n",
      "iteration: 2655 | loss: 0.206021\n",
      "iteration: 2656 | loss: 0.259667\n",
      "iteration: 2657 | loss: 0.074819\n",
      "iteration: 2658 | loss: 0.106666\n",
      "iteration: 2659 | loss: 0.161974\n",
      "iteration: 2660 | loss: 0.152622\n",
      "iteration: 2661 | loss: 0.245216\n",
      "iteration: 2662 | loss: 0.260962\n",
      "iteration: 2663 | loss: 0.185633\n",
      "iteration: 2664 | loss: 0.159689\n",
      "iteration: 2665 | loss: 0.251653\n",
      "iteration: 2666 | loss: 0.181848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2667 | loss: 0.135767\n",
      "iteration: 2668 | loss: 0.139943\n",
      "iteration: 2669 | loss: 0.101649\n",
      "iteration: 2670 | loss: 0.096146\n",
      "iteration: 2671 | loss: 0.079440\n",
      "iteration: 2672 | loss: 0.155191\n",
      "iteration: 2673 | loss: 0.139848\n",
      "iteration: 2674 | loss: 0.112960\n",
      "  Train acc: 0.976, Val acc: 0.5\n",
      "iteration: 2675 | loss: 0.148578\n",
      "iteration: 2676 | loss: 0.023394\n",
      "iteration: 2677 | loss: 0.189894\n",
      "iteration: 2678 | loss: 0.088671\n",
      "iteration: 2679 | loss: 0.377625\n",
      "iteration: 2680 | loss: 0.088494\n",
      "iteration: 2681 | loss: 0.150953\n",
      "iteration: 2682 | loss: 0.150551\n",
      "iteration: 2683 | loss: 0.235321\n",
      "iteration: 2684 | loss: 0.036395\n",
      "iteration: 2685 | loss: 0.153450\n",
      "iteration: 2686 | loss: 0.083666\n",
      "iteration: 2687 | loss: 0.123683\n",
      "iteration: 2688 | loss: 0.044662\n",
      "iteration: 2689 | loss: 0.034132\n",
      "iteration: 2690 | loss: 0.113060\n",
      "iteration: 2691 | loss: 0.124317\n",
      "iteration: 2692 | loss: 0.170135\n",
      "iteration: 2693 | loss: 0.029959\n",
      "iteration: 2694 | loss: 0.117226\n",
      "iteration: 2695 | loss: 0.072571\n",
      "iteration: 2696 | loss: 0.123008\n",
      "iteration: 2697 | loss: 0.121488\n",
      "iteration: 2698 | loss: 0.093630\n",
      "iteration: 2699 | loss: 0.251455\n",
      "  Train acc: 0.95, Val acc: 0.5\n",
      "iteration: 2700 | loss: 0.038376\n",
      "iteration: 2701 | loss: 0.068913\n",
      "iteration: 2702 | loss: 0.125985\n",
      "iteration: 2703 | loss: 0.098186\n",
      "iteration: 2704 | loss: 0.047473\n",
      "iteration: 2705 | loss: 0.192207\n",
      "iteration: 2706 | loss: 0.086541\n",
      "iteration: 2707 | loss: 0.065946\n",
      "iteration: 2708 | loss: 0.133800\n",
      "iteration: 2709 | loss: 0.244858\n",
      "iteration: 2710 | loss: 0.055444\n",
      "iteration: 2711 | loss: 0.099912\n",
      "iteration: 2712 | loss: 0.083561\n",
      "iteration: 2713 | loss: 0.056600\n",
      "iteration: 2714 | loss: 0.133086\n",
      "iteration: 2715 | loss: 0.131198\n",
      "iteration: 2716 | loss: 0.324799\n",
      "iteration: 2717 | loss: 0.094902\n",
      "iteration: 2718 | loss: 0.116818\n",
      "iteration: 2719 | loss: 0.248038\n",
      "iteration: 2720 | loss: 0.187960\n",
      "iteration: 2721 | loss: 0.144946\n",
      "iteration: 2722 | loss: 0.072307\n",
      "iteration: 2723 | loss: 0.072919\n",
      "iteration: 2724 | loss: 0.135561\n",
      "  Train acc: 0.978, Val acc: 0.5\n",
      "iteration: 2725 | loss: 0.041956\n",
      "iteration: 2726 | loss: 0.072125\n",
      "iteration: 2727 | loss: 0.085578\n",
      "iteration: 2728 | loss: 0.078746\n",
      "iteration: 2729 | loss: 0.033479\n",
      "iteration: 2730 | loss: 0.041691\n",
      "iteration: 2731 | loss: 0.021839\n",
      "iteration: 2732 | loss: 0.074676\n",
      "iteration: 2733 | loss: 0.194558\n",
      "iteration: 2734 | loss: 0.098756\n",
      "iteration: 2735 | loss: 0.089025\n",
      "iteration: 2736 | loss: 0.042917\n",
      "iteration: 2737 | loss: 0.164589\n",
      "iteration: 2738 | loss: 0.059878\n",
      "iteration: 2739 | loss: 0.138005\n",
      "iteration: 2740 | loss: 0.073804\n",
      "iteration: 2741 | loss: 0.055967\n",
      "iteration: 2742 | loss: 0.073210\n",
      "iteration: 2743 | loss: 0.117243\n",
      "iteration: 2744 | loss: 0.302125\n",
      "iteration: 2745 | loss: 0.088974\n",
      "iteration: 2746 | loss: 0.103758\n",
      "iteration: 2747 | loss: 0.075097\n",
      "iteration: 2748 | loss: 0.062407\n",
      "iteration: 2749 | loss: 0.151789\n",
      "  Train acc: 0.962, Val acc: 0.5\n",
      "iteration: 2750 | loss: 0.090645\n",
      "iteration: 2751 | loss: 0.124371\n",
      "iteration: 2752 | loss: 0.138306\n",
      "iteration: 2753 | loss: 0.092800\n",
      "iteration: 2754 | loss: 0.220375\n",
      "iteration: 2755 | loss: 0.055469\n",
      "iteration: 2756 | loss: 0.018750\n",
      "iteration: 2757 | loss: 0.158773\n",
      "iteration: 2758 | loss: 0.010043\n",
      "iteration: 2759 | loss: 0.071640\n",
      "iteration: 2760 | loss: 0.044913\n",
      "iteration: 2761 | loss: 0.136353\n",
      "iteration: 2762 | loss: 0.239532\n",
      "iteration: 2763 | loss: 0.057412\n",
      "iteration: 2764 | loss: 0.064192\n",
      "iteration: 2765 | loss: 0.062930\n",
      "iteration: 2766 | loss: 0.087586\n",
      "iteration: 2767 | loss: 0.156065\n",
      "iteration: 2768 | loss: 0.029646\n",
      "iteration: 2769 | loss: 0.107576\n",
      "iteration: 2770 | loss: 0.054721\n",
      "iteration: 2771 | loss: 0.130675\n",
      "iteration: 2772 | loss: 0.063827\n",
      "iteration: 2773 | loss: 0.099631\n",
      "iteration: 2774 | loss: 0.140219\n",
      "  Train acc: 0.958, Val acc: 0.5\n",
      "iteration: 2775 | loss: 0.108849\n",
      "iteration: 2776 | loss: 0.067613\n",
      "iteration: 2777 | loss: 0.213530\n",
      "iteration: 2778 | loss: 0.066599\n",
      "iteration: 2779 | loss: 0.168070\n",
      "iteration: 2780 | loss: 0.099800\n",
      "iteration: 2781 | loss: 0.052965\n",
      "iteration: 2782 | loss: 0.057295\n",
      "iteration: 2783 | loss: 0.047989\n",
      "iteration: 2784 | loss: 0.091990\n",
      "iteration: 2785 | loss: 0.149283\n",
      "iteration: 2786 | loss: 0.112130\n",
      "iteration: 2787 | loss: 0.141033\n",
      "iteration: 2788 | loss: 0.069523\n",
      "iteration: 2789 | loss: 0.021485\n",
      "iteration: 2790 | loss: 0.093158\n",
      "iteration: 2791 | loss: 0.333989\n",
      "iteration: 2792 | loss: 0.202444\n",
      "iteration: 2793 | loss: 0.071247\n",
      "iteration: 2794 | loss: 0.059956\n",
      "iteration: 2795 | loss: 0.037435\n",
      "iteration: 2796 | loss: 0.062353\n",
      "iteration: 2797 | loss: 0.217274\n",
      "iteration: 2798 | loss: 0.091221\n",
      "iteration: 2799 | loss: 0.123649\n",
      "  Train acc: 0.982, Val acc: 0.5\n",
      "iteration: 2800 | loss: 0.060815\n",
      "iteration: 2801 | loss: 0.252635\n",
      "iteration: 2802 | loss: 0.078176\n",
      "iteration: 2803 | loss: 0.092010\n",
      "iteration: 2804 | loss: 0.051957\n",
      "iteration: 2805 | loss: 0.087310\n",
      "iteration: 2806 | loss: 0.021130\n",
      "iteration: 2807 | loss: 0.066586\n",
      "iteration: 2808 | loss: 0.081146\n",
      "iteration: 2809 | loss: 0.184413\n",
      "iteration: 2810 | loss: 0.086558\n",
      "iteration: 2811 | loss: 0.053818\n",
      "iteration: 2812 | loss: 0.356560\n",
      "iteration: 2813 | loss: 0.109928\n",
      "iteration: 2814 | loss: 0.109066\n",
      "iteration: 2815 | loss: 0.212850\n",
      "iteration: 2816 | loss: 0.204637\n",
      "iteration: 2817 | loss: 0.089408\n",
      "iteration: 2818 | loss: 0.055978\n",
      "iteration: 2819 | loss: 0.105866\n",
      "iteration: 2820 | loss: 0.105919\n",
      "iteration: 2821 | loss: 0.086169\n",
      "iteration: 2822 | loss: 0.185719\n",
      "iteration: 2823 | loss: 0.164789\n",
      "iteration: 2824 | loss: 0.040892\n",
      "  Train acc: 0.956, Val acc: 0.5\n",
      "iteration: 2825 | loss: 0.041486\n",
      "iteration: 2826 | loss: 0.067497\n",
      "iteration: 2827 | loss: 0.148751\n",
      "iteration: 2828 | loss: 0.383821\n",
      "iteration: 2829 | loss: 0.038030\n",
      "iteration: 2830 | loss: 0.063784\n",
      "iteration: 2831 | loss: 0.066843\n",
      "iteration: 2832 | loss: 0.165698\n",
      "iteration: 2833 | loss: 0.077748\n",
      "iteration: 2834 | loss: 0.075716\n",
      "iteration: 2835 | loss: 0.155839\n",
      "iteration: 2836 | loss: 0.063525\n",
      "iteration: 2837 | loss: 0.121826\n",
      "iteration: 2838 | loss: 0.050621\n",
      "iteration: 2839 | loss: 0.102638\n",
      "iteration: 2840 | loss: 0.052062\n",
      "iteration: 2841 | loss: 0.181361\n",
      "iteration: 2842 | loss: 0.165128\n",
      "iteration: 2843 | loss: 0.207877\n",
      "iteration: 2844 | loss: 0.155263\n",
      "iteration: 2845 | loss: 0.088836\n",
      "iteration: 2846 | loss: 0.036735\n",
      "iteration: 2847 | loss: 0.134633\n",
      "iteration: 2848 | loss: 0.116739\n",
      "iteration: 2849 | loss: 0.029871\n",
      "  Train acc: 0.968, Val acc: 0.5\n",
      "iteration: 2850 | loss: 0.261537\n",
      "iteration: 2851 | loss: 0.093355\n",
      "iteration: 2852 | loss: 0.044248\n",
      "iteration: 2853 | loss: 0.099884\n",
      "iteration: 2854 | loss: 0.059709\n",
      "iteration: 2855 | loss: 0.159528\n",
      "iteration: 2856 | loss: 0.034518\n",
      "iteration: 2857 | loss: 0.118677\n",
      "iteration: 2858 | loss: 0.105968\n",
      "iteration: 2859 | loss: 0.056645\n",
      "iteration: 2860 | loss: 0.180240\n",
      "iteration: 2861 | loss: 0.093623\n",
      "iteration: 2862 | loss: 0.074693\n",
      "iteration: 2863 | loss: 0.193328\n",
      "iteration: 2864 | loss: 0.087621\n",
      "iteration: 2865 | loss: 0.182420\n",
      "iteration: 2866 | loss: 0.033089\n",
      "iteration: 2867 | loss: 0.191323\n",
      "iteration: 2868 | loss: 0.057824\n",
      "iteration: 2869 | loss: 0.150172\n",
      "iteration: 2870 | loss: 0.157143\n",
      "iteration: 2871 | loss: 0.044171\n",
      "iteration: 2872 | loss: 0.045074\n",
      "iteration: 2873 | loss: 0.219328\n",
      "iteration: 2874 | loss: 0.237642\n",
      "  Train acc: 0.966, Val acc: 0.5\n",
      "iteration: 2875 | loss: 0.157842\n",
      "iteration: 2876 | loss: 0.158124\n",
      "iteration: 2877 | loss: 0.113073\n",
      "iteration: 2878 | loss: 0.065806\n",
      "iteration: 2879 | loss: 0.150668\n",
      "iteration: 2880 | loss: 0.099808\n",
      "iteration: 2881 | loss: 0.036397\n",
      "iteration: 2882 | loss: 0.067448\n",
      "iteration: 2883 | loss: 0.083039\n",
      "iteration: 2884 | loss: 0.107622\n",
      "iteration: 2885 | loss: 0.103898\n",
      "iteration: 2886 | loss: 0.040835\n",
      "iteration: 2887 | loss: 0.266924\n",
      "iteration: 2888 | loss: 0.094819\n",
      "iteration: 2889 | loss: 0.115919\n",
      "iteration: 2890 | loss: 0.096435\n",
      "iteration: 2891 | loss: 0.086763\n",
      "iteration: 2892 | loss: 0.081325\n",
      "iteration: 2893 | loss: 0.071110\n",
      "iteration: 2894 | loss: 0.136423\n",
      "iteration: 2895 | loss: 0.091557\n",
      "iteration: 2896 | loss: 0.176557\n",
      "iteration: 2897 | loss: 0.196801\n",
      "iteration: 2898 | loss: 0.072081\n",
      "iteration: 2899 | loss: 0.081853\n",
      "  Train acc: 0.968, Val acc: 0.5\n",
      "iteration: 2900 | loss: 0.084925\n",
      "iteration: 2901 | loss: 0.172714\n",
      "iteration: 2902 | loss: 0.231427\n",
      "iteration: 2903 | loss: 0.113361\n",
      "iteration: 2904 | loss: 0.061292\n",
      "iteration: 2905 | loss: 0.061036\n",
      "iteration: 2906 | loss: 0.078322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2907 | loss: 0.049913\n",
      "iteration: 2908 | loss: 0.038911\n",
      "iteration: 2909 | loss: 0.043297\n",
      "iteration: 2910 | loss: 0.221088\n",
      "iteration: 2911 | loss: 0.030976\n",
      "iteration: 2912 | loss: 0.130857\n",
      "iteration: 2913 | loss: 0.104005\n",
      "iteration: 2914 | loss: 0.112017\n",
      "iteration: 2915 | loss: 0.109766\n",
      "iteration: 2916 | loss: 0.130654\n",
      "iteration: 2917 | loss: 0.228568\n",
      "iteration: 2918 | loss: 0.190987\n",
      "iteration: 2919 | loss: 0.251313\n",
      "iteration: 2920 | loss: 0.200693\n",
      "iteration: 2921 | loss: 0.093488\n",
      "iteration: 2922 | loss: 0.022631\n",
      "iteration: 2923 | loss: 0.436757\n",
      "iteration: 2924 | loss: 0.194720\n",
      "  Train acc: 0.964, Val acc: 0.5\n",
      "iteration: 2925 | loss: 0.161224\n",
      "iteration: 2926 | loss: 0.190586\n",
      "iteration: 2927 | loss: 0.109137\n",
      "iteration: 2928 | loss: 0.207457\n",
      "iteration: 2929 | loss: 0.086671\n",
      "iteration: 2930 | loss: 0.183793\n",
      "iteration: 2931 | loss: 0.118912\n",
      "iteration: 2932 | loss: 0.114121\n",
      "iteration: 2933 | loss: 0.155302\n",
      "iteration: 2934 | loss: 0.193208\n",
      "iteration: 2935 | loss: 0.185567\n",
      "iteration: 2936 | loss: 0.205983\n",
      "iteration: 2937 | loss: 0.175467\n",
      "iteration: 2938 | loss: 0.121648\n",
      "iteration: 2939 | loss: 0.195168\n",
      "iteration: 2940 | loss: 0.197346\n",
      "iteration: 2941 | loss: 0.075204\n",
      "iteration: 2942 | loss: 0.062767\n",
      "iteration: 2943 | loss: 0.192431\n",
      "iteration: 2944 | loss: 0.118110\n",
      "iteration: 2945 | loss: 0.138978\n",
      "iteration: 2946 | loss: 0.165853\n",
      "iteration: 2947 | loss: 0.113569\n",
      "iteration: 2948 | loss: 0.090228\n",
      "iteration: 2949 | loss: 0.341717\n",
      "  Train acc: 0.968, Val acc: 0.5\n",
      "iteration: 2950 | loss: 0.384196\n",
      "iteration: 2951 | loss: 0.231956\n",
      "iteration: 2952 | loss: 0.085508\n",
      "iteration: 2953 | loss: 0.047745\n",
      "iteration: 2954 | loss: 0.511348\n",
      "iteration: 2955 | loss: 0.181115\n",
      "iteration: 2956 | loss: 0.050407\n",
      "iteration: 2957 | loss: 0.056400\n",
      "iteration: 2958 | loss: 0.299713\n",
      "iteration: 2959 | loss: 0.039442\n",
      "iteration: 2960 | loss: 0.093176\n",
      "iteration: 2961 | loss: 0.140902\n",
      "iteration: 2962 | loss: 0.131514\n",
      "iteration: 2963 | loss: 0.188238\n",
      "iteration: 2964 | loss: 0.048925\n",
      "iteration: 2965 | loss: 0.085292\n",
      "iteration: 2966 | loss: 0.116067\n",
      "iteration: 2967 | loss: 0.137502\n",
      "iteration: 2968 | loss: 0.071831\n",
      "iteration: 2969 | loss: 0.244006\n",
      "iteration: 2970 | loss: 0.175858\n",
      "iteration: 2971 | loss: 0.087966\n",
      "iteration: 2972 | loss: 0.236359\n",
      "iteration: 2973 | loss: 0.129911\n",
      "iteration: 2974 | loss: 0.012424\n",
      "  Train acc: 0.956, Val acc: 0.5\n",
      "iteration: 2975 | loss: 0.084885\n",
      "iteration: 2976 | loss: 0.090588\n",
      "iteration: 2977 | loss: 0.175764\n",
      "iteration: 2978 | loss: 0.105782\n",
      "iteration: 2979 | loss: 0.062204\n",
      "iteration: 2980 | loss: 0.089662\n",
      "iteration: 2981 | loss: 0.240083\n",
      "iteration: 2982 | loss: 0.132668\n",
      "iteration: 2983 | loss: 0.131848\n",
      "iteration: 2984 | loss: 0.075803\n",
      "iteration: 2985 | loss: 0.221849\n",
      "iteration: 2986 | loss: 0.118988\n",
      "iteration: 2987 | loss: 0.156341\n",
      "iteration: 2988 | loss: 0.134495\n",
      "iteration: 2989 | loss: 0.062497\n",
      "iteration: 2990 | loss: 0.038275\n",
      "iteration: 2991 | loss: 0.228107\n",
      "iteration: 2992 | loss: 0.066844\n",
      "iteration: 2993 | loss: 0.158413\n",
      "iteration: 2994 | loss: 0.076414\n",
      "iteration: 2995 | loss: 0.087207\n",
      "iteration: 2996 | loss: 0.080078\n",
      "iteration: 2997 | loss: 0.113612\n",
      "iteration: 2998 | loss: 0.076382\n",
      "iteration: 2999 | loss: 0.065474\n",
      "  Train acc: 0.968, Val acc: 0.5\n",
      "iteration: 3000 | loss: 0.078766\n",
      "iteration: 3001 | loss: 0.146244\n",
      "iteration: 3002 | loss: 0.054525\n",
      "iteration: 3003 | loss: 0.219404\n",
      "iteration: 3004 | loss: 0.323953\n",
      "iteration: 3005 | loss: 0.028719\n",
      "iteration: 3006 | loss: 0.097753\n",
      "iteration: 3007 | loss: 0.036405\n",
      "iteration: 3008 | loss: 0.063405\n",
      "iteration: 3009 | loss: 0.170278\n",
      "iteration: 3010 | loss: 0.067537\n",
      "iteration: 3011 | loss: 0.055052\n",
      "iteration: 3012 | loss: 0.066427\n",
      "iteration: 3013 | loss: 0.117549\n",
      "iteration: 3014 | loss: 0.102473\n",
      "iteration: 3015 | loss: 0.072624\n",
      "iteration: 3016 | loss: 0.096429\n",
      "iteration: 3017 | loss: 0.082460\n",
      "iteration: 3018 | loss: 0.070855\n",
      "iteration: 3019 | loss: 0.067602\n",
      "iteration: 3020 | loss: 0.176667\n",
      "iteration: 3021 | loss: 0.042124\n",
      "iteration: 3022 | loss: 0.017850\n",
      "iteration: 3023 | loss: 0.097901\n",
      "iteration: 3024 | loss: 0.389389\n",
      "  Train acc: 0.98, Val acc: 0.5\n",
      "iteration: 3025 | loss: 0.046634\n",
      "iteration: 3026 | loss: 0.017175\n",
      "iteration: 3027 | loss: 0.021050\n",
      "iteration: 3028 | loss: 0.264633\n",
      "iteration: 3029 | loss: 0.139385\n",
      "iteration: 3030 | loss: 0.063555\n",
      "iteration: 3031 | loss: 0.050418\n",
      "iteration: 3032 | loss: 0.043273\n",
      "iteration: 3033 | loss: 0.055551\n",
      "iteration: 3034 | loss: 0.145624\n",
      "iteration: 3035 | loss: 0.047885\n",
      "iteration: 3036 | loss: 0.120739\n",
      "iteration: 3037 | loss: 0.129392\n",
      "iteration: 3038 | loss: 0.095861\n",
      "iteration: 3039 | loss: 0.084794\n",
      "iteration: 3040 | loss: 0.072471\n",
      "iteration: 3041 | loss: 0.026928\n",
      "iteration: 3042 | loss: 0.106782\n",
      "iteration: 3043 | loss: 0.062151\n",
      "iteration: 3044 | loss: 0.051802\n",
      "iteration: 3045 | loss: 0.039438\n",
      "iteration: 3046 | loss: 0.126427\n",
      "iteration: 3047 | loss: 0.132224\n",
      "iteration: 3048 | loss: 0.293692\n",
      "iteration: 3049 | loss: 0.060362\n",
      "  Train acc: 0.976, Val acc: 0.5\n",
      "iteration: 3050 | loss: 0.091619\n",
      "iteration: 3051 | loss: 0.086770\n",
      "iteration: 3052 | loss: 0.075492\n",
      "iteration: 3053 | loss: 0.056951\n",
      "iteration: 3054 | loss: 0.066471\n",
      "iteration: 3055 | loss: 0.133608\n",
      "iteration: 3056 | loss: 0.111238\n",
      "iteration: 3057 | loss: 0.065036\n",
      "iteration: 3058 | loss: 0.068649\n",
      "iteration: 3059 | loss: 0.109354\n",
      "iteration: 3060 | loss: 0.104431\n",
      "iteration: 3061 | loss: 0.074565\n",
      "iteration: 3062 | loss: 0.089955\n",
      "iteration: 3063 | loss: 0.060530\n",
      "iteration: 3064 | loss: 0.032630\n",
      "iteration: 3065 | loss: 0.024640\n",
      "iteration: 3066 | loss: 0.038344\n",
      "iteration: 3067 | loss: 0.425967\n",
      "iteration: 3068 | loss: 0.050702\n",
      "iteration: 3069 | loss: 0.048943\n",
      "iteration: 3070 | loss: 0.315549\n",
      "iteration: 3071 | loss: 0.044552\n",
      "iteration: 3072 | loss: 0.065026\n",
      "iteration: 3073 | loss: 0.045079\n",
      "iteration: 3074 | loss: 0.259982\n",
      "  Train acc: 0.98, Val acc: 0.5\n",
      "iteration: 3075 | loss: 0.031088\n",
      "iteration: 3076 | loss: 0.103165\n",
      "iteration: 3077 | loss: 0.072886\n",
      "iteration: 3078 | loss: 0.103004\n",
      "iteration: 3079 | loss: 0.150596\n",
      "iteration: 3080 | loss: 0.113014\n",
      "iteration: 3081 | loss: 0.059082\n",
      "iteration: 3082 | loss: 0.136303\n",
      "iteration: 3083 | loss: 0.259132\n",
      "iteration: 3084 | loss: 0.135591\n",
      "iteration: 3085 | loss: 0.042201\n",
      "iteration: 3086 | loss: 0.098795\n",
      "iteration: 3087 | loss: 0.089474\n",
      "iteration: 3088 | loss: 0.018928\n",
      "iteration: 3089 | loss: 0.013108\n",
      "iteration: 3090 | loss: 0.167850\n",
      "iteration: 3091 | loss: 0.097825\n",
      "iteration: 3092 | loss: 0.079419\n",
      "iteration: 3093 | loss: 0.080352\n",
      "iteration: 3094 | loss: 0.197027\n",
      "iteration: 3095 | loss: 0.218755\n",
      "iteration: 3096 | loss: 0.137282\n",
      "iteration: 3097 | loss: 0.027998\n",
      "iteration: 3098 | loss: 0.092635\n",
      "iteration: 3099 | loss: 0.080082\n",
      "  Train acc: 0.98, Val acc: 0.5\n",
      "iteration: 3100 | loss: 0.217211\n",
      "iteration: 3101 | loss: 0.207979\n",
      "iteration: 3102 | loss: 0.161230\n",
      "iteration: 3103 | loss: 0.108848\n",
      "iteration: 3104 | loss: 0.101633\n",
      "iteration: 3105 | loss: 0.040702\n",
      "iteration: 3106 | loss: 0.138330\n",
      "iteration: 3107 | loss: 0.133645\n",
      "iteration: 3108 | loss: 0.133862\n",
      "iteration: 3109 | loss: 0.101110\n",
      "iteration: 3110 | loss: 0.028718\n",
      "iteration: 3111 | loss: 0.115141\n",
      "iteration: 3112 | loss: 0.058995\n",
      "iteration: 3113 | loss: 0.031529\n",
      "iteration: 3114 | loss: 0.206420\n",
      "iteration: 3115 | loss: 0.062913\n",
      "iteration: 3116 | loss: 0.049689\n",
      "iteration: 3117 | loss: 0.264871\n",
      "iteration: 3118 | loss: 0.050648\n",
      "iteration: 3119 | loss: 0.094611\n",
      "iteration: 3120 | loss: 0.091028\n",
      "iteration: 3121 | loss: 0.008239\n",
      "iteration: 3122 | loss: 0.135269\n",
      "iteration: 3123 | loss: 0.095380\n",
      "iteration: 3124 | loss: 0.109334\n",
      "  Train acc: 0.976, Val acc: 0.5\n",
      "iteration: 3125 | loss: 0.194202\n",
      "iteration: 3126 | loss: 0.080523\n",
      "iteration: 3127 | loss: 0.036694\n",
      "iteration: 3128 | loss: 0.023897\n",
      "iteration: 3129 | loss: 0.034980\n",
      "iteration: 3130 | loss: 0.039452\n",
      "iteration: 3131 | loss: 0.029883\n",
      "iteration: 3132 | loss: 0.123829\n",
      "iteration: 3133 | loss: 0.342722\n",
      "iteration: 3134 | loss: 0.420012\n",
      "iteration: 3135 | loss: 0.068305\n",
      "iteration: 3136 | loss: 0.024253\n",
      "iteration: 3137 | loss: 0.117239\n",
      "iteration: 3138 | loss: 0.021286\n",
      "iteration: 3139 | loss: 0.019449\n",
      "iteration: 3140 | loss: 0.049260\n",
      "iteration: 3141 | loss: 0.106819\n",
      "iteration: 3142 | loss: 0.069573\n",
      "iteration: 3143 | loss: 0.168036\n",
      "iteration: 3144 | loss: 0.091495\n",
      "iteration: 3145 | loss: 0.066240\n",
      "iteration: 3146 | loss: 0.063148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3147 | loss: 0.357838\n",
      "iteration: 3148 | loss: 0.409525\n",
      "iteration: 3149 | loss: 0.099703\n",
      "  Train acc: 0.976, Val acc: 0.5\n",
      "iteration: 3150 | loss: 0.062254\n",
      "iteration: 3151 | loss: 0.054693\n",
      "iteration: 3152 | loss: 0.132148\n",
      "iteration: 3153 | loss: 0.112357\n",
      "iteration: 3154 | loss: 0.021686\n",
      "iteration: 3155 | loss: 0.240767\n",
      "iteration: 3156 | loss: 0.110199\n",
      "iteration: 3157 | loss: 0.041014\n",
      "iteration: 3158 | loss: 0.038880\n",
      "iteration: 3159 | loss: 0.010831\n",
      "iteration: 3160 | loss: 0.047534\n",
      "iteration: 3161 | loss: 0.028852\n",
      "iteration: 3162 | loss: 0.044095\n",
      "iteration: 3163 | loss: 0.094837\n",
      "iteration: 3164 | loss: 0.056282\n",
      "iteration: 3165 | loss: 0.028675\n",
      "iteration: 3166 | loss: 0.097717\n",
      "iteration: 3167 | loss: 0.104429\n",
      "iteration: 3168 | loss: 0.161337\n",
      "iteration: 3169 | loss: 0.080611\n",
      "iteration: 3170 | loss: 0.063994\n",
      "iteration: 3171 | loss: 0.008478\n",
      "iteration: 3172 | loss: 0.085122\n",
      "iteration: 3173 | loss: 0.050986\n",
      "iteration: 3174 | loss: 0.018045\n",
      "  Train acc: 0.972, Val acc: 0.5\n",
      "iteration: 3175 | loss: 0.077225\n",
      "iteration: 3176 | loss: 0.035479\n",
      "iteration: 3177 | loss: 0.063417\n",
      "iteration: 3178 | loss: 0.064857\n",
      "iteration: 3179 | loss: 0.057259\n",
      "iteration: 3180 | loss: 0.120444\n",
      "iteration: 3181 | loss: 0.068818\n",
      "iteration: 3182 | loss: 0.021018\n",
      "iteration: 3183 | loss: 0.081004\n",
      "iteration: 3184 | loss: 0.079563\n",
      "iteration: 3185 | loss: 0.044879\n",
      "iteration: 3186 | loss: 0.211062\n",
      "iteration: 3187 | loss: 0.013952\n",
      "iteration: 3188 | loss: 0.012094\n",
      "iteration: 3189 | loss: 0.038891\n",
      "iteration: 3190 | loss: 0.111440\n",
      "iteration: 3191 | loss: 0.034075\n",
      "iteration: 3192 | loss: 0.022824\n",
      "iteration: 3193 | loss: 0.127833\n",
      "iteration: 3194 | loss: 0.032825\n",
      "iteration: 3195 | loss: 0.197469\n",
      "iteration: 3196 | loss: 0.020392\n",
      "iteration: 3197 | loss: 0.031163\n",
      "iteration: 3198 | loss: 0.035983\n",
      "iteration: 3199 | loss: 0.091791\n",
      "  Train acc: 0.982, Val acc: 0.5\n",
      "iteration: 3200 | loss: 0.077934\n",
      "iteration: 3201 | loss: 0.187008\n",
      "iteration: 3202 | loss: 0.037224\n",
      "iteration: 3203 | loss: 0.051217\n",
      "iteration: 3204 | loss: 0.030467\n",
      "iteration: 3205 | loss: 0.048126\n",
      "iteration: 3206 | loss: 0.131170\n",
      "iteration: 3207 | loss: 0.141347\n",
      "iteration: 3208 | loss: 0.063220\n",
      "iteration: 3209 | loss: 0.057708\n",
      "iteration: 3210 | loss: 0.160900\n",
      "iteration: 3211 | loss: 0.049530\n",
      "iteration: 3212 | loss: 0.094022\n",
      "iteration: 3213 | loss: 0.057595\n",
      "iteration: 3214 | loss: 0.063289\n",
      "iteration: 3215 | loss: 0.081822\n",
      "iteration: 3216 | loss: 0.058806\n",
      "iteration: 3217 | loss: 0.018698\n",
      "iteration: 3218 | loss: 0.037827\n",
      "iteration: 3219 | loss: 0.006611\n",
      "iteration: 3220 | loss: 0.011917\n",
      "iteration: 3221 | loss: 0.034443\n",
      "iteration: 3222 | loss: 0.051163\n",
      "iteration: 3223 | loss: 0.067684\n",
      "iteration: 3224 | loss: 0.047351\n",
      "  Train acc: 0.996, Val acc: 0.5\n",
      "iteration: 3225 | loss: 0.046721\n",
      "iteration: 3226 | loss: 0.104657\n",
      "iteration: 3227 | loss: 0.027300\n",
      "iteration: 3228 | loss: 0.031419\n",
      "iteration: 3229 | loss: 0.013074\n",
      "iteration: 3230 | loss: 0.058091\n",
      "iteration: 3231 | loss: 0.045358\n",
      "iteration: 3232 | loss: 0.015103\n",
      "iteration: 3233 | loss: 0.133073\n",
      "iteration: 3234 | loss: 0.095342\n",
      "iteration: 3235 | loss: 0.045064\n",
      "iteration: 3236 | loss: 0.019272\n",
      "iteration: 3237 | loss: 0.037909\n",
      "iteration: 3238 | loss: 0.121326\n",
      "iteration: 3239 | loss: 0.023484\n",
      "iteration: 3240 | loss: 0.027619\n",
      "iteration: 3241 | loss: 0.214508\n",
      "iteration: 3242 | loss: 0.054010\n",
      "iteration: 3243 | loss: 0.078653\n",
      "iteration: 3244 | loss: 0.082774\n",
      "iteration: 3245 | loss: 0.057012\n",
      "iteration: 3246 | loss: 0.158313\n",
      "iteration: 3247 | loss: 0.162739\n",
      "iteration: 3248 | loss: 0.035585\n",
      "iteration: 3249 | loss: 0.030240\n",
      "  Train acc: 0.992, Val acc: 0.5\n",
      "iteration: 3250 | loss: 0.045568\n",
      "iteration: 3251 | loss: 0.171932\n",
      "iteration: 3252 | loss: 0.058397\n",
      "iteration: 3253 | loss: 0.135060\n",
      "iteration: 3254 | loss: 0.015940\n",
      "iteration: 3255 | loss: 0.010772\n",
      "iteration: 3256 | loss: 0.037314\n",
      "iteration: 3257 | loss: 0.336451\n",
      "iteration: 3258 | loss: 0.031499\n",
      "iteration: 3259 | loss: 0.065269\n",
      "iteration: 3260 | loss: 0.195619\n",
      "iteration: 3261 | loss: 0.040074\n",
      "iteration: 3262 | loss: 0.023548\n",
      "iteration: 3263 | loss: 0.036255\n",
      "iteration: 3264 | loss: 0.167746\n",
      "iteration: 3265 | loss: 0.061492\n",
      "iteration: 3266 | loss: 0.086462\n",
      "iteration: 3267 | loss: 0.175780\n",
      "iteration: 3268 | loss: 0.053319\n",
      "iteration: 3269 | loss: 0.094413\n",
      "iteration: 3270 | loss: 0.108143\n",
      "iteration: 3271 | loss: 0.034376\n",
      "iteration: 3272 | loss: 0.030366\n",
      "iteration: 3273 | loss: 0.010220\n",
      "iteration: 3274 | loss: 0.056181\n",
      "  Train acc: 0.984, Val acc: 0.5\n",
      "iteration: 3275 | loss: 0.084987\n",
      "iteration: 3276 | loss: 0.049971\n",
      "iteration: 3277 | loss: 0.124529\n",
      "iteration: 3278 | loss: 0.119923\n",
      "iteration: 3279 | loss: 0.055911\n",
      "iteration: 3280 | loss: 0.098217\n",
      "iteration: 3281 | loss: 0.369788\n",
      "iteration: 3282 | loss: 0.042028\n",
      "iteration: 3283 | loss: 0.089694\n",
      "iteration: 3284 | loss: 0.088106\n",
      "iteration: 3285 | loss: 0.101542\n",
      "iteration: 3286 | loss: 0.024541\n",
      "iteration: 3287 | loss: 0.066608\n",
      "iteration: 3288 | loss: 0.199333\n",
      "iteration: 3289 | loss: 0.040743\n",
      "iteration: 3290 | loss: 0.101680\n",
      "iteration: 3291 | loss: 0.037490\n",
      "iteration: 3292 | loss: 0.030567\n",
      "iteration: 3293 | loss: 0.044888\n",
      "iteration: 3294 | loss: 0.012217\n",
      "iteration: 3295 | loss: 0.088536\n",
      "iteration: 3296 | loss: 0.255462\n",
      "iteration: 3297 | loss: 0.175849\n",
      "iteration: 3298 | loss: 0.132528\n",
      "iteration: 3299 | loss: 0.072849\n",
      "  Train acc: 0.974, Val acc: 0.5\n",
      "iteration: 3300 | loss: 0.114437\n",
      "iteration: 3301 | loss: 0.022046\n",
      "iteration: 3302 | loss: 0.053223\n",
      "iteration: 3303 | loss: 0.055335\n",
      "iteration: 3304 | loss: 0.022422\n",
      "iteration: 3305 | loss: 0.033798\n",
      "iteration: 3306 | loss: 0.031418\n",
      "iteration: 3307 | loss: 0.045913\n",
      "iteration: 3308 | loss: 0.088443\n",
      "iteration: 3309 | loss: 0.031699\n",
      "iteration: 3310 | loss: 0.087217\n",
      "iteration: 3311 | loss: 0.025109\n",
      "iteration: 3312 | loss: 0.115491\n",
      "iteration: 3313 | loss: 0.093747\n",
      "iteration: 3314 | loss: 0.015630\n",
      "iteration: 3315 | loss: 0.034172\n",
      "iteration: 3316 | loss: 0.085603\n",
      "iteration: 3317 | loss: 0.087562\n",
      "iteration: 3318 | loss: 0.063733\n",
      "iteration: 3319 | loss: 0.161590\n",
      "iteration: 3320 | loss: 0.053511\n",
      "iteration: 3321 | loss: 0.105085\n",
      "iteration: 3322 | loss: 0.063572\n",
      "iteration: 3323 | loss: 0.030870\n",
      "iteration: 3324 | loss: 0.153938\n",
      "  Train acc: 0.98, Val acc: 0.5\n",
      "iteration: 3325 | loss: 0.033243\n",
      "iteration: 3326 | loss: 0.053274\n",
      "iteration: 3327 | loss: 0.015520\n",
      "iteration: 3328 | loss: 0.065305\n",
      "iteration: 3329 | loss: 0.098456\n",
      "iteration: 3330 | loss: 0.040306\n",
      "iteration: 3331 | loss: 0.161571\n",
      "iteration: 3332 | loss: 0.018630\n",
      "iteration: 3333 | loss: 0.019018\n",
      "iteration: 3334 | loss: 0.056901\n",
      "iteration: 3335 | loss: 0.040816\n",
      "iteration: 3336 | loss: 0.031017\n",
      "iteration: 3337 | loss: 0.040373\n",
      "iteration: 3338 | loss: 0.146065\n",
      "iteration: 3339 | loss: 0.036340\n",
      "iteration: 3340 | loss: 0.058773\n",
      "iteration: 3341 | loss: 0.036924\n",
      "iteration: 3342 | loss: 0.034072\n",
      "iteration: 3343 | loss: 0.010256\n",
      "iteration: 3344 | loss: 0.057241\n",
      "iteration: 3345 | loss: 0.014595\n",
      "iteration: 3346 | loss: 0.023115\n",
      "iteration: 3347 | loss: 0.077165\n",
      "iteration: 3348 | loss: 0.090853\n",
      "iteration: 3349 | loss: 0.136685\n",
      "  Train acc: 0.988, Val acc: 0.5\n",
      "iteration: 3350 | loss: 0.299668\n",
      "iteration: 3351 | loss: 0.035629\n",
      "iteration: 3352 | loss: 0.064596\n",
      "iteration: 3353 | loss: 0.015363\n",
      "iteration: 3354 | loss: 0.016795\n",
      "iteration: 3355 | loss: 0.133531\n",
      "iteration: 3356 | loss: 0.027388\n",
      "iteration: 3357 | loss: 0.131165\n",
      "iteration: 3358 | loss: 0.035256\n",
      "iteration: 3359 | loss: 0.077042\n",
      "iteration: 3360 | loss: 0.052427\n",
      "iteration: 3361 | loss: 0.023107\n",
      "iteration: 3362 | loss: 0.150811\n",
      "iteration: 3363 | loss: 0.074544\n",
      "iteration: 3364 | loss: 0.236891\n",
      "iteration: 3365 | loss: 0.139425\n",
      "iteration: 3366 | loss: 0.107940\n",
      "iteration: 3367 | loss: 0.033417\n",
      "iteration: 3368 | loss: 0.017499\n",
      "iteration: 3369 | loss: 0.077021\n",
      "iteration: 3370 | loss: 0.017432\n",
      "iteration: 3371 | loss: 0.132822\n",
      "iteration: 3372 | loss: 0.036014\n",
      "iteration: 3373 | loss: 0.024429\n",
      "iteration: 3374 | loss: 0.042422\n",
      "  Train acc: 0.978, Val acc: 0.5\n",
      "iteration: 3375 | loss: 0.021297\n",
      "iteration: 3376 | loss: 0.045696\n",
      "iteration: 3377 | loss: 0.095005\n",
      "iteration: 3378 | loss: 0.031374\n",
      "iteration: 3379 | loss: 0.052874\n",
      "iteration: 3380 | loss: 0.056706\n",
      "iteration: 3381 | loss: 0.031125\n",
      "iteration: 3382 | loss: 0.191142\n",
      "iteration: 3383 | loss: 0.043808\n",
      "iteration: 3384 | loss: 0.160159\n",
      "iteration: 3385 | loss: 0.051818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3386 | loss: 0.049779\n",
      "iteration: 3387 | loss: 0.364786\n",
      "iteration: 3388 | loss: 0.043309\n",
      "iteration: 3389 | loss: 0.033863\n",
      "iteration: 3390 | loss: 0.149042\n",
      "iteration: 3391 | loss: 0.164943\n",
      "iteration: 3392 | loss: 0.086307\n",
      "iteration: 3393 | loss: 0.023830\n",
      "iteration: 3394 | loss: 0.036183\n",
      "iteration: 3395 | loss: 0.038619\n",
      "iteration: 3396 | loss: 0.056037\n",
      "iteration: 3397 | loss: 0.165476\n",
      "iteration: 3398 | loss: 0.170576\n",
      "iteration: 3399 | loss: 0.066616\n",
      "  Train acc: 0.986, Val acc: 0.5\n",
      "iteration: 3400 | loss: 0.099763\n",
      "iteration: 3401 | loss: 0.024965\n",
      "iteration: 3402 | loss: 0.005055\n",
      "iteration: 3403 | loss: 0.065314\n",
      "iteration: 3404 | loss: 0.020606\n",
      "iteration: 3405 | loss: 0.035851\n",
      "iteration: 3406 | loss: 0.072253\n",
      "iteration: 3407 | loss: 0.043185\n",
      "iteration: 3408 | loss: 0.050734\n",
      "iteration: 3409 | loss: 0.090917\n",
      "iteration: 3410 | loss: 0.160395\n",
      "iteration: 3411 | loss: 0.029856\n",
      "iteration: 3412 | loss: 0.033559\n",
      "iteration: 3413 | loss: 0.060195\n",
      "iteration: 3414 | loss: 0.046950\n",
      "iteration: 3415 | loss: 0.119942\n",
      "iteration: 3416 | loss: 0.039099\n",
      "iteration: 3417 | loss: 0.072063\n",
      "iteration: 3418 | loss: 0.031489\n",
      "iteration: 3419 | loss: 0.020329\n",
      "iteration: 3420 | loss: 0.022770\n",
      "iteration: 3421 | loss: 0.024826\n",
      "iteration: 3422 | loss: 0.069794\n",
      "iteration: 3423 | loss: 0.060605\n",
      "iteration: 3424 | loss: 0.046908\n",
      "  Train acc: 0.994, Val acc: 0.5\n",
      "iteration: 3425 | loss: 0.044874\n",
      "iteration: 3426 | loss: 0.064827\n",
      "iteration: 3427 | loss: 0.031033\n",
      "iteration: 3428 | loss: 0.033149\n",
      "iteration: 3429 | loss: 0.034454\n",
      "iteration: 3430 | loss: 0.092580\n",
      "iteration: 3431 | loss: 0.024420\n",
      "iteration: 3432 | loss: 0.023025\n",
      "iteration: 3433 | loss: 0.234061\n",
      "iteration: 3434 | loss: 0.059295\n",
      "iteration: 3435 | loss: 0.069099\n",
      "iteration: 3436 | loss: 0.022225\n",
      "iteration: 3437 | loss: 0.018314\n",
      "iteration: 3438 | loss: 0.208534\n",
      "iteration: 3439 | loss: 0.043425\n",
      "iteration: 3440 | loss: 0.029941\n",
      "iteration: 3441 | loss: 0.030053\n",
      "iteration: 3442 | loss: 0.083238\n",
      "iteration: 3443 | loss: 0.026496\n",
      "iteration: 3444 | loss: 0.082362\n",
      "iteration: 3445 | loss: 0.042037\n",
      "iteration: 3446 | loss: 0.038933\n",
      "iteration: 3447 | loss: 0.089424\n",
      "iteration: 3448 | loss: 0.023223\n",
      "iteration: 3449 | loss: 0.036863\n",
      "  Train acc: 0.99, Val acc: 0.5\n",
      "iteration: 3450 | loss: 0.015858\n",
      "iteration: 3451 | loss: 0.024982\n",
      "iteration: 3452 | loss: 0.012472\n",
      "iteration: 3453 | loss: 0.032929\n",
      "iteration: 3454 | loss: 0.010373\n",
      "iteration: 3455 | loss: 0.017913\n",
      "iteration: 3456 | loss: 0.071611\n",
      "iteration: 3457 | loss: 0.031930\n",
      "iteration: 3458 | loss: 0.056274\n",
      "iteration: 3459 | loss: 0.043731\n",
      "iteration: 3460 | loss: 0.033165\n",
      "iteration: 3461 | loss: 0.028737\n",
      "iteration: 3462 | loss: 0.024575\n",
      "iteration: 3463 | loss: 0.064454\n",
      "iteration: 3464 | loss: 0.007124\n",
      "iteration: 3465 | loss: 0.019001\n",
      "iteration: 3466 | loss: 0.036553\n",
      "iteration: 3467 | loss: 0.039380\n",
      "iteration: 3468 | loss: 0.019605\n",
      "iteration: 3469 | loss: 0.029782\n",
      "iteration: 3470 | loss: 0.127749\n",
      "iteration: 3471 | loss: 0.018396\n",
      "iteration: 3472 | loss: 0.059392\n",
      "iteration: 3473 | loss: 0.038547\n",
      "iteration: 3474 | loss: 0.031323\n",
      "  Train acc: 0.98, Val acc: 0.5\n",
      "iteration: 3475 | loss: 0.080931\n",
      "iteration: 3476 | loss: 0.085030\n",
      "iteration: 3477 | loss: 0.022731\n",
      "iteration: 3478 | loss: 0.036231\n",
      "iteration: 3479 | loss: 0.386957\n",
      "iteration: 3480 | loss: 0.011054\n",
      "iteration: 3481 | loss: 0.028210\n",
      "iteration: 3482 | loss: 0.032271\n",
      "iteration: 3483 | loss: 0.051760\n",
      "iteration: 3484 | loss: 0.004620\n",
      "iteration: 3485 | loss: 0.064642\n",
      "iteration: 3486 | loss: 0.131919\n",
      "iteration: 3487 | loss: 0.072021\n",
      "iteration: 3488 | loss: 0.045300\n",
      "iteration: 3489 | loss: 0.035853\n",
      "iteration: 3490 | loss: 0.067467\n",
      "iteration: 3491 | loss: 0.050319\n",
      "iteration: 3492 | loss: 0.035221\n",
      "iteration: 3493 | loss: 0.024405\n",
      "iteration: 3494 | loss: 0.064058\n",
      "iteration: 3495 | loss: 0.011562\n",
      "iteration: 3496 | loss: 0.013946\n",
      "iteration: 3497 | loss: 0.037733\n",
      "iteration: 3498 | loss: 0.017384\n",
      "iteration: 3499 | loss: 0.062318\n",
      "  Train acc: 0.986, Val acc: 0.5\n",
      "iteration: 3500 | loss: 0.044578\n",
      "iteration: 3501 | loss: 0.036011\n",
      "iteration: 3502 | loss: 0.030898\n",
      "iteration: 3503 | loss: 0.084598\n",
      "iteration: 3504 | loss: 0.031255\n",
      "iteration: 3505 | loss: 0.051818\n",
      "iteration: 3506 | loss: 0.031203\n",
      "iteration: 3507 | loss: 0.070710\n",
      "iteration: 3508 | loss: 0.003316\n",
      "iteration: 3509 | loss: 0.034246\n",
      "iteration: 3510 | loss: 0.254756\n",
      "iteration: 3511 | loss: 0.033089\n",
      "iteration: 3512 | loss: 0.092866\n",
      "iteration: 3513 | loss: 0.028561\n",
      "iteration: 3514 | loss: 0.109668\n",
      "iteration: 3515 | loss: 0.049148\n",
      "iteration: 3516 | loss: 0.032949\n",
      "iteration: 3517 | loss: 0.033461\n",
      "iteration: 3518 | loss: 0.010951\n",
      "iteration: 3519 | loss: 0.017233\n",
      "iteration: 3520 | loss: 0.018517\n",
      "iteration: 3521 | loss: 0.155958\n",
      "iteration: 3522 | loss: 0.015462\n",
      "iteration: 3523 | loss: 0.021613\n",
      "iteration: 3524 | loss: 0.004770\n",
      "  Train acc: 0.982, Val acc: 0.5\n",
      "iteration: 3525 | loss: 0.010662\n",
      "iteration: 3526 | loss: 0.021850\n",
      "iteration: 3527 | loss: 0.080888\n",
      "iteration: 3528 | loss: 0.038399\n",
      "iteration: 3529 | loss: 0.043844\n",
      "iteration: 3530 | loss: 0.035575\n",
      "iteration: 3531 | loss: 0.022938\n",
      "iteration: 3532 | loss: 0.015667\n",
      "iteration: 3533 | loss: 0.128611\n",
      "iteration: 3534 | loss: 0.043270\n",
      "iteration: 3535 | loss: 0.018267\n",
      "iteration: 3536 | loss: 0.041437\n",
      "iteration: 3537 | loss: 0.060463\n",
      "iteration: 3538 | loss: 0.012558\n",
      "iteration: 3539 | loss: 0.010290\n",
      "iteration: 3540 | loss: 0.074734\n",
      "iteration: 3541 | loss: 0.040619\n",
      "iteration: 3542 | loss: 0.010588\n",
      "iteration: 3543 | loss: 0.024988\n",
      "iteration: 3544 | loss: 0.060433\n",
      "iteration: 3545 | loss: 0.004805\n",
      "iteration: 3546 | loss: 0.007468\n",
      "iteration: 3547 | loss: 0.040317\n",
      "iteration: 3548 | loss: 0.017070\n",
      "iteration: 3549 | loss: 0.005570\n",
      "  Train acc: 0.986, Val acc: 0.5\n",
      "iteration: 3550 | loss: 0.055770\n",
      "iteration: 3551 | loss: 0.028326\n",
      "iteration: 3552 | loss: 0.050378\n",
      "iteration: 3553 | loss: 0.015633\n",
      "iteration: 3554 | loss: 0.050030\n",
      "iteration: 3555 | loss: 0.022111\n",
      "iteration: 3556 | loss: 0.028280\n",
      "iteration: 3557 | loss: 0.019398\n",
      "iteration: 3558 | loss: 0.033635\n",
      "iteration: 3559 | loss: 0.018160\n",
      "iteration: 3560 | loss: 0.005396\n",
      "iteration: 3561 | loss: 0.015994\n",
      "iteration: 3562 | loss: 0.011703\n",
      "iteration: 3563 | loss: 0.010061\n",
      "iteration: 3564 | loss: 0.007176\n",
      "iteration: 3565 | loss: 0.042991\n",
      "iteration: 3566 | loss: 0.005716\n",
      "iteration: 3567 | loss: 0.013073\n",
      "iteration: 3568 | loss: 0.011642\n",
      "iteration: 3569 | loss: 0.008758\n",
      "iteration: 3570 | loss: 0.019550\n",
      "iteration: 3571 | loss: 0.019605\n",
      "iteration: 3572 | loss: 0.005889\n",
      "iteration: 3573 | loss: 0.007142\n",
      "iteration: 3574 | loss: 0.065600\n",
      "  Train acc: 0.998, Val acc: 0.5\n",
      "iteration: 3575 | loss: 0.018933\n",
      "iteration: 3576 | loss: 0.015069\n",
      "iteration: 3577 | loss: 0.006273\n",
      "iteration: 3578 | loss: 0.018370\n",
      "iteration: 3579 | loss: 0.015394\n",
      "iteration: 3580 | loss: 0.092234\n",
      "iteration: 3581 | loss: 0.009206\n",
      "iteration: 3582 | loss: 0.010040\n",
      "iteration: 3583 | loss: 0.029676\n",
      "iteration: 3584 | loss: 0.011426\n",
      "iteration: 3585 | loss: 0.020246\n",
      "iteration: 3586 | loss: 0.049687\n",
      "iteration: 3587 | loss: 0.010586\n",
      "iteration: 3588 | loss: 0.035134\n",
      "iteration: 3589 | loss: 0.020278\n",
      "iteration: 3590 | loss: 0.013304\n",
      "iteration: 3591 | loss: 0.035146\n",
      "iteration: 3592 | loss: 0.020682\n",
      "iteration: 3593 | loss: 0.037086\n",
      "iteration: 3594 | loss: 0.015574\n",
      "iteration: 3595 | loss: 0.009707\n",
      "iteration: 3596 | loss: 0.008714\n",
      "iteration: 3597 | loss: 0.032697\n",
      "iteration: 3598 | loss: 0.022808\n",
      "iteration: 3599 | loss: 0.012138\n",
      "  Train acc: 0.994, Val acc: 0.5\n",
      "iteration: 3600 | loss: 0.018131\n",
      "iteration: 3601 | loss: 0.008607\n",
      "iteration: 3602 | loss: 0.021515\n",
      "iteration: 3603 | loss: 0.044186\n",
      "iteration: 3604 | loss: 0.006088\n",
      "iteration: 3605 | loss: 0.011255\n",
      "iteration: 3606 | loss: 0.069136\n",
      "iteration: 3607 | loss: 0.035727\n",
      "iteration: 3608 | loss: 0.042387\n",
      "iteration: 3609 | loss: 0.009857\n",
      "iteration: 3610 | loss: 0.035743\n",
      "iteration: 3611 | loss: 0.010257\n",
      "iteration: 3612 | loss: 0.005490\n",
      "iteration: 3613 | loss: 0.007915\n",
      "iteration: 3614 | loss: 0.013040\n",
      "iteration: 3615 | loss: 0.019385\n",
      "iteration: 3616 | loss: 0.021753\n",
      "iteration: 3617 | loss: 0.012253\n",
      "iteration: 3618 | loss: 0.016722\n",
      "iteration: 3619 | loss: 0.006287\n"
     ]
    }
   ],
   "source": [
    "from network import convNet4AccelBigKernels\n",
    "adam_big_ker_accel = convNet4AccelBigKernels(input_shape=(3, 32, 32), wt_scale=1e-2, verbose=False)\n",
    "adam_big_ker_accel.compile(\"Adam\")\n",
    "adam_big_ker_accel.fit(x_train, y_train, x_val, y_val, mini_batch_sz=25, n_epochs=20, acc_freq=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5025"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam_big_ker_accel.accuracy(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_weights(adam_big_ker_accel.layers[0].wts.transpose(0, 2, 3, 1), saveFig=False, filename='convWts_adam_train_20epoch.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_3 = [a for i, a in enumerate(adam_small_ker_accel.loss_history) if i%50==0]\n",
    "loss_7 = [a for i, a in enumerate(adam_net_accel.loss_history) if i%50==0]\n",
    "loss_9 = [a for i, a in enumerate(adam_big_ker_accel.loss_history) if i%50==0]\n",
    "plt.plot(loss_3, label='3x3')\n",
    "plt.plot(loss_7, label='7x7')\n",
    "plt.plot(loss_9, label='9x9')\n",
    "\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss of Different Kernel Sizes\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(adam_small_ker_accel.train_acc_history, label='3x3')\n",
    "plt.plot(adam_net_accel.train_acc_history, label='7x7')\n",
    "plt.plot(adam_big_ker_accel.train_acc_history, label='9x9')\n",
    "\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Train Accuracy Over Time\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Dream Images(???)\n",
    "\n",
    "For this extension we implemented something similar the dream like backprop into the image, emphasizing parts of the image that would result in it being classified as a particular class. To do this, I implemented a forward pass, followed by a complete backward pass, taking the upstream gradients for the image. This gradient can be considered to be the impact of each pixel on the final output of the image. Thus, by choosing a y one hot vector of our choice from our STL-10 data set, we can try to make our images look more like they belong to that class. Unfortunately, the data our model is trained on is very pixilated and it is tough for us to see good clear results. However, there are some recognizable ones such as when we try to make an aeroplane, most diagonal lines are emphasized (partially seen in images 2 & 9) and the presence of windows can be seen to start moving toward the shape of a cockpit (this can clearly be seen in image 6 below) while the rest of the image starts to get blurry.\n",
    "\n",
    "One difference in this implementation than the one we considered in class was that we did gradient descent as opposed to gradient ascent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAIuCAYAAACy+nJwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOy9Z5RlaX2fu/fJsU7lrtTd1TlMx8nTPXmGAQSDhEFCCEsoB0u6lmTLWtfLFrasK8uyLYsrWQYMQgEhAQI0ZJiBCTB5eqZzDlVdOVedHPbZ+365Wv7w/F0LrXXXotj393z89Tlnp3e/5+1az/4dNwiCwBFCCCGECBGR7/UOCCGEEEL8f40WOEIIIYQIHVrgCCGEECJ0aIEjhBBCiNChBY4QQgghQocWOEIIIYQIHbH1/vHbX/0vyF45dwJZbusIsq0RH9laMY1sONuDbMVtIvPiZWS9Eb733JlLyHbu7eDntbgvLY/rvfqahyzZw+OttQvIto7sQFatV5GVV15GNrZ0EdmRwh5kE602stt2DXC7bhxZaW0e2Ydf+itkP3DrjyGbKl5F9pP7H0F24voZZGdfW+H+NUrI/t0H/wLZ9xq/zvFwJfgQspqzjGx/8EvIon6fsZXvrrnBfJUZ8l50HNd4K193Jfo7yEqrHHPNBrfQdrkzzWYK2cOD/9bYve+yvcJ8GY/NZWTym3/E4y2XeZ/0dfJcrVY5b1nnyo0uIvNnOV6qAXf6s3/7PLLvNTde+BNk0WQCWSyeROYG/AqqtyrIEjF+XiQa5edZ/2c3Ln7EGOuuy88LfN7vrXaLnxfh/BqNMWt5fK/PIeJEjIEdGMfrtDnmEgneY0HA43ACnoPA53Y9jztYraxxu1Eeb61eQ+bXOFk06pz/63W+bmlmBtnjv/lpZP+A/oIjhBBCiNChBY4QQgghQocWOEIIIYQIHVrgCCGEECJ0rCsZnx+j6Lp5lILtnq5hZNPzFPNuv+UIsplFvi6gT+ysrFBWcnqnEA32ZZG1Gp3IJpcMYSuSR7Rv13ZkXkBRrDY9iezyuZeQNVp8b3eB56+Qoij88iwF74QhhV0cROScmHgdWU+aYvTbR9/G7b78GrJ2hALY1yPcxrWpC8hyWcrXm7p7kW1E2k0Ki9v8X+DrDEmwbfzsWzugJGias9+lJWv/tNx3J+xam+gKeK28zByyZqPOrMIPbHnclxlvDFl3MGTs33d7Dpi5hrRsfVqkMo2sq8aHFL72lS8i+/e/cBzZR1+4jiy9k8LnTz/8KLLf+v0/N/ZwA+Ly/8mWsOv4fJ3n8FxEDFm1bcxz9SbHXMwQe92oIdTX+N5alXJzYEjB0azxHdPifNjRvYnvdY2v3Chl37YhMjfKq8iyHfxua7uGGN3i8bZbfF0sTpm75fG90QRf5xv3ZzTGcdA2jjeZoRhdrXIhkEzz+q6H/oIjhBBCiNChBY4QQgghQocWOEIIIYQIHVrgCCGEECJ0rCsZb9u0D9ngSDcyf5UCcKqQQ/b81aeQ7ezehWxikWLe/s2jyIpFth8mCxQCV1m66Lz28ovIXnjyVWSbhrcgu3id8nVPnoLy/qMUlO+99wFk4xOU20a30BQu9OxG1r15M7Jvn/gEsru37UWW7+hCdmN5Cdn/8Z53I/v4338O2fLiNWRbYgeRfeqpryG74+hOZBuRplHZa2q9hhRpC8BWo/B32eJr8V029poec4Rv9v2tyErNK8jKdYqInkeZsNWgTPjS2Q8j69vEsZ7Pc192Ru9GZmGd+89887PIpq7eRDY6cheyiMv7/YNPcLv9A3ciqze/guxXf5f7UjHaoTciVuNs0mhOr7UoyToR/h/bagVuG43CiRTb6NtGs7tryM1OlFlgCMoRI7t6iWNk7y2cvyxR2DcahZN5fscUp04ic412aN/4G0XQ5lj3A0P6tsT7GNumA6PJ2G0bbebG3Niocl6w5je/yc9LZKxfG+A5XQ/9BUcIIYQQoUMLHCGEEEKEDi1whBBCCBE6tMARQgghROhYVzJebtxA1l7gmqhdoyRbSlAuyhfYVhtJU2o6uHkPsqXieWSH9zyI7PoY240rHgWrLTsOI5ueocA0u0Lp9tG3/BD3b4LiWSxFUfja5AqyOw6yLTaSpMQ4OcaWVS9JaTMT43bHjOPoWOJ1my0vIvtSlaJd3Di2cpnNkyMHKd/lU5TlSqtVZBuRltH+aRm7hmNsVuwGDuW6KZcSaj7geM07FMxtKA+bpcDcFWcxxvupVJ9FVjNOS6XCOaBVNcRGnw8kNCZOIevI897Zuvk2ZJ959aPITrzyZWQDTcqdm7u4L69c+BKybA8F6uLsOWTVCue3nq08B4tLPKfdvRlkG5FPfpHj1Ylwzg2MdmPP56CLJvi15PpGS67xurTRxJtMGCJ/m9fPa7BV3BKoUx6vaXGe98mMIUanYpyv77v1ELILp/jAi/H15GTj3JeFlWVkbpKvSxgtw9U697mrk+MwabRXB02+d3qcDf8rK/zeqdZ5cHu3swk6nuC98xCS/4X+giOEEEKI0KEFjhBCCCFChxY4QgghhAgdWuAIIYQQInSsKxkPZyjhnZ++iiwapaw0sTSD7I49R5D5bQpM12fZMpzqKCA7ff1ZZDdn2WRcXKRgdfn6OLIDd7AVdXuZQlTckNsKPT3IknEKUYcPHUAWMVo1C4bsuHnzm5AVy2wHfeHyN5Ad7KLg/dxNNtK++yBbW0+W55Ed7s8iO79IUezR7Twv/2mWnxePfn8IlW2jwdMqKDbbiI2oEqX8ffrmV5FVy2x/DiIch2/Z9XvIUg7Hv/V/G9/YwStrHEv1OhvE6xVK4k1DHKwUKXzWShwPsYDjId3B152//ByyqUm+zpJ4Dw0fQ/b0ua8j8xtsavcYORM3ODfmetgW3jXK8/Lm+7YhWyt/f1QZV4w5MppkC60T4fgqdHBstup8WCGa4OviUY6lRISia2A0I3ttfmdFjWbkiCHer65Snl+och5eXOJ9kstx3hyI8zq7hnw9dvIMsm1Hb0FWMH5FYH5+AZmT4euigXHPrlC+dhM8V0trRWRUuR1nsIf39tQq58FKg+e5uPKPuyf0FxwhhBBChA4tcIQQQggROrTAEUIIIUTo0AJHCCGEEKFjXcm4mub6J5WmnNUbp6zk1DsRLUxfQzZ6y3Zk8Q5+3j3b7kP2qZN/x/0ztts0mlxb9KYc4wflnUSKglrbpzr18T//GLL3/OiPIrt6/TqyVIrtlvEkGzmtX4qPGqLdvhE2QT9/8pvI9mwZRjbXoqD5pVefQraSoiy9Zy/Py9NX2MhZXVtDNp+eQLYRCaw2YiOzmoz9CAW5F6f/ANnaMq99vU7pMOJSvPz7k7+DbO/utyOLxvh5E7N/jyxIstk6CCiV1lvMykUKn7Ui97lSNtps48Y2VvkAQXmNQurqEs/zaNdRZNdnKNlncpSClxcpkI4O9/O9Ed6L/cbrungYjhvn7BPLGzf8BiTdzTk3bvzXueUzLBZpa7eN96aNBzGaDs9PscJsdGgA2WqdUuvRXQeRjc+yPXuszdb6ijHmeob4YEwmzu+TF07yFwP8Hg6S7O7dyCYWeZ806xyv0SjvRTfgfN2wmow7KAW3jHbodJbHVjXmxpahHhey/M73jW/kroz1wMT/Hv0FRwghhBChQwscIYQQQoQOLXCEEEIIETq0wBFCCCFE6FhXMt7TvxNZwmhFvXztArKmS7mo0qQQ6DlsQN03sh/Z9SKbhx85wB9Kf/EEJdlEi/ty/NhxZLEo2xkzHWziHR+7jGxomMLuG6dOIBvZ8jiyuWVKYTuMn6OPJygjx4z22WSCgtrOgR3IlpaWkY1HLyI7NkBp+atvsEHWL/B61OdeQPbgmx9AdvMaRbuNiBd5HVnJkOEmg5eRLS6zTbdc4vivGwK8ZzSq+i0KlekcRb+r459FFjNcvUic8rfvsU207VGo9HzuS6NFEbFc5sHVa3xdvEkRsZXg/LFWZFat85zuyFMejjgUSKcnOH/0944gm5njuTKeZXCySd7HLRbcOksLlOyvW6buBmRizmh6djhgky6/bnzjGNs1jrlYiic3n2UrsNfm+CpV+Hn9faPInjtL6XxzH+e+hTofFEmkKcleuEhBf7SH43otSUk7WOU9Vl9mU7BrDLq6MVlEPKNTeI6flzRE8GqN+xIE3IbxTJLT3UXRumE0FMeMVnavwvblSILz23p8f9xBQgghhBD/CLTAEUIIIUTo0AJHCCGEEKFDCxwhhBBChI51JeM3bryGrNFmc2LOaN29NjGNrDBKmcr1KOtVavy8k0uvINtT2IdsbJzibGA0vlbLbGzcvedWZOcunEVWKFBuu/PYPciuXaGw6xpNlhGjpfPmTUqHPd0UJXM5CsV9lVFkUxE2Cq80aTtOGuWp+wZ5/vZNUkDPFPjmW7beheyjX/00P+/oFm54A3LTnUQ2uUrpsGmc27UlSnOlMs9ZYIh+gVHvGo0Z4qBDydI1xpfj8nVN49o3GrwXa1W+t1XnVNKoUICMGvuSMITnhiFQB01uN3B5Drw2pden36DwX6lRsqwY1+NtR/gAQXaBO715ZDOySIIPLjz/zLPI5lb5oEFsxyZkG5FyyWgjNpqyF+p8XdwQ9K2HKZIORVff5fhKGYNpeJhz1eG9zPoa30LW2cfvu6tnKck6vZyHb7lrL7J2i+PVNZ4q8I2239Yqpfhai+c5FuE5iMT5MEraaM92jO02jQdemoZ43IzwdYsrnAetucyLGK3UC7wnuvv5Hbge+guOEEIIIUKHFjhCCCGECB1a4AghhBAidGiBI4QQQojQsa5k3G3If5mOu5EtdY4hW0lSGuo05KdXxk8jy3dRMuvLs1F41pA2kylu48w5NlTevHYV2ZPf+jqygUGKgwMDg8hy+TxfN8TXra5Qqm40KGwVq5Tbzp3muTp45DCyjPHT847Pduhsgtv4+bveiuxb42wtXt1BCTqyQHH7cvY7yN7zq3ciu/A0BbqNyJWrbCMuVtmm2zakyHqd58c1GkF9472JFMeX7xvbDXjvOIa0bJQRO9UGRcTSCrdRLrMp2KvzOAKHQn3M8p3jlEWzGaP11hKt+XHOyfMZZB3DfG+mxXbvapwt5Scv875zqpRKl42m2T37KbMeOMR23MbrvBfraevoNh65Dp5vv2lI5y0ez7UbnMMDl+Oru4/bGN7M8VWr8L1PPs9W8R6jVX9gqBdZvrMf2TefobDezFB+PXKcD8HUapRu4ynes+k0x1cize+27l4+8BK0KQpXytyuX+N8ZDUF93ZxX5wOzhURh5/nNznR5BLGgwsNzh9bu3hO21FuYz30FxwhhBBChA4tcIQQQggROrTAEUIIIUTo0AJHCCGEEKFjXcl4aY0i1lX3dWTNRQpyHR0UhCIJbu7+4e3ITo0vIeuJUFZaSVIoS6YpMDUNo/LqBCXZTJayV81oT221me3cuQ3ZwcNsRm4ZDa31Bo8jlqCQ1zRaWytltj32dFNuftc734vs1Ck2S09dOIVsV4k/ed/KDiCL9FAE3L3GNtbf+KOPIPuZdzyMbCOyskop0mvz+vlGM2e1QtFvZIQtuR25d3K7SxTlg4DNsMUahdhqxZD/2rymK4tsaF1c5DbKxrzgGGJ0OsXxEDNaz9NZio0po802lWYr8Ef+5CaynUf7kFVLvHdKtSlkNZ/yZNOhZNmZ5hyQ66AEumxI2rEot7HjDm7j7Cqv0UZkbJLzddunNBp1eO237eHDI7EUvyeyHZyrSsu8n1ZnuC9b87wuF93nke3YRyn4E3/598gee5St9X/95AVkrQjHdckQ5Y3ncRwnZT18wM+bXuLxOi2Or1iS95MX44YjgTFvrfLeTnZwvMYdYxvGOPDaxvdsnWuIl1/hrwgEPs/BeugvOEIIIYQIHVrgCCGEECJ0aIEjhBBCiNChBY4QQgghQse6kvHACFs4L1+jZNxnNEB2RLqRvTHHRsnDI29D1tXBVtvR/tuQPXXqSWT79t+O7PL1GWTZPIVFo1TWaTQoE6YybI+cnad8WjXk4WqZ0mazTrmzt5PNtcko16OTM/PIVoo8f91rlFn37GQr9fJri3xvHyXVO6s8f6O3HET2e7//x8geuOUBZMU0j3cj4rcoNsYSHDj1Ns9jJELJMhF/C7JKeQ7Z3NwlZKk077FGg1K34/L6VcsUB1cXONaLK2znDVxDII1Qiq/VuY2YITG6Ed5PCaPy+ORLzLbfybnHaVJurrV4HG6UwmJQ4TWKBMZ58Xi85TJFyT17KVRmhjjtXn2Jc0B/xzKyjUg0wybqdIJt6jGjybhgtNYvG83gxUXOr3lDHt55kM3Djx/dhWx+zhjXcY6HA0cOIWsHfF1ngufg2sUbyHLdHJv1Cq/92irHUjTJcVO8asjIHu+xawucj/qNh3QGb9mLrLfHkuf5HVMwRObAodyfaHIO7e2mRP72N/M7v1TjeVkP/QVHCCGEEKFDCxwhhBBChA4tcIQQQggROrTAEUIIIUToWFcyvjT5ArI9g5RVFw35qddoOrw3QwE4GaOY1HAoXT0/x+bJPaNsQZ4yWjUd4/Puv+8hZC2fMuHsNJtST596FVncENQOH70T2dAgmzurhhTsRimPXb7CNtveXkPwTlPadCIUxQZ6eY3uvpXS6+uXP4/sTHUMWfEq5bFteyiP3XU35bFvPEkBfSPiGs3WjRZlWt/h+Q4M+a9W4jlbWBhDtrjIax+JUliMuhxfvtHkXa+x7bRSNBqZfQrKboRCZRAY/1eKUDBsNvl5jk+ptJAf4TYShhha5NxTqVPkd4xG1aYhHseqPKeNKMXGeMB7bPt23k9OjJ9Xzk0jW5njPh/dadzHG5BsxhCKI7wuVY+t6+0IH1boyPOcuS7l7y5Daj3cx3P23AsXkW3fyib2ixfHkRU6eU0jMaNNN8r9m7lKsffuzWynPr/Ie2J+1RjDcT6I0eIt5gxneW/XqobI7HKOGvvWK8geOL4f2bveytbnwOFxVIwHDcplzoMZYx0Qj/OebTU5XtZDf8ERQgghROjQAkcIIYQQoUMLHCGEEEKEDi1whBBCCBE61pWMNw3vQJbwDImxRknwTO00sh1RCkK1fBey/f2bkV11KOY1V7ndSIzW1ZFDbNh9+bU3kK0Z7YyNFoWofI4SXFcXjyNoUyAdH2MjZzbNz5tf4ut6h7iN5Rm2nWa3UbSrlHhs49M8p1u2sL16pO84su3beY1Oz7K5c1MXx8u5axRmb7uFY20jUl+lYFs32jprTQq7tSZlVbd1HdnU9GvIKmUKi7EY5c5okjKh16SwWClSsG0HHK9OhP8HMkqGzcZS3+W5cl2+ud7me+cbnCsarTVmHuXOVsBja1R5PaJGG3Gmg+fKNY4jcDkvLK/x/HUPULJcus57e/NRHkd1hbLoRuTYbgq7Y3OcW/IDnL8G+tm83WpzDEfqnL8SOQrAXZuGkF0vse39/ALb7csVjs2ffgsfjDl/+gKy3SM8tucvcCx96zLn61KdY6llyPiBw/kjl+U5GGtwvDoeH46oNDj+A2PIXRqnHH75KrMtAzx/QZNLjGiTkna7ZMjIMZ6XbQOGyL8O+guOEEIIIUKHFjhCCCGECB1a4AghhBAidGiBI4QQQojQsa5kXFqjhOT4c4wGKf6MJNl4/NLEKWRHV7iNRIqf99IS24N/YuevIPvqBbZWnjxzFlm1TpFtdc1oFG5TdOrupchWq1K6ajQpgfb2UMjLGbJcNmtIlkZDa7KDTcHdvYPIYkb7rO/y3EfiXPPu3nMU2c0FCt6H8jyn1/dziHkOJehM1BBcNyDFWcqg7SjPY6VNSbDp8xqMrZxA5gW8zo0WP69W573o1mkJttuGdOjy84wh4gQRQ0S0/l8U4XZdx8gCbqS/n+Pr4pUJZI0Wm01LZUqbUUNk9gx5coC3pxM3Gngr8xQ0e/qMqTPO+3i1QtnW83gcgWu0z/rG/LsBOXWVx5jN8R6vBTxn16Z4/dLGQxeOz6bbnNFkHKlQxM309HP/RvjeHz/2VmSrN87x8wpsIy4YWdufQlY3irxTKTYKt425wvMo4zdalOcjxhiOGk378TRvAOOZAqde5fh//STvT2cHm5Y7e/mQSTLFjSSz3GffePhgqc59WQ/9BUcIIYQQoUMLHCGEEEKEDi1whBBCCBE6tMARQgghROhYVzI+4/Pn44/17UXmrbIpskTfyHmg6wCyzm42QH7m5N8he/O+dyMbm7qK7PoNisL1FsUkz5SHKaNVjZ+Zjxly22DvVmSb+ikj93ZRCrYEtcColGz73Oe2x6zRorDbaBkNvE0eW8ujtHb0tmPICulRZIeOPoBs8kv/A1kpxvGyeJPtsxuRuWnK1b5LadQ3pFEnTkE5kmYWDShZpgLeJ62A1yrwOdbjhjjett5riMdOwPHlGC2+TtQSiikJDvRxYhhfpRhaKnL/qmWO18oi9znvsBX16EE25vqG7FsrMcvkKcwuLbBVuVWgHJ7uZub5PFeWTtzKLhnpxmN1jnu/ajyE0DfIBycKGeM+SXHc1OscI9VZZisL/DyvxfG/sMrXZbzPI3vT8Xcgu3zhy8gCYw6IGrJvIm0J/zx/KWOMNFvMYnG+N2ZsNzCk5XiE57l3gPdJtUQRfLCHQv3mIT7ccnOG38dnbrLJ+64DnN+6erkNv2HMUeugv+AIIYQQInRogSOEEEKI0KEFjhBCCCFChxY4QgghhAgd60rGGaMBdaVNue7WEcrDL97kT8q7BcqTrQW2ON7b+xiy0iIFw5dep+xYbzBLp7mNeJxC1FqJ0loiyVPU19fN1yUoCg8MbkbWaFCeXCpyu65DASydoFAWNQS17s5eZG1DqIzHrPNC6fXiGV7Lg4d2IXvt1PPIhkYoraXmKGkPHL4d2UakFfB8u8Y1aLfZHOoGVgMwx1fKamg15GG/QfnVjxktuYaYF4uzYdSNUWIsdHA8pBMU5a0WcMeQGBeM+WNhgtKhZ0jxi+M8B7sHOacMbN7Oz3O5f9U6z1Wrxu0uXVxElhrhvTOyn9dtqcjXRQJeD69hPGhQpGS5Ebl+7RqyZsDxPz3Bc9tlPGQytIXjenCI4zCRo7A+NMCmeN/nde6dm0VmNRR3Ga3wh47fj+z1q3wwJm58d7R83hNBm/uXz/IcVI05POLwnKaMJmjX0Nizxjb6+nn+qnFu99gDh5FtyvPYvDy3e//DB5GtLvB69HRybCQTHFfrob/gCCGEECJ0aIEjhBBCiNChBY4QQgghQocWOEIIIYQIHetKxl1JtvOOpPbxdR2UgfLJ88jqRjPhSIwibsajmPfsi5QEGzUKi9U6ZeRUmttdWWZzbqGDPx/fazQUBz7XhZ1dRtNsm/KwZ/wEvNemdJg2hM9mk5crk6XYWC6xPXVpmedvcJCi6dI8W4b37tqDbHGJUtiSR+EtWWWr7NraTWTF0hyy4/f8NLLvNe0GRde0MW7cOMewY7QbW02kRom148Z4nQNjjARGQ3fEp5gXaXMMD45SOrz46qvIqkluY/vAe5F5jRlkN89cR5bdxHN19SJl/MMH2YSbSjDLdnPM1VZ5jfI5jv83vn0WWU+G2xjM85zWG7w/o74hvdZ4zbf0cBt333YU2UZk+zY2wJdbnPs64pTTsymes0dvO4TsxIVpZJm00ZSd4bWvGOO/sGULsgP7mM0t83us0M0HJw7dsgPZBaP1/OrYJLJkktc+l+Q+l/jV5jRaFIALBaMB2HhopdDB10Udfl46ybmip5uvm55l43F3B7/bujo4hwbGd1utOIGsnuV9vB76C44QQgghQocWOEIIIYQIHVrgCCGEECJ0aIEjhBBCiNCxrmRcWqUQ+JmTlA4fPXofsiBHcXCwRJlq804KWy9epFwUCbirxVWKiNkMWxyrVQpv+Q7uSz5PUdg6RdV6Cdlg2mifjVLiihjSVa1KKXhoE4W8ktF4XKtRZEumKTHu3kaBrlimpL19B5s7ixWKez0excLKMi24Ow49hOzCFJtPb+9nu+VGpLHGa1Cps4k3laZwHc9yPDSXKApnO9iUHRgybSLJeyzwee0bDaMp22h3bX+N12XbTl7nzz3N1/3gv2QL7N888TVkd+8+jqyzm2Pd3/cEspzhF9Za/D9a3uV93HT4UIFf4nnOWfPWdj5o4KSMFvAWs/I8z/2uYZ6rdpXzzOmTL3C7G5Cffe9tyGIpjv+zr1BCvWKIqTcmKBQnjPbnpQnOm89Mca7yYmxBfugRzofPvU6huLzI75gfftfPILvtbjaxL1R4j/UYDyS84/hOZOM32Z79pZM8L9U65WEn4HYd4363/rrRqvM7ob+PzfjXr11G1tvD7/Km8TDD3JJxLY1fKoj5HENTN/kQzLuR/C/0FxwhhBBChA4tcIQQQggROrTAEUIIIUTo0AJHCCGEEKFjXck4vkBh8e1H7kJWL1Hg2zNyD7KTF59HljSkq4UiBatSmWuxdpuSmW+0PUYjbIV0Ax7b8uISsr5NlG6bTYpsM7NsbY1HKLdl88wGB4aQFdco3zlGI+e2zXxvtUaJa8WQYwvdlMeqNYpd6bjxE/UBX3dkN8fGF7/zCWQ7ekeRtTJ5bmMDslajUJxIUZKN+bwGzRUKi1OLHDe9jSlkmzbxOjttCvW+x5bhtnFPbNu+DVltcDuy155n63TU5f594ZlPIcvkKEBOrxifF6dovXsLpfNLVymBpiMcNzMNQ6Cu8yGAvTt43UaH70DWkaA8XK/yWtYM4TNIG+Kx0e4dNDiHJuLfH///fO08xc+JeQqxrSjPd/8WiqkzDuf1dC/PY3c3W6KLq5zDu7s4RiZWOKcFHpu8O/OU7E+98Rqyuw6yyfieQxSZj+7m90lfD2X3q5OryPI5Y/96OAdEjNZir8n24P4hyvM3rr2BzHU51zeivG7X5nlP+MZDD2mX46XhcQ5IuHzv/DIf8FmP7487SAghhBDiH4EWOEIIIYQIHVrgCCGEECJ0aIEjhBBCiNCxrmTcV6D8lPAMsTHJhtalGuXJd9zxKLKvnnwW2dbdB5BdOzuOLJdlu2u1RlnJCZi16kZ78CCltXKNhmZHgU2krtUe6XC7qSgl47ZHOaujQCFveYni8fwiL898kuIAACAASURBVGFfN5tcq23KWX6LImyvIbw16zy2SnkF2a49m5FtH92HLFLh8Z45/W1kx4+9D9n3mkySwl27SiEwljPE4yjH0r7dFP3ml3mdi0VKgq5vZAnKtPUY9+/mBK9pYMj4gSFLd+QpbcZahmDoGvvic9zMrPCeWDNExK33cnxlxoeRdad5bAdvuRPZ2fOnkFXXKJFXjcbomWnuXz5JKTJoUSiueRwHuTT/r1lnSfmG5Ox1nu++TX3MOo1xE+f46sr1IHONbyq/TqF+8zDHQ76Dn1c22r3THZR4/SivS8Noii90jyA7cBvPQVc/5f7SIoXsXZf4KwIvXZpFNjq6F9mxt7wZ2dRFtmJPXn4dWcY43kya37NzC5xTEsb84Uc41l3jwaK4w3l1ZoZriOJNfm+vh/6CI4QQQojQoQWOEEIIIUKHFjhCCCGECB1a4AghhBAidKwrGfcPUVaNZShiOU0KR+1VSlyTXZT1tm9h22OrQnlybZU/4143GkvLFZp5+TxlRz+g3FY3GkYrFR5HhyFJ+W0KxRGjobXW4LE5K8waCYpdI5soWV4fo3y9YwvbMv02hbyYIcy2PJ6XknEOkoZQubxiNZreQLZYZ1N1fyebQDcirTZFuoFhNkLfnJxD1qjy/xM9eWZRQ87duZMS48QYz2O9yOvcbPOaLkd5rV74Dvd5yyYem2dI1d0x7p/bSXn45k3u81KBn9c7TNm9Ns/jaHVRxuzNcPy/duJJZLkM5dOmId7HAu5fOsv3Ts/z/KWSfChj0pAnU3Fe8y0jPI6NSP8wx1xjjTJ5pJvnwk1yjFQMATjl87sjGeccFIlwzp1bYvN2q0n5tTPDdt6JMTYjd/Xwe/ETs19G9hPvfJz7F+fxesYDKtfGxpB1pDlGUvw4p3nmr5Etvcb25WjEeIAgw++2nTv5wEQhy+z8pQvIuvP8vEyE1628zPGS5jBwVn22NK+H/oIjhBBCiNChBY4QQgghQocWOEIIIYQIHVrgCCGEECJ0rCsZOylDzk1xTTQ+RXEw6VEGKnbwvY/t2YXs1dOU9YzSVqdeYauha0hIXosSV7vFD2wZDaMxo9nRDSjnduTY0ul5Rotp2WhGTlPEqhkNypOTE8juv/MoslKNrbJRl8dRK/EctBts0a2WeZ7bHsXCXbsoChf62OY5VuL1HYzzXG1E1so8t92rhpg9y+boZJZGYDPC871c5OfNzVJ23LyJ46beoARd8yjsvnH6CrJj97JltX8/hcr+ZQrFS0WO1xmXrcCpLbxPEinuc7aTUmmryvuuabTZnlwZQ5YfZtt6/tJNZAvzhtnY5rE5hsxaKnKecWOcjwoxPkBQMRqPk/H1p+eNQirNcd3Vw1b4XJbXPuoYD3s0eS5ycY71Fl1VZ2JqDFnBaIVvNLnd1aghiXfydbPzl5CVS9yZr3yD8+tte25BdunCWWSPvJ2t/6OvsXn4jQXOM6dmKOyO7t6D7G3H9iP77595Hpnn8DimF/jQT1cv55lyiffT/BU+eBJpc6xncxxX8bJx0ddBf8ERQgghROjQAkcIIYQQoUMLHCGEEEKEDi1whBBCCBE61rXYFotsyX31HNsKD3dRdC0codQUWeLPvV++WkSWcNieWm+NIYvFKBwtLLIlNNcsIIsmuLaLRHg6GjXKVLks25wbNYpYm7fwOJaXKIDNz1Eg9QLKk5t62bR5bYKiZODxvMSM5uFslrJjOkkRsNWmCBvxDXG7zRbpjEdR/U2b70ZWXuM2NiK5JIXFSJTXPtvD4+7vY5Or7zAb7Oc2ysuU9Z47ewbZww9SHOw1WnLz99+JrBnlvX3+Iltgj97K+/3qLKXloMJjC1yO63aD+7c4w+PNd1AUTsSNe9HjnNIsUcas7TLk5ia3sTJPyXjekDsrqxTQW/2UtOMO78VmiwL1pRuUXjci8TUed9WQprs4HBzPoaztN5l19VPWLjV5zvo6OKf5EY6lQgcF1qDFsdnfyfHV38Xvk0yK+7xstCW3jIdHZif5kM5Ki3NpPMWx2Wucl2iaJ7rd4jX65smTyI4c2I7MzVD4P3meDeKROPevUuF2twzzO2ZhiQ+yFOtGw/kA54r10F9whBBCCBE6tMARQgghROjQAkcIIYQQoUMLHCGEEEKEjnUl43Y/1z/d02yonJynJLswSQk1Pk4xL7WFEtfFGxSs/DY/b2WFwm48ToHPM5pIgyZftzhHQbnQ1Y+sWac45QSUzObnmAWGPJzNUIwrl9mg2WwbPxXf5nF0dVMym5mhyBYzBL+uHgqumTrHwfI8W2qttt1yjcLn9eI8t1v5/lhrZ4Z4vucXeB6tRu3ZaY7DXJKi5OoSr306TikyabS7nj1PKX52ls2h9zzEfX7tRaOx9Drl7+vDg8giaU4lSUOmdSoc/5EYz0ve24dsee0isqixiWhgNLD7lBgD482RHbx35s9Sdmw0ea6WS9zG7CLnsnqL13d4kOLq4cf4kMJG5OhBjkPfZ9ZR6EFWq3N+GNjG7xg/RtG1bDwA0rmFzen1JqXWpsf5K5ngPZYt8L25COV0Y1g7FeN7otLmHLl3305kqT5+J7QMEXcoTZl7bIo709nL8RVv871L89xGzbOuJfdv0WhvH+mjeLx7Cz9vxyDv2Wib30XVIu+n9fj++FYRQgghhPhHoAWOEEIIIUKHFjhCCCGECB1a4AghhBAidKwrGcfmh5AVNlHMu3frMWQnFtmKuve2O5At1CicLi8yq9YoF7kBxeO1FYpOiQQFpqYhCfb0UFBLJShjzs5RvOwsUJyKG2JcdY2tmp39hgAWpXyaTvPcVxsUNJeu8vzdsp8Nt1MTbKktlSieZeNcB5dilMeaAcXaiRYFzZFZXrdWnNdjIxJtUMI7fvB2ZJcnKTG26pTik/1bkN28/CqydJTiZTpJAX5hhts4eJT7/M0vU4BcWmTmGSJu0MsHA7xVjsN6kzJtMsMpxzOaa9da08gy3Xxvu8V7O5LkcfTXdyAbu3CW29jB4931s7y+Z//0RWT1Bsdws8V7ImU0sBervEZrJcqsG5HudDeymMMxkuJ06AQpNj3Xm5yDenootW7ezO+ntTrn5lSb0u1I7z3IFpcmkSXyxv5V+DBKV47zYV+E87rfMh7siPM6VxO8d1pGU3wyw/F/cJ/xYEyZD5nEE7xu3gq/E7IZfhcdvvc+ZG6NzdsR4/pmI7yW4xNj3D+Pc8rYAqX09dBfcIQQQggROrTAEUIIIUTo0AJHCCGEEKFDCxwhhBBChI51JePFJoXdiEtBrtWiOJs1RLrr01f4Op/NoTFjG5MTFGfbRkNxLEYhqlqldNjbQ/nJ8yi3tRqUZPftohharXJfqsZPxW/btg1Zu20IZTGKZxGjyLi4SLGru4fyWHmZ8l0uT9mrI8shcf0Shc96g6Lw3DibQPMp7stilAJ6f4av24iMz1H0izbOIasazvTiEgXgfp/jJu7xGizUJ5BtGtiObLhAAfLpr1Bg9Qz5NZKjsPjQrYeQzc3zfvcS3EY0wv8/tTy+zufwd1qO0T5e5nmJuPw8J+DJX0tw/PcMUVJ99YkXkN39T+9CljpE6bs5zusbM85Bscp55r2/8yCyxfOcfzci+Q7aw6UKpdaazzktk+WYW1vk9bt80mg/z3L+GshS7K0Z32NX3hhHVgk4vvbu34ysbYyvlM/vCa/ILB2nAJxt8zsrZszNpbnryLaM7EYWTfM812rc50I3j62c5z5XXL53kyFfLxiNx/XyLLLVNX4vxuuUr1dX2fqcjq+7ZAH6C44QQgghQocWOEIIIYQIHVrgCCGEECJ0aIEjhBBCiNCxrrGzI0XRqa+Hgu3lJQqQhc0UhVccikRf+IuLyEpltsDevEkprFBgW2YkwkNKJildDfZTkurvG0G2VqJ0tbZKaS2b4b5EXa4fV5Yo3+VyeWQpY+l56Rols00DbF/OprkvK2tsgGzzcjjZDEWx6Rlej77+XmT9/WzzfOMy97nWRzG02zd2ZgPy+PF3ILt85WVk8QYvYNtjo2plhZnhXTqpRCeyqHce2alXKQ97DrOO4UFkrQbl4UyB4nhnglLk+QjvdydJe7hhFJFGXEOoj3I8+PTaHdcw79uG4F01WmBTCcq+B+45gOzCUzeR7XyUgvKJz3DDkRTno9vfTjF09hol6NE4z/NGxG/wOkej/O7YtIljLpPm3NfRwWu1z5jDXWNAtGocN8k856pYnO+1/rff03vYeK/xSuNBkaox2CtVvi5Y5usSac6ld77lR5DVHT5kEo9wDq85xvfxAuePRJLXbWbJkN1dXst8mtvtMq5vPcv7xCtR0A9cyshrxkMZ66G/4AghhBAidGiBI4QQQojQoQWOEEIIIUKHFjhCCCGECB3rSsbpHBsqE3XKSvv6mZ2YoSD01Q+PISuu8efZF+YptboO5azdO29DlkpQirwxzXbX1TIls3p9Elkkwtdl0zwv7TZPZb1hSKX0OJ1WQFFycpztwZs29SBLR7kvFUPYSidprhoFms70DNsjiyVKcN3dRpOl0dT7A7fdguzJJYrbZUMs34icOvM6ssVZin5uiue7f4Ci8Ej/JmQrqxTpBgpjyL7yDY6bRpyS5bHbjyKLpbgv0/Pcxo0b15ANR0aRVV2OzXiKYziR5qCLGuPQq/H/XoHH460YjdrJJO+JuHEf15rcsJviPNM/wHM69wbvibf//mPIPvevvoZs9PBWZN1rlDHH/BvINiJDg3yowfN4bgtG+61jzH1d/Wzo9ttsxI137kLW9jh/RROUX5Mxjv96gw+ApAxRPmZ83uL8Vb43z3vbD/gF0IpxrGezPKepJLcb8/h916jxvst3Go3MEb63PM+HeSKGzJ0xHvBp+8aXm2e0Kpf4UFLU+K7s6jQerGhSQF8P/QVHCCGEEKFDCxwhhBBChA4tcIQQQggROrTAEUIIIUToWFcyfjJ5GdlQQEEuUacM9Hf/+QSy1RWKYrkC37t16z6+t0i5aHXJaudlS2LGEI/npyg6DQ+zyTiV4xrw0mUKZZmc8fP2FTb2Dm8a4OuMn7LfPNyPbHJmHlm1wff2d7AFMzdkNIFGM8jeOHsOWT5DabNc5HbTW7mN6+NsgU3x45wDmygjb0QalTVkWwcp/zUMGf/cDV6/lRVKjPcdonj5+a9wLLncrNOT4TXdf2A/smvThuhnlBFv6hpGtjzLe/HH730Y2Vdf4QfWNlHIblTYKOxHjfGa4MCJuRSAI3FOa2YLsmM0qvI0O+VlPjBx7mUexw7Dsfy5j/wAsvFvG+c+STnWqxmV1huQ+irPT66DQnG9wXHTWOODCc4iHwqJ5Nic2x3j/O+5vJ8iEc7hzSZl2iBaQFYsGd9ZebbH9w5x/gpa3L9m1ZDnjYb/ltGC7EX5Pba0wvOXMB40cCN8cKFQ4IMBxSQf+kkbxxv1eW+n4t3I1iq8TxyHx5HKcd6qNSiqJ9L/uMZ7/QVHCCGEEKFDCxwhhBBChA4tcIQQQggROrTAEUIIIUToWFcy7k5QKK77lJp2dz6IbHH5c8j6uikrVWqUn2arbLod6Od76y0age0WBc1WhZ/nGj8ff2XsOrJNfZSCB/opI7fabGLs7aIYl05TRm60KN9NTlJuixrLUc84f6ttHtvwEKXlk6fPIxvopRzoGyLngd0cG4MBGzTnC/y8ZJ1S6UK0hGwjUrVk1RqF2EaDxulgD5tNh3spRT7xJEVmN8ZxnU9wLLker9W3v/MqsmqTEmM04Lg5PcUm4/138NovL1Oc9Yx26rt2HER2LsX7bmZhC7JUlpJ20KDgulbk+Iq6FBYjJUq8btEQGztoc2dyvO+WzvG6Vfb3Iju8lTLmxQXOq17cqHjegJQWl5HFOVydpNGMv1akhDowyGu/snQK2dQ459yR7buRdW6iPOy5bOJ1DcM8luTrOjsoFK9WriBr1Dn+kynOh4kujsOmy1blRo3n+eYVZjt28/NWShS3o3HjaY8M56i2ITyfvXkWWTbKh1uqFR7H4jy/JxqrvJbdXbxPmlXed+uhv+AIIYQQInRogSOEEEKI0KEFjhBCCCFChxY4QgghhAgd60rGgdGwWylRiL0+901k9RpFvys3biBLpCmApQy5rlzhduuGcNTRyUbEUomvcyPGobtc703OUmxcShgtjklut9XmNioNnpdUgttttWnpFcuU4Ab6KJQlstzuyUsUu8an2VrZ3UUp0mlzHFwe53udLRTB3bTRLJphe3WkRVF3I5KM8tzeupvS+bNnKc72xGkon71IMdXzOV67cmwd3bWHMmahl+fxO6+cRHbk0AFkp17nNT189DCy+hrH4WSbkuyhvduRvXr6IrKdd1Dk7ChSWm5UKKJfabP1PJLhNYrE2BSczlMEb6Z4f7aX+LBAtpfHu30bH0j4wkdeQPaOH+Pr/AbvO9/nvbMRWTOaqCdn2ILf08VrEC9YQizHV6pjG7JYlPJro8lr2jK+J5Jpztdrq3wYxWlTFF6YYtv74hq3G0+NIguMBuW77/opZOcu/I3xXjYAb95C4fnc1deQZRIcS2tLvEaJNMdm3OUctTzD7+iZBl+XiVMeXl7kdUsmKSivVvjARNyTZCyEEEKI/5+jBY4QQgghQocWOEIIIYQIHVrgCCGEECJ0rCsZu21Kke02RafWdX5MNGKJuGwErdUoDgZNrrtWXUpS03NsScwvUVpzHAq72RRft337KLLOjjz3z2N76rUxymNBk69bLVNka3g8z4m4sX9bjQbZNW6jWKbwljBab7NxnudkgvKY77HxMme0kqYSxjgY4P7Fy9zu9tH9yDYi737TMWR//vlnkCXaFC/rBbaE7tvNhumFVb53yxaOw16jdXp8jlLkYCfFQbfN6zfUz89rxNiU2moa197ldU64vN+70hwjKxeZbd1FqXqlSdndeeV5RPseorA4M85zWl7mOS1soygf6aL06kYoXzfoHTs7buP1jbQ5/n1zruU+b0TiDr8TImmK4+kCz63n8JrGo3wIoeXxdduMxuOmx++Tpemr/Lwy5ddkgaL35h2HkJVrfICgb4AiesNomffaPLbpsaeQzU/eRJbNcv4IAj5A4Hh8ICduNKFvG+T3STMwZN81nvuhBK9vbIDfMUVDCh7t3IzMa/Mem57j3OM43MZ66C84QgghhAgdWuAIIYQQInRogSOEEEKI0KEFjhBCCCFChxsEAesChRBCCCG+j9FfcIQQQggROrTAEUIIIUTo0AJHCCGEEKFDCxwhhBBChA4tcIQQQggROrTAEUIIIUTo0AJHCCGEEKFDCxwhhBBChA4tcIQQQggROrTAEUIIIUTo0AJHCCGEEKFDCxwhhBBChA4tcIQQQggROrTAEUIIIUTo0AJHCCGEEKFDCxwhhBBChA4tcIQQQggROrTAEUIIIUTo0AJHCCGEEKFDCxwhhBBChA4tcIQQQggROrTAEUIIIUTo0AJHCCGEEKFDCxwhhBBChA4tcIQQQggROrTAEUIIIUTo0AJHCCGEEKFDCxwhhBBChA4tcIQQQggROrTAEUIIIUTo0AJHCCGEEKEjtt4/XvrMHyNzXeNDUglkqVwK2blXbyA78qaDyPx6Ddn5b15C9szFOWQ/91N3Iov4PjI3wbWda6z3otEqMidSYBTU+XkB32pEjnFKHTcSZRZjFo0luS/G61yXWSTw+DpjBz23jSwW70V2/aVTyLYc3GTsi3HuI8zSR97LnfkeM/rgzyILPI7X/OheZI2VZWTNYglZoqcLWTSdRlafX0SW7O1E1prj6+oRXvt4gtNBNtOPrNnk8fqtFrJoTzeyiHUHlBvcv2oZWTLBeabV5HsTxnbdFo+3bfz3Lsqh7tTKRWS5Ho7/hrHPbpX7FxvsQ5Yw7nff2Oczn/x33MHvMRdmjLnPus5GZP0POxIz0sCYw415JGnMI6tL/J746y89i2xoiHPVX3/yc8hGD92N7L//nz/G/Qt4wGtLS8jmZuaRHTy4D1nU+KYwToGzsryCrKuLcwrPqOOcOX0e2X/9v/4E2SNvvg/Zj77/R5Bdu3QV2cjWLcg681lk//nPvoJstcLv4z/4V9zuP6C/4AghhBAidGiBI4QQQojQoQWOEEIIIUKHFjhCCCGECB3rSsaGm+sEEYYxQ+zy05SGFsfHkY2/0UQ2sPsQsp13DyO7/BIlpG98eyeyd73vNmSPves/IfupX/xnyIL4ELLPfovCc2JgB7K/+hHKnU1DRLQ040iMl8ZtG6Kdz3MfM+S2iMPzvFaisNVZoMwaeHFkz/7lp5Edf9cxZA1DlIwY+xcYS23uyfeedpXnLL1lFNnyIsXGWI3CaWvNeF0vJfZGne9N91EcbFYpfNZ8nu/2KuVm37Dd49soxEZixnhNdSCLJThuaiWO/3qR90ksk0PWiHOQRBIZZGs3x5DFM5Tx3awhczu0jDN9PAflhQXuX4vnPtXJaxk1xkG5Zoyrnh5kG5FGg8fjGk8rBNa8ZDz84Hqc56KGTRsY45VXwHGyOc4ky4Z4fOzgbr6uRbH9j3/0fmQvPvMdZMfvvhVZd0ceWW8n7522R2nf8N+dpUVKy319FOCbxkMAv/brv4Xsg3/0B/y8Au+xYw8dR+YZIvgrL7+GzHrQpj26GVkkwc+rLxsP/ayD/oIjhBBCiNChBY4QQgghQocWOEIIIYQIHVrgCCGEECJ0rC8ZGw22jiEUN41OxEiDbae1EsW8tXFKXD27uFk3Runwzf/i15BF41SYPvUxCmB/8+/uQXbX+34BWctofK0Zx+Y6lOXe8fK7kH3otx9B1umy4baVoNgY8ymUxVs8Xj/gvrz8Zx9Fdvc/+xVut04Z+cJLryO79W138L0tvrdtKGWuIVUHhkC9EfF72OzbWl1FZrVJt+NGE2+UAl+9Zoy5pWlkXi/HiGVe+lFmqe3b+Hl1CnyeQznRMa5VO2Jc+3He74ksHz7I9rNBNmpI9uXiGrJcjhJvKcEWddeY6qK+sc8t49habDJ2srxuuQSl5eWzvHecka2Iknkex8oEr/lGpGnI1VYrfCzCcRiN8DvGNV6XNF5nkTbauOMus1qZY/3VExRif/gBiselZY7raJwS+4zRIL6pn2MkaBvSviFVT05OIhsZGUFmCcWW2Dt2c4bvNZrBh3dRAE51sS38xWdfRnbHXfye6DH2+cKpc8g8Y57x/O9uHPwD+guOEEIIIUKHFjhCCCGECB1a4AghhBAidGiBI4QQQojQsa5kvDpLmaq3j7Kvm2JjaaNGga9W4s/Cjzz4k8iaHiXeSNtq56VwVDeacx95jJLUtz5HqekPf/kuZL/ywWeRtTxuwyjVdE6f+Dqyj3+S+/ILP0xZdP4Gf7Z+8w4Kai2j3dXN8/N2Pv4eZM0Sz3O1zobbHbfv43Ytkc1oJW03eY0Co1nXNVowNyJBm+M6yLOJtGU008aTFBFrLaPd2GjJHdy3H9nShYvI/ALvz9YKJfbKLIXF5CDF48Dh/jkuR3v9xnVkMaPNPNHDMbxqHG9zloJto0qZO3orHxbIdFAyLi7yHMRqlL4ji9yuOzqKzG8b7zVOVXb7Xr7XUD5rayvIcj2GRL4BcduW+MksGuVclTJk8pzxrWS1IFsPKxSXeZ0vXeBcGjMa+VMFit57t7BB/8AettZfneX1m6vwHHhTFHs7uzqRzc/znthsyLnWPGwRtPmdNTNNCbpstFLfdudRZBnXaFo25rLhkQFkVy6cQXbwFt4nT5+ZQFZv/OO+J/QXHCGEEEKEDi1whBBCCBE6tMARQgghROjQAkcIIYQQoWNdyTgeZ0NlsoOtow2jxddqTnRcCpqxOEWxZt1oE7U8Nks8MwRWL+Cb3/LrbBl+/i8+juyhI2yyfPLkOPclylPZ3WG0tuYoZ8UHKHcO8pQ6fstoqe3j9UhUKNrlutLIAqONNV5la+vqKsdBJsUd9HuMVs0FimIRY3AE/ncny32vSeQM0duhwOfXeTy1NgXuVB9F0tYqBeX5CZ7HVo3XKp6mYJvexDESM6792jylw1SWjaUVQwDODQwiq7V43y0b7byxFIXd1PadyLryFKirZZ7T0hQF6vwAx2ZtfhZZsn8IWcSQpSMNXvO1OpuWG+M3kHUcPowsmskjK67yemxETr72CrJ77zPkb0Mydo25uVSsIPvYx/4K2c/83I8je+UVthE/9PADyL72+mlkn3/6DWRvfdCQoDM8jidevoJsuczvsd/7mbdwu196Ctnxu25F1jQeoDEKj+2meL7M2bOP3zsnz/Lhm03WgwsNzm+T05yjXvswBe8b13lPbN65B1nWWBvs7eO8tR76C44QQgghQocWOEIIIYQIHVrgCCGEECJ0aIEjhBBCiNCxrmQ8cJANhmee4k+iz125huz4T74P2c7bDyFbmWcDZCZjScsUtqxG0KjRsurF2FDpliniDh9gW2zjOQrFj72F7ZYvnbiKrNJmc+1amcd78blvINu+l22ZC6uUSq/+1aeQ3fcz70WWHaTEVa9TPF5ZpHhZGKK4ahRLO8kcZdHSOcpouV5+nmtr6RuO2grFT79Bed7p5phLOTzfTUPWc1zKqvUFtoC7se9O7q8WKeIG80aj6i42VjeqZWSFrZQTq8bYbK9xu36dAmnPMEX+VaN92TcGXf0G557cbn5e27hGjaUpZNHeLcjW5oxW9mmKzKmh7cgS/RS8W0We08oym6DdOFtgNyKnnud3wpOf+yyy8ZucW9ptzusN44kS3+frvvr088haTV6rD/7xx5Clcpybq3Vu91ufv4ns5Sd5b/s+W3yPvfmHkJ0xJN4ffPubkC0ucfyfPc/3HjxwAJlnfFc+/Y1vIqtXeX9++VN/i+yxN92LLNfFhy2qxgMqQYRLjP4hCv9j5yl9b917C7J8lnPoeugvOEIIIYQIHVrgCCGEECJ0aIEjhBBCiNChBY4QQgghQocbWL9D///y6od/E1mmZ5QfkqLYrOwsIgAAIABJREFU23OYTYxXv/h5ZIszlMJ23EPZtx1QnIpEDcnSkNF691KenHyVP9neMn4C/v73/09k+3ZSsPINX3vRYzvp7m6el199gE3B1bWLyI4/fj8ynnnHyQwdRPatP+FxHP9xtmp+/T+zMfTN/+InkEV8ro1bPq9Hs8g9TOYNKde4bjsf+xm+7nvM0Dv+JbLGLOXJaD8F0UZxla8zrmAyy+bclnGXVucoCsdyfG88zrEZifH6RYw27maD8qR1j0UsvbnKRubVWbadOineJ/mo0drdy9bnWJzHGzgcX4l0B7KoUaldnqPc2WrXkOUS/LzKCkXw3GYK2cmkMW+1DNnWkLQXX/ozZN9rfuvf/CmyYaM9+90/dBzZ1DSbrRuGeB9LscE2n6Fwms7wAYaI8d/4j37i08g+//xlZNHuTmS7jIcpXvoKv9uO3n0nsomZJWTxNu+TiNHc32zyvDQDZp7HxuNUnPtcr/A+GRhiI/lQdA5ZwTMetDGat2vGtaxV+KBB1HhgwjN+ISEdYXbl+gvI/gH9BUcIIYQQoUMLHCGEEEKEDi1whBBCCBE6tMARQgghROhYt8k4OzyKrO1xTXT9ldeRecbvuK9UKQhNXGNT8LZjbDB0LBe6TZnKiVAyayxQflpYphDYbFL2ihcotxVrNMAKuTiyg13G/kXZeHzzLLNDhyl7OT1sN87le5C98KEPIbv7RykU+02e00d+4/3cbpvDxDMEzYjRIt21j62f1Rm2OTuBca42II1Ztt86eaMp2xACk4btWJnjOIymjDE8Rzk3maLoGjdkTKdOib1eouiXyFP2rc5RoI7FjGbrGkXcZIZiY8cIG7UzwxzDa9d4T+QKvchqixQgszmeFzfF+7M+wTZiN85ji7n8vGaL56//6BFkS6f5MEN8GxuPWy0Kn36E4vFGpLOX5+fSCtuaay3Om0+/wPNTMoz65RLvp2iM89Jv/dzjyKyW9LUq9yVlzPVBth9ZpsBx/fg/ZXP/zNVLyB5808PI3rjKtuQ9g5uZ7d7J7d7PB2hqFT4Y8Mu/+OvIDj36LmRXX30a2eYRXt+ObXyQ5cM/8A5kH/jXv4PMNR4qmJ7iPLNW4z0Wd3nu10N/wRFCCCFE6NACRwghhBChQwscIYQQQoQOLXCEEEIIETrWlYx9lz8pf31qAdm2WynXBR4FuS272Or5xt8+YWyYPx9v/AK81Z3qdG1mg+bV73wL2dmXzyN76RxFp0iCbZnlGNtTvRJ/Kj7qUGQb6Kbs2HnPDyIbvY2trZ1bR5E99aefQ3bX2+9DFrQpMbbT3EYmz+Otr1AKDoy1ccwQj71qNzKnvYbI8JM3JB3bdiNrtCjxZpIUFtdWKLsPHjiEbHGO95hnNPY2qhQ5u2I8kfGRLcj8eW6jUeVxFPopOwaGPJxJcf/qRbYCdw8MIauWeRy9u/igQZvPKDgNh63ibeMBh/oE5fDsFp6X7hiPrVIyxn+Tx7t8yRCKO7h/iYIhLS+w0TeXory+EVldMJpuA47DD33ob5AluiiYT8yywdk3vgB6ug2536otNr4phjexabx3kuN10XiQZe8Qv2M+eYaSfaqT34uXr3AsZevcvxdn+MDLmeXTyM5Nss28P8tzUFpig/JskRKv3+Z5Xlrg637j938R2RNf+gqywUFe3zmf7dD9Lpcih3cdRtascI5aD/0FRwghhBChQwscIYQQQoQOLXCEEEIIETq0wBFCCCFE6FhXMl44fwJZ/8htyHyfAqvrU7CdeOUUsqEDFF2//lGKx4+9nw2VvmGmVksUWKdnKGItr1EK68jxdBxvshXyO2sUDLuMJuNmm/JYtU557MY4hc+HHtqKbPGF55Hd+Shf96UPfwPZD/72P+e+nHkG2S8//h+RfeQbf4msXeX5mz31IrLevTwHhb0UV0uX2ea5EWksURL0WhTMK1nK1fkOynWrRmOvk6Tone+jrOpGKewmC3xvPOD/Y7KbeN/VDCm+aBxvIUURN5LkAwmpKO/PZpECqWtIy36d+xI3tpuOcrudnTz37V6KoQs3xpB5Hhtz4wWeq0QPz3Oul9eoYrSxZjyKq4kB3scth/uyEUkmeF3cCI3wwDi3QwXOm5uMxurJEsdDOmkI4YaEmslzjETizI7uZ1Pw7EU+jPLsxz6L7NZ3/xKyhM/77uxlPsjy73+BLfOXblJ4rs1cRpYfYCvw7h0jyJ78K47XhUtsWk5EeD2mljnX//a/YUPxf/i9/4Dsg//pT5Edexdbn19/5iKyPl4OJ5vn/q2H/oIjhBBCiNChBY4QQgghQocWOEIIIYQIHVrgCCGEECJ0rCsZZ7t3ICuvUojNbWKjZKuDYt6VCxRJdx4ZRFYJKJTNNHPIBhIUiutFSryNGtsZCx0UhdsZHofhuzk3T4whm2iwGdNvcf345Bd+j9kH+FP2Tz3Nz3v0GEVJv8lz9ZaffDMyb+osspsvMbvn8Xci+4sPU25+33uPIus5eByZE1CorN6gCBgY4uVGpDI7gSySpsCXHqZQXJtlW233oYPI6muryJbHbiDr3EoxtbnGVuBagw8BZDopJ8YzvCdSHtuXayVuI2+8NzNMmdyLUhIMjCbjhk+5v9GitBz1KLHPXWCjcGHzdmRDu2kxZowHF0pNnr9mk+O1ZTRBZ9OcU5ouZVvPeCAhaXa1bzysFnKj1NxpRyj21uucmyMxvrnd4jWoGdtdXeJ4zXZQxn/10hVkWweGke0/djey5Twl3pghUF+b5v2+3WgVd1sc69OnX0WW7eM967o8VzMVntPf+i8fRBbL8p5NGtJ+0+dY9wNu49uX+H38b//sk8jcFs/VkSOcB599hufg0AHOKeuhv+AIIYQQInRogSOEEEKI0KEFjhBCCCFChxY4QgghhAgd60rGkTgtrlyW0pxn/ER9UKRg9dBPvw3ZR3+fTYc7b+fPzL/4SbZH/pN/+jC367A59PCdh5A1XmaLY7RC+anpUIo8so+i2Jf/2weQTX2H+/wrP//byKbLKWT7y2x9fuTuR5A5Aa+RbwiLvsdrtOPRR5Ht5a44T3ycx/HENyi8/dBb9xjbpYzm9lLA/eRH/ieyD7zlp7gz32P8Ept4W4aE1zTE1I4do8i8FQq2gctrVRgy5MQEL1YsxVu6e5gStNPmPv/6UcqYE7t4rRZyfIBgJsksZojCL33nBWSJKPc5P8jPa67yXCUHKN53jvDBBa9BAbhmCNn1DM9VfY6tso0W35vOsEH5v76bze+PPMT7ZM+7/whZO82m3o1IzLh+jjUHGe32bctQtuRqY7zGjP+fP/caH4honua4Xl6aQ9YxSMl4+hqbh7uNtnDHOIxCnven77Lh+aOf+DtkP/hjP8f3Nvn91DDm1+LiErJEiuN/9TIfMql7vJaT42xbvznOB4ayWX4nlMoUjw/cdj+yuatsMj6whw8BtDyOofXQX3CEEEIIETq0wBFCCCFE6NACRwghhBChQwscIYQQQoSOdSXjzbfejuyDv/t/I7vjIbY91ssUDG891I/slz7wr5D5LuW6tiEJuikKz9brtj3yELKhOyg6tZMdyC49T2lt+LmnkH3pv/4+sv/w+ZPIkqOUDosBxbN4lXLzYqMLWSFgc2dgGG++TxnNaRstolmegwffSjm83ZhC9tRzFMuH91C8PPnnH0P2vl/6Qe7fBqTnNl6/xgqbh4MZNh43Ghz/1TRFxPo4z+3QLQeQuYbIWbnJFt/aEq/pH7yX9+yKx3GzbTuv341xivyFTlZ+j594HZlXpXzdblLYTRjyaS7Ge2JpihJopIut5+0S9znSMmTWGuctN8H7M2c0tX/zX/wIsvzWDLITW/kQxcO3/Riys/0UqDci9SbPWSbG6xd3OdYjEX4FuS6F4rYh3h/v5Hxz8uw5ZLMDb0VW6KG0n6yxpd8xHpbJ9rFNt2o8LPAjD9+K7F/+679A9rE/5MMUH/r4x5G96/EHkfVu5QM00Shl6Uad16jQzfmoZYjMW3bwFw3u9I22aaNVvG08bNE2HtzZsW0XsobxiwaBb0np/3v0FxwhhBBChA4tcIQQQggROrTAEUIIIUTo0AJHCCGEEKFjXcn47Fe/juzMyxQHhxIUmHbdthfZq1//BrJmnRJSZ5ZNkZfPUZ7s2U7xcmWcDcXHFt+ObGJqElmtRYGpWOSxlT02Ni4ZwuI7DMnshQkeb3SVkuqV+h3I3vPvv4PsqQ8cRpYd2opsYeoys/NXkPXt3YYskTFEwAxFtn1Fti+Pn6D0/crF68je16IIvhFpeRROU52Uv9dm2H67dvolZB233IXMNdo6P/21/4Jsuk0h8EaCY/N3d92LrPjf/hDZ/CCF4uDyNWTZXBbZLe/8CWRf/wobWvvueSeyxBDv4/LEaWRTF7kvmaFRZJXJcWQ9WygxuoEhRdY5Xj1DmP30L70FWf82CsWn+yiBtn73nyN71xHex8/8Oe+njUijRim4uzvJrIvzyKVxXtP5C68gW61xu9uPU369PMP5ejjPltxMiU3GK3O89oeO7Ee2d/92ZOeucC794mf/HtmOTTxXvvFwy0OP8p4d2cbv1Eqb59Rq+21HOIYNh9dx4hSAXaNF2jUeAgiMpupIjOPA9zhvWa3sboWNzNU1PiywHvoLjhBCCCFChxY4QgghhAgdWuAIIYQQInRogSOEEEKI0LGuZDx4zzFkH/2BNyGbukqBNQjYktu7dTcyv220FTqU/7bcTlnvuS+zZbj7XqMRN0Vped9hClsnXqMolkpxDRhxuX/RGF9X6KA8tlYcQ/byitEoXC0hy23qROa5PH/LN43r4XAbfXsoI7sehTInZsiYLb6uZzN/3n4hxlbZ929mQ3ajVOR2NyCZCAU5z6VIN3CAAmTHPTzu1Tm2pz5+jE2pL9zgNrYXKLXeZ5TzPjPPbcxPU8a8b42SZbXE6/zOA29G9tKTX0D2xysUOb9T+hSyn/3oPLIVo7D0uRTvp29vG0Q2cewRZLEVSt8H2mypfbxIIfVgcYWf97vPIBubpQnb+9xXkS1/6m+R9f3xbyBrbmED70bk3BTnqqkFCqLHDvJaBc0qsnve/m5k9TrnOd8QWD3jIY7pMT5Qsu0A26THz57g/hky7eoaW4uXFii/Bj7vnVza+J7I8jhqJW4jmTZeVzNuFKO1PmpIxl6Ek4VnNHkHRtt0zGiWTndwrq+XeH2XV3kvFgo8ttl5fickUnzIYz30FxwhhBBChA4tcIQQQggROrTAEUIIIUTo0AJHCCGEEKFjXcm4uTqFrNHDhl2nbbQaBsbayTN+Ot342XVL7GoE3NVrM5QEr71BifED//rnkVXKFMCyKW633KKw5UWYxVuU4KIRtjM+fMdBZAd6nkP2P15hc3Nj8+PILq9RoN6SYDNyLMrr4RvXyPo1et8Qj4MWr+W5U5RZP/U026tH+9j8u/99D3DDG5DF6RlkboTnZ+kaZeT6OK9prIPi+N+cpaw38donkAVuAtmNS5RkR7dTJt8e4XhdK/Gavv7Ky8h+9Au8phNFjqWv3c724O1b9iH7zI/zvc8+xzbbA3ceRfYrj/BBiN2nTyJbevlryFJFipzN9/wTZF/bwznv00+xZbhjK6/bkRfY1LvjyIPIRh97lPv3Z5ReNyLNOsd6Vz8btW/cHEP2wJt+CFnLGNfXz7LZuvgSx+H8NAXWPbs5/ouGdL77VrYHj1/lPevHKEtbD104ER5Htc3vu5defBZZMkGh/gtPfBHZ7qN3IhscZNNyscTvhNlxzhXXznNcFw0puFpeQ9ZscP6o0zF2RvaxufzkyQvIHn3sbcj6Cjwv66G/4AghhBAidGiBI4QQQojQoQWOEEIIIUKHFjhCCCGECB3rSsbTl8aQvfIX/An40ccp5o30UQaqLl9l1sgiC6IUsYziROf9P/8+ZM98+WlkS6tsZ+zuogB25z95P7KT3/g7ZPMTbMY8vofi2QtfpDz8yK/8CLIn3qBoOuqPI1vxKDf/x4+fRfY/foFSXdv4KXujbNoJDOnbbfOF7SY/b2GB+/xr73kQWSTJsWEc2oakc5Rt3LFVisfFbjZz9h2kJFtd5lhyGxyvLz3/KrKZG2PI2g1el+HNI8gmx3itRndsQ3b7HZQYdx1mq/jXv8JW8b172Wx95CAbnmMR3ty/GeXU1KiwLdZqVG3fz8bozp//cWRuwLE+fpmy4zu3Udp8cDvnrZhD2TaVLTDr6UP2+utsH48bzbUbkWaTTcY//M53IquW2JRdbFJMffbv2PR828OUyWMPP4Rs8Qzb6EcHON+cNb7b7rrnfmRTY5SM/+rjH0G2e0s3svfewrbkucEeZCffOI+sq58PYqwssh16ZozjplSmPJ/v5nitGa3F+SQfWnECCtTJHD/PjRpNy022EZ96nQ8BRIztvnriNWTb3spfUlgP/QVHCCGEEKFDCxwhhBBChA4tcIQQQggROrTAEUIIIUToWFcyfuMURcQH3sE23cHNFKy+/Zd/iax3H9tqUw2237qbKFi1o6zY9VuU1pwxisz1N/0Uspi/iGxwlOJUeTvbWPPGWdvzNrZgdh3ndp/58z9EVtxFcfXdOyho/vfPP4Gs0dPL/UtSMvaatHgbhtzpG02bnsfMicQR3X4Hpbq4w+s2epRNlldOsql0I9Ja47hxXMp1bolNn/9Pe28ebtlZkPmutfa8zzxU1Tk1D5kqc0hICAkBAmFQZHAMKHBBwRYUjaZFukVRbNFG+rEdUERFBoki0abDHDKPJIEMlapUpea5Tg1nPntea90/rt57n+f35rhJpc3Jet7fn2/tvdf0rW9/tZ/fes+cuAbpDCW8dJAi4lv/5wPIOnOUCX/+Ksp63/7tv0RWmzqI7OhRtp2GISXQ6669EtlAP2Xa79xzD7Jtu9nsm08p5xYLfAgg7VCgDgJmYczP64gW9aDAtt12g+c03r6PnyeE50K1iqyvxM97y4+8Ddlnv3Azslp9DNlSpBxSVm23WGE7XaOsWp/n/fSKN70G2dpVfIjj0ATl5re9g63T93yDD8Zs37sX2RvzPI7po9y/Dat4f75cNGrfdRebqNONK5FVBvi9M7vA8xeVeU/kUo7/wSLvxUAI8D1lNu3H4vN6erh/zTo/LyrzOyEU93EoWtSLZbaA9wS8dx6/jfdJ8F4K7f/vPj3jvxhjjDHGvEDxAscYY4wxmcMLHGOMMcZkDi9wjDHGGJM5FpWMH7yfklRvgW+57n1sCe0bZ1vnlu/xz9urOt3KYTav/vQv/Ryyfd9mo+T1n7oJWVU0I1eGKPEmCWXREzFlr8t+gg3KR59my+QTd38KWRpRtFtVO4zs1df/GLI3v34tsgOHKWLteZJtzo99hY2X193wbmTCz5SNx0nM4wiCHJIOo+DgE2z+DerihUuQVN0yRcp1uZgCa8/YCmTxCIXAvDiPaR9fNzrO++Sc9VPItj80iez+OcqOYT/H19+970XIth6k3H+ixnvslv3M5h7Yh2x0M9uNZ4+Lhw8SDsSoh+f5+BNsQC0WKQCvOPcCZCf2Ur5ORONrbphyfyTmiuYcx/oHP/Nxft7gcr73BFuulyLnXXYpsmPHKdk//uDXkeWLFF3bDUqoX5vkGC7J1m7O4dMd3rM/9HLu85Q43+vGKBRv3LAKWRBQpi2eywdUUtHcnATMCuKhmqjDLA55bLF4MCAR81YU8fOCDn/zmDh0HNnAMj5YpGbwVDzIkhb43ZHW6shOHONDD8fqfN1i+BccY4wxxmQOL3CMMcYYkzm8wDHGGGNM5vACxxhjjDGZY1HJ+NdufAeyb9xyK7JP/vrvIPvvX/8nZFd8/yFkrRobQRdOUSg7uPVRZMcm2No69e3bkN3zT2w/fMlb+GfXz9zMBuCrf+gnkO34BuXheJAy5s7DbNq89bEDyI4FlCyvfQtFzlaboumBo3zdmRteguxFP0WhMk6ohSVCgk5iCnRBxPeOn7Me2dP3UlS/6eZPIHv9q67lNpYgeSHIvXIDRcQb3vFDyA4eOoZseo7S3EKTWUs08eY6NMK3Pf59ZH0Rm8E//iNshu2rUNCsn9qBLDlMAbgS8l58Ef3fYGItp5zBGlusn6hTPj1rA8XoA0cohm4+i/fTiuWUgndu3YmsN6S4elKIwmFCub+QZ+NrZVSI5SGF55lD+7gNus1Lkm/ex/O4so9jc8Pmy/jmlPdTlKO0v1E86bAg5O+hQTbiror53lqb752lIx4Mb6B4PyuE2FPT/M4qJxxL6lmKMKXsqxrgO2LODcQ2IiH2RqKNPs3xdR3RMjw8xHOatHgO8mWO/zjl/b5yPR/wOfQk54BUjINhVdK8CP4FxxhjjDGZwwscY4wxxmQOL3CMMcYYkzm8wDHGGGNM5lhUMu4IOeuql1+F7OavP4Ds8x/5H8jOP4fyX5zS7BoVYl51kM2JK3+CjZL56kZkw+NsGb7jHygtN45SFDsVUxT+4p8+jOy+Y7cj6ytS7Dpc2oDskgtehmxk+XpkX73lfm6jQlnu/AvOQfbwbXuZPbEHWT5PAXJ5ynNQLFF4a8cU1AbHKXf+/M+zCToMVTPy0uMlY/3IrruC0tyBo5RQH9kiGkH7eQsem5hAdsYGNoPPNSkeX3zd25CdLaTIhSb3r6Gk1khMEb3MhkqUgl+6gnL69OxJZCcnKSgvq4qW1YjtuBvXDyJbvoxSdb1GGX/9i9cgS+ucA46t4vWdEy26qgY8H7KNdXJqF7JmRXxeDyXLpcjlIzxnjcZ6ZKUCj7Fa5hjphKL9Vpzv41O8ps02r8Ea0aoftPl5Scx7oiXmtDAUYzPkdqOQ910u5TVVnxcLATiXcl+EnxykOc7NqgU8V+A2SrH4zaOH3wlBm3NPXkjBsWg4HxEtza1xytyH9+1DNrx+jPuyCP4FxxhjjDGZwwscY4wxxmQOL3CMMcYYkzm8wDHGGGNM5lhUMlaCYe8AJcu3vflKZF/44jeQ1aYpCb78x9+MbN8TbL+99t3cxqOf+QKyNHcQ2dGdTyFrjVP2veC6C5Ed2snP+/hffADZ297/p8hO0S8MghGK0VMP/xWy751xBbJQNG0O9rNlcs+W3cjapyg2XnHxxciaDcpjnZTXPGlQWktiCmWxaNtNhBkXpi+MtfaWKYqDu7/C9uBqxNfNphRigxYF7hXL+boTHb5uIOUA2/0E28KHBvl5qbj1+/opEx4+zPblXJ4y4dAKyn+tPMdme4Hja75BKbK3yn1ZmGGDcij+j/Y3X/0WsmKOMuvacT64UBcy66HjU8jOHGOl6oa1PAdb9lDuH+qhVH1ctBtPTLDlfSnykh97F7JWneO/fnw7sulJfieUenku+nvZsl3Kcb6pifF1/JTYhhBsU9UKLGRasdkgSPh59Y5oFBbTXKKkZfGAj9qsemu+rRqKhWSsPjASjcfivFTyvJ/KVWYr+vYhOzHB+ePss85HNt6/Bdlju0Q9+iK8ML5VjDHGGGN+ALzAMcYYY0zm8ALHGGOMMZnDCxxjjDHGZI5FJeNcJBoWAwpHF11BQeiMC1+K7A9//YPIZifY7nrWGZQTt9/KpuDz3ngdsqe+exjZJWfydfv+4S5kae4iZJe+7ieQ/c6v/jKy37/x7cg6HUqCL/+dR5D9+cfegywQxb6DU2wMrTfZ5jk5J94shPFajQJdf57vnaoLoVgIaqloyxRDSIahKHJdirRaFOQ61R5kkwmlyGJeSPui/XN1Qnl4Tc9yZFPTvAg7jvHzohO00/tFG3HfNC/CwjHen6U+Hu999zyObNlGNpdPzXGf5xLu8+XnsM18boHjphEw2yTmnoJod13Zz+02hNy5ZgPvk1g0QW/Zywbq4cGVyE6J+7gxQ5E5EvuyFKl1KJe2xPwQjb0IWbpAGfnkFM/jwR1HkJ04Qek8afOcLXT43oWFWWT1eV5n9UBEO+acG6ecN1t1MQ+LxvZUyMhK7BVDPcirNmIxz1TKfHNfH9vHe6qct3rKzJp9vJ+GcnwY5Vv38zswDvgQ0Z338K8DpEKrjlv8fl8M/4JjjDHGmMzhBY4xxhhjMocXOMYYY4zJHF7gGGOMMSZzLCoZr7rkamQ7vv0lZFvvoEhUWsk/Uf+uG34W2bc//2VkT55kI+hZeYpOrTkKkBsvHkK27a79yHY9RKlpzxtej+xTn/0VZKXxzdyXGkXOv/rK/XzvHEW2Ro1tv9XZJ5BNPskm0Kt+8WPI7vubzyO77LozkX3/gZPI0nGevyAUslcsWj+FyByHQqCLeQ7yIaW1pcjJfWzFzhcp6/WtWYusHnMMJ3m+9266k0H/rkeRTYlm6xWj48habY6v5SUKttP72XY9uSDubdE6XVzNBw0i0YpaGuX4Guvjedl/vInsqRNscx4do8Q78TTPVd8gpeWtDY7/Yg9bn1espiw9PUvJeFTMpmMreT0OLlDKPVGifFqpvDDuid5+tstGorI3l+fxNEVT8NgqXtP0vEv43pjjOu0IybjNc9uscVwXRNt1K+Y4VOp3Khrb2zXKyK15jrnGJNvC505QjG40Of6b85S0F+qcGJpCeD55nK+biDkvJELQL1b4INA5F/K6lZSgLFqua3WOg1Q80BSLxujF8C84xhhjjMkcXuAYY4wxJnN4gWOMMcaYzOEFjjHGGGMyx6KS8d4H7kRWWkaRKBQSUielilUIKHGNjlJW2raNkuCuCy9ANrFrB7LzXvJqZMVllJZf85orkH3nljv5eRElwadOcbvtkJLlN/ew8fUdb7wSWSJaMGdKZyOrbF6N7Lvf+Aay3Eq23n73zq3I8qsvRVYIKJ5R/wqCRK2NxTUPRbuxaqhstCjpLUWqy9cgKzbYilqbOoos1zuKrEEPMRjOUSas9fC+613GeycpsbG0NcX927mP4v1Ck/dnMx5GNj/B+33DMGXMk1OUCXdPUc4NiqLheZT3bK5/BNnRY5Q2k4TH0WjwHhtdfzGyupBFG0KAbIpG66cQIhpoAAAgAElEQVQafLCiOsnxX6xQyu1p8bycEiLsUmR2muM1UfO/EE5j0RQcqrkl5pyRK3IctsR8E4qHH/p6Kbs3O7wZSxHn8FyZ1z5VTexDPLY05hyeE83DnZZ4ECPH14nTF0SiZr7d4Q62xcMHiRB7E1GhXBTbbYp75+cuvgpZI+FcURSlz5UKx8vQEO+dxfAvOMYYY4zJHF7gGGOMMSZzeIFjjDHGmMzhBY4xxhhjMseiknFbiGJ50RSpJK5QiEmJEJNe9pPXI/unX/oDZMvv+Q6ya9/1DmRxQvFs9ThFsb6XUbD9+99nS/PLf43ty7vvfBBZJUdxarY2g+wnr2ZzbTzP19Vb/LxOg+JZklDsCnOUs8pjbGOtzU4jaw7y/KXCZCuXhVje5thIEmGPpZTgUpEtRSorVyFLFii/FucmkTUWeK3611Bir+YoI6v7qT1LCTVX5bXPCU18xdhGZAdP8fP6hbDYI2TRWshr3xrmNkZ6KR7Pz1Nsr/RUkSUlCob9fWwejnuE2DvA87wgWmBzZQrK+8Xr6hMTyPoKHOt3PLgTWSDOabLAc1A840K+dwmSF5JsKh48CcVxF8V/sTtiLBWFiJ6PxBeKkn3zlIJjISMXI87NOXHfSbE3LxrbxcMUqThXuZj7UqlWkDWEKJx2OOZE8XyQy3Gnczker+ppDkUbfZAT80JuAFmzTnG7T7yuqOY31WQsmpYXw7/gGGOMMSZzeIFjjDHGmMzhBY4xxhhjMocXOMYYY4zJHItKxg9uZdvpNZedxRdGap0k5CyR1UWV66f/5qPI/uw3/wTZXV/638h+6WMfRHbgkd3IGrsp//3X33o3sj/8468i+9Avvg7ZTV+7E1nzKEXToE6RsxlTpmrWKRm3haTXEmJvIaFUKpywYHyUbZ71lmhPDSl2HdnxNLKVZ1Mq7cRCvhNSXUHId0uR+vHjyCp9lF/zQxSFc6emkEWzzKbF+R4S12ry2AFkp+a43VKBjccPPL4NWRJTgl5+xgZkuT4hVbdF82qB17Q6xpbtQpOiZC5kVquJNtY6m4zLI2ybbjd5A8we5fmr9lJarpYpYy7bwGbpzWezffzk4RPIjk/zms9Os8l4ZITneSlSrfL8iGdRgkTMS1FEGblapOgtpr4gEKJwby8fKEkSMb8KGblS4H2nHqAp5LnPag5vi3uikOex5YQsHQmxt1/Yw4kQmfPiXM2LNu4oVW30nAMOPM25ftN553EbKb+zog63EYY8f9+74zZkL7nutcgSIUEvhn/BMcYYY0zm8ALHGGOMMZnDCxxjjDHGZA4vcIwxxhiTORY1OyPRvBpVRXPo7ByyNCf+7LpoRs6FlK4e2n47sja9pGDuICXoz/3FPyP74csoHRYvpMC0YhMFtVdefgGyjmiPvPVx7t8lF13M97YpVTcalLNSIcE1hSjWEn/yPqxSliuEQvDuiIbWDs9BME9Rcu35FCqVCZhTdnObw66tDngJ0jsoxE9xF1VEe+rgWZSwIyEOpg2ei4ltO5AtP5Oi37Rou26I+yQRInNY7UdWz1GgjqYoyS7k2W5cmp9FdnSWrd29o8PIqkWOw94BNqAen+ecErd4/vqKnEAKKyg85xIhRm9ci2ywxftu1wnRDF4X92eB+7JhjNvdc4gS9FKkWmbrbl2IvT0lXtO4LcZ/JGTaNufcYoVjLhE1w02xL73igRfVsB6KfQmFZJwX7y308LxEYh7Oi98ZwhyzTodjKZeKxmjRqhzM8Tu60McHF/Y/8SSysU3rkN3/9X9E1jvClndVUH/eVVcju/erf4/s7Es5vzUn+V0UBHzdv+FfcIwxxhiTObzAMcYYY0zm8ALHGGOMMZnDCxxjjDHGZI5FJeP7HnkI2b3f/T6y3/0lCrvB2CWIevspBP7hb/8FsmteuhrZu278KWRf/eQXkDX3bEH26cfuQlaoUHjbNMDtFgbYAlsQDa0TcxQq/+YXKeImCUVEVc7YEM2YnSYF0lC0b6oG2VyBMncovN5yQvG4PEYZrSCaNgs5CnQLTYpx6c77+N4zXsydWYJ0hNRdPz7BFwp5MqlT9CuvHEfWPMCW7VVXvJz7cpgSaiFHsXFeCJq9YxSeR5ZR4m2WKHJWhHjZyHHMhUKoH15GEbHYEq3FC2z2XbGKDzi0hnk9arMcw/kqZelq7zJkUSwamYUo+dST25GNnbUe2dw89yXiKQ16lrExunPkKb5wCbL1gbuRPXjbnch+8oZfRrZuAwXuHXsOIotn2Qq/bhNb9UPxIEsY8wLG4v/2HTEOyznOm6l4MCAS83BvL+/FppDTVZaKuV61ORdEC3IsmsErZR7HsX37kOVSbneowP0riXbvmSP8vGHR6H7nZ/4Y2ctefS2yuV0c/1u+/xiy4Ma3MftX/AuOMcYYYzKHFzjGGGOMyRxe4BhjjDEmc3iBY4wxxpjMsahkvEKISU/nKOcuVFYiO/H4E8iWDVJW3ahkwn7Rktvgrr7hndcj+/pn2WR8zit/GNlZGygPH3mIIttrr78c2ban2So7N0c5qy/isbVi0WQZ8dgKecpyiRC78qIxN5fn5+WFZFzIc1/Wirbd3Q9RIoxWsh06FrZ0JBo5o/PZZDlx7/9GFvzsrzN7nqkURdNthdelPVxFlitQuOspUX5tikbQE1so1/Wv5rUKRNv1pvVsIu0bp9x89BQl6ChkU2qnxOMd7adQeerwEWT9RY7XpMxz1TfEeWbPFs4pBSGBBn187+zhPciG129Cloa8HsdEu+voRkrBJ3ZyG2edQxF2ZoHXKBYyfnn5GLKlyKO38d49IgTWz330t5DF4mGKS3/4DciaMxybN//ZnyH71U/8ETLV9t5X5ZgLchzr/T2cv/I5WuJtITcnop192Sjvk1pDNBm3Oa4rvbzvTh09iuypLRyvGy6/BtlyYS1v2c177F/uvg1ZO+X+5cRDJs2Y52Xb45zLwhznhXtn+eBOb0c8kbMI/gXHGGOMMZnDCxxjjDHGZA4vcIwxxhiTObzAMcYYY0zmWFQyfv+vvQdZQ7Q9NoXENbCCLaEHv/kNZGecQ0H5kldcgez+29l+u271CmSlKtds07t2IytsvIjbvY5yc2mQ7a53PkEZ+VVXs4mx1aFktmEDBdKdOw9z/4ScW+6lBJcWKXvlRatmscT35gNKYUcOUKCuVShUFmJe83zIzxPlm0Hc5OtWXH6deOXSI+oRMu0uXr+ouBxZMr0XWXwGRddWRAF+ZBOF4t7lFIXzLZ7xU7MUNPc9cC+y8bXcl9lDbGlWja9TRYqXpb5hZPWUzb5JWzxosHE990+cq2ovpeBDByk39208A9nE45Qxi/3c55Wbz+Prqpw6ywOcU+YaPLag2EQ0NUGhcmiQ+7IUOXzoELJ2wOOenGTzdlAScunNX0I2MM55c3b6OLI//dCHkI2I74niMAXuy1/5emRrx/hgwLJR0VoccX7N9XNsHj92Elm7zvupJT5vy3fuQDayZgTZrV+7BdkrhVT92K18XSekyFwY4HFcdOGlyPbu4fy2bJx/HeDQNt53czMcQyVOtUE1FuEi+BccY4wxxmQOL3CMMcYYkzm8wDHGGGNM5vACxxhjjDGZY1HJuCNadwuidTdXFm2nHbZ1rnsjJa75++9HtnsbRdejWx9C9qrr/xvf++C3kT1w5ASyF3P3gqnZGWQbNp2J7GfevIDsnYMUQ/d/7/vI2jMHkeVFM2w5R0E5TcTlKjAL86J9UzQexx3Kbe24H1kpbiAbbh5DNleg9NoUTaXCnwvabZ6DpUgS85z1rjsHWXGA4yEfsFE4FCdj0/AgspJoiT48SZFz74NsHU1rHNeh+LzWSu5fKtqzRXdwkBcyflHIifkeft5AiZ84Kx5cyEfc5/1btyJbOMysdDYF4D7RMhw3KEGf3Ed5sjTOa7RyOWXWqVnOoe3jp5CNnX8usvqCUvSXHu0cJfbxcc6bxw7zuKs8PUHAqSqYnaSE2tPLxupzLqQQvn8PG6Zf+oofQrZhHR946e2hPL8QiybqGsdr/RgF/doMJeP54/x++vTHP4HsgosvRLb/SfF9nHK+vu8r/4js6F5K360O55Re0dS+94nv8b2iRb2d8rw0Yo7ruMExVCjx+k7HPH+L4V9wjDHGGJM5vMAxxhhjTObwAscYY4wxmcMLHGOMMcZkjjBN0xeGyWaMMcYY0yX+BccYY4wxmcMLHGOMMcZkDi9wjDHGGJM5vMAxxhhjTObwAscYY4wxmcMLHGOMMcZkDi9wjDHGGJM5vMAxxhhjTObwAscYY4wxmcMLHGOMMcZkDi9wjDHGGJM5vMAxxhhjTObwAscYY4wxmcMLHGOMMcZkDi9wjDHGGJM5vMAxxhhjTObwAscYY4wxmcMLHGOMMcZkDi9wjDHGGJM5vMAxxhhjTObwAscYY4wxmcMLHGOMMcZkDi9wjDHGGJM5vMAxxhhjTObwAscYY4wxmcMLHGOMMcZkDi9wjDHGGJM5vMAxxhhjTObwAscYY4wxmcMLHGOMMcZkDi9wjDHGGJM58ov943D/MoZpiihJk25e9gx0+8JQbEO9V2V8r9yCeJncu66Prctd6XaXu9xuqA6kS7p/6+lsg++NImanZk486238n2KgOoRMjcNEjc0ub4rTGV76nugOeUW7vMynsdnu7zu1M11u+PTuiWf/Xvl54jjUJsKI//+cWZh8TvfluaC/OohMjUOddbuV07h3nutJ/LS+KLocS/8h3xPP7YZP7zZRn9ddNlubesZP9S84xhhjjMkcXuAYY4wxJnN4gWOMMcaYzOEFjjHGGGMyx6KScbvdQiaFyqRLAaxbo6xLzyk9DVHsdMTB0xHZulequ5O45ClVwuLpSMHP+p3di2LPtcj5f4pWl/eEdoy7Ey8lp3VPPHvJvltOx+Ps9j5+vu6J03Ix1VuVZC8t4xfGPdFut5GdjnjftXjctQC/hL4n5AuX0vfEs0eeq9O4J56L7wn/gmOMMcaYzOEFjjHGGGMyhxc4xhhjjMkcXuAYY4wxJnMsKhm/4+c/gCwX5ZCFAZuMw/DZ1ymKYuQgjbqT0bT7p2QlvrlrEVfJT8KmEofxDFIY3xuF3a090y4Fb0WSKtlRbEPK0uL8ic/T50pc89PS2/7j2H/kKLJ8t8PmOZYnu7YEuzSAuxb4uhaeu8wS3im/+3dfRvaRd//kv7trz4QSTdU4VI3a6r1P79qD7IFHHkR293fuQHbxFS/lDgp5/e3v/Bm+bgkSyrlKzGndziPi457rpmyFmr6i05iXut1ldQ70drv8wlPfMd1/WXa32W5PqriW6ntCO/aWjI0xxhhjgBc4xhhjjMkcXuAYY4wxJnN4gWOMMcaYzLGoZPz2992ILCeXRLSQ8kIGKuQpKOeEoVkWrwuF/KeE2FCs2ZIuG4XzIkxy3EgspEh1WpR8J4VdsV15bF0KVt36ZAp5bNL6U1GXjdaJOjhe86VIT6WKTAzXrs+Pbv/s9mo9+9biSN/I3dFlVao63nqtgSxX5L709Q0gu/2hx5C94RUUdpUU3Gx3kJULBWRqqMdxjOzU1ElkeTGGKz0VZJPHKaqfPMXP++Rf/Bmy//6x3+MOPs/8y/27kOnW7m7nQ55vNcPmTufBhFDNc8++8bvbFl9513UptnfrGOuzp86z2K46ti6bltW+yIdq1AM54vyp69v11Piv+BccY4wxxmQOL3CMMcYYkzm8wDHGGGNM5vACxxhjjDGZY1HJOBXtmqkSZ4X40xaCULut9CcyJ2UvIWgKUTInhK2ikEDz4nX5HF9YSMWbRXtwKvY5SSk2quOIhcSlmiy7dDuDVBxbTuxzrK0w0Ip5HO0ms2aLWdwW50osq3NiXK1fPix28PlFnYukQ2Gxo5pzxQXMR+JkKMO8y3bSbkX0WNSFy7Zf8XmthPfx/Pw8skOHDyLbd3wSWf/AELKVI4PIHnj0CWQLjTqygd4ysnzIfb7soouR/c8//ySyeo3zYLNeQ1Yuczqdmuf+TR59FNkFI6PI7v727ciCjzF6vlEStpaMxetkiy9JRQ14d98m3TeIq2cfuqXrEnDVzisq79WDHVI87rKNuKP+PMBpfMcoaVk9VKPmGXmuxPdTIuZB2Za/CP4FxxhjjDGZwwscY4wxxmQOL3CMMcYYkzm8wDHGGGNM5lhUMm422wyl4yMsJCEAS6FSwtdJMUm0k6r9q6ntCnMqJ/dZ7J14XblAGbkoKm637t6H7KzVq5DVWzz3cas7MVRKxuKc5kWLtLpChSIbX4tiG6VqCVmi2iilpP3CWGsrmbYozo9qRZ2dnUU20N+PLCdk95ysSyapaqIW4/+W79yGbGaOx/baV74S2fJB7vO2PXuRzS4sPON+/v+ZnOF56WNhdHDWxjFkD+/ZiWylkFlPTM8g+9q3eQ5OHTmC7NCRE8iWLaMEvXoZpfjV4yuQ3btzN7KTk9y/5YM9yJYiSuJV97iaw9VdnyjZXZmuSpKVrcBCdO3yu0jNr+reVrunHnjpdruBuI+1m6vOlWoPfvbHGwTcF3F5g1Q8fKBai6XzrR7SEQ+oBOIvCyzGC+NbxRhjjDHmB8ALHGOMMcZkDi9wjDHGGJM5vMAxxhhjTOZYVDKuC6lVCUfK+0kjCsAdIVipBuCCanFUjZfi85RkFikRV7UvNylJNYWwqASrBSGGVoR8uv2R7dyXBrcxtILtrvv2H0Z28hibYVeM8b0XnHcWsp58EVkihLxIVA+r85fIRlMl5Clxr8u60eeZmSZbbYfFPbFrP1t8Rwd5XU52ppDVW2y/LRYqyMIir9+xIxwj4+s2INuwgdmXvvI1ZAcP34Rs58FDyAbETLJCyMjDoxRxHz80gezwAR7HimG2/a4epY28q8nxOl7k2GyIhxTOO3MdsoHBXmRnrqQ8/PTTFK2nhFheEA8pzNSayF7yyquRLUWUAKzKuEP1wIGY1/Ni/k/EPRaJjaj5Sz3corYrW3yVEitel1NvVq/Tii3fKvdZiMeqFl7MpYmSviMhBavPU3O42Iaaw+XRispo1dwvt6GfcnpG/AuOMcYYYzKHFzjGGGOMyRxe4BhjjDEmc3iBY4wxxpjMsahk3BYSnvDjgo6Qn06eovw60kfpMFVtuqolUclFYl8KQs6KRMtwQWV5SsGlAkXOEyfZbDp5gk2kvb0UQ8+8YCOyY5MnkW17ijLywiybZgviGg31U4r8xy9RIL3gvM3IRkVD66YxCpVxrIQ3IbLJNbQylF8YkvGOp9mcu2vb48haQhpds3YNst4ettX29Q8g+1+P70N25eo+ZB3RgHrkKCXedmsO2fkbVyM79q3bkb3pda9C9r2n2M57ap6C7b5T3G494r1YKvO+WyVM5jDHxu8VvRxzEyd476RC5j5Z4/1U6OP+HW3w2A6dOIrsx37iHcj+6csUt1/y4pciO+fsM5EtRfJCsJWNvaFoxI3Fe0Vpt5ZpldgrWsCl3CzeqlqQVYuvbAvvrmlcEUphl6/T7cHiQSBxXlQReirOaajOqdiElLTFXK+kb9W0Lx884Wb1ziyCf8ExxhhjTObwAscYY4wxmcMLHGOMMcZkDi9wjDHGGJM5FpWM5xco4RWKfEuxwHXSnoNHkI1dyiZSpXsp2SsU7ZY50R6s3rt3+2PI2uLQv7eVDa2npikPl3MUEc/ZQCHw5i9+BtkNH/oNZJUypeA1myiQqqbgSIp2zK644lJkc1MULw9sZwPv1id3IRtfM45s44oRsX88z8I7C4qlRYfikmHyCMf1xjGK433LKNQrcbBULCHj6AqCgVN7kM0OsZ26LBp7Z+fYltyJed9VcxR7x17GcbN/5w5kK4c5hmvzDWTniFbgp49Tsp8W5+rhx7Yh65TLyEoJtztS5fjac1Dc26KB/b0/ew2yR/byetRq/Lzb7/gmsrM3Uea++557kT3+8IPI3nr9W5A930ifWMzX2glWTcHdScGRqNCP5PeJaAUWk5D67ggC8R0jtquK2JWwqzOxWdU8LPZFRYEQdmUBsJqIxW8eqZqaZUO9+DQhMqtW5UiNF9VeLXZlMfwLjjHGGGMyhxc4xhhjjMkcXuAYY4wxJnN4gWOMMcaYzLGo2ankrFgIQo2WaP8sCelQvE79mXlVCllqUuBrDLF19+EHKevd9Z3vIHtyByXB+QZbUcMyZdGkXEX2B0LivfJ1r+f+PfoEso5ove0bZZvtRReciywnrlGnQ9H0lGhaLuR5+UfWsbV4SAipjz6yBdmTQiheJo6jt0yxdtNqSsvB5mXMnme2P00R/f4tW5HlE46lZUOUeOMcx1Kxxes3J+q90zKbss9avxLZSD/vk6mpaWTNFuXc/G42ah9f4LHlTrHdu9bkcUycZANwW8iOvWKuuGQtH1KYSTj+D5zgdi8U0vfMAs9pvc578ZOfugvZWUqyF2N9z16OlwMzPFc7dlPuv/o6zh9LkUi11SqZVgjAOSGX6pZhkakw4LWX6rD4kum2S109OCE3oqRq/YEiVJKxeJVsj+9uZxJ1/tRJEG3JiRLB1TiQF7O796o3xz/gbzL+BccYY4wxmcMLHGOMMcZkDi9wjDHGGJM5vMAxxhhjTOZYVDKuz9aQRSUhMIlmx4lDx5ENVArIRkYo/z0qpM2//srXkfWuXIWsZ5Cfd/IkhcV2DwXW8667EtnyTWuQDYwNIysW2ahau2ATstv/7hZk7/+xH+Z75+aQKelbdVF2hLB1x8NsI37l2RSKk0FKr8oTO/98tug26kIiF3LsMTE29hyeQPaKa7iN55tHHroH2bpRNjjXEyFcj/B1eSHtBzm+98x+NlsrCe/2O7h/qyJKwYeKvE9Wimt/Uoi4kZDY9+5lw3NvkSJndZAS9MEDFP7Xjy9HNpsX+yJO3+p1ZyP78p23Ihsf4fF22rzHLipw3vr+jn3Irn7p5cie/PYXkFV7eO4vuPo6ZAuzFLKXIvML3M+owAcJlCmsHpKI8pTxQ/HgSSTGf6oacVXDrhB7lRCbitlPtccr2Ve186rXqVZghRrrSiiO1QErh1ccW5oIGVlsI1TzlmgtTtW+yKi71udIVjc/M/4FxxhjjDGZwwscY4wxxmQOL3CMMcYYkzm8wDHGGGNM5lhUMv6N3/19vkGIg3nRCjmycgzZLd/6GrIkT4HvwnMpl/aMU06MC5TR5hotZM0mG1oLQmB66v4HkR2rUZx9qWhFnZ5kM+wdf//PyM49mwJkLsd1ZqNDE6utWitF1hYS6MteTOFZiWexaC1ud3gOlChWLPJaHv/mfcjWnskW2H4xXpYiUXsBWf/QBmQDQry/dNV6ZDumTyHLFzgelq9gi++JQ5RzX341RdcT0/PIju6gyJ8kvI/np6eQXfqii5ANLuf9mcxNIjt8/CSyFWNDyA4cPYqsLe6JkaEeZAMBhedahw3FCzWKsGOreRxPHmYb8bFTPI7pGs9zIeLDB5USt9sWou7cLMfGUiRXpKwdx5yDWq06sqJoNW/X+IBF7yAFfWUP50POQcKblQ9OyPZl8V7l16ry4FjJw6GyfbtrHtYucnctyKkylEULuBKPE9FkrE+gylSjtXiZeDBGesxd903/P/gXHGOMMcZkDi9wjDHGGJM5vMAxxhhjTObwAscYY4wxmWNRyXh5lRLvORvPQDY60IvsscMU/QpNCpphha3Au7c/jqwtjNiaECCH1m9GVpo6jKzcxybjkZVsLc4f43sHn6Lw1lxNcTYWctbMUQqLTz9BuXNszXpkHeF6RULZUu2gScw2244QlJOEcuDMDKW/lC8LQnGNjgYUL5McxcL5Xfv4gcE1Int+6VnBa79MiKlH9u9GdrK5H1lvP+XhghCUly/n+Drr3POQ5YW0P1ajZL9xE+/jO+68A1mrwOO9+0kKtvUjlJabMeX0UDwYUO2hpFoX743aHHQLLY6lzcMVZGPXXILsVLO7Btmdu3j+zrvgHH7eNKXq6y9i2/rmMmXbD973GLLV6zgfLUWSgGMuFG3E5Tyvi2rBL+b4ulNTnOsHeylwJzlut1gU2xXyayQe9hDPXASiBFkSKrFXtP2qhnrt64qHTFSVvfhOiKR4zHcmQg5X+6JamtV3h3pzIlufVTs0D67L0uf/73N/sJcbY4wxxix9vMAxxhhjTObwAscYY4wxmcMLHGOMMcZkjkUl46svYOvu/Y89hKz/whcju3DtamSX/MxPIjv/Im5jdo4SXhBQYOodpNzc38dm06hAibct7LFWhy3ICzVmx49OIDtymM2r733rm5GVGhSte8cpIgaiVTYW1Y6dDuXhuVMU8tZtWIcsUlXGQh5TZlc75nnpiHM6fB6l71aew65eoDC4FBmoDiC79Y47kV15+WXIDp5kW229fQBZby/H9XSN4v1VL7kKWalIyXJi3w5kzYhi6MXnU5xtf51N1LvzlM6Pj1NGnp2hYD43PYPs2HHeT+UKx+GLX3I+sn1NtiA/8v3vIhsc4uv2ivt4apL3TlGIsAcOsBn5xAQ/72dfdi6y5THnt9+/hO3ofzfLa7kUSYXUGgppVBTn6lZgTn3B4FAfsht/4f3I/uivP8M3tzjnJkXeY6lqilcPbKh6Y0WXMm0sC4+FFCw3opqCxfeEaigWH5gLefKV3KweUFH2tTwOlYnzokTmHxT/gmOMMcaYzOEFjjHGGGMyhxc4xhhjjMkcXuAYY4wxJnMsKhkPjyxH9rpXvAHZtW9/E7IZIRgmCdtJDxxkU3AipL5VK9nkOtNkw+jeffy8/iOPIjtVHUNW6qNAetfdfO+mSy5Clt/2JLKBCy9EdvSee5Edb/B483lma1exMTcVja910QC574ktyOaFaNqsU54cGOV56etnA3VJyHJ1ZbJ1KIw/ePetfN1/oZT+fFPMU8I79/yLkY2PcXyFwQpkqagijROeyLkmr0skZO3ewUFkazZTzu0fphScCGH9c089jGxyisJntHw9skqDYvRlV16A7N6vL7AAABnDSURBVJMzbOydLFC6PXv2bmQ7Jik8/8jFbHi+f8t2ZD0liu1zJTYjx0KoLwgp/jMvZSt11DyO7LNPswn6K0d5zXtGXyD//1RNvMrDFSKp8nXzogF4aoIt4B/9b7+KbOvdX+fniet81hWvRpaLhN3c5XFI2Vc9ryGmw1BIvKrhWRTjB7mQc2lHzB/ViHNFUzy4Myqe9Wh0eF6mapwrUrGDoTgJoTrPgXhoJRKSfUtWNz8jL5A7yBhjjDGme7zAMcYYY0zm8ALHGGOMMZnDCxxjjDHGZI5FJeOkRZFoYBVl30985LeQqQbI4bXrkc0cP8YNC3HqTde/A9nsPEXmsMbWyoV5ZqOb2aA8vpzi5RkXUorcvZci82dupyT1o5UqsmA122JHRtiy+rsf+BlkkWiKTGJKV+LUB+0WZWTVKHn2ZVcie++7b0D2v37nw8guKbJFetUHPoAsLFJuXqj/YPLY80Wa8uTmEsruk3Mcc5EQ6XoHeO3bHQrFq1ZRWj45xXtnPsfz+LmHDiG75yCl+JaQHXPVlyE7P6awfvAU5dw/fetPITtygI3fyw8cQbamw9cVTlHYfZ1ofR4aovT92nGKvaOjFOUffOgRZM0czcsnT/Lz3vcgr+/PrOc98cg0p92ozDmvb5By/1KkLET5nJDxZ/l1EijfVN1j6/t5j0U9lPbvuHs3sjCeRrb5Un53NBOOpYqYq3ilgiAU9vChfbuQHdzHsf7oFj7I0pvjGHn3L3IurYjJviAa6mPRUKzem4i66ZmA3x0tkYViOZGKBuVKifLw3CzPaoFTivy8xfAvOMYYY4zJHF7gGGOMMSZzeIFjjDHGmMzhBY4xxhhjMseikjFVxyBYPsCG0VAIZUHIj1ZNjG0hMqdKkhJCbJ8QNNeL9uBly9juWilw/+bb3EZLNMguH+I5+JX3UKjc9r73IXu0SFH4e0cOIKv289jiVg1ZsUwxTgnePX0UKlXb9MFdbHwdXEH5+k03fgjZocMUQ2eEbDt1cB+ykbXLkC1FSmLcXPvq1yL751u+guxH3/IWZBN1ynU3PUWB9cF7ppAVenjtk4DicW5+BlnQz9bd4tQEsmse/yd+Xj/HQzRYR3brFykjv/5K3p83nkGRszTP81Ia5n38SIci/92P3IfsPatoLBbWrUP2Q6Nsb587sBPZ47dPIqu1OFd8eivPy8AgxeMNZ7B9eXZWXLclyFSNx/3qSzhGGk3OXx/96J8g27Kdcu6vfeDdyK697Fxk73vvKmTLhzlGfvrnfxPZgpDJ2/kKso/e+H5kfWJe/4MneT/1VTh/vPFSXvuPfOZmZIXPfx5ZzwoebzhNkfm3fuXtyG746L8gu+fu25BVJvlQzSc/9l+QfelrX0Y2W2T7/l0Ps+H8U3/1l8g6dbaUB4FqQX5m/AuOMcYYYzKHFzjGGGOMyRxe4BhjjDEmc3iBY4wxxpjMsahk3G6xmTPfQxFLyb71BsWzfIEyYaFE+S+fF22xOb734gs38/OK/LxUeEm7D5/gdnN84U+/+gpkFSH2piWKbH/Yx6bNt86xAfJFb34nsr/5l88gK1YoJ7Ybos25Q1l6dpZtnpsufjmyHfdQFNt7kNLaXV+i8PbwQxTUyn2UWVeso1S3aR2FwaXI2ChbOMtiDL/1+rch+5U/uQnZ9LIzkcWiGXk85nVe0eFYWi6aV4cCyp3lNoXwYh8/b+jCjcj6Qt6fs0WO/3OvuAZZXObrhpoUcW/+xq3IGgvc7s6nv4/sp3/szcgOimu0oYfzViKE2VXnX4LsjB1sh36izvkyjnhONw7wPp7bzmbp6bxoQl+CdIT4GRUo51byvAb7D/I8vuzK85Hd9eB3kfUP8LvopvsfQlauXoTsmJjTrrh2LbfRz4dgWocoz3/6T/4Hsh9/C8XeySbHyJntU8h+8xWbkO0MOTb3H6MAXDixFdn3Pv1nyHLiLwa89OLVyKoBv8fufIqicNDLh292PM77Myf+2sBPvfFNyNQDSH/1aZ7nIOA+/xv+BccYY4wxmcMLHGOMMcZkDi9wjDHGGJM5vMAxxhhjTOYI01T8nfd/5Z1v/zCy9ZdcimxgnC25IYsdg/kFyo59fX3IVHtwZYBi719+4uPIzjyf+3fmtz+FbLUQoo6+60Zkf/+3f4ss7gj5WrQv9y2n/HTiwNPIojxlucrwGmStGYpx9VnK0mnAk6/+lP3V1/8Csrs/y3OqxO2eXjYPL1tLUXh8GZs2e4TwGSXc57//O7YlP9/89Dvfi+zySygKbzyHcnq+wGOcq3Osl/MUhWemKCImqRhzQwPIckLaLwjhf2GeIvPW71ESXJhl0/Jb3v5zyKKIx5vPcxz+5w/8GrIjRw4iGx7lPFMS7bM/8irKzZ/98peQfeI3fwdZrsr9+4333YCsVuEYXhDzVtLgNXrXizletomHDx7dx/t95x7KyM83t9y2G1n8LTYUHzvJBx3Wb+Q8d3A3r32nwPPdFo3t7RyvXyPmua01mSXi85Ictzs/z++xUHyLRkWOzZkahfpA7HMz5P3ZiSndRuLhm6BIebgYUfo+NsPjmJnnd9vkDBu1xR8WkF/6hw+x8Ttpi3OfMEvrlJFv/tY3kP3o1fyO+Tf8C44xxhhjMocXOMYYY4zJHF7gGGOMMSZzeIFjjDHGmMyxaJPx4wf2Idt/cgrZU0/dh2ygQsHq/EspXp554YuQLVu9DlmUci327vf/MrJ6gxJX4Twhzm44A9lfv+8dyPJC4opSilgtIai1Ur63WGF7anPqALM2/1S8cEqDQkDbq9Wi7BgV2MDb1+K5WnPOi5GNjvJ6DPZRZu0R2wgitpzGoqGy2WG2FDk6MYGslbsM2cP3Uoa76tVs6xzuF03eolF7SLTfpsJsjBMOkijHsRkKIbC3h9tY9vrXI5ua4jlQn6eaSDtCMGzFlB2rvWzx7a1yToly3G4q5Ob+Eh9m2P7Qvcg2XsTW4rI4L1M1tk3nRcNzIgTvv3zoKWSvGeOxNVuURZcin/tntp8vr1AeXnPx5chuenoXsrDI+SZpijEiHn7Ii/mmJR66iHr5XiXjN9uc64srKewWRZtzLCbsUfGAxaxoJE/bvPaREJ5LCfevJr4rC0KK7x3i98RQiWN9vZhT1L2dy/McrJ/lgwvTC+ohHV6jZovn5bf+9NPIfvTqjyD7N/wLjjHGGGMyhxc4xhhjjMkcXuAYY4wxJnN4gWOMMcaYzLGoZNypHUX21F42m7brFGJfc/1HkY2sHUP257/7n5BJUbIkBMM8xSlZyyykw1KREmNZbGPVpnOQ/dePUVr+8C+8C9nkxB5krQU20gaiTDoRTZaDo+PIOm2Kwm0hWqtzuncnW5XP3ngxsoIQqEPRhNsRDc9Bh9vNqYZb0Xy9FMmFvGUG+geRrVh+FbLtj1Jq/crX70TWrM0iywuJcWCQovfESbYMj49z3LznP3G8lnp4HJEQZ5UQ2BFieyemKBmKCtRLRZvtjh07+boe3p/li/iQwk03fxXZUInn786t3Mb3D3HOK7YpVBYL/LycuEYLAe+JIdFUffs+XvNQNOEuRbYe5fz/dJH3SXSU86GasBNxHnN5tlgHHHJB0BKid8JxWChyG0HKcd1q8TiKLe60au5XD4WEEeX0SBxvrU6penhAtI8v8CSE4v4MFjiGkxbHZrXCY5sX+9IQf5WgLB4syomW5lwgHjKJud2caH7Pd36wLwr/gmOMMcaYzOEFjjHGGGMyhxc4xhhjjMkcXuAYY4wxJnMsKhlffdl1yPbNnED23W/ehOyLf/thZEowFF5XEIkm11D8yfuOaJmMhNSklnFNIefmC2yofMNb2G5849t/HNmaMy5AdnjvdmQ9QyuQ9fZSoOsbppA92D/Cz6uwebJQ4DkohELci8T1EMJzJCRjZQfmRUtnS4imqqEyUQNhCRKH4nhqQrAVx1MLKAm+5/2/gKwoROZUWIxFcZ0VScp97iRCHG/wflLtpHGdkmBbSIexuPEmJo4jKwz0Izvj7I3Ihto8z5//HOee4hDvp2IPhezCMTaIP7ofUTAkBMgk5jlYNr4c2Xib123b4cPIGqJ9NpmlvLsUicW5yCXqwQ42nSdiHAYB7dxYzCNF0TycirEeCek2L65pJMTjvLgupQLnubl5NvaWK/w+ScQ90WlRPO4rsnl7fo7bUM3NPX1sy281+d6oyvtOteCXxHdqUlBCMc+LajxutXh9i+KhlYYQqKNImNuL4F9wjDHGGJM5vMAxxhhjTObwAscYY4wxmcMLHGOMMcZkjkUtxdmm+HPvZQp8hTKFqIU5ysiy7lEIYOs3X8F9OXUEWatBCa8l2hnVZpUQm3QoNU1MTSJTZYqVKgU6JbyplslEtAznhchWFGJXpcpG5oJqnxWyaL3B4x2ocrsdsX+haCBtiHPfqFGg6+ntRZYWZAf1kmNeiG97Dx9CtnrNamTV3lFkv/2fP4jsw7/8y8hK4yuRtYXcGYqW6JyS9sUFjFscrzkhgaZiDM/VKO03xecNDC9jNkB5vihaxW97YAuy47PcblSfQDZ5gg3i6zeuR1Y/QPF4ZC2bltvHjnFfOkK8F/fdRWeyWXrblr3IWj28F5ciqilYlekmHT5ccGqa82u+TDk3Jz6vLcTUuCmafcU1qFQ4B0VirmqLY2uIh1t6+/h5k1PT3BfxwIZ4riOoRxzXVTH/q30JF7jdyZkZfp5oHu7EqpKZ80wqHhgKxHohFcJ4u8VjazX4kIKSzYt5jo3F8C84xhhjjMkcXuAYY4wxJnN4gWOMMcaYzOEFjjHGGGMyx6KScb22wEw0E15w6euQPfrI15DFLfEn1vPchZMHt/G9SmQTnpNqrZStu0VKYUpa3v7wg8iu+RG2G9/yt59ANrJqM7Nla5kNsHmyr59ZjxCjI2HftduUs5QovKzEbEE0kMYiS8X1iALRqtnLpuVAtG8qoWxJInZ9ZITivZLdy1Weixs+/BFkf/yJP0L267/5IWRtcU0j0Vgdt5UEKt4rBMjjxyjn9vXxOEIx5qoVivdf/fI/ILvln2/h56k2Z9G8PbqC4nYkWqQbHZ6DySk+CLF2He/PtM05b3ycrxtMKHL2Tu5EtjDJ/TtRpxy7aoAS6FKkJBp7lasa53n9ir0cI4ODg8jqNTbxqjFcqfKBl6Zo543ySpzlToeiObdQ4Txc6/C7rdLH1+XE3Fcu8jrP18QDNKJ9PyfazMMC7+OePm6jLL5P6kLSroqHiKZnKDIXSryWhRyzipDn5xZ4fft72bQ8M817bDH8C44xxhhjMocXOMYYY4zJHF7gGGOMMSZzeIFjjDHGmMyxqGS8UBctiW3KQJU6Wz3HxjYiawjXMRFyVkc0HeZEa2sa8wNTIRSrRuFYiIOR+HPvj937FWSPP/ANZCPj65Bt3HQxsqKQqvtFs29ZNLk2O9zngmiazed4Dl4zQGntllPcbinfneyrGplzRWHgCuFTCcqJEPyWIms2bkK2d99+ZCtWrULWFueiJlpW/68bbkA2McN7YqDMz6sv8H5SEmhJbDcVlapRm+2uszN83e/93seQDZc51idjvnfZGrY0z8wrqZRjvRmyzTYS2+0Tjd9tcT81hVB51Yt5zati3urNcbv1+rnItu9la/HI9FZkLfUUxRJkeIVoBRb/dW42+dBKRTxgEQa8LhtXUeo+NsEG8UKJ42GoyGsvZXzxHVOtiIck1NwnDrjR5L0TijHSafLeHhQCcCdgVhBf4UXRgh+I94qvz6AS8/wVRWP0wMAKZM2YgrL46g1K4th61cMoIZuvi2WOl8XwLzjGGGOMyRxe4BhjjDEmc3iBY4wxxpjM4QWOMcYYYzLHopJxTrTkpgW2THZ6ma3so3DUTJglHYrMSv5rCxGrk1BCitvchvq8WMiT7ab4k+1lCmrnXfIqZH2ipbZX/Dn6WIiDoZBPQyF85sR69OWjPI57jiAKbk15jco5fl5BNG02xDUq5PneVotGWT7Hz8tHQmSrvjAk42aDYyTXL+4Jcc7qNXV+eAvW5iiEF4tsBJ0Ssu/M5BSyR+69E9mJY3wwYHqK7aQlMf6LRV6/les2IDvrXDZ5Hxfb2Hze+ciCUMw9sWpuFuNGCJ9pzOuxYxdl35PHefPc/IWbkL3tja9G1k6FpCqEyguGeU+c9earkaWiDXspsrKH83CpSLE9TdlMq5puE/EgRj7kvD48TiG8VBzg54k5KKca7yPRxBtxX5RAPVfjuA6qvPalAvc5DNmEHovvyrjF89yO+b0YhjyOkhCP26LdOxVjuKWaoMX3RKWyHJl6mKchWqmbPdyXYsR9bgpxezH8C44xxhhjMocXOMYYY4zJHF7gGGOMMSZzeIFjjDHGmMyxqGQ81EvBMBbSVT4SQmAP35uI6sSWaLXtdCgT5kSbYiDe22oLIVYImsWiaIUURbxJyOPtKXNfQtGMmaQ8jqQt5GFxFaoR5awfX8tj++v9QuYr8Lz0iP0LItGUGop97lBuC8X5q4pm3ZkFCmoDQlw9XvvB5LHni4ljE8gu3ExJNhZjMxbieKPF486Ja6VEvyRRY4mD6ZpXvxaZcnM7wp5sN8VDAOLY0oTjJhRtyQMr2Fos5WF1vwspPhH7UhLzUSvhedl0xhnImjUK3nNrKVD/7W3fRVau81quGaL0Wh2ilP7YE/ciU/PHh5E8/1y7egRZQYnCQrpNxfgaGhlDNraSTfEzU7PIShVud2aO4r366hvs5bUKU7Yv1+j1BuUejqWFee5fIh4oqUY8B7k8z5X6DmwKuTlucV4olMXDI4loSxYPiuRy4vtYNCOHIcd/FIrvGCEK50VLeVs8MBSJ+30x/AuOMcYYYzKHFzjGGGOMyRxe4BhjjDEmc3iBY4wxxpjMsahkXKqyeTIMKPk0hYRaFOZsUTRKdoRIJ1zMoN2idFsp9yLLiZbVthAgIyEiVoQ4G8eiPVJI0EqyzOW5L5UC15Q/u56i2Bf3sgX5pqNsS66UhC0qTmBHCJANIXFVe7iNfJn7khci7GyNQl6rxm1MCnFblFIvSYpCnpTemzg/oTB786JRNe7w+inJuCCkw1TcT50Ws7w4jkaNLc35Al8XinsnFwopWPz3KVeg8J8Xragd8bBAGIj7TjSDt4V8nQp5PmzzwjUaNEh7KxT5OxXeJx3RWrxzgfdEMj2DLD/IhttCSTwYsATp6VuNLOmIsRSLhzM4HIJGh8d9eIKicL7MN8/PqocVKA9HYixNLvA7Jg26G6+NWdE8HIuHb8RE14rFAyqBePgg4f51xH0XpeIBByEe54RAncSiaV/MUal4b6QeqlH3rJgXwkTNZdyXSEjai+FfcIwxxhiTObzAMcYYY0zm8ALHGGOMMZnDCxxjjDHGZI4wVSbPv1KpjJ7GJ3cnA+mXMVSCpnpzlx/X/TaExCjpcl+e+Wz/+y9Ub1WXr+uj6HJnFhki/+7nyfeqjxM7Xa+f7G67/4EUCmyh1ajx2uU7T2Osd/teuV29M129t/u3KmGx25tC0O2Ye/YfF6gB2+3rZCRkzG7viXabDyQ83/z2x/8SmWqYzuUpZicx5eEoR6k7CoSIHlK6zYkHGNS5LYp2+3aLgnknYVYq8uEbda3SVEjLwrCNxO8MqRCK45SCcqEg/mKAeOgnEq3igWgQV+32ccxzoNrWlfAfieMN1T2rxGMRpi3K6x/64K/zzf+2/Wf8F2OMMcaYFyhe4BhjjDEmc3iBY4wxxpjM4QWOMcYYYzLHok3G6k/ea32vW3uyy5d1LShLzVJkQsQ9DRmzayPwOUa1JZ/eB4pM/Hl76Ql3Kw93K2m/QCiIduquj/A0hkgYif+LKMF8CUnGehvd3Z/du/hycP5A+/RsUNvtXsZ/YTQUd8ugKLGOhegaBGy/LfaOIIsifqASbCNRgxyK5uEwYsN0mlJWzVXGxL4gCqJIyNKpEHFjtht3OmwojoWQnc9THk47/Lxcka8LhGidClE4DVR7sDrPvEZhJNqS26JBX5yXYoHnL+6IOnjRltwpsPF7MfwLjjHGGGMyhxc4xhhjjMkcXuAYY4wxJnN4gWOMMcaYzLGoZJxTkvGzL/YNuu7Y7Voe7na76nVdypinIc4+56pjqNajXbasnkat8um0tp6Wt70EyYlG0G7PtxZsu0OPV0ZqX7pt6FavU9npuOSq7VS2istMfF731eBdbbfbz9Ov6+69ehScRov680zf0EpknSZl2lJlgG/uCNk3x3muE4gHLISXWijy/oxjcW47/G4rlCkoxx1uNwkozoZK7BWbLVfYgqxai5NEzPVljodcgfucCpFZOd/iNAftmJ8nHPIgEGJ0R7RD52Oel3yB5zQW4z/KUW7+QR8g8C84xhhjjMkcXuAYY4wxJnN4gWOMMcaYzOEFjjHGGGMyx+JNxgXVdMjXSeGuS8lSS4fdvle87jluXpXH0aXcqen2hc/tcZyWjPkcH9tzfo3+AykIqU9d/G7Hdbdie7djXV3nMOpuG90+GKCOret7+7S8WXUzqn0Rm+1WglbnT71OngP1OtLt6D8dKf0/kkoiWnLzlFCjkEJxPplH1oopCpdzoiU3ZItvSdm0KRuAQ9EAnLa5L0mH16AqROZQXOk4EK3Aou03iJhFpQq3kfDz1EMPrYDNzZVQXQ/xwIQo2Q5LnPOSphibCY8jEVXQqbge+TKvRyKa+0sFHtti+BccY4wxxmQOL3CMMcYYkzm8wDHGGGNM5vACxxhjjDGZI0y7t0+NMcYYY14Q+BccY4wxxmQOL3CMMcYYkzm8wDHGGGNM5vACxxhjjDGZwwscY4wxxmQOL3CMMcYYkzn+b6ykaTRyEW25AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 1 4 1 0 8 9 8 8]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "plot_weights(x_test[0:9].transpose(0, 2, 3, 1))\n",
    "print(y_test[0:9])\n",
    "test_img1 = x_test[0:1]\n",
    "test_img2 = x_test[1:2]\n",
    "test_img3 = x_test[2:3]\n",
    "test_img4 = x_test[3:4]\n",
    "test_img5 = x_test[4:5]\n",
    "test_img6 = x_test[5:6]\n",
    "test_img7 = x_test[6:7]\n",
    "test_img8 = x_test[7:8]\n",
    "test_img9 = x_test[8:9]\n",
    "results=[]\n",
    "y = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "print(np.argmax(y))\n",
    "results.append(adam_small_ker_accel.dream_img(test_img1, y=y, intensity_iterations=75))\n",
    "results.append(adam_small_ker_accel.dream_img(test_img2, y=y, intensity_iterations=75))\n",
    "results.append(adam_small_ker_accel.dream_img(test_img3, y=y, intensity_iterations=75))\n",
    "results.append(adam_small_ker_accel.dream_img(test_img4, y=y, intensity_iterations=75))\n",
    "results.append(adam_small_ker_accel.dream_img(test_img5, y=y, intensity_iterations=75))\n",
    "results.append(adam_small_ker_accel.dream_img(test_img6, y=y, intensity_iterations=75))\n",
    "results.append(adam_small_ker_accel.dream_img(test_img7, y=y, intensity_iterations=75))\n",
    "results.append(adam_small_ker_accel.dream_img(test_img8, y=y, intensity_iterations=75))\n",
    "results.append(adam_small_ker_accel.dream_img(test_img9, y=y, intensity_iterations=75))\n",
    "results = np.stack(results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 3, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = np.squeeze(results)\n",
    "print(results.shape)\n",
    "plot_weights(results.transpose(0, 2, 3, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
